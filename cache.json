{"2024-08-01T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2308.05846v2","updated":"2024-08-01T17:46:38Z","published":"2023-08-10T19:56:15Z","title":"Seed Kernel Counting using Domain Randomization and Object Tracking\n  Neural Networks","summary":"  High-throughput phenotyping (HTP) of seeds, also known as seed phenotyping,\nis the comprehensive assessment of complex seed traits such as growth,\ndevelopment, tolerance, resistance, ecology, yield, and the measurement of\nparameters that form more complex traits. One of the key aspects of seed\nphenotyping is cereal yield estimation that the seed production industry relies\nupon to conduct their business. While mechanized seed kernel counters are\navailable in the market currently, they are often priced high and sometimes\noutside the range of small scale seed production firms' affordability. The\ndevelopment of object tracking neural network models such as You Only Look Once\n(YOLO) enables computer scientists to design algorithms that can estimate\ncereal yield inexpensively. The key bottleneck with neural network models is\nthat they require a plethora of labelled training data before they can be put\nto task. We demonstrate that the use of synthetic imagery serves as a feasible\nsubstitute to train neural networks for object tracking that includes the tasks\nof object classification and detection. Furthermore, we propose a seed kernel\ncounter that uses a low-cost mechanical hopper, trained YOLOv8 neural network\nmodel, and object tracking algorithms on StrongSORT and ByteTrack to estimate\ncereal yield from videos. The experiment yields a seed kernel count with an\naccuracy of 95.2\\% and 93.2\\% for Soy and Wheat respectively using the\nStrongSORT algorithm, and an accuray of 96.8\\% and 92.4\\% for Soy and Wheat\nrespectively using the ByteTrack algorithm.\n","authors":["Venkat Margapuri","Prapti Thapaliya","Mitchell Neilsen"],"pdf_url":"https://arxiv.org/pdf/2308.05846v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18320v2","updated":"2024-08-01T17:43:19Z","published":"2024-05-28T16:11:11Z","title":"Self-Supervised Learning Based Handwriting Verification","summary":"  We present SSL-HV: Self-Supervised Learning approaches applied to the task of\nHandwriting Verification. This task involves determining whether a given pair\nof handwritten images originate from the same or different writer distribution.\nWe have compared the performance of multiple generative, contrastive SSL\napproaches against handcrafted feature extractors and supervised learning on\nCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)\noutperforms other generative approaches achieving 76.3% accuracy, while\nResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization\n(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using\na pre-trained VAE and VICReg for the downstream task of writer verification we\nobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18\nsupervised baseline with 10% writer labels.\n","authors":["Mihir Chauhan","Mohammad Abuzar Hashemi","Abhishek Satbhai","Mir Basheer Ali","Bina Ramamurthy","Mingchen Gao","Siwei Lyu","Sargur Srihari"],"pdf_url":"https://arxiv.org/pdf/2405.18320v2.pdf","comment":"8 pages, 2 figures, 2 tables, Accepted at Irish Machine Vision and\n  Image Processing Conference 2024"},{"id":"http://arxiv.org/abs/2402.10344v2","updated":"2024-08-01T17:34:51Z","published":"2024-02-15T22:17:17Z","title":"Evaluating Neural Radiance Fields (NeRFs) for 3D Plant Geometry\n  Reconstruction in Field Conditions","summary":"  We evaluate different Neural Radiance Fields (NeRFs) techniques for\nreconstructing (3D) plants in varied environments, from indoor settings to\noutdoor fields. Traditional techniques often struggle to capture the complex\ndetails of plants, which is crucial for botanical and agricultural\nunderstanding. We evaluate three scenarios with increasing complexity and\ncompare the results with the point cloud obtained using LiDAR as ground truth\ndata. In the most realistic field scenario, the NeRF models achieve a 74.65% F1\nscore with 30 minutes of training on the GPU, highlighting the efficiency and\naccuracy of NeRFs in challenging environments. These findings not only\ndemonstrate the potential of NeRF in detailed and realistic 3D plant modeling\nbut also suggest practical approaches for enhancing the speed and efficiency of\nthe 3D reconstruction process.\n","authors":["Muhammad Arbab Arshad","Talukder Jubery","James Afful","Anushrut Jignasu","Aditya Balu","Baskar Ganapathysubramanian","Soumik Sarkar","Adarsh Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2402.10344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14360v2","updated":"2024-08-01T17:14:17Z","published":"2024-06-20T14:33:51Z","title":"Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment","summary":"  Neural Radiance Fields (NeRF) achieves impressive 3D representation learning\nand novel view synthesis results with high-quality multi-view images as input.\nHowever, motion blur in images often occurs in low-light and high-speed motion\nscenes, which significantly degrades the reconstruction quality of NeRF.\nPrevious deblurring NeRF methods struggle to estimate pose and lighting changes\nduring the exposure time, making them unable to accurately model the motion\nblur. The bio-inspired event camera measuring intensity changes with high\ntemporal resolution makes up this information deficiency. In this paper, we\npropose Event-driven Bundle Adjustment for Deblurring Neural Radiance Fields\n(EBAD-NeRF) to jointly optimize the learnable poses and NeRF parameters by\nleveraging the hybrid event-RGB data. An intensity-change-metric event loss and\na photo-metric blur loss are introduced to strengthen the explicit modeling of\ncamera motion blur. Experiments on both synthetic and real-captured data\ndemonstrate that EBAD-NeRF can obtain accurate camera trajectory during the\nexposure time and learn a sharper 3D representations compared to prior works.\n","authors":["Yunshan Qi","Lin Zhu","Yifan Zhao","Nan Bao","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2406.14360v2.pdf","comment":"Accepted by 32nd ACM International Conference on Multimedia (MM 2024)"},{"id":"http://arxiv.org/abs/2407.20021v3","updated":"2024-08-01T16:13:45Z","published":"2024-07-29T13:57:40Z","title":"MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with\n  Encouraging Inter-Head Attention Similarity","summary":"  Data-free quantization (DFQ) is a technique that creates a lightweight\nnetwork from its full-precision counterpart without the original training data,\noften through a synthetic dataset. Although several DFQ methods have been\nproposed for vision transformer (ViT) architectures, they fail to achieve\nefficacy in low-bit settings. Examining the existing methods, we identify that\ntheir synthetic data produce misaligned attention maps, while those of the real\nsamples are highly aligned. From the observation of aligned attention, we find\nthat aligning attention maps of synthetic data helps to improve the overall\nperformance of quantized ViTs. Motivated by this finding, we devise MimiQ, a\nnovel DFQ method designed for ViTs that focuses on inter-head attention\nsimilarity. First, we generate synthetic data by aligning head-wise attention\nresponses in relation to spatial query patches. Then, we apply head-wise\nstructural attention distillation to align the attention maps of the quantized\nnetwork to those of the full-precision teacher. The experimental results show\nthat the proposed method significantly outperforms baselines, setting a new\nstate-of-the-art performance for data-free ViT quantization.\n","authors":["Kanghyun Choi","Hye Yoon Lee","Dain Kwon","SunJong Park","Kyuyeun Kim","Noseong Park","Jinho Lee"],"pdf_url":"https://arxiv.org/pdf/2407.20021v3.pdf","comment":"Author Preprint"},{"id":"http://arxiv.org/abs/2307.09067v2","updated":"2024-08-01T16:09:50Z","published":"2023-07-18T08:37:58Z","title":"Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image\n  Segmentation with U-Net","summary":"  Fetal head segmentation is a crucial step in measuring the fetal head\ncircumference (HC) during gestation, an important biometric in obstetrics for\nmonitoring fetal growth. However, manual biometry generation is time-consuming\nand results in inconsistent accuracy. To address this issue, convolutional\nneural network (CNN) models have been utilized to improve the efficiency of\nmedical biometry. But training a CNN network from scratch is a challenging\ntask, we proposed a Transfer Learning (TL) method. Our approach involves\nfine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder to\nperform segmentation on a set of fetal head ultrasound (US) images with limited\neffort. This method addresses the challenges associated with training a CNN\nnetwork from scratch. It suggests that our proposed FT strategy yields\nsegmentation performance that is comparable when trained with a reduced number\nof parameters by 85.8%. And our proposed FT strategy outperforms other\nstrategies with smaller trainable parameter sizes below 4.4 million. Thus, we\ncontend that it can serve as a dependable FT approach for reducing the size of\nmodels in medical image analysis. Our key findings highlight the importance of\nthe balance between model performance and size in developing Artificial\nIntelligence (AI) applications by TL methods. Code is available at\nhttps://github.com/13204942/FT_Methods_for_Fetal_Head_Segmentation.\n","authors":["Fangyijie Wang","Guénolé Silvestre","Kathleen M. Curran"],"pdf_url":"https://arxiv.org/pdf/2307.09067v2.pdf","comment":"Irish Machine Vision and Image Processing Conference Proceedings 2023"},{"id":"http://arxiv.org/abs/2406.11551v3","updated":"2024-08-01T16:00:04Z","published":"2024-06-17T13:49:12Z","title":"Towards Self-Supervised FG-SBIR with Unified Sample Feature Alignment\n  and Multi-Scale Token Recycling","summary":"  Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) aims to minimize the\ndistance between sketches and corresponding images in the embedding space.\nHowever, scalability is hindered by the growing complexity of solutions, mainly\ndue to the abstract nature of fine-grained sketches. In this paper, we propose\nan effective approach to narrow the gap between the two domains. It mainly\nfacilitates unified mutual information sharing both intra- and inter-samples,\nrather than treating them as a single feature alignment problem between\nmodalities. Specifically, our approach includes: (i) Employing dual\nweight-sharing networks to optimize alignment within the sketch and image\ndomain, which also effectively mitigates model learning saturation issues. (ii)\nIntroducing an objective optimization function based on contrastive loss to\nenhance the model's ability to align features in both intra- and inter-samples.\n(iii) Presenting a self-supervised Multi-Scale Token Recycling (MSTR) Module\nfeatured by recycling discarded patch tokens in multi-scale features, further\nenhancing representation capability and retrieval performance. Our framework\nachieves excellent results on CNN- and ViT-based backbones. Extensive\nexperiments demonstrate its superiority over existing methods. We also\nintroduce Cloths-V1, the first professional fashion sketch-image dataset,\nutilized to validate our method and will be beneficial for other applications\n","authors":["Jianan Jiang","Hao Tang","Zhilin Jiang","Weiren Yu","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2406.11551v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14168v4","updated":"2024-08-01T15:56:43Z","published":"2024-01-25T13:27:03Z","title":"Vivim: a Video Vision Mamba for Medical Video Segmentation","summary":"  Medical video segmentation gains increasing attention in clinical practice\ndue to the redundant dynamic references in video frames. However, traditional\nconvolutional neural networks have a limited receptive field and\ntransformer-based networks are mediocre in constructing long-term dependency\nfrom the perspective of computational complexity. This bottleneck poses a\nsignificant challenge when processing longer sequences in medical video\nanalysis tasks using available devices with limited memory. Recently, state\nspace models (SSMs), famous by Mamba, have exhibited impressive achievements in\nefficient long sequence modeling, which develops deep neural networks by\nexpanding the receptive field on many vision tasks significantly.\nUnfortunately, vanilla SSMs failed to simultaneously capture causal temporal\ncues and preserve non-casual spatial information. To this end, this paper\npresents a Video Vision Mamba-based framework, dubbed as Vivim, for medical\nvideo segmentation tasks. Our Vivim can effectively compress the long-term\nspatiotemporal representation into sequences at varying scales with our\ndesigned Temporal Mamba Block. We also introduce an improved boundary-aware\naffine constraint across frames to enhance the discriminative ability of Vivim\non ambiguous lesions. Extensive experiments on thyroid segmentation, breast\nlesion segmentation in ultrasound videos, and polyp segmentation in colonoscopy\nvideos demonstrate the effectiveness and efficiency of our Vivim, superior to\nexisting methods. The code is available at:\nhttps://github.com/scott-yjyang/Vivim. The dataset will be released once\naccepted.\n","authors":["Yijun Yang","Zhaohu Xing","Lequan Yu","Chunwang Huang","Huazhu Fu","Lei Zhu"],"pdf_url":"https://arxiv.org/pdf/2401.14168v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13312v2","updated":"2024-08-01T15:54:29Z","published":"2023-04-26T06:33:31Z","title":"Technical Note: Defining and Quantifying AND-OR Interactions for\n  Faithful and Concise Explanation of DNNs","summary":"  In this technical note, we aim to explain a deep neural network (DNN) by\nquantifying the encoded interactions between input variables, which reflects\nthe DNN's inference logic. Specifically, we first rethink the definition of\ninteractions, and then formally define faithfulness and conciseness for\ninteraction-based explanation. To this end, we propose two kinds of\ninteractions, i.e., the AND interaction and the OR interaction. For\nfaithfulness, we prove the uniqueness of the AND (OR) interaction in\nquantifying the effect of the AND (OR) relationship between input variables.\nBesides, based on AND-OR interactions, we design techniques to boost the\nconciseness of the explanation, while not hurting the faithfulness. In this\nway, the inference logic of a DNN can be faithfully and concisely explained by\na set of symbolic concepts.\n","authors":["Mingjie Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.13312v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2111.06206"},{"id":"http://arxiv.org/abs/2401.14832v3","updated":"2024-08-01T15:46:43Z","published":"2024-01-26T13:01:28Z","title":"Text Image Inpainting via Global Structure-Guided Diffusion Models","summary":"  Real-world text can be damaged by corrosion issues caused by environmental or\nhuman factors, which hinder the preservation of the complete styles of texts,\ne.g., texture and structure. These corrosion issues, such as graffiti signs and\nincomplete signatures, bring difficulties in understanding the texts, thereby\nposing significant challenges to downstream applications, e.g., scene text\nrecognition and signature identification. Notably, current inpainting\ntechniques often fail to adequately address this problem and have difficulties\nrestoring accurate text images along with reasonable and consistent styles.\nFormulating this as an open problem of text image inpainting, this paper aims\nto build a benchmark to facilitate its study. In doing so, we establish two\nspecific text inpainting datasets which contain scene text images and\nhandwritten text images, respectively. Each of them includes images revamped by\nreal-life and synthetic datasets, featuring pairs of original images, corrupted\nimages, and other assistant information. On top of the datasets, we further\ndevelop a novel neural framework, Global Structure-guided Diffusion Model\n(GSDM), as a potential solution. Leveraging the global structure of the text as\na prior, the proposed GSDM develops an efficient diffusion model to recover\nclean texts. The efficacy of our approach is demonstrated by thorough empirical\nstudy, including a substantial boost in both recognition accuracy and image\nquality. These findings not only highlight the effectiveness of our method but\nalso underscore its potential to enhance the broader field of text image\nunderstanding and processing. Code and datasets are available at:\nhttps://github.com/blackprotoss/GSDM.\n","authors":["Shipeng Zhu","Pengfei Fang","Chenjie Zhu","Zuoyan Zhao","Qiang Xu","Hui Xue"],"pdf_url":"https://arxiv.org/pdf/2401.14832v3.pdf","comment":"Accepted by AAAI-24"},{"id":"http://arxiv.org/abs/2311.00048v2","updated":"2024-08-01T15:37:52Z","published":"2023-10-31T18:01:41Z","title":"SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image\n  Classification","summary":"  Multiple Instance Learning (MIL) has been widely used in weakly supervised\nwhole slide image (WSI) classification. Typical MIL methods include a feature\nembedding part, which embeds the instances into features via a pre-trained\nfeature extractor, and an MIL aggregator that combines instance embeddings into\npredictions. Most efforts have typically focused on improving these parts. This\ninvolves refining the feature embeddings through self-supervised pre-training\nas well as modeling the correlations between instances separately.\n  In this paper, we proposed a sparsely coding MIL (SC-MIL) method that\naddresses those two aspects at the same time by leveraging sparse dictionary\nlearning. The sparse dictionary learning captures the similarities of instances\nby expressing them as sparse linear combinations of atoms in an over-complete\ndictionary. In addition, imposing sparsity improves instance feature embeddings\nby suppressing irrelevant instances while retaining the most relevant ones. To\nmake the conventional sparse coding algorithm compatible with deep learning, we\nunrolled it into a sparsely coded module leveraging deep unrolling. The\nproposed SC module can be incorporated into any existing MIL framework in a\nplug-and-play manner with an acceptable computational cost. The experimental\nresults on multiple datasets demonstrated that the proposed SC module could\nsubstantially boost the performance of state-of-the-art MIL methods. The codes\nare available at\n\\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.\n","authors":["Peijie Qiu","Pan Xiao","Wenhui Zhu","Yalin Wang","Aristeidis Sotiras"],"pdf_url":"https://arxiv.org/pdf/2311.00048v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02111v3","updated":"2024-08-01T14:01:56Z","published":"2023-12-04T18:43:45Z","title":"TriDeNT: Triple Deep Network Training for Privileged Knowledge\n  Distillation in Histopathology","summary":"  Computational pathology models rarely utilise data that will not be available\nfor inference. This means most models cannot learn from highly informative data\nsuch as additional immunohistochemical (IHC) stains and spatial\ntranscriptomics. We present TriDeNT, a novel self-supervised method for\nutilising privileged data that is not available during inference to improve\nperformance. We demonstrate the efficacy of this method for a range of\ndifferent paired data including immunohistochemistry, spatial transcriptomics\nand expert nuclei annotations. In all settings, TriDeNT outperforms other\nstate-of-the-art methods in downstream tasks, with observed improvements of up\nto 101%. Furthermore, we provide qualitative and quantitative measurements of\nthe features learned by these models and how they differ from baselines.\nTriDeNT offers a novel method to distil knowledge from scarce or costly data\nduring training, to create significantly better models for routine inputs.\n","authors":["Lucas Farndale","Robert Insall","Ke Yuan"],"pdf_url":"https://arxiv.org/pdf/2312.02111v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12715v2","updated":"2024-08-01T13:53:43Z","published":"2022-09-26T14:11:05Z","title":"Enhancing convolutional neural network generalizability via low-rank\n  weight approximation","summary":"  Noise is ubiquitous during image acquisition. Sufficient denoising is often\nan important first step for image processing. In recent decades, deep neural\nnetworks (DNNs) have been widely used for image denoising. Most DNN-based image\ndenoising methods require a large-scale dataset or focus on supervised\nsettings, in which single/pairs of clean images or a set of noisy images are\nrequired. This poses a significant burden on the image acquisition process.\nMoreover, denoisers trained on datasets of limited scale may incur\nover-fitting. To mitigate these issues, we introduce a new self-supervised\nframework for image denoising based on the Tucker low-rank tensor\napproximation. With the proposed design, we are able to characterize our\ndenoiser with fewer parameters and train it based on a single image, which\nconsiderably improves the model's generalizability and reduces the cost of data\nacquisition. Extensive experiments on both synthetic and real-world noisy\nimages have been conducted. Empirical results show that our proposed method\noutperforms existing non-learning-based methods (e.g., low-pass filter,\nnon-local mean), single-image unsupervised denoisers (e.g., DIP, NN+BM3D)\nevaluated on both in-sample and out-sample datasets. The proposed method even\nachieves comparable performances with some supervised methods (e.g., DnCNN).\n","authors":["Chenyin Gao","Shu Yang","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.12715v2.pdf","comment":"accepted by IET Image Processing"},{"id":"http://arxiv.org/abs/2407.12927v2","updated":"2024-08-01T13:51:26Z","published":"2024-07-17T18:01:25Z","title":"Textualized and Feature-based Models for Compound Multimodal Emotion\n  Recognition in the Wild","summary":"  Systems for multimodal emotion recognition (ER) are commonly trained to\nextract features from different modalities (e.g., visual, audio, and textual)\nthat are combined to predict individual basic emotions. However, compound\nemotions often occur in real-world scenarios, and the uncertainty of\nrecognizing such complex emotions over diverse modalities is challenging for\nfeature-based models As an alternative, emerging multimodal large language\nmodels (LLMs) like BERT and LLaMA rely on explicit non-verbal cues that may be\ntranslated from different non-textual modalities (e.g., audio and visual) into\ntext. Textualization of modalities augments data with emotional cues to help\nthe LLM encode the interconnections between all modalities in a shared text\nspace. In such text-based models, prior knowledge of ER tasks is leveraged to\ntextualize relevant nonverbal cues such as audio tone from vocal expressions,\nand action unit intensity from facial expressions. Since the pre-trained\nweights are publicly available for many LLMs, training on large-scale datasets\nis unnecessary, allowing fine-tuning for downstream tasks such as compound ER\n(CER). This paper compares the potential of text- and feature-based approaches\nfor compound multimodal ER in videos. Experiments were conducted on the\nchallenging C-EXPR-DB dataset in the wild for CER, and contrasted with results\non the MELD dataset for basic ER. Our results indicate that multimodal\ntextualization provides lower accuracy than feature-based models on C-EXPR-DB,\nwhere text transcripts are captured in the wild. However, higher accuracy can\nbe achieved when the video data has rich transcripts. Our code is available.\n","authors":["Nicolas Richet","Soufiane Belharbi","Haseeb Aslam","Meike Emilie Schadt","Manuela González-González","Gustave Cortal","Alessandro Lameiras Koerich","Marco Pedersoli","Alain Finkel","Simon Bacon","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/2407.12927v2.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.11356v2","updated":"2024-08-01T12:58:29Z","published":"2024-07-16T03:41:48Z","title":"The Devil is in the Statistics: Mitigating and Exploiting Statistics\n  Difference for Generalizable Semi-supervised Medical Image Segmentation","summary":"  Despite the recent success of domain generalization in medical image\nsegmentation, voxel-wise annotation for all source domains remains a huge\nburden. Semi-supervised domain generalization has been proposed very recently\nto combat this challenge by leveraging limited labeled data along with abundant\nunlabeled data collected from multiple medical institutions, depending on\nprecisely harnessing unlabeled data while improving generalization\nsimultaneously. In this work, we observe that domain shifts between medical\ninstitutions cause disparate feature statistics, which significantly\ndeteriorates pseudo-label quality due to an unexpected normalization process.\nNevertheless, this phenomenon could be exploited to facilitate unseen domain\ngeneralization. Therefore, we propose 1) multiple statistics-individual\nbranches to mitigate the impact of domain shifts for reliable pseudo-labels and\n2) one statistics-aggregated branch for domain-invariant feature learning.\nFurthermore, to simulate unseen domains with statistics difference, we approach\nthis from two aspects, i.e., a perturbation with histogram matching at image\nlevel and a random batch normalization selection strategy at feature level,\nproducing diverse statistics to expand the training distribution. Evaluation\nresults on three medical image datasets demonstrate the effectiveness of our\nmethod compared with recent SOTA methods. The code is available at\nhttps://github.com/qiumuyang/SIAB.\n","authors":["Muyang Qiu","Jian Zhang","Lei Qi","Qian Yu","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2407.11356v2.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2404.04526v2","updated":"2024-08-01T11:17:28Z","published":"2024-04-06T06:48:16Z","title":"DATENeRF: Depth-Aware Text-based Editing of NeRFs","summary":"  Recent advancements in diffusion models have shown remarkable proficiency in\nediting 2D images based on text prompts. However, extending these techniques to\nedit scenes in Neural Radiance Fields (NeRF) is complex, as editing individual\n2D frames can result in inconsistencies across multiple views. Our crucial\ninsight is that a NeRF scene's geometry can serve as a bridge to integrate\nthese 2D edits. Utilizing this geometry, we employ a depth-conditioned\nControlNet to enhance the coherence of each 2D image modification. Moreover, we\nintroduce an inpainting approach that leverages the depth information of NeRF\nscenes to distribute 2D edits across different images, ensuring robustness\nagainst errors and resampling challenges. Our results reveal that this\nmethodology achieves more consistent, lifelike, and detailed edits than\nexisting leading methods for text-driven NeRF scene editing.\n","authors":["Sara Rojas","Julien Philip","Kai Zhang","Sai Bi","Fujun Luan","Bernard Ghanem","Kalyan Sunkavall"],"pdf_url":"https://arxiv.org/pdf/2404.04526v2.pdf","comment":"3D Scene Editing, Neural Rendering, Diffusion Models, Accepted to\n  ECCV24"},{"id":"http://arxiv.org/abs/2404.10572v2","updated":"2024-08-01T10:34:47Z","published":"2024-04-16T13:47:27Z","title":"Label merge-and-split: A graph-colouring approach for memory-efficient\n  brain parcellation","summary":"  Whole brain parcellation requires inferring hundreds of segmentation labels\nin large image volumes and thus presents significant practical challenges for\ndeep learning approaches. We introduce label merge-and-split, a method that\nfirst greatly reduces the effective number of labels required for\nlearning-based whole brain parcellation and then recovers original labels.\nUsing a greedy graph colouring algorithm, our method automatically groups and\nmerges multiple spatially separate labels prior to model training and\ninference. The merged labels may be semantically unrelated. A deep learning\nmodel is trained to predict merged labels. At inference time, original labels\nare restored using atlas-based influence regions. In our experiments, the\nproposed approach reduces the number of labels by up to 68% while achieving\nsegmentation accuracy comparable to the baseline method without label merging\nand splitting. Moreover, model training and inference times as well as GPU\nmemory requirements were reduced significantly. The proposed method can be\napplied to all semantic segmentation tasks with a large number of spatially\nseparate classes within an atlas-based prior.\n","authors":["Aaron Kujawa","Reuben Dorent","Sebastien Ourselin","Tom Vercauteren"],"pdf_url":"https://arxiv.org/pdf/2404.10572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07558v2","updated":"2024-08-01T09:57:28Z","published":"2024-04-21T04:37:24Z","title":"An AI-Enabled Framework Within Reach for Enhancing Healthcare\n  Sustainability and Fairness","summary":"  Good health and well-being is among key issues in the United Nations 2030\nSustainable Development Goals. The rising prevalence of large-scale infectious\ndiseases and the accelerated aging of the global population are driving the\ntransformation of healthcare technologies. In this context, establishing\nlarge-scale public health datasets, developing medical models, and creating\ndecision-making systems with a human-centric approach are of strategic\nsignificance. Recently, by leveraging the extraordinary number of accessible\ncameras, groundbreaking advancements have emerged in AI methods for\nphysiological signal monitoring and disease diagnosis using camera sensors.\nThese approaches, requiring no specialized medical equipment, offer convenient\nmanners of collecting large-scale medical data in response to public health\nevents. Therefore, we outline a prospective framework and heuristic vision for\na camera-based public health (CBPH) framework utilizing visual physiological\nmonitoring technology. The CBPH can be considered as a convenient and universal\nframework for public health, advancing the United Nations Sustainable\nDevelopment Goals, particularly in promoting the universality, sustainability,\nand equity of healthcare in low- and middle-income countries or regions.\nFurthermore, CBPH provides a comprehensive solution for building a large-scale\nand human-centric medical database, and a multi-task large medical model for\npublic health and medical scientific discoveries. It has a significant\npotential to revolutionize personal monitoring technologies, digital medicine,\ntelemedicine, and primary health care in public health. Therefore, it can be\ndeemed that the outcomes of this paper will contribute to the establishment of\na sustainable and fair framework for public health, which serves as a crucial\nbridge for advancing scientific discoveries in the realm of AI for medicine\n(AI4Medicine).\n","authors":["Bin Huang","Changchen Zhao","Zimeng Liu","Shenda Hong","Baochang Zhang","Hao Lu","Zhijun Liu","Wenjin Wang","Hui Liu"],"pdf_url":"https://arxiv.org/pdf/2406.07558v2.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.20660v2","updated":"2024-08-01T09:56:15Z","published":"2024-07-30T08:52:51Z","title":"What makes for good morphology representations for spatial omics?","summary":"  Spatial omics has transformed our understanding of tissue architecture by\npreserving spatial context of gene expression patterns. Simultaneously,\nadvances in imaging AI have enabled extraction of morphological features\ndescribing the tissue. The intersection of spatial omics and imaging AI\npresents opportunities for a more holistic understanding. In this review we\nintroduce a framework for categorizing spatial omics-morphology combination\nmethods, focusing on how morphological features can be translated or integrated\ninto spatial omics analyses. By translation we mean finding morphological\nfeatures that spatially correlate with gene expression patterns with the\npurpose of predicting gene expression. Such features can be used to generate\nsuper-resolution gene expression maps or infer genetic information from\nclinical H&E-stained samples. By integration we mean finding morphological\nfeatures that spatially complement gene expression patterns with the purpose of\nenriching information. Such features can be used to define spatial domains,\nespecially where gene expression has preceded morphological changes and where\nmorphology remains after gene expression. We discuss learning strategies and\ndirections for further development of the field.\n","authors":["Eduard Chelebian","Christophe Avenel","Carolina Wählby"],"pdf_url":"https://arxiv.org/pdf/2407.20660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18401v3","updated":"2024-08-01T09:04:39Z","published":"2024-04-29T03:36:05Z","title":"Spectral-Spatial Mamba for Hyperspectral Image Classification","summary":"  Recently, deep learning models have achieved excellent performance in\nhyperspectral image (HSI) classification. Among the many deep models,\nTransformer has gradually attracted interest for its excellence in modeling the\nlong-range dependencies of spatial-spectral features in HSI. However,\nTransformer has the problem of quadratic computational complexity due to the\nself-attention mechanism, which is heavier than other models and thus has\nlimited adoption in HSI processing. Fortunately, the recently emerging state\nspace model-based Mamba shows great computational efficiency while achieving\nthe modeling power of Transformers. Therefore, in this paper, we make a\npreliminary attempt to apply the Mamba to HSI classification, leading to the\nproposed spectral-spatial Mamba (SS-Mamba). Specifically, the proposed SS-Mamba\nmainly consists of spectral-spatial token generation module and several stacked\nspectral-spatial Mamba blocks. Firstly, the token generation module converts\nany given HSI cube to spatial and spectral tokens as sequences. And then these\ntokens are sent to stacked spectral-spatial mamba blocks (SS-MB). Each SS-MB\nblock consists of two basic mamba blocks and a spectral-spatial feature\nenhancement module. The spatial and spectral tokens are processed separately by\nthe two basic mamba blocks, respectively. Besides, the feature enhancement\nmodule modulates spatial and spectral tokens using HSI sample's center region\ninformation. In this way, the spectral and spatial tokens cooperate with each\nother and achieve information fusion within each block. The experimental\nresults conducted on widely used HSI datasets reveal that the proposed model\nachieves competitive results compared with the state-of-the-art methods. The\nMamba-based method opens a new window for HSI classification.\n","authors":["Lingbo Huang","Yushi Chen","Xin He"],"pdf_url":"https://arxiv.org/pdf/2404.18401v3.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2405.01409v3","updated":"2024-08-01T08:58:40Z","published":"2024-05-02T16:01:58Z","title":"Goal-conditioned reinforcement learning for ultrasound navigation\n  guidance","summary":"  Transesophageal echocardiography (TEE) plays a pivotal role in cardiology for\ndiagnostic and interventional procedures. However, using it effectively\nrequires extensive training due to the intricate nature of image acquisition\nand interpretation. To enhance the efficiency of novice sonographers and reduce\nvariability in scan acquisitions, we propose a novel ultrasound (US) navigation\nassistance method based on contrastive learning as goal-conditioned\nreinforcement learning (GCRL). We augment the previous framework using a novel\ncontrastive patient batching method (CPB) and a data-augmented contrastive\nloss, both of which we demonstrate are essential to ensure generalization to\nanatomical variations across patients. The proposed framework enables\nnavigation to both standard diagnostic as well as intricate interventional\nviews with a single model. Our method was developed with a large dataset of 789\npatients and obtained an average error of 6.56 mm in position and 9.36 degrees\nin angle on a testing dataset of 140 patients, which is competitive or superior\nto models trained on individual views. Furthermore, we quantitatively validate\nour method's ability to navigate to interventional views such as the Left\nAtrial Appendage (LAA) view used in LAA closure. Our approach holds promise in\nproviding valuable guidance during transesophageal ultrasound examinations,\ncontributing to the advancement of skill acquisition for cardiac ultrasound\npractitioners.\n","authors":["Abdoul Aziz Amadou","Vivek Singh","Florin C. Ghesu","Young-Ho Kim","Laura Stanciulescu","Harshitha P. Sai","Puneet Sharma","Alistair Young","Ronak Rajani","Kawal Rhode"],"pdf_url":"https://arxiv.org/pdf/2405.01409v3.pdf","comment":"Accepted in MICCAI 2024; 11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.04664v2","updated":"2024-08-01T08:39:23Z","published":"2023-03-08T15:34:57Z","title":"Centroid-centered Modeling for Efficient Vision Transformer Pre-training","summary":"  Masked Image Modeling (MIM) is a new self-supervised vision pre-training\nparadigm using a Vision Transformer (ViT). Previous works can be pixel-based or\ntoken-based, using original pixels or discrete visual tokens from parametric\ntokenizer models, respectively. Our proposed centroid-based approach, CCViT,\nleverages k-means clustering to obtain centroids for image modeling without\nsupervised training of the tokenizer model, which only takes seconds to create.\nThis non-parametric centroid tokenizer only takes seconds to create and is\nfaster for token inference. The centroids can represent both patch pixels and\nindex tokens with the property of local invariance. Specifically, we adopt\npatch masking and centroid replacing strategies to construct corrupted inputs,\nand two stacked encoder blocks to predict corrupted patch tokens and\nreconstruct original patch pixels. Experiments show that our CCViT achieves\n84.4% top-1 accuracy on ImageNet-1K classification with ViT-B and 86.0% with\nViT-L. We also transfer our pre-trained model to other downstream tasks. Our\napproach achieves competitive results with recent baselines without external\nsupervision and distillation training from other models.\n","authors":["Xin Yan","Zuchao Li","Lefei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.04664v2.pdf","comment":"Codes are available at https://github.com/Cakeyan/CCViT_Public"},{"id":"http://arxiv.org/abs/2407.03104v2","updated":"2024-08-01T08:08:43Z","published":"2024-07-03T13:41:44Z","title":"KeyVideoLLM: Towards Large-scale Video Keyframe Selection","summary":"  Recently, with the rise of web videos, managing and understanding large-scale\nvideo datasets has become increasingly important. Video Large Language Models\n(VideoLLMs) have emerged in recent years due to their strong video\nunderstanding capabilities. However, training and inference processes for\nVideoLLMs demand vast amounts of data, presenting significant challenges to\ndata management, particularly regarding efficiency, robustness, and\neffectiveness. In this work, we present KeyVideoLLM, a text-video frame\nsimilarity-based keyframe selection method designed to manage VideoLLM data\nefficiently, robustly, and effectively. Specifically, KeyVideoLLM achieves a\nremarkable data compression rate of up to 60.9 times, substantially lowering\ndisk space requirements, which proves its high efficiency. Additionally, it\nmaintains a 100% selection success rate across all video formats and scales,\nenhances processing speed by up to 200 times compared to existing keyframe\nselection methods, and does not require hyperparameter tuning. Beyond its\noutstanding efficiency and robustness, KeyVideoLLM further improves model\nperformance in video question-answering tasks during both training and\ninference stages. Notably, it consistently achieved the state-of-the-art (SoTA)\nexperimental results on diverse datasets.\n","authors":["Hao Liang","Jiapeng Li","Tianyi Bai","Xijie Huang","Linzhuang Sun","Zhengren Wang","Conghui He","Bin Cui","Chong Chen","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.03104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08604v2","updated":"2024-08-01T07:55:49Z","published":"2024-06-12T19:17:17Z","title":"GRU-Net: Gaussian Attention Aided Dense Skip Connection Based\n  MultiResUNet for Breast Histopathology Image Segmentation","summary":"  Breast cancer is a major global health concern. Pathologists face challenges\nin analyzing complex features from pathological images, which is a\ntime-consuming and labor-intensive task. Therefore, efficient computer-based\ndiagnostic tools are needed for early detection and treatment planning. This\npaper presents a modified version of MultiResU-Net for histopathology image\nsegmentation, which is selected as the backbone for its ability to analyze and\nsegment complex features at multiple scales and ensure effective feature flow\nvia skip connections. The modified version also utilizes the Gaussian\ndistribution-based Attention Module (GdAM) to incorporate\nhistopathology-relevant text information in a Gaussian distribution. The\nsampled features from the Gaussian text feature-guided distribution highlight\nspecific spatial regions based on prior knowledge. Finally, using the\nControlled Dense Residual Block (CDRB) on skip connections of MultiResU-Net,\nthe information is transferred from the encoder layers to the decoder layers in\na controlled manner using a scaling parameter derived from the extracted\nspatial features. We validate our approach on two diverse breast cancer\nhistopathology image datasets: TNBC and MonuSeg, demonstrating superior\nsegmentation performance compared to state-of-the-art methods. The code for our\nproposed model is available on https://github.com/AyushRoy2001/GRU-Net.\n","authors":["Ayush Roy","Payel Pramanik","Sohom Ghosal","Daria Valenkova","Dmitrii Kaplun","Ram Sarkar"],"pdf_url":"https://arxiv.org/pdf/2406.08604v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20843v2","updated":"2024-08-01T07:43:11Z","published":"2024-07-30T14:16:09Z","title":"DFE-IANet: A Method for Polyp Image Classification Based on Dual-domain\n  Feature Extraction and Interaction Attention","summary":"  It is helpful in preventing colorectal cancer to detect and treat polyps in\nthe gastrointestinal tract early. However, there have been few studies to date\non designing polyp image classification networks that balance efficiency and\naccuracy. This challenge is mainly attributed to the fact that polyps are\nsimilar to other pathologies and have complex features influenced by texture,\ncolor, and morphology. In this paper, we propose a novel network DFE-IANet\nbased on both spectral transformation and feature interaction. Firstly, to\nextract detailed features and multi-scale features, the features are\ntransformed by the multi-scale frequency domain feature extraction (MSFD) block\nto extract texture details at the fine-grained level in the frequency domain.\nSecondly, the multi-scale interaction attention (MSIA) block is designed to\nenhance the network's capability of extracting critical features. This block\nintroduces multi-scale features into self-attention, aiming to adaptively guide\nthe network to concentrate on vital regions. Finally, with a compact parameter\nof only 4M, DFE-IANet outperforms the latest and classical networks in terms of\nefficiency. Furthermore, DFE-IANet achieves state-of-the-art (SOTA) results on\nthe challenging Kvasir dataset, demonstrating a remarkable Top-1 accuracy of\n93.94%. This outstanding accuracy surpasses ViT by 8.94%, ResNet50 by 1.69%,\nand VMamba by 1.88%. Our code is publicly available at\nhttps://github.com/PURSUETHESUN/DFE-IANet.\n","authors":["Wei Wang","Jixing He","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2407.20843v2.pdf","comment":"This paper has been accepted by 2024 International Conference on\n  Intelligent Computing (ICIC 2024). It can be accessed at\n  http://poster-openaccess.com"},{"id":"http://arxiv.org/abs/2312.03781v4","updated":"2024-08-01T07:29:47Z","published":"2023-12-06T09:39:38Z","title":"Lite-Mind: Towards Efficient and Robust Brain Representation Network","summary":"  The limited data availability and the low signal-to-noise ratio of fMRI\nsignals lead to the challenging task of fMRI-to-image retrieval.\nState-of-the-art MindEye remarkably improves fMRI-to-image retrieval\nperformance by leveraging a large model, i.e., a 996M MLP Backbone per subject,\nto align fMRI embeddings to the final hidden layer of CLIP's Vision Transformer\n(ViT). However, significant individual variations exist among subjects, even\nunder identical experimental setups, mandating the training of large\nsubject-specific models. The substantial parameters pose significant challenges\nin deploying fMRI decoding on practical devices. To this end, we propose\nLite-Mind, a lightweight, efficient, and robust brain representation learning\nparadigm based on Discrete Fourier Transform (DFT), which efficiently aligns\nfMRI voxels to fine-grained information of CLIP. We elaborately design a DFT\nbackbone with Spectrum Compression and Frequency Projector modules to learn\ninformative and robust voxel embeddings. Our experiments demonstrate that\nLite-Mind achieves an impressive 94.6% fMRI-to-image retrieval accuracy on the\nNSD dataset for Subject 1, with 98.7% fewer parameters than MindEye. Lite-Mind\nis also proven to be able to be migrated to smaller fMRI datasets and\nestablishes a new state-of-the-art for zero-shot classification on the GOD\ndataset.\n","authors":["Zixuan Gong","Qi Zhang","Guangyin Bao","Lei Zhu","Ke Liu","Liang Hu","Duoqian Miao","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.03781v4.pdf","comment":"17 pages, ACM MM 2024 Oral"},{"id":"http://arxiv.org/abs/2404.01065v2","updated":"2024-08-01T07:01:49Z","published":"2024-04-01T11:57:40Z","title":"T-Mamba: A unified framework with Long-Range Dependency in dual-domain\n  for 2D & 3D Tooth Segmentation","summary":"  Tooth segmentation is a pivotal step in modern digital dentistry, essential\nfor applications across orthodontic diagnosis and treatment planning. Despite\nits importance, this process is fraught with challenges due to the high noise\nand low contrast inherent in 2D and 3D tooth data. Both Convolutional Neural\nNetworks (CNNs) and Transformers has shown promise in medical image\nsegmentation, yet each method has limitations in handling long-range\ndependencies and computational complexity. To address this issue, this paper\nintroduces T-Mamba, integrating frequency-based features and shared\nbi-positional encoding into vision mamba to address limitations in efficient\nglobal feature modeling. Besides, we design a gate selection unit to integrate\ntwo features in spatial domain and one feature in frequency domain adaptively.\nT-Mamba is the first work to introduce frequency-based features into vision\nmamba, and its flexibility allows it to process both 2D and 3D tooth data\nwithout the need for separate modules. Also, the TED3, a large-scale public\ntooth 2D dental X-ray dataset, has been presented in this paper. Extensive\nexperiments demonstrate that T-Mamba achieves new SOTA results on a public\ntooth CBCT dataset and outperforms previous SOTA methods on TED3 dataset. The\ncode and models are publicly available at: https://github.com/isbrycee/T-Mamba.\n","authors":["Jing Hao","Yonghui Zhu","Lei He","Moyun Liu","James Kit Hon Tsoi","Kuo Feng Hung"],"pdf_url":"https://arxiv.org/pdf/2404.01065v2.pdf","comment":"25 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2404.17100v2","updated":"2024-08-01T06:46:04Z","published":"2024-04-26T01:21:08Z","title":"Open-Set Video-based Facial Expression Recognition with Human\n  Expression-sensitive Prompting","summary":"  In Video-based Facial Expression Recognition (V-FER), models are typically\ntrained on closed-set datasets with a fixed number of known classes. However,\nthese models struggle with unknown classes common in real-world scenarios. In\nthis paper, we introduce a challenging Open-set Video-based Facial Expression\nRecognition (OV-FER) task, aiming to identify both known and new, unseen facial\nexpressions. While existing approaches use large-scale vision-language models\nlike CLIP to identify unseen classes, we argue that these methods may not\nadequately capture the subtle human expressions needed for OV-FER. To address\nthis limitation, we propose a novel Human Expression-Sensitive Prompting (HESP)\nmechanism to significantly enhance CLIP's ability to model video-based facial\nexpression details effectively. Our proposed HESP comprises three components:\n1) a textual prompting module with learnable prompts to enhance CLIP's textual\nrepresentation of both known and unknown emotions, 2) a visual prompting module\nthat encodes temporal emotional information from video frames using\nexpression-sensitive attention, equipping CLIP with a new visual modeling\nability to extract emotion-rich information, and 3) an open-set multi-task\nlearning scheme that promotes interaction between the textual and visual\nmodules, improving the understanding of novel human emotions in video\nsequences. Extensive experiments conducted on four OV-FER task settings\ndemonstrate that HESP can significantly boost CLIP's performance (a relative\nimprovement of 17.93% on AUROC and 106.18% on OSCR) and outperform other\nstate-of-the-art open-set video understanding methods by a large margin. Code\nis available at https://github.com/cosinehuang/HESP.\n","authors":["Yuanyuan Liu","Yuxuan Huang","Shuyang Liu","Yibing Zhan","Zijing Chen","Zhe Chen"],"pdf_url":"https://arxiv.org/pdf/2404.17100v2.pdf","comment":"Accepted by ACM MM2024"},{"id":"http://arxiv.org/abs/2210.03437v2","updated":"2024-08-01T06:02:27Z","published":"2022-10-07T10:13:30Z","title":"KRF: Keypoint Refinement with Fusion Network for 6D Pose Estimation","summary":"  Some robust point cloud registration approaches with controllable pose\nrefinement magnitude, such as ICP and its variants, are commonly used to\nimprove 6D pose estimation accuracy. However, the effectiveness of these\nmethods gradually diminishes with the advancement of deep learning techniques\nand the enhancement of initial pose accuracy, primarily due to their lack of\nspecific design for pose refinement. In this paper, we propose Point Cloud\nCompletion and Keypoint Refinement with Fusion Data (PCKRF), a new pose\nrefinement pipeline for 6D pose estimation. The pipeline consists of two steps.\nFirst, it completes the input point clouds via a novel pose-sensitive point\ncompletion network. The network uses both local and global features with pose\ninformation during point completion. Then, it registers the completed object\npoint cloud with the corresponding target point cloud by our proposed Color\nsupported Iterative KeyPoint (CIKP) method. The CIKP method introduces color\ninformation into registration and registers a point cloud around each keypoint\nto increase stability. The PCKRF pipeline can be integrated with existing\npopular 6D pose estimation methods, such as the full flow bidirectional fusion\nnetwork, to further improve their pose estimation accuracy. Experiments\ndemonstrate that our method exhibits superior stability compared to existing\napproaches when optimizing initial poses with relatively high precision.\nNotably, the results indicate that our method effectively complements most\nexisting pose estimation techniques, leading to improved performance in most\ncases. Furthermore, our method achieves promising results even in challenging\nscenarios involving textureless and symmetrical objects. Our source code is\navailable at https://github.com/zhanhz/KRF.\n","authors":["Yiheng Han","Irvin Haozhe Zhan","Long Zeng","Yu-Ping Wang","Ran Yi","Minjing Yu","Matthieu Gaetan Lin","Jenny Sheng","Yong-Jin Liu"],"pdf_url":"https://arxiv.org/pdf/2210.03437v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10224v3","updated":"2024-08-01T05:18:48Z","published":"2024-01-18T18:59:09Z","title":"The Manga Whisperer: Automatically Generating Transcriptions for Comics","summary":"  In the past few decades, Japanese comics, commonly referred to as Manga, have\ntranscended both cultural and linguistic boundaries to become a true worldwide\nsensation. Yet, the inherent reliance on visual cues and illustration within\nmanga renders it largely inaccessible to individuals with visual impairments.\nIn this work, we seek to address this substantial barrier, with the aim of\nensuring that manga can be appreciated and actively engaged by everyone.\nSpecifically, we tackle the problem of diarisation i.e. generating a\ntranscription of who said what and when, in a fully automatic way.\n  To this end, we make the following contributions: (1) we present a unified\nmodel, Magi, that is able to (a) detect panels, text boxes and character boxes,\n(b) cluster characters by identity (without knowing the number of clusters\napriori), and (c) associate dialogues to their speakers; (2) we propose a novel\napproach that is able to sort the detected text boxes in their reading order\nand generate a dialogue transcript; (3) we annotate an evaluation benchmark for\nthis task using publicly available [English] manga pages. The code, evaluation\ndatasets and the pre-trained model can be found at:\nhttps://github.com/ragavsachdeva/magi.\n","authors":["Ragav Sachdeva","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2401.10224v3.pdf","comment":"Accepted at CVPR'24"},{"id":"http://arxiv.org/abs/2303.08046v2","updated":"2024-08-01T05:15:43Z","published":"2023-03-07T09:20:39Z","title":"Ultra-High-Resolution Detector Simulation with Intra-Event Aware GAN and\n  Self-Supervised Relational Reasoning","summary":"  Simulating high-resolution detector responses is a computationally intensive\nprocess that has long been challenging in Particle Physics. Despite the ability\nof generative models to streamline it, full ultra-high-granularity detector\nsimulation still proves to be difficult as it contains correlated and\nfine-grained information. To overcome these limitations, we propose Intra-Event\nAware Generative Adversarial Network (IEA-GAN). IEA-GAN presents a Relational\nReasoning Module that approximates an event in detector simulation, generating\ncontextualized high-resolution full detector responses with a proper relational\ninductive bias. IEA-GAN also introduces a Self-Supervised intra-event aware\nloss and Uniformity loss, significantly enhancing sample fidelity and\ndiversity. We demonstrate IEA-GAN's application in generating sensor-dependent\nimages for the ultra-high-granularity Pixel Vertex Detector (PXD), with more\nthan 7.5 M information channels at the Belle II Experiment. Applications of\nthis work span from Foundation Models for high-granularity detector simulation,\nsuch as at the HL-LHC (High Luminosity LHC), to simulation-based inference and\nfine-grained density estimation. To our knowledge, IEA-GAN is the first\nalgorithm for faithful ultra-high-granularity full detector simulation with\nevent-based reasoning.\n","authors":["Baran Hashemi","Nikolai Hartmann","Sahand Sharifzadeh","James Kahn","Thomas Kuhr"],"pdf_url":"https://arxiv.org/pdf/2303.08046v2.pdf","comment":"Published at Nature Communications"},{"id":"http://arxiv.org/abs/2406.13642v5","updated":"2024-08-01T04:46:58Z","published":"2024-06-19T15:41:30Z","title":"SpatialBot: Precise Spatial Understanding with Vision Language Models","summary":"  Vision Language Models (VLMs) have achieved impressive performance in 2D\nimage understanding, however they are still struggling with spatial\nunderstanding which is the foundation of Embodied AI. In this paper, we propose\nSpatialBot for better spatial understanding by feeding both RGB and depth\nimages. Additionally, we have constructed the SpatialQA dataset, which involves\nmulti-level depth-related questions to train VLMs for depth understanding.\nFinally, we present SpatialBench to comprehensively evaluate VLMs' capabilities\nin spatial understanding at different levels. Extensive experiments on our\nspatial-understanding benchmark, general VLM benchmarks and Embodied AI tasks,\ndemonstrate the remarkable improvements of SpatialBot trained on SpatialQA. The\nmodel, code and data are available at https://github.com/BAAI-DCAI/SpatialBot.\n","authors":["Wenxiao Cai","Yaroslav Ponomarenko","Jianhao Yuan","Xiaoqi Li","Wankou Yang","Hao Dong","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.13642v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19394v2","updated":"2024-08-01T04:22:29Z","published":"2024-07-28T04:23:40Z","title":"Depth-Wise Convolutions in Vision Transformers for Efficient Training on\n  Small Datasets","summary":"  The Vision Transformer (ViT) leverages the Transformer's encoder to capture\nglobal information by dividing images into patches and achieves superior\nperformance across various computer vision tasks. However, the self-attention\nmechanism of ViT captures the global context from the outset, overlooking the\ninherent relationships between neighboring pixels in images or videos.\nTransformers mainly focus on global information while ignoring the fine-grained\nlocal details. Consequently, ViT lacks inductive bias during image or video\ndataset training. In contrast, convolutional neural networks (CNNs), with their\nreliance on local filters, possess an inherent inductive bias, making them more\nefficient and quicker to converge than ViT with less data. In this paper, we\npresent a lightweight Depth-Wise Convolution module as a shortcut in ViT\nmodels, bypassing entire Transformer blocks to ensure the models capture both\nlocal and global information with minimal overhead. Additionally, we introduce\ntwo architecture variants, allowing the Depth-Wise Convolution modules to be\napplied to multiple Transformer blocks for parameter savings, and incorporating\nindependent parallel Depth-Wise Convolution modules with different kernels to\nenhance the acquisition of local information. The proposed approach\nsignificantly boosts the performance of ViT models on image classification,\nobject detection and instance segmentation by a large margin, especially on\nsmall datasets, as evaluated on CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet\nfor image classification, and COCO for object detection and instance\nsegmentation. The source code can be accessed at\nhttps://github.com/ZTX-100/Efficient_ViT_with_DW.\n","authors":["Tianxiao Zhang","Wenju Xu","Bo Luo","Guanghui Wang"],"pdf_url":"https://arxiv.org/pdf/2407.19394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20756v2","updated":"2024-08-01T04:01:39Z","published":"2024-07-30T11:57:40Z","title":"SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision\n  Language Models","summary":"  Recently, with the rise of web images, managing and understanding large-scale\nimage datasets has become increasingly important. Vision Large Language Models\n(VLLMs) have recently emerged due to their robust vision-understanding\ncapabilities. However, training these models requires vast amounts of data,\nposing challenges to efficiency, effectiveness, data quality, and privacy. In\nthis paper, we introduce SynthVLM, a novel data synthesis pipeline for VLLMs.\nUnlike existing methods that generate captions from images, SynthVLM employs\nadvanced diffusion models and high-quality captions to automatically generate\nand select high-resolution images from captions, creating precisely aligned\nimage-text pairs. Leveraging these pairs, we achieve state-of-the-art (SoTA)\nperformance on various vision question answering tasks, maintaining high\nalignment quality and preserving advanced language abilities. Moreover,\nSynthVLM surpasses traditional GPT-4 Vision-based caption generation methods in\nperformance while significantly reducing computational overhead. Crucially, our\nmethod's reliance on purely generated data ensures the preservation of privacy,\nachieving SoTA performance with just 100k data points (only 18% of the official\ndataset size).\n","authors":["Zheng Liu","Hao Liang","Xijie Huang","Wentao Xiong","Qinhan Yu","Linzhuang Sun","Chong Chen","Conghui He","Bin Cui","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.20756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09786v4","updated":"2024-08-01T03:57:24Z","published":"2024-01-18T08:10:34Z","title":"Adaptive Self-training Framework for Fine-grained Scene Graph Generation","summary":"  Scene graph generation (SGG) models have suffered from inherent problems\nregarding the benchmark datasets such as the long-tailed predicate distribution\nand missing annotation problems. In this work, we aim to alleviate the\nlong-tailed problem of SGG by utilizing unannotated triplets. To this end, we\nintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels\nfor unannotated triplets based on which the SGG models are trained. While there\nhas been significant progress in self-training for image recognition, designing\na self-training framework for the SGG task is more challenging due to its\ninherent nature such as the semantic ambiguity and the long-tailed distribution\nof predicate classes. Hence, we propose a novel pseudo-labeling technique for\nSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is\na model-agnostic framework that can be applied to any existing SGG models.\nFurthermore, we devise a graph structure learner (GSL) that is beneficial when\nadopting our proposed self-training framework to the state-of-the-art\nmessage-passing neural network (MPNN)-based SGG models. Our extensive\nexperiments verify the effectiveness of ST-SGG on various SGG models,\nparticularly in enhancing the performance on fine-grained predicate classes.\n","authors":["Kibum Kim","Kanghoon Yoon","Yeonjun In","Jinyoung Moon","Donghyun Kim","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2401.09786v4.pdf","comment":"9 pages; ICLR 2024"},{"id":"http://arxiv.org/abs/2407.21740v2","updated":"2024-08-01T03:16:43Z","published":"2024-07-31T16:52:00Z","title":"Contrastive Factor Analysis","summary":"  Factor analysis, often regarded as a Bayesian variant of matrix\nfactorization, offers superior capabilities in capturing uncertainty, modeling\ncomplex dependencies, and ensuring robustness. As the deep learning era\narrives, factor analysis is receiving less and less attention due to their\nlimited expressive ability. On the contrary, contrastive learning has emerged\nas a potent technique with demonstrated efficacy in unsupervised\nrepresentational learning. While the two methods are different paradigms,\nrecent theoretical analysis has revealed the mathematical equivalence between\ncontrastive learning and matrix factorization, providing a potential\npossibility for factor analysis combined with contrastive learning. Motivated\nby the interconnectedness of contrastive learning, matrix factorization, and\nfactor analysis, this paper introduces a novel Contrastive Factor Analysis\nframework, aiming to leverage factor analysis's advantageous properties within\nthe realm of contrastive learning. To further leverage the interpretability\nproperties of non-negative factor analysis, which can learn disentangled\nrepresentations, contrastive factor analysis is extended to a non-negative\nversion. Finally, extensive experimental validation showcases the efficacy of\nthe proposed contrastive (non-negative) factor analysis methodology across\nmultiple key properties, including expressiveness, robustness,\ninterpretability, and accurate uncertainty estimation.\n","authors":["Zhibin Duan","Tiansheng Wen","Yifei Wang","Chen Zhu","Bo Chen","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.21740v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13211v2","updated":"2024-08-01T03:07:49Z","published":"2024-07-18T06:50:39Z","title":"Research on Image Super-Resolution Reconstruction Mechanism based on\n  Convolutional Neural Network","summary":"  Super-resolution reconstruction techniques entail the utilization of software\nalgorithms to transform one or more sets of low-resolution images captured from\nthe same scene into high-resolution images. In recent years, considerable\nadvancement has been observed in the domain of single-image super-resolution\nalgorithms, particularly those based on deep learning techniques. Nevertheless,\nthe extraction of image features and nonlinear mapping methods in the\nreconstruction process remain challenging for existing algorithms. These issues\nresult in the network architecture being unable to effectively utilize the\ndiverse range of information at different levels. The loss of high-frequency\ndetails is significant, and the final reconstructed image features are overly\nsmooth, with a lack of fine texture details. This negatively impacts the\nsubjective visual quality of the image. The objective is to recover\nhigh-quality, high-resolution images from low-resolution images. In this work,\nan enhanced deep convolutional neural network model is employed, comprising\nmultiple convolutional layers, each of which is configured with specific\nfilters and activation functions to effectively capture the diverse features of\nthe image. Furthermore, a residual learning strategy is employed to accelerate\ntraining and enhance the convergence of the network, while sub-pixel\nconvolutional layers are utilized to refine the high-frequency details and\ntextures of the image. The experimental analysis demonstrates the superior\nperformance of the proposed model on multiple public datasets when compared\nwith the traditional bicubic interpolation method and several other\nlearning-based super-resolution methods. Furthermore, it proves the model's\nefficacy in maintaining image edges and textures.\n","authors":["Hao Yan","Zixiang Wang","Zhengjia Xu","Zhuoyue Wang","Zhizhong Wu","Ranran Lyu"],"pdf_url":"https://arxiv.org/pdf/2407.13211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11816v2","updated":"2024-08-01T02:49:00Z","published":"2023-12-19T03:15:50Z","title":"A Dual-way Enhanced Framework from Text Matching Point of View for\n  Multimodal Entity Linking","summary":"  Multimodal Entity Linking (MEL) aims at linking ambiguous mentions with\nmultimodal information to entity in Knowledge Graph (KG) such as Wikipedia,\nwhich plays a key role in many applications. However, existing methods suffer\nfrom shortcomings, including modality impurity such as noise in raw image and\nambiguous textual entity representation, which puts obstacles to MEL. We\nformulate multimodal entity linking as a neural text matching problem where\neach multimodal information (text and image) is treated as a query, and the\nmodel learns the mapping from each query to the relevant entity from candidate\nentities. This paper introduces a dual-way enhanced (DWE) framework for MEL:\n(1) our model refines queries with multimodal data and addresses semantic gaps\nusing cross-modal enhancers between text and image information. Besides, DWE\ninnovatively leverages fine-grained image attributes, including facial\ncharacteristic and scene feature, to enhance and refine visual features. (2)By\nusing Wikipedia descriptions, DWE enriches entity semantics and obtains more\ncomprehensive textual representation, which reduces between textual\nrepresentation and the entities in KG. Extensive experiments on three public\nbenchmarks demonstrate that our method achieves state-of-the-art (SOTA)\nperformance, indicating the superiority of our model. The code is released on\nhttps://github.com/season1blue/DWE\n","authors":["Shezheng Song","Shan Zhao","Chengyu Wang","Tianwei Yan","Shasha Li","Xiaoguang Mao","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2312.11816v2.pdf","comment":"AAAI23 Accept"},{"id":"http://arxiv.org/abs/2407.14055v2","updated":"2024-08-01T02:19:08Z","published":"2024-07-19T06:31:22Z","title":"Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers","summary":"  When applying quantum computing to machine learning tasks, one of the first\nconsiderations is the design of the quantum machine learning model itself.\nConventionally, the design of quantum machine learning algorithms relies on the\n``quantisation\" of classical learning algorithms, such as using quantum linear\nalgebra to implement important subroutines of classical algorithms, if not the\nentire algorithm, seeking to achieve quantum advantage through possible\nrun-time accelerations brought by quantum computing. However, recent research\nhas started questioning whether quantum advantage via speedup is the right goal\nfor quantum machine learning [1]. Research also has been undertaken to exploit\nproperties that are unique to quantum systems, such as quantum contextuality,\nto better design quantum machine learning models [2]. In this paper, we take an\nalternative approach by incorporating the heuristics and empirical evidences\nfrom the design of classical deep learning algorithms to the design of quantum\nneural networks. We first construct a model based on the data reuploading\ncircuit [3] with the quantum Hamiltonian data embedding unitary [4]. Through\nnumerical experiments on images datasets, including the famous MNIST and\nFashionMNIST datasets, we demonstrate that our model outperforms the quantum\nconvolutional neural network (QCNN)[5] by a large margin (up to over 40% on\nMNIST test set). Based on the model design process and numerical results, we\nthen laid out six principles for designing quantum machine learning models,\nespecially quantum neural networks.\n","authors":["Peiyong Wang","Casey R. Myers","Lloyd C. L. Hollenberg","Udaya Parampalli"],"pdf_url":"https://arxiv.org/pdf/2407.14055v2.pdf","comment":"11 figures, 31 pages. Code available on\n  https://github.com/peiyong-addwater/HamEmbedding. Author affiliation updated\n  for v2. Acknowledgements and funding information added for v2"},{"id":"http://arxiv.org/abs/2407.21266v2","updated":"2024-08-01T01:59:58Z","published":"2024-07-31T01:07:21Z","title":"DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image\n  Segmentation on Multiple GPUs","summary":"  The segmentation of ultra-high resolution images poses challenges such as\nloss of spatial information or computational inefficiency. In this work, a\nnovel approach that combines encoder-decoder architectures with domain\ndecomposition strategies to address these challenges is proposed. Specifically,\na domain decomposition-based U-Net (DDU-Net) architecture is introduced, which\npartitions input images into non-overlapping patches that can be processed\nindependently on separate devices. A communication network is added to\nfacilitate inter-patch information exchange to enhance the understanding of\nspatial context. Experimental validation is performed on a synthetic dataset\nthat is designed to measure the effectiveness of the communication network.\nThen, the performance is tested on the DeepGlobe land cover classification\ndataset as a real-world benchmark data set. The results demonstrate that the\napproach, which includes inter-patch communication for images divided into\n$16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher\nintersection over union (IoU) score compared to the same network without\ninter-patch communication. The performance of the network which includes\ncommunication is equivalent to that of a baseline U-Net trained on the full\nimage, showing that our model provides an effective solution for segmenting\nultra-high-resolution images while preserving spatial context. The code is\navailable at https://github.com/corne00/HiRes-Seg-CNN.\n","authors":["Corné Verburg","Alexander Heinlein","Eric C. Cyr"],"pdf_url":"https://arxiv.org/pdf/2407.21266v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21263v2","updated":"2024-08-01T01:59:39Z","published":"2024-07-31T00:56:06Z","title":"Outlier Detection in Large Radiological Datasets using UMAP","summary":"  The success of machine learning algorithms heavily relies on the quality of\nsamples and the accuracy of their corresponding labels. However, building and\nmaintaining large, high-quality datasets is an enormous task. This is\nespecially true for biomedical data and for meta-sets that are compiled from\nsmaller ones, as variations in image quality, labeling, reports, and archiving\ncan lead to errors, inconsistencies, and repeated samples. Here, we show that\nthe uniform manifold approximation and projection (UMAP) algorithm can find\nthese anomalies essentially by forming independent clusters that are distinct\nfrom the main (good) data but similar to other points with the same error type.\nAs a representative example, we apply UMAP to discover outliers in the publicly\navailable ChestX-ray14, CheXpert, and MURA datasets. While the results are\narchival and retrospective and focus on radiological images, the graph-based\nmethods work for any data type and will prove equally beneficial for curation\nat the time of dataset creation.\n","authors":["Mohammad Tariqul Islam","Jason W. Fleischer"],"pdf_url":"https://arxiv.org/pdf/2407.21263v2.pdf","comment":"Accepted in MICCAI-2024 Workshop on Topology- and Graph-Informed\n  Imaging Informatics (TGI3)"},{"id":"http://arxiv.org/abs/2408.00766v1","updated":"2024-08-01T17:59:59Z","published":"2024-08-01T17:59:59Z","title":"Optimizing Diffusion Models for Joint Trajectory Prediction and\n  Controllable Generation","summary":"  Diffusion models are promising for joint trajectory prediction and\ncontrollable generation in autonomous driving, but they face challenges of\ninefficient inference steps and high computational demands. To tackle these\nchallenges, we introduce Optimal Gaussian Diffusion (OGD) and Estimated Clean\nManifold (ECM) Guidance. OGD optimizes the prior distribution for a small\ndiffusion time $T$ and starts the reverse diffusion process from it. ECM\ndirectly injects guidance gradients to the estimated clean manifold,\neliminating extensive gradient backpropagation throughout the network. Our\nmethodology streamlines the generative process, enabling practical applications\nwith reduced computational overhead. Experimental validation on the large-scale\nArgoverse 2 dataset demonstrates our approach's superior performance, offering\na viable solution for computationally efficient, high-quality joint trajectory\nprediction and controllable generation for autonomous driving. Our project\nwebpage is at https://yixiaowang7.github.io/OptTrajDiff_Page/.\n","authors":["Yixiao Wang","Chen Tang","Lingfeng Sun","Simone Rossi","Yichen Xie","Chensheng Peng","Thomas Hannagan","Stefano Sabatini","Nicola Poerio","Masayoshi Tomizuka","Wei Zhan"],"pdf_url":"https://arxiv.org/pdf/2408.00766v1.pdf","comment":"30 pages, 20 figures, Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00765v1","updated":"2024-08-01T17:59:54Z","published":"2024-08-01T17:59:54Z","title":"MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models\n  for Integrated Capabilities","summary":"  MM-Vet, with open-ended vision-language questions targeting at evaluating\nintegrated capabilities, has become one of the most popular benchmarks for\nlarge multimodal model evaluation. MM-Vet assesses six core vision-language\n(VL) capabilities: recognition, knowledge, spatial awareness, language\ngeneration, OCR, and math. However, its question format is restricted to single\nimage-text pairs, lacking the interleaved image and text sequences prevalent in\nreal-world scenarios. To address this limitation, we introduce MM-Vet v2, which\nincludes a new VL capability called \"image-text sequence understanding\",\nevaluating models' ability to process VL sequences. Furthermore, we maintain\nthe high quality of evaluation samples while further expanding the evaluation\nset size. Using MM-Vet v2 to benchmark large multimodal models, we found that\nClaude 3.5 Sonnet is the best model with a score of 71.8, slightly\noutperforming GPT-4o which scored 71.0. Among open-weight models,\nInternVL2-Llama3-76B leads with a score of 68.4.\n","authors":["Weihao Yu","Zhengyuan Yang","Linfeng Ren","Linjie Li","Jianfeng Wang","Kevin Lin","Chung-Ching Lin","Zicheng Liu","Lijuan Wang","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00765v1.pdf","comment":"Extension of MM-Vet: arXiv:2308.02490"},{"id":"http://arxiv.org/abs/2408.00762v1","updated":"2024-08-01T17:59:27Z","published":"2024-08-01T17:59:27Z","title":"UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified\n  Model","summary":"  Audio-driven 3D facial animation aims to map input audio to realistic facial\nmotion. Despite significant progress, limitations arise from inconsistent 3D\nannotations, restricting previous models to training on specific annotations\nand thereby constraining the training scale. In this work, we present\nUniTalker, a unified model featuring a multi-head architecture designed to\neffectively leverage datasets with varied annotations. To enhance training\nstability and ensure consistency among multi-head outputs, we employ three\ntraining strategies, namely, PCA, model warm-up, and pivot identity embedding.\nTo expand the training scale and diversity, we assemble A2F-Bench, comprising\nfive publicly available datasets and three newly curated datasets. These\ndatasets contain a wide range of audio domains, covering multilingual speech\nvoices and songs, thereby scaling the training data from commonly employed\ndatasets, typically less than 1 hour, to 18.5 hours. With a single trained\nUniTalker model, we achieve substantial lip vertex error reductions of 9.2% for\nBIWI dataset and 13.7% for Vocaset. Additionally, the pre-trained UniTalker\nexhibits promise as the foundation model for audio-driven facial animation\ntasks. Fine-tuning the pre-trained UniTalker on seen datasets further enhances\nperformance on each dataset, with an average error reduction of 6.3% on\nA2F-Bench. Moreover, fine-tuning UniTalker on an unseen dataset with only half\nthe data surpasses prior state-of-the-art models trained on the full dataset.\nThe code and dataset are available at the project page\nhttps://github.com/X-niper/UniTalker.\n","authors":["Xiangyu Fan","Jiaqi Li","Zhiqian Lin","Weiye Xiao","Lei Yang"],"pdf_url":"https://arxiv.org/pdf/2408.00762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00760v1","updated":"2024-08-01T17:59:09Z","published":"2024-08-01T17:59:09Z","title":"Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy\n  Curvature of Attention","summary":"  Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.\n","authors":["Susung Hong"],"pdf_url":"https://arxiv.org/pdf/2408.00760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00759v1","updated":"2024-08-01T17:58:19Z","published":"2024-08-01T17:58:19Z","title":"Text-Guided Video Masked Autoencoder","summary":"  Recent video masked autoencoder (MAE) works have designed improved masking\nalgorithms focused on saliency. These works leverage visual cues such as motion\nto mask the most salient regions. However, the robustness of such visual cues\ndepends on how often input videos match underlying assumptions. On the other\nhand, natural language description is an information dense representation of\nvideo that implicitly captures saliency without requiring modality-specific\nassumptions, and has not been explored yet for video MAE. To this end, we\nintroduce a novel text-guided masking algorithm (TGM) that masks the video\nregions with highest correspondence to paired captions. Without leveraging any\nexplicit visual cues for saliency, our TGM is competitive with state-of-the-art\nmasking algorithms such as motion-guided masking. To further benefit from the\nsemantics of natural language for masked reconstruction, we next introduce a\nunified framework for joint MAE and masked video-text contrastive learning. We\nshow that across existing masking algorithms, unifying MAE and masked\nvideo-text contrastive learning improves downstream performance compared to\npure MAE on a variety of video recognition tasks, especially for linear probe.\nWithin this unified framework, our TGM achieves the best relative performance\non five action recognition and one egocentric datasets, highlighting the\ncomplementary nature of natural language for masked video modeling.\n","authors":["David Fan","Jue Wang","Shuai Liao","Zhikang Zhang","Vimal Bhat","Xinyu Li"],"pdf_url":"https://arxiv.org/pdf/2408.00759v1.pdf","comment":"Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00756v1","updated":"2024-08-01T17:57:25Z","published":"2024-08-01T17:57:25Z","title":"Segment anything model 2: an application to 2D and 3D medical images","summary":"  Segment Anything Model (SAM) has gained significant attention because of its\nability to segment a variety of objects in images given a prompt. The recently\ndeveloped SAM 2 has extended this ability to video inputs. This opens an\nopportunity to apply SAM to 3D images, one of the fundamental tasks in the\nmedical imaging field. In this paper, we provide an extensive evaluation of SAM\n2's ability to segment both 2D and 3D medical images. We collect 18 medical\nimaging datasets, including common 3D modalities such as computed tomography\n(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)\nas well as 2D modalities such as X-ray and ultrasound. We consider two\nevaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where prompts\nare provided to one or multiple slice(s) selected from the volume, and (2)\nsingle-frame 2D segmentation, where prompts are provided to each slice. The\nformer is only applicable to 3D modalities, while the latter applies to both 2D\nand 3D modalities. We learn that SAM 2 exhibits similar performance as SAM\nunder single-frame 2D segmentation, and has variable performance under\nmulti-frame 3D segmentation depending on the choices of slices to annotate, the\ndirection of the propagation, the predictions utilized during the propagation,\netc.\n","authors":["Haoyu Dong","Hanxue Gu","Yaqian Chen","Jichen Yang","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.00756v1.pdf","comment":"11 pages, 7 figures. A first attempt on evaluating SAM 2 on medical\n  images"},{"id":"http://arxiv.org/abs/2408.00754v1","updated":"2024-08-01T17:57:12Z","published":"2024-08-01T17:57:12Z","title":"Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal\n  Language Model","summary":"  Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.\n","authors":["Benlin Liu","Yuhao Dong","Yiqin Wang","Yongming Rao","Yansong Tang","Wei-Chiu Ma","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2408.00754v1.pdf","comment":"project page: https://coarse-correspondence.github.io"},{"id":"http://arxiv.org/abs/2408.00749v1","updated":"2024-08-01T17:52:10Z","published":"2024-08-01T17:52:10Z","title":"Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer","summary":"  Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.\n","authors":["Venkat Margapuri","Prapti Thapaliya","Trevor Rife"],"pdf_url":"https://arxiv.org/pdf/2408.00749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00744v1","updated":"2024-08-01T17:48:08Z","published":"2024-08-01T17:48:08Z","title":"Collaborative Vision-Text Representation Optimizing for Open-Vocabulary\n  Segmentation","summary":"  Pre-trained vision-language models, e.g. CLIP, have been increasingly used to\naddress the challenging Open-Vocabulary Segmentation (OVS) task, benefiting\nfrom their well-aligned vision-text embedding space. Typical solutions involve\neither freezing CLIP during training to unilaterally maintain its zero-shot\ncapability, or fine-tuning CLIP vision encoder to achieve perceptual\nsensitivity to local regions. However, few of them incorporate vision-text\ncollaborative optimization. Based on this, we propose the Content-Dependent\nTransfer to adaptively enhance each text embedding by interacting with the\ninput image, which presents a parameter-efficient way to optimize the text\nrepresentation. Besides, we additionally introduce a Representation\nCompensation strategy, reviewing the original CLIP-V representation as\ncompensation to maintain the zero-shot capability of CLIP. In this way, the\nvision and text representation of CLIP are optimized collaboratively, enhancing\nthe alignment of the vision-text feature space. To the best of our knowledge,\nwe are the first to establish the collaborative vision-text optimizing\nmechanism within the OVS field. Extensive experiments demonstrate our method\nachieves superior performance on popular OVS benchmarks. In open-vocabulary\nsemantic segmentation, our method outperforms the previous state-of-the-art\napproaches by +0.5, +2.3, +3.4, +0.4 and +1.1 mIoU, respectively on A-847,\nA-150, PC-459, PC-59 and PAS-20. Furthermore, in a panoptic setting on ADE20K,\nwe achieve the performance of 27.1 PQ, 73.5 SQ, and 32.9 RQ. Code will be\navailable at https://github.com/jiaosiyu1999/MAFT-Plus.git .\n","authors":["Siyu Jiao","Hongguang Zhu","Jiannan Huang","Yao Zhao","Yunchao Wei","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2408.00744v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00738v1","updated":"2024-08-01T17:35:58Z","published":"2024-08-01T17:35:58Z","title":"Virchow 2: Scaling Self-Supervised Mixed Magnification Models in\n  Pathology","summary":"  Foundation models are rapidly being developed for computational pathology\napplications. However, it remains an open question which factors are most\nimportant for downstream performance with data scale and diversity, model size,\nand training algorithm all playing a role. In this work, we present the result\nof scaling both data and model size, surpassing previous studies in both\ndimensions, and introduce two new models: Virchow 2, a 632M parameter vision\ntransformer, and Virchow 2G, a 1.85B parameter vision transformer, each trained\nwith 3.1M histopathology whole slide images. To support this scale, we propose\ndomain-inspired adaptations to the DINOv2 training algorithm, which is quickly\nbecoming the default method in self-supervised learning for computational\npathology. We achieve state of the art performance on twelve tile-level tasks,\nas compared to the top performing competing models. Our results suggest that\ndata diversity and domain-specific training can outperform models that only\nscale in the number of parameters, but, on average, performance benefits from\ndomain-tailoring, data scale, and model scale.\n","authors":["Eric Zimmermann","Eugene Vorontsov","Julian Viret","Adam Casson","Michal Zelechowski","George Shaikovski","Neil Tenenholtz","James Hall","Thomas Fuchs","Nicolo Fusi","Siqi Liu","Kristen Severson"],"pdf_url":"https://arxiv.org/pdf/2408.00738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00735v1","updated":"2024-08-01T17:27:28Z","published":"2024-08-01T17:27:28Z","title":"TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models","summary":"  Diffusion models have opened the path to a wide range of text-based image\nediting frameworks. However, these typically build on the multi-step nature of\nthe diffusion backwards process, and adapting them to distilled, fast-sampling\nmethods has proven surprisingly challenging. Here, we focus on a popular line\nof text-based editing frameworks - the ``edit-friendly'' DDPM-noise inversion\napproach. We analyze its application to fast sampling methods and categorize\nits failures into two classes: the appearance of visual artifacts, and\ninsufficient editing strength. We trace the artifacts to mismatched noise\nstatistics between inverted noises and the expected noise schedule, and suggest\na shifted noise schedule which corrects for this offset. To increase editing\nstrength, we propose a pseudo-guidance approach that efficiently increases the\nmagnitude of edits without introducing new artifacts. All in all, our method\nenables text-based image editing with as few as three diffusion steps, while\nproviding novel insights into the mechanisms behind popular text-based editing\napproaches.\n","authors":["Gilad Deutch","Rinon Gal","Daniel Garibi","Or Patashnik","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2408.00735v1.pdf","comment":"Project page: https://turboedit-paper.github.io/"},{"id":"http://arxiv.org/abs/2408.00714v1","updated":"2024-08-01T17:00:08Z","published":"2024-08-01T17:00:08Z","title":"SAM 2: Segment Anything in Images and Videos","summary":"  We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.\n","authors":["Nikhila Ravi","Valentin Gabeur","Yuan-Ting Hu","Ronghang Hu","Chaitanya Ryali","Tengyu Ma","Haitham Khedr","Roman Rädle","Chloe Rolland","Laura Gustafson","Eric Mintun","Junting Pan","Kalyan Vasudev Alwala","Nicolas Carion","Chao-Yuan Wu","Ross Girshick","Piotr Dollár","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2408.00714v1.pdf","comment":"Website: https://ai.meta.com/sam2"},{"id":"http://arxiv.org/abs/2408.00712v1","updated":"2024-08-01T16:58:50Z","published":"2024-08-01T16:58:50Z","title":"MotionFix: Text-Driven 3D Human Motion Editing","summary":"  The focus of this paper is 3D motion editing. Given a 3D human motion and a\ntextual description of the desired modification, our goal is to generate an\nedited motion as described by the text. The challenges include the lack of\ntraining data and the design of a model that faithfully edits the source\nmotion. In this paper, we address both these challenges. We build a methodology\nto semi-automatically collect a dataset of triplets in the form of (i) a source\nmotion, (ii) a target motion, and (iii) an edit text, and create the new\nMotionFix dataset. Having access to such data allows us to train a conditional\ndiffusion model, TMED, that takes both the source motion and the edit text as\ninput. We further build various baselines trained only on text-motion pairs\ndatasets, and show superior performance of our model trained on triplets. We\nintroduce new retrieval-based metrics for motion editing and establish a new\nbenchmark on the evaluation set of MotionFix. Our results are encouraging,\npaving the way for further research on finegrained motion generation. Code and\nmodels will be made publicly available.\n","authors":["Nikos Athanasiou","Alpár Ceske","Markos Diomataris","Michael J. Black","Gül Varol"],"pdf_url":"https://arxiv.org/pdf/2408.00712v1.pdf","comment":"arXiv v1"},{"id":"http://arxiv.org/abs/2408.00707v1","updated":"2024-08-01T16:54:11Z","published":"2024-08-01T16:54:11Z","title":"Synthetic dual image generation for reduction of labeling efforts in\n  semantic segmentation of micrographs with a customized metric function","summary":"  Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.\n","authors":["Matias Oscar Volman Stern","Dominic Hohs","Andreas Jansche","Timo Bernthaler","Gerhard Schneider"],"pdf_url":"https://arxiv.org/pdf/2408.00707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00706v1","updated":"2024-08-01T16:52:39Z","published":"2024-08-01T16:52:39Z","title":"Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM","summary":"  Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.\n","authors":["Xiaofeng Liu","Jonghye Woo","Chao Ma","Jinsong Ouyang","Georges El Fakhri"],"pdf_url":"https://arxiv.org/pdf/2408.00706v1.pdf","comment":"2024 IEEE Nuclear Science Symposium and Medical Imaging Conference"},{"id":"http://arxiv.org/abs/2408.00701v1","updated":"2024-08-01T16:48:03Z","published":"2024-08-01T16:48:03Z","title":"Joint Neural Networks for One-shot Object Recognition and Detection","summary":"  This paper presents a novel joint neural networks approach to address the\nchallenging one-shot object recognition and detection tasks. Inspired by\nSiamese neural networks and state-of-art multi-box detection approaches, the\njoint neural networks are able to perform object recognition and detection for\ncategories that remain unseen during the training process. Following the\none-shot object recognition/detection constraints, the training and testing\ndatasets do not contain overlapped classes, in other words, all the test\nclasses remain unseen during training. The joint networks architecture is able\nto effectively compare pairs of images via stacked convolutional layers of the\nquery and target inputs, recognising patterns of the same input query category\nwithout relying on previous training around this category. The proposed\napproach achieves 61.41% accuracy for one-shot object recognition on the\nMiniImageNet dataset and 47.1% mAP for one-shot object detection when trained\non the COCO dataset and tested using the Pascal VOC dataset. Code available at\nhttps://github.com/cjvargasc/JNN recog and https://github.com/cjvargasc/JNN\ndetection/\n","authors":["Camilo J. Vargas","Qianni Zhang","Ebroul Izquierdo"],"pdf_url":"https://arxiv.org/pdf/2408.00701v1.pdf","comment":"published as part of the PhD thesis:\n  https://qmro.qmul.ac.uk/xmlui/handle/123456789/72758"},{"id":"http://arxiv.org/abs/2408.00677v1","updated":"2024-08-01T16:20:02Z","published":"2024-08-01T16:20:02Z","title":"Scaling Backwards: Minimal Synthetic Pre-training?","summary":"  Pre-training and transfer learning are an important building block of current\ncomputer vision systems. While pre-training is usually performed on large\nreal-world image datasets, in this paper we ask whether this is truly\nnecessary. To this end, we search for a minimal, purely synthetic pre-training\ndataset that allows us to achieve performance similar to the 1 million images\nof ImageNet-1k. We construct such a dataset from a single fractal with\nperturbations. With this, we contribute three main findings. (i) We show that\npre-training is effective even with minimal synthetic images, with performance\non par with large-scale pre-training datasets like ImageNet-1k for full\nfine-tuning. (ii) We investigate the single parameter with which we construct\nartificial categories for our dataset. We find that while the shape differences\ncan be indistinguishable to humans, they are crucial for obtaining strong\nperformances. (iii) Finally, we investigate the minimal requirements for\nsuccessful pre-training. Surprisingly, we find that a substantial reduction of\nsynthetic images from 1k to 1 can even lead to an increase in pre-training\nperformance, a motivation to further investigate ``scaling backwards''.\nFinally, we extend our method from synthetic images to real images to see if a\nsingle real image can show similar pre-training effect through shape\naugmentation. We find that the use of grayscale images and affine\ntransformations allows even real images to ``scale backwards''.\n","authors":["Ryo Nakamura","Ryu Tadokoro","Ryosuke Yamada","Yuki M. Asano","Iro Laina","Christian Rupprecht","Nakamasa Inoue","Rio Yokota","Hirokatsu Kataoka"],"pdf_url":"https://arxiv.org/pdf/2408.00677v1.pdf","comment":"Accepted to ECCV2024"},{"id":"http://arxiv.org/abs/2408.00672v1","updated":"2024-08-01T16:13:07Z","published":"2024-08-01T16:13:07Z","title":"ExpertAF: Expert Actionable Feedback from Video","summary":"  Feedback is essential for learning a new skill or improving one's current\nskill-level. However, current methods for skill-assessment from video only\nprovide scores or compare demonstrations, leaving the burden of knowing what to\ndo differently on the user. We introduce a novel method to generate actionable\nfeedback from video of a person doing a physical activity, such as basketball\nor soccer. Our method takes a video demonstration and its accompanying 3D body\npose and generates (1) free-form expert commentary describing what the person\nis doing well and what they could improve, and (2) a visual expert\ndemonstration that incorporates the required corrections. We show how to\nleverage Ego-Exo4D's videos of skilled activity and expert commentary together\nwith a strong language model to create a weakly-supervised training dataset for\nthis task, and we devise a multimodal video-language model to infer coaching\nfeedback. Our method is able to reason across multi-modal input combinations to\noutput full-spectrum, actionable coaching -- expert commentary, expert video\nretrieval, and the first-of-its-kind expert pose generation -- outperforming\nstrong vision-language models on both established metrics and human preference\nstudies.\n","authors":["Kumar Ashutosh","Tushar Nagarajan","Georgios Pavlakos","Kris Kitani","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2408.00672v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2408.00653v1","updated":"2024-08-01T15:41:57Z","published":"2024-08-01T15:41:57Z","title":"SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and\n  Illumination Disentanglement","summary":"  We present SF3D, a novel method for rapid and high-quality textured object\nmesh reconstruction from a single image in just 0.5 seconds. Unlike most\nexisting approaches, SF3D is explicitly trained for mesh generation,\nincorporating a fast UV unwrapping technique that enables swift texture\ngeneration rather than relying on vertex colors. The method also learns to\npredict material parameters and normal maps to enhance the visual quality of\nthe reconstructed 3D meshes. Furthermore, SF3D integrates a delighting step to\neffectively remove low-frequency illumination effects, ensuring that the\nreconstructed meshes can be easily used in novel illumination conditions.\nExperiments demonstrate the superior performance of SF3D over the existing\ntechniques. Project page: https://stable-fast-3d.github.io\n","authors":["Mark Boss","Zixuan Huang","Aaryaman Vasishta","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2408.00653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00644v1","updated":"2024-08-01T15:35:44Z","published":"2024-08-01T15:35:44Z","title":"Towards End-to-End Explainable Facial Action Unit Recognition via\n  Vision-Language Joint Learning","summary":"  Facial action units (AUs), as defined in the Facial Action Coding System\n(FACS), have received significant research interest owing to their diverse\nrange of applications in facial state analysis. Current mainstream FAU\nrecognition models have a notable limitation, i.e., focusing only on the\naccuracy of AU recognition and overlooking explanations of corresponding AU\nstates. In this paper, we propose an end-to-end Vision-Language joint learning\nnetwork for explainable FAU recognition (termed VL-FAU), which aims to\nreinforce AU representation capability and language interpretability through\nthe integration of joint multimodal tasks. Specifically, VL-FAU brings together\nlanguage models to generate fine-grained local muscle descriptions and\ndistinguishable global face description when optimising FAU recognition.\nThrough this, the global facial representation and its local AU representations\nwill achieve higher distinguishability among different AUs and different\nsubjects. In addition, multi-level AU representation learning is utilised to\nimprove AU individual attention-aware representation capabilities based on\nmulti-scale combined facial stem feature. Extensive experiments on DISFA and\nBP4D AU datasets show that the proposed approach achieves superior performance\nover the state-of-the-art methods on most of the metrics. In addition, compared\nwith mainstream FAU recognition methods, VL-FAU can provide local- and\nglobal-level interpretability language descriptions with the AUs' predictions.\n","authors":["Xuri Ge","Junchen Fu","Fuhai Chen","Shan An","Nicu Sebe","Joemon M. Jose"],"pdf_url":"https://arxiv.org/pdf/2408.00644v1.pdf","comment":"10 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2408.00640v1","updated":"2024-08-01T15:27:48Z","published":"2024-08-01T15:27:48Z","title":"AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data\n  for 3D-Native Segmentation","summary":"  This study investigates the impact of self-supervised pretraining of 3D\nsemantic segmentation models on a large-scale, domain-specific dataset. We\nintroduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from public\nsources, the largest public dataset available, and revisit a number of design\nchoices for pretraining modern segmentation architectures by simplifying and\noptimizing state-of-the-art methods, and combining them with a novel\naugmentation strategy. The resulting AMAES framework is based on\nmasked-image-modeling and intensity-based augmentation reversal and balances\nmemory usage, runtime, and finetuning performance. Using the popular U-Net and\nthe recent MedNeXt architecture as backbones, we evaluate the effect of\npretraining on three challenging downstream tasks, covering single-sequence,\nlow-resource settings, and out-of-domain generalization. The results highlight\nthat pretraining on the proposed dataset with AMAES significantly improves\nsegmentation performance in the majority of evaluated cases, and that it is\nbeneficial to pretrain the model with augmentations, despite pretraing on a\nlarge-scale dataset. Code and model checkpoints for reproducing results, as\nwell as the BRAINS-45K dataset are available at\n\\url{https://github.com/asbjrnmunk/amaes}.\n","authors":["Asbjørn Munk","Jakob Ambsdorf","Sebastian Llambias","Mads Nielsen"],"pdf_url":"https://arxiv.org/pdf/2408.00640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00639v1","updated":"2024-08-01T15:26:24Z","published":"2024-08-01T15:26:24Z","title":"Privacy-preserving datasets by capturing feature distributions with\n  Conditional VAEs","summary":"  Large and well-annotated datasets are essential for advancing deep learning\napplications, however often costly or impossible to obtain by a single entity.\nIn many areas, including the medical domain, approaches relying on data sharing\nhave become critical to address those challenges. While effective in increasing\ndataset size and diversity, data sharing raises significant privacy concerns.\nCommonly employed anonymization methods based on the k-anonymity paradigm often\nfail to preserve data diversity, affecting model robustness. This work\nintroduces a novel approach using Conditional Variational Autoencoders (CVAEs)\ntrained on feature vectors extracted from large pre-trained vision foundation\nmodels. Foundation models effectively detect and represent complex patterns\nacross diverse domains, allowing the CVAE to faithfully capture the embedding\nspace of a given data distribution to generate (sample) a diverse,\nprivacy-respecting, and potentially unbounded set of synthetic feature vectors.\nOur method notably outperforms traditional approaches in both medical and\nnatural image domains, exhibiting greater dataset diversity and higher\nrobustness against perturbations while preserving sample privacy. These results\nunderscore the potential of generative models to significantly impact deep\nlearning applications in data-scarce and privacy-sensitive environments. The\nsource code is available at\nhttps://github.com/francescodisalvo05/cvae-anonymization .\n","authors":["Francesco Di Salvo","David Tafler","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2408.00639v1.pdf","comment":"Accepted at BMVC 2024"},{"id":"http://arxiv.org/abs/2408.00636v1","updated":"2024-08-01T15:20:20Z","published":"2024-08-01T15:20:20Z","title":"Deep Learning in Medical Image Classification from MRI-based Brain Tumor\n  Images","summary":"  Brain tumors are among the deadliest diseases in the world. Magnetic\nResonance Imaging (MRI) is one of the most effective ways to detect brain\ntumors. Accurate detection of brain tumors based on MRI scans is critical, as\nit can potentially save many lives and facilitate better decision-making at the\nearly stages of the disease. Within our paper, four different types of\nMRI-based images have been collected from the database: glioma tumor, no tumor,\npituitary tumor, and meningioma tumor. Our study focuses on making predictions\nfor brain tumor classification. Five models, including four pre-trained models\n(MobileNet, EfficientNet-B0, ResNet-18, and VGG16) and one new model,\nMobileNet-BT, have been proposed for this study.\n","authors":["Xiaoyi Liu","Zhuoyue Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00629v1","updated":"2024-08-01T15:14:10Z","published":"2024-08-01T15:14:10Z","title":"Empowering Snapshot Compressive Imaging: Spatial-Spectral State Space\n  Model with Across-Scanning and Local Enhancement","summary":"  Snapshot Compressive Imaging (SCI) relies on decoding algorithms such as CNN\nor Transformer to reconstruct the hyperspectral image (HSI) from its compressed\nmeasurement. Although existing CNN and Transformer-based methods have proven\neffective, CNNs are limited by their inadequate modeling of long-range\ndependencies, while Transformer ones face high computational costs due to\nquadratic complexity. Recent Mamba models have demonstrated superior\nperformance over CNN and Transformer-based architectures in some visual tasks,\nbut these models have not fully utilized the local similarities in both spatial\nand spectral dimensions. Moreover, the long-sequence modeling capability of SSM\nmay offer an advantage in processing the numerous spectral bands for HSI\nreconstruction, which has not yet been explored. In this paper, we introduce a\nState Space Model with Across-Scanning and Local Enhancement, named ASLE-SSM,\nthat employs a Spatial-Spectral SSM for global-local balanced context encoding\nand cross-channel interaction promoting. Specifically, we introduce local\nscanning in the spatial dimension to balance the global and local receptive\nfields, and then propose our across-scanning method based on spatial-spectral\nlocal cubes to leverage local similarities between adjacent spectral bands and\npixels to guide the reconstruction process. These two scanning mechanisms\nextract the HSI's local features while balancing the global perspective without\nany additional costs. Experimental results illustrate ASLE-SSM's superiority\nover existing state-of-the-art methods, with an inference speed 2.4 times\nfaster than Transformer-based MST and saving 0.12 (M) of parameters, achieving\nthe lowest computational cost and parameter count.\n","authors":["Wenzhe Tian","Haijin Zeng","Yin-Ping Zhao","Yongyong Chen","Zhen Wang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.00629v1.pdf","comment":"12 pages,6 figures"},{"id":"http://arxiv.org/abs/2408.00624v1","updated":"2024-08-01T15:09:32Z","published":"2024-08-01T15:09:32Z","title":"SynesLM: A Unified Approach for Audio-visual Speech Recognition and\n  Translation via Language Model and Synthetic Data","summary":"  In this work, we present SynesLM, an unified model which can perform three\nmultimodal language understanding tasks: audio-visual automatic speech\nrecognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).\nUnlike previous research that focused on lip motion as visual cues for speech\nsignals, our work explores more general visual information within entire\nframes, such as objects and actions. Additionally, we use synthetic image data\nto enhance the correlation between image and speech data. We benchmark SynesLM\nagainst the How2 dataset, demonstrating performance on par with\nstate-of-the-art (SOTA) models dedicated to AV-ASR while maintaining our\nmultitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTA\nperformance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on the\nVisSpeech Dataset. Furthermore, our results in VST and VMT outperform the\nprevious results, improving the BLEU score to 43.5 from 37.2 for VST, and to\n54.8 from 54.4 for VMT.\n","authors":["Yichen Lu","Jiaqi Song","Xuankai Chang","Hengwei Bian","Soumi Maiti","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2408.00624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00620v1","updated":"2024-08-01T15:05:42Z","published":"2024-08-01T15:05:42Z","title":"Are Bigger Encoders Always Better in Vision Large Models?","summary":"  In recent years, multimodal large language models (MLLMs) have shown strong\npotential in real-world applications. They are developing rapidly due to their\nremarkable ability to comprehend multimodal information and their inherent\npowerful cognitive and reasoning capabilities. Among MLLMs, vision language\nmodels (VLM) stand out for their ability to understand vision information.\nHowever, the scaling trend of VLMs under the current mainstream paradigm has\nnot been extensively studied. Whether we can achieve better performance by\ntraining even larger models is still unclear. To address this issue, we\nconducted experiments on the pretraining stage of MLLMs. We conduct our\nexperiment using different encoder sizes and large language model (LLM) sizes.\nOur findings indicate that merely increasing the size of encoders does not\nnecessarily enhance the performance of VLMs. Moreover, we analyzed the effects\nof LLM backbone parameter size and data quality on the pretraining outcomes.\nAdditionally, we explored the differences in scaling laws between LLMs and\nVLMs.\n","authors":["Bozhou Li","Hao Liang","Zimo Meng","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00619v1","updated":"2024-08-01T15:01:07Z","published":"2024-08-01T15:01:07Z","title":"Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object\n  Detection","summary":"  Unsupervised 3D object detection aims to identify objects of interest from\nunlabeled raw data, such as LiDAR points. Recent approaches usually adopt\npseudo 3D bounding boxes (3D bboxes) from clustering algorithm to initialize\nthe model training, and then iteratively updating both pseudo labels and the\ntrained model. However, pseudo bboxes inevitably contain noises, and such\ninaccurate annotation accumulates to the final model, compromising the\nperformance. Therefore, in an attempt to mitigate the negative impact of pseudo\nbboxes, we introduce a new uncertainty-aware framework. In particular, Our\nmethod consists of two primary components: uncertainty estimation and\nuncertainty regularization. (1) In the uncertainty estimation phase, we\nincorporate an extra auxiliary detection branch alongside the primary detector.\nThe prediction disparity between the primary and auxiliary detectors is\nleveraged to estimate uncertainty at the box coordinate level, including\nposition, shape, orientation. (2) Based on the assessed uncertainty, we\nregularize the model training via adaptively adjusting every 3D bboxes\ncoordinates. For pseudo bbox coordinates with high uncertainty, we assign a\nrelatively low loss weight. Experiment verifies that the proposed method is\nrobust against the noisy pseudo bboxes, yielding substantial improvements on\nnuScenes and Lyft compared to existing techniques, with increases of 6.9% in\nAP$_{BEV}$ and 2.5% in AP$_{3D}$ on nuScenes, and 2.2% in AP$_{BEV}$ and 1.0%\nin AP$_{3D}$ on Lyft.\n","authors":["Ruiyang Zhang","Hu Zhang","Hang Yu","Zhedong Zheng"],"pdf_url":"https://arxiv.org/pdf/2408.00619v1.pdf","comment":"Preprint, 14 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2408.00599v1","updated":"2024-08-01T14:31:06Z","published":"2024-08-01T14:31:06Z","title":"Learned Compression of Point Cloud Geometry and Attributes in a Single\n  Model through Multimodal Rate-Control","summary":"  Point cloud compression is essential to experience volumetric multimedia as\nit drastically reduces the required streaming data rates. Point attributes,\nspecifically colors, extend the challenge of lossy compression beyond geometric\nrepresentation to achieving joint reconstruction of texture and geometry.\nState-of-the-art methods separate geometry and attributes to compress them\nindividually. This comes at a computational cost, requiring an encoder and a\ndecoder for each modality. Additionally, as attribute compression methods\nrequire the same geometry for encoding and decoding, the encoder emulates the\ndecoder-side geometry reconstruction as an input step to project and compress\nthe attributes. In this work, we propose to learn joint compression of geometry\nand attributes using a single, adaptive autoencoder model, embedding both\nmodalities into a unified latent space which is then entropy encoded. Key to\nthe technique is to replace the search for trade-offs between rate, attribute\nquality and geometry quality, through conditioning the model on the desired\nqualities of both modalities, bypassing the need for training model ensembles.\nTo differentiate important point cloud regions during encoding or to allow\nview-dependent compression for user-centered streaming, conditioning is\npointwise, which allows for local quality and rate variation. Our evaluation\nshows comparable performance to state-of-the-art compression methods for\ngeometry and attributes, while reducing complexity compared to related\ncompression methods.\n","authors":["Michael Rudolph","Aron Riemenschneider","Amr Rizk"],"pdf_url":"https://arxiv.org/pdf/2408.00599v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2408.00591v1","updated":"2024-08-01T14:20:47Z","published":"2024-08-01T14:20:47Z","title":"Regional quality estimation for echocardiography using deep learning","summary":"  Automatic estimation of cardiac ultrasound image quality can be beneficial\nfor guiding operators and ensuring the accuracy of clinical measurements.\nPrevious work often fails to distinguish the view correctness of the\nechocardiogram from the image quality. Additionally, previous studies only\nprovide a global image quality value, which limits their practical utility. In\nthis work, we developed and compared three methods to estimate image quality:\n1) classic pixel-based metrics like the generalized contrast-to-noise ratio\n(gCNR) on myocardial segments as region of interest and left ventricle lumen as\nbackground, obtained using a U-Net segmentation 2) local image coherence\nderived from a U-Net model that predicts coherence from B-Mode images 3) a deep\nconvolutional network that predicts the quality of each region directly in an\nend-to-end fashion. We evaluate each method against manual regional image\nquality annotations by three experienced cardiologists. The results indicate\npoor performance of the gCNR metric, with Spearman correlation to the\nannotations of \\r{ho} = 0.24. The end-to-end learning model obtains the best\nresult, \\r{ho} = 0.69, comparable to the inter-observer correlation, \\r{ho} =\n0.63. Finally, the coherence-based method, with \\r{ho} = 0.58, outperformed the\nclassical metrics and is more generic than the end-to-end approach.\n","authors":["Gilles Van De Vyver","Svein-Erik Måsøy","Håvard Dalen","Bjørnar Leangen Grenne","Espen Holte","Sindre Hellum Olaisen","John Nyberg","Andreas Østvik","Lasse Løvstakken","Erik Smistad"],"pdf_url":"https://arxiv.org/pdf/2408.00591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00565v1","updated":"2024-08-01T13:52:18Z","published":"2024-08-01T13:52:18Z","title":"MUFASA: Multi-View Fusion and Adaptation Network with Spatial Awareness\n  for Radar Object Detection","summary":"  In recent years, approaches based on radar object detection have made\nsignificant progress in autonomous driving systems due to their robustness\nunder adverse weather compared to LiDAR. However, the sparsity of radar point\nclouds poses challenges in achieving precise object detection, highlighting the\nimportance of effective and comprehensive feature extraction technologies. To\naddress this challenge, this paper introduces a comprehensive feature\nextraction method for radar point clouds. This study first enhances the\ncapability of detection networks by using a plug-and-play module, GeoSPA. It\nleverages the Lalonde features to explore local geometric patterns.\nAdditionally, a distributed multi-view attention mechanism, DEMVA, is designed\nto integrate the shared information across the entire dataset with the global\ninformation of each individual frame. By employing the two modules, we present\nour method, MUFASA, which enhances object detection performance through\nimproved feature extraction. The approach is evaluated on the VoD and\nTJ4DRaDSet datasets to demonstrate its effectiveness. In particular, we achieve\nstate-of-the-art results among radar-based methods on the VoD dataset with the\nmAP of 50.24%.\n","authors":["Xiangyuan Peng","Miao Tang","Huawei Sun","Kay Bierzynski","Lorenzo Servadei","Robert Wille"],"pdf_url":"https://arxiv.org/pdf/2408.00565v1.pdf","comment":"Accepted by ICANN 2024"},{"id":"http://arxiv.org/abs/2408.00555v1","updated":"2024-08-01T13:38:58Z","published":"2024-08-01T13:38:58Z","title":"Alleviating Hallucination in Large Vision-Language Models with Active\n  Retrieval Augmentation","summary":"  Despite the remarkable ability of large vision-language models (LVLMs) in\nimage comprehension, these models frequently generate plausible yet factually\nincorrect responses, a phenomenon known as hallucination.Recently, in large\nlanguage models (LLMs), augmenting LLMs by retrieving information from external\nknowledge resources has been proven as a promising solution to mitigate\nhallucinations.However, the retrieval augmentation in LVLM significantly lags\nbehind the widespread applications of LVLM. Moreover, when transferred to\naugmenting LVLMs, sometimes the hallucination degree of the model is even\nexacerbated.Motivated by the research gap and counter-intuitive phenomenon, we\nintroduce a novel framework, the Active Retrieval-Augmented large\nvision-language model (ARA), specifically designed to address hallucinations by\nincorporating three critical dimensions: (i) dissecting the retrieval targets\nbased on the inherent hierarchical structures of images. (ii) pinpointing the\nmost effective retrieval methods and filtering out the reliable retrieval\nresults. (iii) timing the retrieval process to coincide with episodes of low\ncertainty, while circumventing unnecessary retrieval during periods of high\ncertainty. To assess the capability of our proposed ARA model in reducing\nhallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and\nmPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by\nutilizing fitting retrieval mechanisms and timing the retrieval judiciously, we\ncan effectively mitigate the hallucination problem. We hope that this study can\nprovide deeper insights into how to adapt the retrieval augmentation to LVLMs\nfor reducing hallucinations with more effective retrieval and minimal retrieval\noccurrences.\n","authors":["Xiaoye Qu","Qiyuan Chen","Wei Wei","Jishuo Sun","Jianfeng Dong"],"pdf_url":"https://arxiv.org/pdf/2408.00555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00550v1","updated":"2024-08-01T13:34:35Z","published":"2024-08-01T13:34:35Z","title":"Mitigating Multilingual Hallucination in Large Vision-Language Models","summary":"  While Large Vision-Language Models (LVLMs) have exhibited remarkable\ncapabilities across a wide range of tasks, they suffer from hallucination\nproblems, where models generate plausible yet incorrect answers given the input\nimage-query pair. This hallucination phenomenon is even more severe when\nquerying the image in non-English languages, while existing methods for\nmitigating hallucinations in LVLMs only consider the English scenarios. In this\npaper, we make the first attempt to mitigate this important multilingual\nhallucination in LVLMs. With thorough experiment analysis, we found that\nmultilingual hallucination in LVLMs is a systemic problem that could arise from\ndeficiencies in multilingual capabilities or inadequate multimodal abilities.\nTo this end, we propose a two-stage Multilingual Hallucination Removal (MHR)\nframework for LVLMs, aiming to improve resistance to hallucination for both\nhigh-resource and low-resource languages. Instead of relying on the intricate\nmanual annotations of multilingual resources, we fully leverage the inherent\ncapabilities of the LVLM and propose a novel cross-lingual alignment method,\nwhich generates multiple responses for each image-query input and then\nidentifies the hallucination-aware pairs for each language. These data pairs\nare finally used for direct preference optimization to prompt the LVLMs to\nfavor non-hallucinating responses. Experimental results show that our MHR\nachieves a substantial reduction in hallucination generation for LVLMs.\nNotably, on our extended multilingual POPE benchmark, our framework delivers an\naverage increase of 19.0% in accuracy across 13 different languages. Our code\nand model weights are available at https://github.com/ssmisya/MHR\n","authors":["Xiaoye Qu","Mingyang Song","Wei Wei","Jianfeng Dong","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2408.00550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00538v1","updated":"2024-08-01T13:21:34Z","published":"2024-08-01T13:21:34Z","title":"High-Quality, ROS Compatible Video Encoding and Decoding for\n  High-Definition Datasets","summary":"  Robotic datasets are important for scientific benchmarking and developing\nalgorithms, for example for Simultaneous Localization and Mapping (SLAM).\nModern robotic datasets feature video data of high resolution and high\nframerates. Storing and sharing those datasets becomes thus very costly,\nespecially if more than one camera is used for the datasets. It is thus\nessential to store this video data in a compressed format. This paper\ninvestigates the use of modern video encoders for robotic datasets. We provide\na software that can replay mp4 videos within ROS 1 and ROS 2 frameworks,\nsupporting the synchronized playback in simulated time. Furthermore, the paper\nevaluates different encoders and their settings to find optimal configurations\nin terms of resulting size, quality and encoding time. Through this work we\nshow that it is possible to store and share even highest quality video datasets\nwithin reasonable storage constraints.\n","authors":["Jian Li","Bowen Xu","Sören Schwertfeger"],"pdf_url":"https://arxiv.org/pdf/2408.00538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00498v1","updated":"2024-08-01T12:08:20Z","published":"2024-08-01T12:08:20Z","title":"How Effective are Self-Supervised Models for Contact Identification in\n  Videos","summary":"  The exploration of video content via Self-Supervised Learning (SSL) models\nhas unveiled a dynamic field of study, emphasizing both the complex challenges\nand unique opportunities inherent in this area. Despite the growing body of\nresearch, the ability of SSL models to detect physical contacts in videos\nremains largely unexplored, particularly the effectiveness of methods such as\ndownstream supervision with linear probing or full fine-tuning. This work aims\nto bridge this gap by employing eight different convolutional neural networks\n(CNNs) based video SSL models to identify instances of physical contact within\nvideo sequences specifically. The Something-Something v2 (SSv2) and\nEpic-Kitchen (EK-100) datasets were chosen for evaluating these approaches due\nto the promising results on UCF101 and HMDB51, coupled with their limited prior\nassessment on SSv2 and EK-100. Additionally, these datasets feature diverse\nenvironments and scenarios, essential for testing the robustness and accuracy\nof video-based models. This approach not only examines the effectiveness of\neach model in recognizing physical contacts but also explores the performance\nin the action recognition downstream task. By doing so, valuable insights into\nthe adaptability of SSL models in interpreting complex, dynamic visual\ninformation are contributed.\n","authors":["Malitha Gunawardhana","Limalka Sadith","Liel David","Daniel Harari","Muhammad Haris Khan"],"pdf_url":"https://arxiv.org/pdf/2408.00498v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.00496v1","updated":"2024-08-01T12:05:02Z","published":"2024-08-01T12:05:02Z","title":"SegStitch: Multidimensional Transformer for Robust and Efficient Medical\n  Imaging Segmentation","summary":"  Medical imaging segmentation plays a significant role in the automatic\nrecognition and analysis of lesions. State-of-the-art methods, particularly\nthose utilizing transformers, have been prominently adopted in 3D semantic\nsegmentation due to their superior performance in scalability and\ngeneralizability. However, plain vision transformers encounter challenges due\nto their neglect of local features and their high computational complexity. To\naddress these challenges, we introduce three key contributions: Firstly, we\nproposed SegStitch, an innovative architecture that integrates transformers\nwith denoising ODE blocks. Instead of taking whole 3D volumes as inputs, we\nadapt axial patches and customize patch-wise queries to ensure semantic\nconsistency. Additionally, we conducted extensive experiments on the BTCV and\nACDC datasets, achieving improvements up to 11.48% and 6.71% respectively in\nmDSC, compared to state-of-the-art methods. Lastly, our proposed method\ndemonstrates outstanding efficiency, reducing the number of parameters by 36.7%\nand the number of FLOPS by 10.7% compared to UNETR. This advancement holds\npromising potential for adapting our method to real-world clinical practice.\nThe code will be available at https://github.com/goblin327/SegStitch\n","authors":["Shengbo Tan","Zeyu Zhang","Ying Cai","Daji Ergu","Lin Wu","Binbin Hu","Pengzhang Yu","Yang Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.00496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00493v1","updated":"2024-08-01T11:53:44Z","published":"2024-08-01T11:53:44Z","title":"Explainable Emotion Decoding for Human and Computer Vision","summary":"  Modern Machine Learning (ML) has significantly advanced various research\nfields, but the opaque nature of ML models hinders their adoption in several\ndomains. Explainable AI (XAI) addresses this challenge by providing additional\ninformation to help users understand the internal decision-making process of ML\nmodels. In the field of neuroscience, enriching a ML model for brain decoding\nwith attribution-based XAI techniques means being able to highlight which brain\nareas correlate with the task at hand, thus offering valuable insights to\ndomain experts. In this paper, we analyze human and Computer Vision (CV)\nsystems in parallel, training and explaining two ML models based respectively\non functional Magnetic Resonance Imaging (fMRI) and movie frames. We do so by\nleveraging the \"StudyForrest\" dataset, which includes functional Magnetic\nResonance Imaging (fMRI) scans of subjects watching the \"Forrest Gump\" movie,\nemotion annotations, and eye-tracking data. For human vision the ML task is to\nlink fMRI data with emotional annotations, and the explanations highlight the\nbrain regions strongly correlated with the label. On the other hand, for\ncomputer vision, the input data is movie frames, and the explanations are\npixel-level heatmaps. We cross-analyzed our results, linking human attention\n(obtained through eye-tracking) with XAI saliency on CV models and brain region\nactivations. We show how a parallel analysis of human and computer vision can\nprovide useful information for both the neuroscience community (allocation\ntheory) and the ML community (biological plausibility of convolutional models).\n","authors":["Alessio Borriero","Martina Milazzo","Matteo Diano","Davide Orsenigo","Maria Chiara Villa","Chiara Di Fazio","Marco Tamietto","Alan Perotti"],"pdf_url":"https://arxiv.org/pdf/2408.00493v1.pdf","comment":"This work has been accepted to be presented to The 2nd World\n  Conference on eXplainable Artificial Intelligence (xAI 2024), July 17-19,\n  2024 - Malta"},{"id":"http://arxiv.org/abs/2408.00491v1","updated":"2024-08-01T11:52:56Z","published":"2024-08-01T11:52:56Z","title":"GalleryGPT: Analyzing Paintings with Large Multimodal Models","summary":"  Artwork analysis is important and fundamental skill for art appreciation,\nwhich could enrich personal aesthetic sensibility and facilitate the critical\nthinking ability. Understanding artworks is challenging due to its subjective\nnature, diverse interpretations, and complex visual elements, requiring\nexpertise in art history, cultural background, and aesthetic theory. However,\nlimited by the data collection and model ability, previous works for\nautomatically analyzing artworks mainly focus on classification, retrieval, and\nother simple tasks, which is far from the goal of AI. To facilitate the\nresearch progress, in this paper, we step further to compose comprehensive\nanalysis inspired by the remarkable perception and generation ability of large\nmultimodal models. Specifically, we first propose a task of composing paragraph\nanalysis for artworks, i.e., painting in this paper, only focusing on visual\ncharacteristics to formulate more comprehensive understanding of artworks. To\nsupport the research on formal analysis, we collect a large dataset\nPaintingForm, with about 19k painting images and 50k analysis paragraphs. We\nfurther introduce a superior large multimodal model for painting analysis\ncomposing, dubbed GalleryGPT, which is slightly modified and fine-tuned based\non LLaVA architecture leveraging our collected data. We conduct formal analysis\ngeneration and zero-shot experiments across several datasets to assess the\ncapacity of our model. The results show remarkable performance improvements\ncomparing with powerful baseline LMMs, demonstrating its superb ability of art\nanalysis and generalization. \\textcolor{blue}{The codes and model are available\nat: https://github.com/steven640pixel/GalleryGPT.\n","authors":["Yi Bin","Wenhao Shi","Yujuan Ding","Zhiqiang Hu","Zheng Wang","Yang Yang","See-Kiong Ng","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00491v1.pdf","comment":"Accepted as Oral Presentation at ACM Multimedia 2024"},{"id":"http://arxiv.org/abs/2408.00489v1","updated":"2024-08-01T11:51:50Z","published":"2024-08-01T11:51:50Z","title":"Multi-label Sewer Pipe Defect Recognition with Mask Attention Feature\n  Enhancement and Label Correlation Learning","summary":"  The coexistence of multiple defect categories as well as the substantial\nclass imbalance problem significantly impair the detection of sewer pipeline\ndefects. To solve this problem, a multi-label pipe defect recognition method is\nproposed based on mask attention guided feature enhancement and label\ncorrelation learning. The proposed method can achieve current approximate\nstate-of-the-art classification performance using just 1/16 of the Sewer-ML\ntraining dataset and exceeds the current best method by 11.87\\% in terms of F2\nmetric on the full dataset, while also proving the superiority of the model.\nThe major contribution of this study is the development of a more efficient\nmodel for identifying and locating multiple defects in sewer pipe images for a\nmore accurate sewer pipeline condition assessment. Moreover, by employing class\nactivation maps, our method can accurately pinpoint multiple defect categories\nin the image which demonstrates a strong model interpretability. Our code is\navailable at\n\\href{https://github.com/shengyu27/MA-Q2L}{\\textcolor{black}{https://github.com/shengyu27/MA-Q2L.}\n","authors":["Xin Zuo","Yu Sheng","Jifeng Shen","Yongwei Shan"],"pdf_url":"https://arxiv.org/pdf/2408.00489v1.pdf","comment":"Accepted by the Journal of Computing in Civil Engineering"},{"id":"http://arxiv.org/abs/2408.00483v1","updated":"2024-08-01T11:39:45Z","published":"2024-08-01T11:39:45Z","title":"A Systematic Review on Long-Tailed Learning","summary":"  Long-tailed data is a special type of multi-class imbalanced data with a very\nlarge amount of minority/tail classes that have a very significant combined\ninfluence. Long-tailed learning aims to build high-performance models on\ndatasets with long-tailed distributions, which can identify all the classes\nwith high accuracy, in particular the minority/tail classes. It is a\ncutting-edge research direction that has attracted a remarkable amount of\nresearch effort in the past few years. In this paper, we present a\ncomprehensive survey of latest advances in long-tailed visual learning. We\nfirst propose a new taxonomy for long-tailed learning, which consists of eight\ndifferent dimensions, including data balancing, neural architecture, feature\nenrichment, logits adjustment, loss function, bells and whistles, network\noptimization, and post hoc processing techniques. Based on our proposed\ntaxonomy, we present a systematic review of long-tailed learning methods,\ndiscussing their commonalities and alignable differences. We also analyze the\ndifferences between imbalance learning and long-tailed learning approaches.\nFinally, we discuss prospects and future directions in this field.\n","authors":["Chongsheng Zhang","George Almpanidis","Gaojuan Fan","Binquan Deng","Yanbo Zhang","Ji Liu","Aouaidjia Kamel","Paolo Soda","João Gama"],"pdf_url":"https://arxiv.org/pdf/2408.00483v1.pdf","comment":"Current Under Revision at IEEE TNNLS. [This is the long/Full-length\n  version of our Long-Tailed Learning Survey paper]"},{"id":"http://arxiv.org/abs/2408.00470v1","updated":"2024-08-01T11:16:26Z","published":"2024-08-01T11:16:26Z","title":"Image Super-Resolution with Taylor Expansion Approximation and Large\n  Field Reception","summary":"  Self-similarity techniques are booming in blind super-resolution (SR) due to\naccurate estimation of the degradation types involved in low-resolution images.\nHowever, high-dimensional matrix multiplication within self-similarity\ncomputation prohibitively consumes massive computational costs. We find that\nthe high-dimensional attention map is derived from the matrix multiplication\nbetween Query and Key, followed by a softmax function. This softmax makes the\nmatrix multiplication between Query and Key inseparable, posing a great\nchallenge in simplifying computational complexity. To address this issue, we\nfirst propose a second-order Taylor expansion approximation (STEA) to separate\nthe matrix multiplication of Query and Key, resulting in the complexity\nreduction from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Then, we design a\nmulti-scale large field reception (MLFR) to compensate for the performance\ndegradation caused by STEA. Finally, we apply these two core designs to\nlaboratory and real-world scenarios by constructing LabNet and RealNet,\nrespectively. Extensive experimental results tested on five synthetic datasets\ndemonstrate that our LabNet sets a new benchmark in qualitative and\nquantitative evaluations. Tested on the RealWorld38 dataset, our RealNet\nachieves superior visual quality over existing methods. Ablation studies\nfurther verify the contributions of STEA and MLFR towards both LabNet and\nRealNet frameworks.\n","authors":["Jiancong Feng","Yuan-Gen Wang","Mingjie Li","Fengchuang Xing"],"pdf_url":"https://arxiv.org/pdf/2408.00470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00458v1","updated":"2024-08-01T10:55:20Z","published":"2024-08-01T10:55:20Z","title":"Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual\n  Inversion","summary":"  Recent years have seen a tremendous improvement in the quality of video\ngeneration and editing approaches. While several techniques focus on editing\nappearance, few address motion. Current approaches using text, trajectories, or\nbounding boxes are limited to simple motions, so we specify motions with a\nsingle motion reference video instead. We further propose to use a pre-trained\nimage-to-video model rather than a text-to-video model. This approach allows us\nto preserve the exact appearance and position of a target object or scene and\nhelps disentangle appearance from motion. Our method, called motion-textual\ninversion, leverages our observation that image-to-video models extract\nappearance mainly from the (latent) image input, while the text/image embedding\ninjected via cross-attention predominantly controls motion. We thus represent\nmotion using text/image embedding tokens. By operating on an inflated\nmotion-text embedding containing multiple text/image embedding tokens per\nframe, we achieve a high temporal motion granularity. Once optimized on the\nmotion reference video, this embedding can be applied to various target images\nto generate videos with semantically similar motions. Our approach does not\nrequire spatial alignment between the motion reference video and target image,\ngeneralizes across various domains, and can be applied to various tasks such as\nfull-body and face reenactment, as well as controlling the motion of inanimate\nobjects and the camera. We empirically demonstrate the effectiveness of our\nmethod in the semantic video motion transfer task, significantly outperforming\nexisting methods in this context.\n","authors":["Manuel Kansy","Jacek Naruniec","Christopher Schroers","Markus Gross","Romann M. Weber"],"pdf_url":"https://arxiv.org/pdf/2408.00458v1.pdf","comment":"Preprint. All videos in this paper are best viewed as animations with\n  Acrobat Reader by pressing the highlighted frame of each video"},{"id":"http://arxiv.org/abs/2408.00441v1","updated":"2024-08-01T10:25:14Z","published":"2024-08-01T10:25:14Z","title":"Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and\n  Flexible Scene Text Retrieval","summary":"  Scene text retrieval aims to find all images containing the query text from\nan image gallery. Current efforts tend to adopt an Optical Character\nRecognition (OCR) pipeline, which requires complicated text detection and/or\nrecognition processes, resulting in inefficient and inflexible retrieval.\nDifferent from them, in this work we propose to explore the intrinsic potential\nof Contrastive Language-Image Pre-training (CLIP) for OCR-free scene text\nretrieval. Through empirical analysis, we observe that the main challenges of\nCLIP as a text retriever are: 1) limited text perceptual scale, and 2)\nentangled visual-semantic concepts. To this end, a novel model termed FDP\n(Focus, Distinguish, and Prompt) is developed. FDP first focuses on scene text\nvia shifting the attention to the text area and probing the hidden text\nknowledge, and then divides the query text into content word and function word\nfor processing, in which a semantic-aware prompting scheme and a distracted\nqueries assistance module are utilized. Extensive experiments show that FDP\nsignificantly enhances the inference speed while achieving better or\ncompetitive retrieval accuracy compared to existing methods. Notably, on the\nIIIT-STR benchmark, FDP surpasses the state-of-the-art model by 4.37% with a 4\ntimes faster speed. Furthermore, additional experiments under phrase-level and\nattribute-aware scene text retrieval settings validate FDP's particular\nadvantages in handling diverse forms of query text. The source code will be\npublicly available at https://github.com/Gyann-z/FDP.\n","authors":["Gangyan Zeng","Yuan Zhang","Jin Wei","Dongbao Yang","Peng Zhang","Yiwen Gao","Xugong Qin","Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.00441v1.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2408.00438v1","updated":"2024-08-01T10:16:58Z","published":"2024-08-01T10:16:58Z","title":"MonoMM: A Multi-scale Mamba-Enhanced Network for Real-time Monocular 3D\n  Object Detection","summary":"  Recent advancements in transformer-based monocular 3D object detection\ntechniques have exhibited exceptional performance in inferring 3D attributes\nfrom single 2D images. However, most existing methods rely on\nresource-intensive transformer architectures, which often lead to significant\ndrops in computational efficiency and performance when handling long sequence\ndata. To address these challenges and advance monocular 3D object detection\ntechnology, we propose an innovative network architecture, MonoMM, a\nMulti-scale \\textbf{M}amba-Enhanced network for real-time Monocular 3D object\ndetection. This well-designed architecture primarily includes the following two\ncore modules: Focused Multi-Scale Fusion (FMF) Module, which focuses on\neffectively preserving and fusing image information from different scales with\nlower computational resource consumption. By precisely regulating the\ninformation flow, the FMF module enhances the model adaptability and robustness\nto scale variations while maintaining image details. Depth-Aware Feature\nEnhancement Mamba (DMB) Module: It utilizes the fused features from image\ncharacteristics as input and employs a novel adaptive strategy to globally\nintegrate depth information and visual information. This depth fusion strategy\nnot only improves the accuracy of depth estimation but also enhances the model\nperformance under different viewing angles and environmental conditions.\nMoreover, the modular design of MonoMM provides high flexibility and\nscalability, facilitating adjustments and optimizations according to specific\napplication needs. Extensive experiments conducted on the KITTI dataset show\nthat our method outperforms previous monocular methods and achieves real-time\ndetection.\n","authors":["Youjia Fu","Zihao Xu","Junsong Fu","Huixia Xue","Shuqiu Tan","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2408.00438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00427v1","updated":"2024-08-01T09:59:57Z","published":"2024-08-01T09:59:57Z","title":"CARMIL: Context-Aware Regularization on Multiple Instance Learning\n  models for Whole Slide Images","summary":"  Multiple Instance Learning (MIL) models have proven effective for cancer\nprognosis from Whole Slide Images. However, the original MIL formulation\nincorrectly assumes the patches of the same image to be independent, leading to\na loss of spatial context as information flows through the network.\nIncorporating contextual knowledge into predictions is particularly important\ngiven the inclination for cancerous cells to form clusters and the presence of\nspatial indicators for tumors. State-of-the-art methods often use attention\nmechanisms eventually combined with graphs to capture spatial knowledge. In\nthis paper, we take a novel and transversal approach, addressing this issue\nthrough the lens of regularization. We propose Context-Aware Regularization for\nMultiple Instance Learning (CARMIL), a versatile regularization scheme designed\nto seamlessly integrate spatial knowledge into any MIL model. Additionally, we\npresent a new and generic metric to quantify the Context-Awareness of any MIL\nmodel when applied to Whole Slide Images, resolving a previously unexplored gap\nin the field. The efficacy of our framework is evaluated for two survival\nanalysis tasks on glioblastoma (TCGA GBM) and colon cancer data (TCGA COAD).\n","authors":["Thiziri Nait Saada","Valentina Di-Proietto","Benoit Schmauch","Katharina Von Loga","Lucas Fidon"],"pdf_url":"https://arxiv.org/pdf/2408.00427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00420v1","updated":"2024-08-01T09:42:44Z","published":"2024-08-01T09:42:44Z","title":"MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition","summary":"  The objective of the panoramic activity recognition task is to identify\nbehaviors at various granularities within crowded and complex environments,\nencompassing individual actions, social group activities, and global\nactivities. Existing methods generally use either parameter-independent modules\nto capture task-specific features or parameter-sharing modules to obtain common\nfeatures across all tasks. However, there is often a strong interrelatedness\nand complementary effect between tasks of different granularities that previous\nmethods have yet to notice. In this paper, we propose a model called MPT-PAR\nthat considers both the unique characteristics of each task and the synergies\nbetween different tasks simultaneously, thereby maximizing the utilization of\nfeatures across multi-granularity activity recognition. Furthermore, we\nemphasize the significance of temporal and spatial information by introducing a\nspatio-temporal relation-enhanced module and a scene representation learning\nmodule, which integrate the the spatio-temporal context of action and global\nscene into the feature map of each granularity. Our method achieved an overall\nF1 score of 47.5\\% on the JRDB-PAR dataset, significantly outperforming all the\nstate-of-the-art methods.\n","authors":["Wenqing Gan","Yan Sun","Feiran Liu","Xiangfeng Luo"],"pdf_url":"https://arxiv.org/pdf/2408.00420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00418v1","updated":"2024-08-01T09:39:27Z","published":"2024-08-01T09:39:27Z","title":"Towards Reliable Advertising Image Generation Using Human Feedback","summary":"  In the e-commerce realm, compelling advertising images are pivotal for\nattracting customer attention. While generative models automate image\ngeneration, they often produce substandard images that may mislead customers\nand require significant labor costs to inspect. This paper delves into\nincreasing the rate of available generated images. We first introduce a\nmulti-modal Reliable Feedback Network (RFNet) to automatically inspect the\ngenerated images. Combining the RFNet into a recurrent process, Recurrent\nGeneration, results in a higher number of available advertising images. To\nfurther enhance production efficiency, we fine-tune diffusion models with an\ninnovative Consistent Condition regularization utilizing the feedback from\nRFNet (RFFT). This results in a remarkable increase in the available rate of\ngenerated images, reducing the number of attempts in Recurrent Generation, and\nproviding a highly efficient production process without sacrificing visual\nappeal. We also construct a Reliable Feedback 1 Million (RF1M) dataset which\ncomprises over one million generated advertising images annotated by human,\nwhich helps to train RFNet to accurately assess the availability of generated\nimages and faithfully reflect the human feedback. Generally speaking, our\napproach offers a reliable solution for advertising image generation.\n","authors":["Zhenbang Du","Wei Feng","Haohan Wang","Yaoyu Li","Jingsen Wang","Jian Li","Zheng Zhang","Jingjing Lv","Xin Zhu","Junsheng Jin","Junjie Shen","Zhangang Lin","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2408.00418v1.pdf","comment":"ECCV2024"},{"id":"http://arxiv.org/abs/2408.00415v1","updated":"2024-08-01T09:32:01Z","published":"2024-08-01T09:32:01Z","title":"DriveArena: A Closed-loop Generative Simulation Platform for Autonomous\n  Driving","summary":"  This paper presented DriveArena, the first high-fidelity closed-loop\nsimulation system designed for driving agents navigating in real scenarios.\nDriveArena features a flexible, modular architecture, allowing for the seamless\ninterchange of its core components: Traffic Manager, a traffic simulator\ncapable of generating realistic traffic flow on any worldwide street map, and\nWorld Dreamer, a high-fidelity conditional generative model with infinite\nautoregression. This powerful synergy empowers any driving agent capable of\nprocessing real-world images to navigate in DriveArena's simulated environment.\nThe agent perceives its surroundings through images generated by World Dreamer\nand output trajectories. These trajectories are fed into Traffic Manager,\nachieving realistic interactions with other vehicles and producing a new scene\nlayout. Finally, the latest scene layout is relayed back into World Dreamer,\nperpetuating the simulation cycle. This iterative process fosters closed-loop\nexploration within a highly realistic environment, providing a valuable\nplatform for developing and evaluating driving agents across diverse and\nchallenging scenarios. DriveArena signifies a substantial leap forward in\nleveraging generative image data for the driving simulation platform, opening\ninsights for closed-loop autonomous driving. Code will be available soon on\nGitHub: https://github.com/PJLab-ADG/DriveArena\n","authors":["Xuemeng Yang","Licheng Wen","Yukai Ma","Jianbiao Mei","Xin Li","Tiantian Wei","Wenjie Lei","Daocheng Fu","Pinlong Cai","Min Dou","Botian Shi","Liang He","Yong Liu","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.00415v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.00388v1","updated":"2024-08-01T08:57:47Z","published":"2024-08-01T08:57:47Z","title":"Deepfake Media Forensics: State of the Art and Challenges Ahead","summary":"  AI-generated synthetic media, also called Deepfakes, have significantly\ninfluenced so many domains, from entertainment to cybersecurity. Generative\nAdversarial Networks (GANs) and Diffusion Models (DMs) are the main frameworks\nused to create Deepfakes, producing highly realistic yet fabricated content.\nWhile these technologies open up new creative possibilities, they also bring\nsubstantial ethical and security risks due to their potential misuse. The rise\nof such advanced media has led to the development of a cognitive bias known as\nImpostor Bias, where individuals doubt the authenticity of multimedia due to\nthe awareness of AI's capabilities. As a result, Deepfake detection has become\na vital area of research, focusing on identifying subtle inconsistencies and\nartifacts with machine learning techniques, especially Convolutional Neural\nNetworks (CNNs). Research in forensic Deepfake technology encompasses five main\nareas: detection, attribution and recognition, passive authentication,\ndetection in realistic scenarios, and active authentication. Each area tackles\nspecific challenges, from tracing the origins of synthetic media and examining\nits inherent characteristics for authenticity. This paper reviews the primary\nalgorithms that address these challenges, examining their advantages,\nlimitations, and future prospects.\n","authors":["Irene Amerini","Mauro Barni","Sebastiano Battiato","Paolo Bestagini","Giulia Boato","Tania Sari Bonaventura","Vittoria Bruni","Roberto Caldelli","Francesco De Natale","Rocco De Nicola","Luca Guarnera","Sara Mandelli","Gian Luca Marcialis","Marco Micheletto","Andrea Montibeller","Giulia Orru'","Alessandro Ortis","Pericle Perazzo","Davide Salvi","Stefano Tubaro","Claudia Melis Tonti","Massimo Villari","Domenico Vitulano"],"pdf_url":"https://arxiv.org/pdf/2408.00388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00380v1","updated":"2024-08-01T08:41:13Z","published":"2024-08-01T08:41:13Z","title":"Enhancing Whole Slide Pathology Foundation Models through Stain\n  Normalization","summary":"  Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nStain Normalized Pathology Foundational Model, a novel foundational model\ntrained on patches that have undergone stain normalization. Stain normalization\nhelps reduce color variability arising from different laboratories and\nscanners, enabling the model to learn more consistent features. Stain\nNormalized Pathology Foundational Model is trained using 285,153,903 patches\nextracted from a total of 34,795 WSIs, combining data from The Cancer Genome\nAtlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments\ndemonstrate that Stain Normalized Pathology Foundational Model significantly\nmitigates the feature collapse problem, indicating that the model has learned\nmore generalized features rather than overfitting to individual WSI\ncharacteristics. We compared Stain Normalized Pathology Foundational Model with\nstate-of-the-art models across six downstream task datasets, and our results\nshow that \\name{} achieves excellent performance relative to the number of WSIs\nused and the model's parameter count. This suggests that the application of\nstain normalization has substantially improved the model's efficiency and\ngeneralization capabilities.\n","authors":["Juseung Yun","Yi Hu","Jinhyung Kim","Jongseong Jang","Soonyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00380v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.00374v1","updated":"2024-08-01T08:32:03Z","published":"2024-08-01T08:32:03Z","title":"Conformal Trajectory Prediction with Multi-View Data Integration in\n  Cooperative Driving","summary":"  Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\n\\url{https://github.com/xichennn/V2I_trajectory_prediction}.\n","authors":["Xi Chen","Rahul Bhadani","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2408.00374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00372v1","updated":"2024-08-01T08:29:42Z","published":"2024-08-01T08:29:42Z","title":"Few-shot Defect Image Generation based on Consistency Modeling","summary":"  Image generation can solve insufficient labeled data issues in defect\ndetection. Most defect generation methods are only trained on a single product\nwithout considering the consistencies among multiple products, leading to poor\nquality and diversity of generated results. To address these issues, we propose\nDefectDiffu, a novel text-guided diffusion method to model both intra-product\nbackground consistency and inter-product defect consistency across multiple\nproducts and modulate the consistency perturbation directions to control\nproduct type and defect strength, achieving diversified defect image\ngeneration. Firstly, we leverage a text encoder to separately provide\nconsistency prompts for background, defect, and fusion parts of the\ndisentangled integrated architecture, thereby disentangling defects and normal\nbackgrounds. Secondly, we propose the double-free strategy to generate defect\nimages through two-stage perturbation of consistency direction, thereby\ncontrolling product type and defect strength by adjusting the perturbation\nscale. Besides, DefectDiffu can generate defect mask annotations utilizing\ncross-attention maps from the defect part. Finally, to improve the generation\nquality of small defects and masks, we propose the adaptive attention-enhance\nloss to increase the attention to defects. Experimental results demonstrate\nthat DefectDiffu surpasses state-of-the-art methods in terms of generation\nquality and diversity, thus effectively improving downstream defection\nperformance. Moreover, defect perturbation directions can be transferred among\nvarious products to achieve zero-shot defect generation, which is highly\nbeneficial for addressing insufficient data issues. The code are available at\nhttps://github.com/FFDD-diffusion/DefectDiffu.\n","authors":["Qingfeng Shi","Jing Wei","Fei Shen","Zhengtao Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00365v1","updated":"2024-08-01T08:10:32Z","published":"2024-08-01T08:10:32Z","title":"Multimodal Fusion and Coherence Modeling for Video Topic Segmentation","summary":"  The video topic segmentation (VTS) task segments videos into intelligible,\nnon-overlapping topics, facilitating efficient comprehension of video content\nand quick access to specific content. VTS is also critical to various\ndownstream video understanding tasks. Traditional VTS methods using shallow\nfeatures or unsupervised approaches struggle to accurately discern the nuances\nof topical transitions. Recently, supervised approaches have achieved superior\nperformance on video action or scene segmentation over unsupervised approaches.\nIn this work, we improve supervised VTS by thoroughly exploring multimodal\nfusion and multimodal coherence modeling. Specifically, (1) we enhance\nmultimodal fusion by exploring different architectures using cross-attention\nand mixture of experts. (2) To generally strengthen multimodality alignment and\nfusion, we pre-train and fine-tune the model with multimodal contrastive\nlearning. (3) We propose a new pre-training task tailored for the VTS task, and\na novel fine-tuning task for enhancing multimodal coherence modeling for VTS.\nWe evaluate the proposed approaches on educational videos, in the form of\nlectures, due to the vital role of topic segmentation of educational videos in\nboosting learning experiences. Additionally, we introduce a large-scale Chinese\nlecture video dataset to augment the existing English corpus, promoting further\nresearch in VTS. Experiments on both English and Chinese lecture datasets\ndemonstrate that our model achieves superior VTS performance compared to\ncompetitive unsupervised and supervised baselines.\n","authors":["Hai Yu","Chong Deng","Qinglin Zhang","Jiaqing Liu","Qian Chen","Wen Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00361v1","updated":"2024-08-01T08:03:13Z","published":"2024-08-01T08:03:13Z","title":"High-Precision Self-Supervised Monocular Depth Estimation with\n  Rich-Resource Prior","summary":"  In the area of self-supervised monocular depth estimation, models that\nutilize rich-resource inputs, such as high-resolution and multi-frame inputs,\ntypically achieve better performance than models that use ordinary single image\ninput. However, these rich-resource inputs may not always be available,\nlimiting the applicability of these methods in general scenarios. In this\npaper, we propose Rich-resource Prior Depth estimator (RPrDepth), which only\nrequires single input image during the inference phase but can still produce\nhighly accurate depth estimations comparable to rich resource based methods.\nSpecifically, we treat rich-resource data as prior information and extract\nfeatures from it as reference features in an offline manner. When estimating\nthe depth for a single-image image, we search for similar pixels from the\nrich-resource features and use them as prior information to estimate the depth.\nExperimental results demonstrate that our model outperform other single-image\nmodel and can achieve comparable or even better performance than models with\nrich-resource inputs, only using low-resolution single-image input.\n","authors":["Wencheng Han","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00361v1.pdf","comment":"ECCV2024"},{"id":"http://arxiv.org/abs/2408.00355v1","updated":"2024-08-01T07:52:07Z","published":"2024-08-01T07:52:07Z","title":"DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved\n  Denoising Training","summary":"  More and more end-to-end text spotting methods based on Transformer\narchitecture have demonstrated superior performance. These methods utilize a\nbipartite graph matching algorithm to perform one-to-one optimal matching\nbetween predicted objects and actual objects. However, the instability of\nbipartite graph matching can lead to inconsistent optimization targets, thereby\naffecting the training performance of the model. Existing literature applies\ndenoising training to solve the problem of bipartite graph matching instability\nin object detection tasks. Unfortunately, this denoising training method cannot\nbe directly applied to text spotting tasks, as these tasks need to perform\nirregular shape detection tasks and more complex text recognition tasks than\nclassification. To address this issue, we propose a novel denoising training\nmethod (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we\ndecompose the queries of the denoising part into noised positional queries and\nnoised content queries. We use the four Bezier control points of the Bezier\ncenter curve to generate the noised positional queries. For the noised content\nqueries, considering that the output of the text in a fixed positional order is\nnot conducive to aligning position with content, we employ a masked character\nsliding method to initialize noised content queries, thereby assisting in the\nalignment of text content and position. To improve the model's perception of\nthe background, we further utilize an additional loss function for background\ncharacters classification in the denoising training part.Although DNTextSpotter\nis conceptually simple, it outperforms the state-of-the-art methods on four\nbenchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially\nyielding an improvement of 11.3% against the best approach in Inverse-Text\ndataset.\n","authors":["Yu Xie","Qian Qiao","Jun Gao","Tianxiang Wu","Shaoyao Huang","Jiaqing Fan","Ziqiang Cao","Zili Wang","Yue Zhang","Jielei Zhang","Huyang Sun"],"pdf_url":"https://arxiv.org/pdf/2408.00355v1.pdf","comment":"Accepted by ACMMM2024"},{"id":"http://arxiv.org/abs/2408.00352v1","updated":"2024-08-01T07:44:11Z","published":"2024-08-01T07:44:11Z","title":"Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion","summary":"  Human motion generation driven by deep generative models has enabled\ncompelling applications, but the ability of text-to-motion (T2M) models to\nproduce realistic motions from text prompts raises security concerns if\nexploited maliciously. Despite growing interest in T2M, few methods focus on\nsafeguarding these models against adversarial attacks, with existing work on\ntext-to-image models proving insufficient for the unique motion domain. In the\npaper, we propose ALERT-Motion, an autonomous framework leveraging large\nlanguage models (LLMs) to craft targeted adversarial attacks against black-box\nT2M models. Unlike prior methods modifying prompts through predefined rules,\nALERT-Motion uses LLMs' knowledge of human motion to autonomously generate\nsubtle yet powerful adversarial text descriptions. It comprises two key\nmodules: an adaptive dispatching module that constructs an LLM-based agent to\niteratively refine and search for adversarial prompts; and a multimodal\ninformation contrastive module that extracts semantically relevant motion\ninformation to guide the agent's search. Through this LLM-driven approach,\nALERT-Motion crafts adversarial prompts querying victim models to produce\noutputs closely matching targeted motions, while avoiding obvious\nperturbations. Evaluations across popular T2M models demonstrate ALERT-Motion's\nsuperiority over previous methods, achieving higher attack success rates with\nstealthier adversarial prompts. This pioneering work on T2M adversarial attacks\nhighlights the urgency of developing defensive measures as motion generation\ntechnology advances, urging further research into safe and responsible\ndeployment.\n","authors":["Honglei Miao","Fan Ma","Ruijie Quan","Kun Zhan","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2408.00352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00351v1","updated":"2024-08-01T07:42:45Z","published":"2024-08-01T07:42:45Z","title":"Hierarchically Structured Neural Bones for Reconstructing Animatable\n  Objects from Casual Videos","summary":"  We propose a new framework for creating and easily manipulating 3D models of\narbitrary objects using casually captured videos. Our core ingredient is a\nnovel hierarchy deformation model, which captures motions of objects with a\ntree-structured bones. Our hierarchy system decomposes motions based on the\ngranularity and reveals the correlations between parts without exploiting any\nprior structural knowledge. We further propose to regularize the bones to be\npositioned at the basis of motions, centers of parts, sufficiently covering\nrelated surfaces of the part. This is achieved by our bone occupancy function,\nwhich identifies whether a given 3D point is placed within the bone. Coupling\nthe proposed components, our framework offers several clear advantages: (1)\nusers can obtain animatable 3D models of the arbitrary objects in improved\nquality from their casual videos, (2) users can manipulate 3D models in an\nintuitive manner with minimal costs, and (3) users can interactively add or\ndelete control points as necessary. The experimental results demonstrate the\nefficacy of our framework on diverse instances, in reconstruction quality,\ninterpretability and easier manipulation. Our code is available at\nhttps://github.com/subin6/HSNB.\n","authors":["Subin Jeon","In Cho","Minsu Kim","Woong Oh Cho","Seon Joo Kim"],"pdf_url":"https://arxiv.org/pdf/2408.00351v1.pdf","comment":"ECCV 2024 accepted"},{"id":"http://arxiv.org/abs/2408.00350v1","updated":"2024-08-01T07:40:00Z","published":"2024-08-01T07:40:00Z","title":"A Simple Background Augmentation Method for Object Detection with\n  Diffusion Model","summary":"  In computer vision, it is well-known that a lack of data diversity will\nimpair model performance. In this study, we address the challenges of enhancing\nthe dataset diversity problem in order to benefit various downstream tasks such\nas object detection and instance segmentation. We propose a simple yet\neffective data augmentation approach by leveraging advancements in generative\nmodels, specifically text-to-image synthesis technologies like Stable\nDiffusion. Our method focuses on generating variations of labeled real images,\nutilizing generative object and background augmentation via inpainting to\naugment existing training data without the need for additional annotations. We\nfind that background augmentation, in particular, significantly improves the\nmodels' robustness and generalization capabilities. We also investigate how to\nadjust the prompt and mask to ensure the generated content comply with the\nexisting annotations. The efficacy of our augmentation techniques is validated\nthrough comprehensive evaluations of the COCO dataset and several other key\nobject detection benchmarks, demonstrating notable enhancements in model\nperformance across diverse scenarios. This approach offers a promising solution\nto the challenges of dataset enhancement, contributing to the development of\nmore accurate and robust computer vision models.\n","authors":["Yuhang Li","Xin Dong","Chen Chen","Weiming Zhuang","Lingjuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2408.00350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00347v1","updated":"2024-08-01T07:35:54Z","published":"2024-08-01T07:35:54Z","title":"Advancing Medical Image Segmentation: Morphology-Driven Learning with\n  Diffusion Transformer","summary":"  Understanding the morphological structure of medical images and precisely\nsegmenting the region of interest or abnormality is an important task that can\nassist in diagnosis. However, the unique properties of medical imaging make\nclear segmentation difficult, and the high cost and time-consuming task of\nlabeling leads to a coarse-grained representation of ground truth. Facing with\nthese problems, we propose a novel Diffusion Transformer Segmentation (DTS)\nmodel for robust segmentation in the presence of noise. We propose an\nalternative to the dominant Denoising U-Net encoder through experiments\napplying a transformer architecture, which captures global dependency through\nself-attention. Additionally, we propose k-neighbor label smoothing, reverse\nboundary attention, and self-supervised learning with morphology-driven\nlearning to improve the ability to identify complex structures. Our model,\nwhich analyzes the morphological representation of images, shows better results\nthan the previous models in various medical imaging modalities, including CT,\nMRI, and lesion images.\n","authors":["Sungmin Kang","Jaeha Song","Jihie Kim"],"pdf_url":"https://arxiv.org/pdf/2408.00347v1.pdf","comment":"Accepted in BMVC 2024"},{"id":"http://arxiv.org/abs/2408.00343v1","updated":"2024-08-01T07:27:54Z","published":"2024-08-01T07:27:54Z","title":"IN-Sight: Interactive Navigation through Sight","summary":"  Current visual navigation systems often treat the environment as static,\nlacking the ability to adaptively interact with obstacles. This limitation\nleads to navigation failure when encountering unavoidable obstructions. In\nresponse, we introduce IN-Sight, a novel approach to self-supervised path\nplanning, enabling more effective navigation strategies through interaction\nwith obstacles. Utilizing RGB-D observations, IN-Sight calculates\ntraversability scores and incorporates them into a semantic map, facilitating\nlong-range path planning in complex, maze-like environments. To precisely\nnavigate around obstacles, IN-Sight employs a local planner, trained\nimperatively on a differentiable costmap using representation learning\ntechniques. The entire framework undergoes end-to-end training within the\nstate-of-the-art photorealistic Intel SPEAR Simulator. We validate the\neffectiveness of IN-Sight through extensive benchmarking in a variety of\nsimulated scenarios and ablation studies. Moreover, we demonstrate the system's\nreal-world applicability with zero-shot sim-to-real transfer, deploying our\nplanner on the legged robot platform ANYmal, showcasing its practical potential\nfor interactive navigation in real environments.\n","authors":["Philipp Schoch","Fan Yang","Yuntao Ma","Stefan Leutenegger","Marco Hutter","Quentin Leboute"],"pdf_url":"https://arxiv.org/pdf/2408.00343v1.pdf","comment":"The 2024 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2408.00337v1","updated":"2024-08-01T07:17:10Z","published":"2024-08-01T07:17:10Z","title":"DistillGrasp: Integrating Features Correlation with Knowledge\n  Distillation for Depth Completion of Transparent Objects","summary":"  Due to the visual properties of reflection and refraction, RGB-D cameras\ncannot accurately capture the depth of transparent objects, leading to\nincomplete depth maps. To fill in the missing points, recent studies tend to\nexplore new visual features and design complex networks to reconstruct the\ndepth, however, these approaches tremendously increase computation, and the\ncorrelation of different visual features remains a problem. To this end, we\npropose an efficient depth completion network named DistillGrasp which\ndistillates knowledge from the teacher branch to the student branch.\nSpecifically, in the teacher branch, we design a position correlation block\n(PCB) that leverages RGB images as the query and key to search for the\ncorresponding values, guiding the model to establish correct correspondence\nbetween two features and transfer it to the transparent areas. For the student\nbranch, we propose a consistent feature correlation module (CFCM) that retains\nthe reliable regions of RGB images and depth maps respectively according to the\nconsistency and adopts a CNN to capture the pairwise relationship for depth\ncompletion. To avoid the student branch only learning regional features from\nthe teacher branch, we devise a distillation loss that not only considers the\ndistance loss but also the object structure and edge information. Extensive\nexperiments conducted on the ClearGrasp dataset manifest that our teacher\nnetwork outperforms state-of-the-art methods in terms of accuracy and\ngeneralization, and the student network achieves competitive results with a\nhigher speed of 48 FPS. In addition, the significant improvement in a\nreal-world robotic grasping system illustrates the effectiveness and robustness\nof our proposed system.\n","authors":["Yiheng Huang","Junhong Chen","Nick Michiels","Muhammad Asim","Luc Claesen","Wenyin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.00337v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.00332v1","updated":"2024-08-01T07:10:45Z","published":"2024-08-01T07:10:45Z","title":"Vision-based Wearable Steering Assistance for People with Impaired\n  Vision in Jogging","summary":"  Outdoor sports pose a challenge for people with impaired vision. The demand\nfor higher-speed mobility inspired us to develop a vision-based wearable\nsteering assistance. To ensure broad applicability, we focused on a\nrepresentative sports environment, the athletics track. Our efforts centered on\nimproving the speed and accuracy of perception, enhancing planning adaptability\nfor the real world, and providing swift and safe assistance for people with\nimpaired vision. In perception, we engineered a lightweight multitask network\ncapable of simultaneously detecting track lines and obstacles. Additionally,\ndue to the limitations of existing datasets for supporting multi-task detection\nin athletics tracks, we diligently collected and annotated a new dataset (MAT)\ncontaining 1000 images. In planning, we integrated the methods of sampling and\nspline curves, addressing the planning challenges of curves. Meanwhile, we\nutilized the positions of the track lines and obstacles as constraints to guide\npeople with impaired vision safely along the current track. Our system is\ndeployed on an embedded device, Jetson Orin NX. Through outdoor experiments, it\ndemonstrated adaptability in different sports scenarios, assisting users in\nachieving free movement of 400-meter at an average speed of 1.34 m/s, meeting\nthe level of normal people in jogging. Our MAT dataset is publicly available\nfrom https://github.com/snoopy-l/MAT\n","authors":["Xiaotong Liu","Binglu Wang","Zhijun Li"],"pdf_url":"https://arxiv.org/pdf/2408.00332v1.pdf","comment":"Accepted to ICRA 2024"},{"id":"http://arxiv.org/abs/2408.00331v1","updated":"2024-08-01T07:08:11Z","published":"2024-08-01T07:08:11Z","title":"DECIDER: Leveraging Foundation Model Priors for Improved Model Failure\n  Detection and Explanation","summary":"  Reliably detecting when a deployed machine learning model is likely to fail\non a given input is crucial for ensuring safe operation. In this work, we\npropose DECIDER (Debiasing Classifiers to Identify Errors Reliably), a novel\napproach that leverages priors from large language models (LLMs) and\nvision-language models (VLMs) to detect failures in image classification\nmodels. DECIDER utilizes LLMs to specify task-relevant core attributes and\nconstructs a ``debiased'' version of the classifier by aligning its visual\nfeatures to these core attributes using a VLM, and detects potential failure by\nmeasuring disagreement between the original and debiased models. In addition to\nproactively identifying samples on which the model would fail, DECIDER also\nprovides human-interpretable explanations for failure through a novel\nattribute-ablation strategy. Through extensive experiments across diverse\nbenchmarks spanning subpopulation shifts (spurious correlations, class\nimbalance) and covariate shifts (synthetic corruptions, domain shifts), DECIDER\nconsistently achieves state-of-the-art failure detection performance,\nsignificantly outperforming baselines in terms of the overall Matthews\ncorrelation coefficient as well as failure and success recall. Our codes can be\naccessed at~\\url{https://github.com/kowshikthopalli/DECIDER/}\n","authors":["Rakshith Subramanyam","Kowshik Thopalli","Vivek Narayanaswamy","Jayaraman J. Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2408.00331v1.pdf","comment":"Accepted at ECCV (European Conference on Computer Vision) 2024"},{"id":"http://arxiv.org/abs/2408.00315v1","updated":"2024-08-01T06:26:05Z","published":"2024-08-01T06:26:05Z","title":"ADBM: Adversarial diffusion bridge model for reliable adversarial\n  purification","summary":"  Recently Diffusion-based Purification (DiffPure) has been recognized as an\neffective defense method against adversarial examples. However, we find\nDiffPure which directly employs the original pre-trained diffusion models for\nadversarial purification, to be suboptimal. This is due to an inherent\ntrade-off between noise purification performance and data recovery quality.\nAdditionally, the reliability of existing evaluations for DiffPure is\nquestionable, as they rely on weak adaptive attacks. In this work, we propose a\nnovel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs\na reverse bridge from the diffused adversarial data back to its original clean\nexamples, enhancing the purification capabilities of the original diffusion\nmodels. Through theoretical analysis and experimental validation across various\nscenarios, ADBM has proven to be a superior and robust defense mechanism,\noffering significant promise for practical applications.\n","authors":["Xiao Li","Wenxuan Sun","Huanran Chen","Qiongxiu Li","Yining Liu","Yingzhe He","Jie Shi","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2408.00315v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2408.00311v1","updated":"2024-08-01T06:14:37Z","published":"2024-08-01T06:14:37Z","title":"Translating Imaging to Genomics: Leveraging Transformers for Predictive\n  Modeling","summary":"  In this study, we present a novel approach for predicting genomic information\nfrom medical imaging modalities using a transformer-based model. We aim to\nbridge the gap between imaging and genomics data by leveraging transformer\nnetworks, allowing for accurate genomic profile predictions from CT/MRI images.\nPresently most studies rely on the use of whole slide images (WSI) for the\nassociation, which are obtained via invasive methodologies. We propose using\nonly available CT/MRI images to predict genomic sequences. Our transformer\nbased approach is able to efficiently generate associations between multiple\nsequences based on CT/MRI images alone. This work paves the way for the use of\nnon-invasive imaging modalities for precise and personalized healthcare,\nallowing for a better understanding of diseases and treatment.\n","authors":["Aiman Farooq","Deepak Mishra","Santanu Chaudhury"],"pdf_url":"https://arxiv.org/pdf/2408.00311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00303v1","updated":"2024-08-01T06:02:59Z","published":"2024-08-01T06:02:59Z","title":"Neural Octahedral Field: Octahedral prior for simultaneous smoothing and\n  sharp edge regularization","summary":"  Neural implicit representation, the parameterization of distance function as\na coordinate neural field, has emerged as a promising lead in tackling surface\nreconstruction from unoriented point clouds. To enforce consistent orientation,\nexisting methods focus on regularizing the gradient of the distance function,\nsuch as constraining it to be of the unit norm, minimizing its divergence, or\naligning it with the eigenvector of Hessian that corresponds to zero\neigenvalue. However, under the presence of large scanning noise, they tend to\neither overfit the noise input or produce an excessively smooth reconstruction.\nIn this work, we propose to guide the surface reconstruction under a new\nvariant of neural field, the octahedral field, leveraging the spherical\nharmonics representation of octahedral frames originated in the hexahedral\nmeshing. Such field automatically snaps to geometry features when constrained\nto be smooth, and naturally preserves sharp angles when interpolated over\ncreases. By simultaneously fitting and smoothing the octahedral field alongside\nthe implicit geometry, it behaves analogously to bilateral filtering, resulting\nin smooth reconstruction while preserving sharp edges. Despite being operated\npurely pointwise, our method outperforms various traditional and neural\napproaches across extensive experiments, and is very competitive with methods\nthat require normal and data priors. Our full implementation is available at:\nhttps://github.com/Ankbzpx/frame-field.\n","authors":["Ruichen Zheng","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2408.00303v1.pdf","comment":"project page: https://github.com/Ankbzpx/frame-field"},{"id":"http://arxiv.org/abs/2408.00300v1","updated":"2024-08-01T05:56:34Z","published":"2024-08-01T05:56:34Z","title":"Towards Flexible Evaluation for Generative Visual Question Answering","summary":"  Throughout rapid development of multimodal large language models, a crucial\ningredient is a fair and accurate evaluation of their multimodal comprehension\nabilities. Although Visual Question Answering (VQA) could serve as a developed\ntest field, limitations of VQA evaluation, like the inflexible pattern of Exact\nMatch, have hindered MLLMs from demonstrating their real capability and\ndiscourage rich responses. Therefore, this paper proposes the use of\nsemantics-based evaluators for assessing unconstrained open-ended responses on\nVQA datasets. As characteristics of VQA have made such evaluation significantly\ndifferent than the traditional Semantic Textual Similarity (STS) task, to\nsystematically analyze the behaviour and compare the performance of various\nevaluators including LLM-based ones, we proposes three key properties, i.e.,\nAlignment, Consistency and Generalization, and a corresponding dataset\nAssessing VQA Evaluators (AVE) to facilitate analysis. In addition, this paper\nproposes a Semantically Flexible VQA Evaluator (SFVE) with meticulous design\nbased on the unique features of VQA evaluation. Experimental results verify the\nfeasibility of model-based VQA evaluation and effectiveness of the proposed\nevaluator that surpasses existing semantic evaluators by a large margin. The\nproposed training scheme generalizes to both the BERT-like encoders and\ndecoder-only LLM.\n","authors":["Huishan Ji","Qingyi Si","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00298v1","updated":"2024-08-01T05:47:04Z","published":"2024-08-01T05:47:04Z","title":"Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names","summary":"  Enabling engagement of manga by visually impaired individuals presents a\nsignificant challenge due to its inherently visual nature. With the goal of\nfostering accessibility, this paper aims to generate a dialogue transcript of a\ncomplete manga chapter, entirely automatically, with a particular emphasis on\nensuring narrative consistency. This entails identifying (i) what is being\nsaid, i.e., detecting the texts on each page and classifying them into\nessential vs non-essential, and (ii) who is saying it, i.e., attributing each\ndialogue to its speaker, while ensuring the same characters are named\nconsistently throughout the chapter.\n  To this end, we introduce: (i) Magiv2, a model that is capable of generating\nhigh-quality chapter-wide manga transcripts with named characters and\nsignificantly higher precision in speaker diarisation over prior works; (ii) an\nextension of the PopManga evaluation dataset, which now includes annotations\nfor speech-bubble tail boxes, associations of text to corresponding tails,\nclassifications of text as essential or non-essential, and the identity for\neach character box; and (iii) a new character bank dataset, which comprises\nover 11K characters from 76 manga series, featuring 11.5K exemplar character\nimages in total, as well as a list of chapters in which they appear. The code,\ntrained model, and both datasets can be found at:\nhttps://github.com/ragavsachdeva/magi\n","authors":["Ragav Sachdeva","Gyungin Shin","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2408.00298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00297v1","updated":"2024-08-01T05:46:57Z","published":"2024-08-01T05:46:57Z","title":"EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking\n  Head","summary":"  We present a novel approach for synthesizing 3D talking heads with\ncontrollable emotion, featuring enhanced lip synchronization and rendering\nquality. Despite significant progress in the field, prior methods still suffer\nfrom multi-view consistency and a lack of emotional expressiveness. To address\nthese issues, we collect EmoTalk3D dataset with calibrated multi-view videos,\nemotional annotations, and per-frame 3D geometry. By training on the EmoTalk3D\ndataset, we propose a \\textit{`Speech-to-Geometry-to-Appearance'} mapping\nframework that first predicts faithful 3D geometry sequence from the audio\nfeatures, then the appearance of a 3D talking head represented by 4D Gaussians\nis synthesized from the predicted geometry. The appearance is further\ndisentangled into canonical and dynamic Gaussians, learned from multi-view\nvideos, and fused to render free-view talking head animation. Moreover, our\nmodel enables controllable emotion in the generated talking heads and can be\nrendered in wide-range views. Our method exhibits improved rendering quality\nand stability in lip motion generation while capturing dynamic facial details\nsuch as wrinkles and subtle expressions. Experiments demonstrate the\neffectiveness of our approach in generating high-fidelity and\nemotion-controllable 3D talking heads. The code and EmoTalk3D dataset are\nreleased at https://nju-3dv.github.io/projects/EmoTalk3D.\n","authors":["Qianyun He","Xinya Ji","Yicheng Gong","Yuanxun Lu","Zhengyu Diao","Linjia Huang","Yao Yao","Siyu Zhu","Zhan Ma","Songcen Xu","Xiaofei Wu","Zixiao Zhang","Xun Cao","Hao Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.00297v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00296v1","updated":"2024-08-01T05:46:06Z","published":"2024-08-01T05:46:06Z","title":"Head360: Learning a Parametric 3D Full-Head for Free-View Synthesis in\n  360°","summary":"  Creating a 360{\\deg} parametric model of a human head is a very challenging\ntask. While recent advancements have demonstrated the efficacy of leveraging\nsynthetic data for building such parametric head models, their performance\nremains inadequate in crucial areas such as expression-driven animation,\nhairstyle editing, and text-based modifications. In this paper, we build a\ndataset of artist-designed high-fidelity human heads and propose to create a\nnovel parametric 360{\\deg} renderable parametric head model from it. Our scheme\ndecouples the facial motion/shape and facial appearance, which are represented\nby a classic parametric 3D mesh model and an attached neural texture,\nrespectively. We further propose a training method for decompositing hairstyle\nand facial appearance, allowing free-swapping of the hairstyle. A novel\ninversion fitting method is presented based on single image input with high\ngeneralization and fidelity. To the best of our knowledge, our model is the\nfirst parametric 3D full-head that achieves 360{\\deg} free-view synthesis,\nimage-based fitting, appearance editing, and animation within a single model.\nExperiments show that facial motions and appearances are well disentangled in\nthe parametric space, leading to SOTA performance in rendering and animating\nquality. The code and SynHead100 dataset are released at\nhttps://nju-3dv.github.io/projects/Head360.\n","authors":["Yuxiao He","Yiyu Zhuang","Yanwen Wang","Yao Yao","Siyu Zhu","Xiaoyu Li","Qi Zhang","Xun Cao","Hao Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.00296v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00294v1","updated":"2024-08-01T05:41:59Z","published":"2024-08-01T05:41:59Z","title":"RDP: Ranked Differential Privacy for Facial Feature Protection in\n  Multiscale Sparsified Subspace","summary":"  With the widespread sharing of personal face images in applications' public\ndatabases, face recognition systems faces real threat of being breached by\npotential adversaries who are able to access users' face images and use them to\nintrude the face recognition systems. In this paper, we propose a novel privacy\nprotection method in the multiscale sparsified feature subspaces to protect\nsensitive facial features, by taking care of the influence or weight ranked\nfeature coefficients on the privacy budget, named \"Ranked Differential Privacy\n(RDP)\". After the multiscale feature decomposition, the lightweight Laplacian\nnoise is added to the dimension-reduced sparsified feature coefficients\naccording to the geometric superposition method. Then, we rigorously prove that\nthe RDP satisfies Differential Privacy. After that, the nonlinear Lagrange\nMultiplier (LM) method is formulated for the constraint optimization problem of\nmaximizing the utility of the visualization quality protected face images with\nsanitizing noise, under a given facial features privacy budget. Then, two\nmethods are proposed to solve the nonlinear LM problem and obtain the optimal\nnoise scale parameters: 1) the analytical Normalization Approximation (NA)\nmethod with identical average noise scale parameter for real-time online\napplications; and 2) the LM optimization Gradient Descent (LMGD) numerical\nmethod to obtain the nonlinear solution through iterative updating for more\naccurate offline applications. Experimental results on two real-world datasets\nshow that our proposed RDP outperforms other state-of-the-art methods: at a\nprivacy budget of 0.2, the PSNR (Peak Signal-to-Noise Ratio) of the RDP is\nabout ~10 dB higher than (10 times as high as) the highest PSNR of all compared\nmethods.\n","authors":["Lu Ou","Shaolin Liao","Shihui Gao","Guandong Huang","Zheng Qi"],"pdf_url":"https://arxiv.org/pdf/2408.00294v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.00290v1","updated":"2024-08-01T05:24:20Z","published":"2024-08-01T05:24:20Z","title":"Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network","summary":"  With the advent of the era of foundation models, pre-training and fine-tuning\nhave become common paradigms. Recently, parameter-efficient fine-tuning has\ngarnered widespread attention due to its better balance between the number of\nlearnable parameters and performance. However, some current parameter-efficient\nfine-tuning methods only model a single modality and lack the utilization of\nstructural knowledge in downstream tasks. To address this issue, this paper\nproposes a multi-modal parameter-efficient fine-tuning method based on graph\nnetworks. Each image is fed into a multi-modal large language model (MLLM) to\ngenerate a text description. The image and its corresponding text description\nare then processed by a frozen image encoder and text encoder to generate image\nfeatures and text features, respectively. A graph is constructed based on the\nsimilarity of the multi-modal feature nodes, and knowledge and relationships\nrelevant to these features are extracted from each node. Additionally, Elastic\nWeight Consolidation (EWC) regularization is incorporated into the loss\nfunction to mitigate the problem of forgetting during task learning. The\nproposed model achieves test accuracies on the OxfordPets, Flowers102, and\nFood101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The\ncode is available at https://github.com/yunche0/GA-Net/tree/master.\n","authors":["Bin Cheng","Jiaxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2408.00290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00288v1","updated":"2024-08-01T05:22:41Z","published":"2024-08-01T05:22:41Z","title":"Gradient Harmonization in Unsupervised Domain Adaptation","summary":"  Unsupervised domain adaptation (UDA) intends to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Many current methods focus\non learning feature representations that are both discriminative for\nclassification and invariant across domains by simultaneously optimizing domain\nalignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during\ngradient-based optimization. In this paper, we delve into this issue and\nintroduce two effective solutions known as Gradient Harmonization, including GH\nand GH++, to mitigate the conflict between domain alignment and classification\ntasks. GH operates by altering the gradient angle between different tasks from\nan obtuse angle to an acute angle, thus resolving the conflict and trade-offing\nthe two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an\nimproved version, GH++, which adjusts the gradient angle between tasks from an\nobtuse angle to a vertical angle. This not only eliminates the conflict but\nalso minimizes deviation from the original gradient directions. Finally, for\noptimization convenience and efficiency, we evolve the gradient harmonization\nstrategies into a dynamically weighted loss function using an integral operator\non the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be\nseamlessly integrated into most existing UDA models. Theoretical insights and\nexperimental analyses demonstrate that the proposed approaches not only enhance\npopular UDA baselines but also improve recent state-of-the-art models.\n","authors":["Fuxiang Huang","Suqi Song","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00288v1.pdf","comment":"IEEE TPAMI 2024"},{"id":"http://arxiv.org/abs/2408.00286v1","updated":"2024-08-01T05:04:22Z","published":"2024-08-01T05:04:22Z","title":"Diff3DETR:Agent-based Diffusion Model for Semi-supervised 3D Object\n  Detection","summary":"  3D object detection is essential for understanding 3D scenes. Contemporary\ntechniques often require extensive annotated training data, yet obtaining\npoint-wise annotations for point clouds is time-consuming and laborious. Recent\ndevelopments in semi-supervised methods seek to mitigate this problem by\nemploying a teacher-student framework to generate pseudo-labels for unlabeled\npoint clouds. However, these pseudo-labels frequently suffer from insufficient\ndiversity and inferior quality. To overcome these hurdles, we introduce an\nAgent-based Diffusion Model for Semi-supervised 3D Object Detection\n(Diff3DETR). Specifically, an agent-based object query generator is designed to\nproduce object queries that effectively adapt to dynamic scenes while striking\na balance between sampling locations and content embedding. Additionally, a\nbox-aware denoising module utilizes the DDIM denoising process and the\nlong-range attention in the transformer decoder to refine bounding boxes\nincrementally. Extensive experiments on ScanNet and SUN RGB-D datasets\ndemonstrate that Diff3DETR outperforms state-of-the-art semi-supervised 3D\nobject detection methods.\n","authors":["Jiacheng Deng","Jiahao Lu","Tianzhu Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00286v1.pdf","comment":"Accepted to ECCV2024"},{"id":"http://arxiv.org/abs/2408.00283v1","updated":"2024-08-01T04:56:13Z","published":"2024-08-01T04:56:13Z","title":"Navigating Text-to-Image Generative Bias across Indic Languages","summary":"  This research investigates biases in text-to-image (TTI) models for the Indic\nlanguages widely spoken across India. It evaluates and compares the generative\nperformance and cultural relevance of leading TTI models in these languages\nagainst their performance in English. Using the proposed IndicTTI benchmark, we\ncomprehensively assess the performance of 30 Indic languages with two\nopen-source diffusion models and two commercial generation APIs. The primary\nobjective of this benchmark is to evaluate the support for Indic languages in\nthese models and identify areas needing improvement. Given the linguistic\ndiversity of 30 languages spoken by over 1.4 billion people, this benchmark\naims to provide a detailed and insightful analysis of TTI models' effectiveness\nwithin the Indic linguistic landscape. The data and code for the IndicTTI\nbenchmark can be accessed at\nhttps://iab-rubric.org/resources/other-databases/indictti.\n","authors":["Surbhi Mittal","Arnav Sudan","Mayank Vatsa","Richa Singh","Tamar Glaser","Tal Hassner"],"pdf_url":"https://arxiv.org/pdf/2408.00283v1.pdf","comment":"Accepted in ECCV 2024"},{"id":"http://arxiv.org/abs/2408.00279v1","updated":"2024-08-01T04:39:36Z","published":"2024-08-01T04:39:36Z","title":"DMESA: Densely Matching Everything by Segmenting Anything","summary":"  We propose MESA and DMESA as novel feature matching methods, which utilize\nSegment Anything Model (SAM) to effectively mitigate matching redundancy. The\nkey insight of our methods is to establish implicit-semantic area matching\nprior to point matching, based on advanced image understanding of SAM. Then,\ninformative area matches with consistent internal semantic are able to undergo\ndense feature comparison, facilitating precise inside-area point matching.\nSpecifically, MESA adopts a sparse matching framework and first obtains\ncandidate areas from SAM results through a novel Area Graph (AG). Then, area\nmatching among the candidates is formulated as graph energy minimization and\nsolved by graphical models derived from AG. To address the efficiency issue of\nMESA, we further propose DMESA as its dense counterpart, applying a dense\nmatching framework. After candidate areas are identified by AG, DMESA\nestablishes area matches through generating dense matching distributions. The\ndistributions are produced from off-the-shelf patch matching utilizing the\nGaussian Mixture Model and refined via the Expectation Maximization. With less\nrepetitive computation, DMESA showcases a speed improvement of nearly five\ntimes compared to MESA, while maintaining competitive accuracy. Our methods are\nextensively evaluated on five datasets encompassing indoor and outdoor scenes.\nThe results illustrate consistent performance improvements from our methods for\nfive distinct point matching baselines across all datasets. Furthermore, our\nmethods exhibit promise generalization and improved robustness against image\nresolution variations. The code is publicly available at\nhttps://github.com/Easonyesheng/A2PM-MESA.\n","authors":["Yesheng Zhang","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.00279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00273v1","updated":"2024-08-01T04:27:10Z","published":"2024-08-01T04:27:10Z","title":"3D U-KAN Implementation for Multi-modal MRI Brain Tumor Segmentation","summary":"  We explore the application of U-KAN, a U-Net based network enhanced with\nKolmogorov-Arnold Network (KAN) layers, for 3D brain tumor segmentation using\nmulti-modal MRI data. We adapt the original 2D U-KAN model to the 3D task, and\nintroduce a variant called UKAN-SE, which incorporates Squeeze-and-Excitation\nmodules for global attention. We compare the performance of U-KAN and UKAN-SE\nagainst existing methods such as U-Net, Attention U-Net, and Swin UNETR, using\nthe BraTS 2024 dataset. Our results show that U-KAN and UKAN-SE, with\napproximately 10.6 million parameters, achieve exceptional efficiency,\nrequiring only about 1/4 of the training time of U-Net and Attention U-Net, and\n1/6 that of Swin UNETR, while surpassing these models across most evaluation\nmetrics. Notably, UKAN-SE slightly outperforms U-KAN.\n","authors":["Tianze Tang","Yanbing Chen","Hai Shu"],"pdf_url":"https://arxiv.org/pdf/2408.00273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00258v1","updated":"2024-08-01T03:31:45Z","published":"2024-08-01T03:31:45Z","title":"Improving Image De-raining Using Reference-Guided Transformers","summary":"  Image de-raining is a critical task in computer vision to improve visibility\nand enhance the robustness of outdoor vision systems. While recent advances in\nde-raining methods have achieved remarkable performance, the challenge remains\nto produce high-quality and visually pleasing de-rained results. In this paper,\nwe present a reference-guided de-raining filter, a transformer network that\nenhances de-raining results using a reference clean image as guidance. We\nleverage the capabilities of the proposed module to further refine the images\nde-rained by existing methods. We validate our method on three datasets and\nshow that our module can improve the performance of existing prior-based,\nCNN-based, and transformer-based approaches.\n","authors":["Zihao Ye","Jaehoon Cho","Changjae Oh"],"pdf_url":"https://arxiv.org/pdf/2408.00258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00255v1","updated":"2024-08-01T03:27:48Z","published":"2024-08-01T03:27:48Z","title":"Revocable Backdoor for Deep Model Trading","summary":"  Deep models are being applied in numerous fields and have become a new\nimportant digital product. Meanwhile, previous studies have shown that deep\nmodels are vulnerable to backdoor attacks, in which compromised models return\nattacker-desired results when a trigger appears. Backdoor attacks severely\nbreak the trust-worthiness of deep models. In this paper, we turn this weakness\nof deep models into a strength, and propose a novel revocable backdoor and deep\nmodel trading scenario. Specifically, we aim to compromise deep models without\ndegrading their performance, meanwhile, we can easily detoxify poisoned models\nwithout re-training the models. We design specific mask matrices to manage the\ninternal feature maps of the models. These mask matrices can be used to\ndeactivate the backdoors. The revocable backdoor can be adopted in the deep\nmodel trading scenario. Sellers train models with revocable backdoors as a\ntrial version. Buyers pay a deposit to sellers and obtain a trial version of\nthe deep model. If buyers are satisfied with the trial version, they pay a\nfinal payment to sellers and sellers send mask matrices to buyers to withdraw\nrevocable backdoors. We demonstrate the feasibility and robustness of our\nrevocable backdoor by various datasets and network architectures.\n","authors":["Yiran Xu","Nan Zhong","Zhenxing Qian","Xinpeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00255v1.pdf","comment":"to appear in ECAI 2024"},{"id":"http://arxiv.org/abs/2408.00254v1","updated":"2024-08-01T03:26:50Z","published":"2024-08-01T03:26:50Z","title":"LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting","summary":"  Despite the photorealistic novel view synthesis (NVS) performance achieved by\nthe original 3D Gaussian splatting (3DGS), its rendering quality significantly\ndegrades with sparse input views. This performance drop is mainly caused by the\nlimited number of initial points generated from the sparse input, insufficient\nsupervision during the training process, and inadequate regularization of the\noversized Gaussian ellipsoids. To handle these issues, we propose the\nLoopSparseGS, a loop-based 3DGS framework for the sparse novel view synthesis\ntask. In specific, we propose a loop-based Progressive Gaussian Initialization\n(PGI) strategy that could iteratively densify the initialized point cloud using\nthe rendered pseudo images during the training process. Then, the sparse and\nreliable depth from the Structure from Motion, and the window-based dense\nmonocular depth are leveraged to provide precise geometric supervision via the\nproposed Depth-alignment Regularization (DAR). Additionally, we introduce a\nnovel Sparse-friendly Sampling (SFS) strategy to handle oversized Gaussian\nellipsoids leading to large pixel errors. Comprehensive experiments on four\ndatasets demonstrate that LoopSparseGS outperforms existing state-of-the-art\nmethods for sparse-input novel view synthesis, across indoor, outdoor, and\nobject-level scenes with various image resolutions.\n","authors":["Zhenyu Bao","Guibiao Liao","Kaichen Zhou","Kanglin Liu","Qing Li","Guoping Qiu"],"pdf_url":"https://arxiv.org/pdf/2408.00254v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2408.00249v1","updated":"2024-08-01T03:06:56Z","published":"2024-08-01T03:06:56Z","title":"Task-Adapter: Task-specific Adaptation of Image Models for Few-shot\n  Action Recognition","summary":"  Existing works in few-shot action recognition mostly fine-tune a pre-trained\nimage model and design sophisticated temporal alignment modules at feature\nlevel. However, simply fully fine-tuning the pre-trained model could cause\noverfitting due to the scarcity of video samples. Additionally, we argue that\nthe exploration of task-specific information is insufficient when relying\nsolely on well extracted abstract features. In this work, we propose a simple\nbut effective task-specific adaptation method (Task-Adapter) for few-shot\naction recognition. By introducing the proposed Task-Adapter into the last\nseveral layers of the backbone and keeping the parameters of the original\npre-trained model frozen, we mitigate the overfitting problem caused by full\nfine-tuning and advance the task-specific mechanism into the process of feature\nextraction. In each Task-Adapter, we reuse the frozen self-attention layer to\nperform task-specific self-attention across different videos within the given\ntask to capture both distinctive information among classes and shared\ninformation within classes, which facilitates task-specific adaptation and\nenhances subsequent metric measurement between the query feature and support\nprototypes. Experimental results consistently demonstrate the effectiveness of\nour proposed Task-Adapter on four standard few-shot action recognition\ndatasets. Especially on temporal challenging SSv2 dataset, our method\noutperforms the state-of-the-art methods by a large margin.\n","authors":["Congqi Cao","Yueran Zhang","Yating Yu","Qinyi Lv","Lingtong Min","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00249v1.pdf","comment":"Accepted by ACM MM2024"},{"id":"http://arxiv.org/abs/2408.00221v1","updated":"2024-08-01T01:23:02Z","published":"2024-08-01T01:23:02Z","title":"multiGradICON: A Foundation Model for Multimodal Medical Image\n  Registration","summary":"  Modern medical image registration approaches predict deformations using deep\nnetworks. These approaches achieve state-of-the-art (SOTA) registration\naccuracy and are generally fast. However, deep learning (DL) approaches are, in\ncontrast to conventional non-deep-learning-based approaches, anatomy-specific.\nRecently, a universal deep registration approach, uniGradICON, has been\nproposed. However, uniGradICON focuses on monomodal image registration. In this\nwork, we therefore develop multiGradICON as a first step towards universal\n*multimodal* medical image registration. Specifically, we show that 1) we can\ntrain a DL registration model that is suitable for monomodal *and* multimodal\nregistration; 2) loss function randomization can increase multimodal\nregistration accuracy; and 3) training a model with multimodal data helps\nmultimodal generalization. Our code and the multiGradICON model are available\nat https://github.com/uncbiag/uniGradICON.\n","authors":["Basar Demir","Lin Tian","Thomas Hastings Greer","Roland Kwitt","Francois-Xavier Vialard","Raul San Jose Estepar","Sylvain Bouix","Richard Jarrett Rushmore","Ebrahim Ebrahim","Marc Niethammer"],"pdf_url":"https://arxiv.org/pdf/2408.00221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00210v1","updated":"2024-08-01T00:40:17Z","published":"2024-08-01T00:40:17Z","title":"A Prior Embedding-Driven Architecture for Long Distance Blind Iris\n  Recognition","summary":"  Blind iris images, which result from unknown degradation during the process\nof iris recognition at long distances, often lead to decreased iris recognition\nrates. Currently, little existing literature offers a solution to this problem.\nIn response, we propose a prior embedding-driven architecture for long distance\nblind iris recognition. We first proposed a blind iris image restoration\nnetwork called Iris-PPRGAN. To effectively restore the texture of the blind\niris, Iris-PPRGAN includes a Generative Adversarial Network (GAN) used as a\nPrior Decoder, and a DNN used as the encoder. To extract iris features more\nefficiently, we then proposed a robust iris classifier by modifying the\nbottleneck module of InsightFace, which called Insight-Iris. A low-quality\nblind iris image is first restored by Iris-PPRGAN, then the restored iris image\nundergoes recognition via Insight-Iris. Experimental results on the public\nCASIA-Iris-distance dataset demonstrate that our proposed method significantly\nsuperior results to state-of-the-art blind iris restoration methods both\nquantitatively and qualitatively, Specifically, the recognition rate for\nlong-distance blind iris images reaches 90% after processing with our methods,\nrepresenting an improvement of approximately ten percentage points compared to\nimages without restoration.\n","authors":["Qi Xiong","Xinman Zhang","Jun Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00203v1","updated":"2024-08-01T00:00:43Z","published":"2024-08-01T00:00:43Z","title":"OmniParser for Pure Vision Based GUI Agent","summary":"  The recent success of large vision language models shows great potential in\ndriving the agent system operating on user interfaces. However, we argue that\nthe power multimodal models like GPT-4V as a general agent on multiple\noperating systems across different applications is largely underestimated due\nto the lack of a robust screen parsing technique capable of: 1) reliably\nidentifying interactable icons within the user interface, and 2) understanding\nthe semantics of various elements in a screenshot and accurately associate the\nintended action with the corresponding region on the screen. To fill these\ngaps, we introduce \\textsc{OmniParser}, a comprehensive method for parsing user\ninterface screenshots into structured elements, which significantly enhances\nthe ability of GPT-4V to generate actions that can be accurately grounded in\nthe corresponding regions of the interface. We first curated an interactable\nicon detection dataset using popular webpages and an icon description dataset.\nThese datasets were utilized to fine-tune specialized models: a detection model\nto parse interactable regions on the screen and a caption model to extract the\nfunctional semantics of the detected elements. \\textsc{OmniParser}\nsignificantly improves GPT-4V's performance on ScreenSpot benchmark. And on\nMind2Web and AITW benchmark, \\textsc{OmniParser} with screenshot only input\noutperforms the GPT-4V baselines requiring additional information outside of\nscreenshot.\n","authors":["Yadong Lu","Jianwei Yang","Yelong Shen","Ahmed Awadallah"],"pdf_url":"https://arxiv.org/pdf/2408.00203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00950v1","updated":"2024-08-01T23:11:03Z","published":"2024-08-01T23:11:03Z","title":"PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking\n  Services","summary":"  Eye gaze contains rich information about human attention and cognitive\nprocesses. This capability makes the underlying technology, known as gaze\ntracking, a critical enabler for many ubiquitous applications and has triggered\nthe development of easy-to-use gaze estimation services. Indeed, by utilizing\nthe ubiquitous cameras on tablets and smartphones, users can readily access\nmany gaze estimation services. In using these services, users must provide\ntheir full-face images to the gaze estimator, which is often a black box. This\nposes significant privacy threats to the users, especially when a malicious\nservice provider gathers a large collection of face images to classify\nsensitive user attributes. In this work, we present PrivateGaze, the first\napproach that can effectively preserve users' privacy in black-box gaze\ntracking services without compromising gaze estimation performance.\nSpecifically, we proposed a novel framework to train a privacy preserver that\nconverts full-face images into obfuscated counterparts, which are effective for\ngaze estimation while containing no privacy information. Evaluation on four\ndatasets shows that the obfuscated image can protect users' private\ninformation, such as identity and gender, against unauthorized attribute\nclassification. Meanwhile, when used directly by the black-box gaze estimator\nas inputs, the obfuscated images lead to comparable tracking performance to the\nconventional, unprotected full-face images.\n","authors":["Lingyu Du","Jinyuan Jia","Xucong Zhang","Guohao Lan"],"pdf_url":"https://arxiv.org/pdf/2408.00950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00943v1","updated":"2024-08-01T22:25:06Z","published":"2024-08-01T22:25:06Z","title":"Data-Driven Traffic Simulation for an Intersection in a Metropolis","summary":"  We present a novel data-driven simulation environment for modeling traffic in\nmetropolitan street intersections. Using real-world tracking data collected\nover an extended period of time, we train trajectory forecasting models to\nlearn agent interactions and environmental constraints that are difficult to\ncapture conventionally. Trajectories of new agents are first coarsely generated\nby sampling from the spatial and temporal generative distributions, then\nrefined using state-of-the-art trajectory forecasting models. The simulation\ncan run either autonomously, or under explicit human control conditioned on the\ngenerative distributions. We present the experiments for a variety of model\nconfigurations. Under an iterative prediction scheme, the way-point-supervised\nTrajNet++ model obtained 0.36 Final Displacement Error (FDE) in 20 FPS on an\nNVIDIA A100 GPU.\n","authors":["Chengbo Zang","Mehmet Kerem Turkcan","Gil Zussman","Javad Ghaderi","Zoran Kostic"],"pdf_url":"https://arxiv.org/pdf/2408.00943v1.pdf","comment":"CVPR 2024 Workshop POETS Oral"},{"id":"http://arxiv.org/abs/2408.00940v1","updated":"2024-08-01T22:08:52Z","published":"2024-08-01T22:08:52Z","title":"A dual-task mutual learning framework for predicting post-thrombectomy\n  cerebral hemorrhage","summary":"  Ischemic stroke is a severe condition caused by the blockage of brain blood\nvessels, and can lead to the death of brain tissue due to oxygen deprivation.\nThrombectomy has become a common treatment choice for ischemic stroke due to\nits immediate effectiveness. But, it carries the risk of postoperative cerebral\nhemorrhage. Clinically, multiple CT scans within 0-72 hours post-surgery are\nused to monitor for hemorrhage. However, this approach exposes radiation dose\nto patients, and may delay the detection of cerebral hemorrhage. To address\nthis dilemma, we propose a novel prediction framework for measuring\npostoperative cerebral hemorrhage using only the patient's initial CT scan.\nSpecifically, we introduce a dual-task mutual learning framework to takes the\ninitial CT scan as input and simultaneously estimates both the follow-up CT\nscan and prognostic label to predict the occurrence of postoperative cerebral\nhemorrhage. Our proposed framework incorporates two attention mechanisms, i.e.,\nself-attention and interactive attention. Specifically, the self-attention\nmechanism allows the model to focus more on high-density areas in the image,\nwhich are critical for diagnosis (i.e., potential hemorrhage areas). The\ninteractive attention mechanism further models the dependencies between the\ninterrelated generation and classification tasks, enabling both tasks to\nperform better than the case when conducted individually. Validated on clinical\ndata, our method can generate follow-up CT scans better than state-of-the-art\nmethods, and achieves an accuracy of 86.37% in predicting follow-up prognostic\nlabels. Thus, our work thus contributes to the timely screening of\npost-thrombectomy cerebral hemorrhage, and could significantly reform the\nclinical process of thrombectomy and other similar operations related to\nstroke.\n","authors":["Caiwen Jiang","Tianyu Wang","Xiaodan Xing","Mianxin Liu","Guang Yang","Zhongxiang Ding","Dinggang Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00938v1","updated":"2024-08-01T22:01:42Z","published":"2024-08-01T22:01:42Z","title":"CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting\n  Idiopathic Pulmonary Fibrosis Progression","summary":"  The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly\ncorrelates with higher patient mortality rates. Early detection of IPF\nprogression is critical for initiating timely treatment, which can effectively\nslow down the advancement of the disease. However, the current clinical\ncriteria define disease progression requiring two CT scans with a one-year\ninterval, presenting a dilemma: a disease progression is identified only after\nthe disease has already progressed. To this end, in this paper, we develop a\nnovel diffusion model to accurately predict the progression of IPF by\ngenerating patient's follow-up CT scan from the initial CT scan. Specifically,\nfrom the clinical prior knowledge, we tailor improvements to the traditional\ndiffusion model and propose a Clinically-Informed Residual Diffusion model,\ncalled CIResDiff. The key innovations of CIResDiff include 1) performing the\ntarget region pre-registration to align the lung regions of two CT scans at\ndifferent time points for reducing the generation difficulty, 2) adopting the\nresidual diffusion instead of traditional diffusion to enable the model focus\nmore on differences (i.e., lesions) between the two CT scans rather than the\nlargely identical anatomical content, and 3) designing the clinically-informed\nprocess based on CLIP technology to integrate lung function information which\nis highly relevant to diagnosis into the reverse process for assisting\ngeneration. Extensive experiments on clinical data demonstrate that our\napproach can outperform state-of-the-art methods and effectively predict the\nprogression of IPF.\n","authors":["Caiwen Jiang","Xiaodan Xing","Zaixin Ou","Mianxin Liu","Walsh Simon","Guang Yang","Dinggang Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00938v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00932v1","updated":"2024-08-01T21:50:23Z","published":"2024-08-01T21:50:23Z","title":"Towards Zero-Shot Annotation of the Built Environment with\n  Vision-Language Models (Vision Paper)","summary":"  Equitable urban transportation applications require high-fidelity digital\nrepresentations of the built environment: not just streets and sidewalks, but\nbike lanes, marked and unmarked crossings, curb ramps and cuts, obstructions,\ntraffic signals, signage, street markings, potholes, and more. Direct\ninspections and manual annotations are prohibitively expensive at scale.\nConventional machine learning methods require substantial annotated training\ndata for adequate performance. In this paper, we consider vision language\nmodels as a mechanism for annotating diverse urban features from satellite\nimages, reducing the dependence on human annotation to produce large training\nsets. While these models have achieved impressive results in describing common\nobjects in images captured from a human perspective, their training sets are\nless likely to include strong signals for esoteric features in the built\nenvironment, and their performance in these settings is therefore unclear. We\ndemonstrate proof-of-concept combining a state-of-the-art vision language model\nand variants of a prompting strategy that asks the model to consider segmented\nelements independently of the original image. Experiments on two urban features\n-- stop lines and raised tables -- show that while direct zero-shot prompting\ncorrectly annotates nearly zero images, the pre-segmentation strategies can\nannotate images with near 40% intersection-over-union accuracy. We describe how\nthese results inform a new research agenda in automatic annotation of the built\nenvironment to improve equity, accessibility, and safety at broad scale and in\ndiverse environments.\n","authors":["Bin Han","Yiwei Yang","Anat Caspi","Bill Howe"],"pdf_url":"https://arxiv.org/pdf/2408.00932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.13651v4","updated":"2024-08-01T21:49:31Z","published":"2023-08-25T19:40:56Z","title":"PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained\n  Image Classification Accuracy for AIs and Humans","summary":"  Nearest neighbors (NN) are traditionally used to compute final decisions,\ne.g., in Support Vector Machines or k-NN classifiers, and to provide users with\nexplanations for the model's decision. In this paper, we show a novel utility\nof nearest neighbors: To improve predictions of a frozen, pretrained classifier\nC. We leverage an image comparator S that (1) compares the input image with NN\nimages from the top-K most probable classes; and (2) uses S' output scores to\nweight the confidence scores of C. Our method consistently improves\nfine-grained image classification accuracy on CUB-200, Cars-196, and Dogs-120.\nAlso, a human study finds that showing lay users our probable-class nearest\nneighbors (PCNN) reduces over-reliance on AI, thus improving their decision\naccuracy over prior work which only shows only the top-1 class examples.\n","authors":["Giang Nguyen","Valerie Chen","Mohammad Reza Taesiri","Anh Totti Nguyen"],"pdf_url":"https://arxiv.org/pdf/2308.13651v4.pdf","comment":"Accepted to Transaction of Machine Learning Research"},{"id":"http://arxiv.org/abs/2408.00923v1","updated":"2024-08-01T21:27:31Z","published":"2024-08-01T21:27:31Z","title":"Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization","summary":"  This paper explores a novel paradigm in low-bit (i.e. 4-bits or lower)\nquantization, differing from existing state-of-the-art methods, by framing\noptimal quantization as an architecture search problem within convolutional\nneural networks (ConvNets). Our framework, dubbed \\textbf{CoRa} (Optimal\nQuantization Residual \\textbf{Co}nvolutional Operator Low-\\textbf{Ra}nk\nAdaptation), is motivated by two key aspects. Firstly, quantization residual\nknowledge, i.e. the lost information between floating-point weights and\nquantized weights, has long been neglected by the research community.\nReclaiming the critical residual knowledge, with an infinitesimal extra\nparameter cost, can reverse performance degradation without training. Secondly,\nstate-of-the-art quantization frameworks search for optimal quantized weights\nto address the performance degradation. Yet, the vast search spaces in weight\noptimization pose a challenge for the efficient optimization in large models.\nFor example, state-of-the-art BRECQ necessitates $2 \\times 10^4$ iterations to\nquantize models. Fundamentally differing from existing methods, \\textbf{CoRa}\nsearches for the optimal architectures of low-rank adapters, reclaiming\ncritical quantization residual knowledge, within the search spaces smaller\ncompared to the weight spaces, by many orders of magnitude. The low-rank\nadapters approximate the quantization residual weights, discarded in previous\nmethods. We evaluate our approach over multiple pre-trained ConvNets on\nImageNet. \\textbf{CoRa} achieves comparable performance against both\nstate-of-the-art quantization-aware training and post-training quantization\nbaselines, in $4$-bit and $3$-bit quantization, by using less than $250$\niterations on a small calibration set with $1600$ images. Thus, \\textbf{CoRa}\nestablishes a new state-of-the-art in terms of the optimization efficiency in\nlow-bit quantization.\n","authors":["Róisín Luo","Alexandru Drimbarean","James McDermott","Colm O'Riordan"],"pdf_url":"https://arxiv.org/pdf/2408.00923v1.pdf","comment":"Accepted by The 35th British Machine Vision Conference (BMVC 2024)"},{"id":"http://arxiv.org/abs/2406.02529v2","updated":"2024-08-01T20:53:09Z","published":"2024-06-04T17:51:08Z","title":"ReLUs Are Sufficient for Learning Implicit Neural Representations","summary":"  Motivated by the growing theoretical understanding of neural networks that\nemploy the Rectified Linear Unit (ReLU) as their activation function, we\nrevisit the use of ReLU activation functions for learning implicit neural\nrepresentations (INRs). Inspired by second order B-spline wavelets, we\nincorporate a set of simple constraints to the ReLU neurons in each layer of a\ndeep neural network (DNN) to remedy the spectral bias. This in turn enables its\nuse for various INR tasks. Empirically, we demonstrate that, contrary to\npopular belief, one can learn state-of-the-art INRs based on a DNN composed of\nonly ReLU neurons. Next, by leveraging recent theoretical works which\ncharacterize the kinds of functions ReLU neural networks learn, we provide a\nway to quantify the regularity of the learned function. This offers a\nprincipled approach to selecting the hyperparameters in INR architectures. We\nsubstantiate our claims through experiments in signal representation, super\nresolution, and computed tomography, demonstrating the versatility and\neffectiveness of our method. The code for all experiments can be found at\nhttps://github.com/joeshenouda/relu-inrs.\n","authors":["Joseph Shenouda","Yamin Zhou","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2406.02529v2.pdf","comment":"Accepted to ICML 2024"},{"id":"http://arxiv.org/abs/2403.14837v2","updated":"2024-08-01T20:01:58Z","published":"2024-03-21T21:13:53Z","title":"Osmosis: RGBD Diffusion Prior for Underwater Image Restoration","summary":"  Underwater image restoration is a challenging task because of water effects\nthat increase dramatically with distance. This is worsened by lack of ground\ntruth data of clean scenes without water. Diffusion priors have emerged as\nstrong image restoration priors. However, they are often trained with a dataset\nof the desired restored output, which is not available in our case. We also\nobserve that using only color data is insufficient, and therefore augment the\nprior with a depth channel. We train an unconditional diffusion model prior on\nthe joint space of color and depth, using standard RGBD datasets of natural\noutdoor scenes in air. Using this prior together with a novel guidance method\nbased on the underwater image formation model, we generate posterior samples of\nclean images, removing the water effects. Even though our prior did not see any\nunderwater images during training, our method outperforms state-of-the-art\nbaselines for image restoration on very challenging scenes. Our code, models\nand data are available on the project website.\n","authors":["Opher Bar Nathan","Deborah Levy","Tali Treibitz","Dan Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2403.14837v2.pdf","comment":"ECCV 2024. Project page with results and code:\n  https://osmosis-diffusion.github.io/"},{"id":"http://arxiv.org/abs/2408.00891v1","updated":"2024-08-01T20:00:18Z","published":"2024-08-01T20:00:18Z","title":"Temporal Evolution of Knee Osteoarthritis: A Diffusion-based Morphing\n  Model for X-ray Medical Image Synthesis","summary":"  Knee Osteoarthritis (KOA) is a common musculoskeletal disorder that\nsignificantly affects the mobility of older adults. In the medical domain,\nimages containing temporal data are frequently utilized to study temporal\ndynamics and statistically monitor disease progression. While deep\nlearning-based generative models for natural images have been widely\nresearched, there are comparatively few methods available for synthesizing\ntemporal knee X-rays. In this work, we introduce a novel deep-learning model\ndesigned to synthesize intermediate X-ray images between a specific patient's\nhealthy knee and severe KOA stages. During the testing phase, based on a\nhealthy knee X-ray, the proposed model can produce a continuous and effective\nsequence of KOA X-ray images with varying degrees of severity. Specifically, we\nintroduce a Diffusion-based Morphing Model by modifying the Denoising Diffusion\nProbabilistic Model. Our approach integrates diffusion and morphing modules,\nenabling the model to capture spatial morphing details between source and\ntarget knee X-ray images and synthesize intermediate frames along a geodesic\npath. A hybrid loss consisting of diffusion loss, morphing loss, and\nsupervision loss was employed. We demonstrate that our proposed approach\nachieves the highest temporal frame synthesis performance, effectively\naugmenting data for classification models and simulating the progression of\nKOA.\n","authors":["Zhe Wang","Aladine Chetouani","Rachid Jennane","Yuhua Ru","Wasim Issa","Mohamed Jarraya"],"pdf_url":"https://arxiv.org/pdf/2408.00891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04943v2","updated":"2024-08-01T18:55:16Z","published":"2024-03-07T23:18:34Z","title":"AFreeCA: Annotation-Free Counting for All","summary":"  Object counting methods typically rely on manually annotated datasets. The\ncost of creating such datasets has restricted the versatility of these networks\nto count objects from specific classes (such as humans or penguins), and\ncounting objects from diverse categories remains a challenge. The availability\nof robust text-to-image latent diffusion models (LDMs) raises the question of\nwhether these models can be utilized to generate counting datasets. However,\nLDMs struggle to create images with an exact number of objects based solely on\ntext prompts but they can be used to offer a dependable \\textit{sorting} signal\nby adding and removing objects within an image. Leveraging this data, we\ninitially introduce an unsupervised sorting methodology to learn object-related\nfeatures that are subsequently refined and anchored for counting purposes using\ncounting data generated by LDMs. Further, we present a density\nclassifier-guided method for dividing an image into patches containing objects\nthat can be reliably counted. Consequently, we can generate counting data for\nany type of object and count them in an unsupervised manner. Our approach\noutperforms other unsupervised and few-shot alternatives and is not restricted\nto specific object classes for which counting data is available. Code to be\nreleased upon acceptance.\n","authors":["Adriano D'Alessandro","Ali Mahdavi-Amiri","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2403.04943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.04421v2","updated":"2024-08-01T18:52:31Z","published":"2023-09-08T16:32:56Z","title":"SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture\n  Generation for Driving Scenarios","summary":"  Creating a diverse and comprehensive dataset of hand gestures for dynamic\nhuman-machine interfaces in the automotive domain can be challenging and\ntime-consuming. To overcome this challenge, we propose using synthetic gesture\ndatasets generated by virtual 3D models. Our framework utilizes Unreal Engine\nto synthesize realistic hand gestures, offering customization options and\nreducing the risk of overfitting. Multiple variants, including gesture speed,\nperformance, and hand shape, are generated to improve generalizability. In\naddition, we simulate different camera locations and types, such as RGB,\ninfrared, and depth cameras, without incurring additional time and cost to\nobtain these cameras. Experimental results demonstrate that our proposed\nframework, SynthoGestures (https://github.com/amrgomaaelhady/SynthoGestures),\nimproves gesture recognition accuracy and can replace or augment real-hand\ndatasets. By saving time and effort in the creation of the data set, our tool\naccelerates the development of gesture recognition systems for automotive\napplications.\n","authors":["Amr Gomaa","Robin Zitt","Guillermo Reyes","Antonio Krüger"],"pdf_url":"https://arxiv.org/pdf/2309.04421v2.pdf","comment":"Accepted at IEEE IV'24. Shorter versions were accepted as\n  AutomotiveUI2023 Work in Progress and UIST2023 Poster Papers"},{"id":"http://arxiv.org/abs/2408.00874v1","updated":"2024-08-01T18:49:45Z","published":"2024-08-01T18:49:45Z","title":"Medical SAM 2: Segment medical images as video via Segment Anything\n  Model 2","summary":"  In this paper, we introduce Medical SAM 2 (MedSAM-2), an advanced\nsegmentation model that utilizes the SAM 2 framework to address both 2D and 3D\nmedical image segmentation tasks. By adopting the philosophy of taking medical\nimages as videos, MedSAM-2 not only applies to 3D medical images but also\nunlocks new One-prompt Segmentation capability. That allows users to provide a\nprompt for just one or a specific image targeting an object, after which the\nmodel can autonomously segment the same type of object in all subsequent\nimages, regardless of temporal relationships between the images. We evaluated\nMedSAM-2 across a variety of medical imaging modalities, including abdominal\norgans, optic discs, brain tumors, thyroid nodules, and skin lesions, comparing\nit against state-of-the-art models in both traditional and interactive\nsegmentation settings. Our findings show that MedSAM-2 not only surpasses\nexisting models in performance but also exhibits superior generalization across\na range of medical image segmentation tasks. Our code will be released at:\nhttps://github.com/MedicineToken/Medical-SAM2\n","authors":["Jiayuan Zhu","Yunli Qi","Junde Wu"],"pdf_url":"https://arxiv.org/pdf/2408.00874v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10280v2","updated":"2024-08-01T18:49:11Z","published":"2023-03-17T23:23:55Z","title":"Synthetic-to-Real Domain Adaptation for Action Recognition: A Dataset\n  and Baseline Performances","summary":"  Human action recognition is a challenging problem, particularly when there is\nhigh variability in factors such as subject appearance, backgrounds and\nviewpoint. While deep neural networks (DNNs) have been shown to perform well on\naction recognition tasks, they typically require large amounts of high-quality\nlabeled data to achieve robust performance across a variety of conditions.\nSynthetic data has shown promise as a way to avoid the substantial costs and\npotential ethical concerns associated with collecting and labeling enormous\namounts of data in the real-world. However, synthetic data may differ from real\ndata in important ways. This phenomenon, known as \\textit{domain shift}, can\nlimit the utility of synthetic data in robotics applications. To mitigate the\neffects of domain shift, substantial effort is being dedicated to the\ndevelopment of domain adaptation (DA) techniques. Yet, much remains to be\nunderstood about how best to develop these techniques. In this paper, we\nintroduce a new dataset called Robot Control Gestures (RoCoG-v2). The dataset\nis composed of both real and synthetic videos from seven gesture classes, and\nis intended to support the study of synthetic-to-real domain shift for\nvideo-based action recognition. Our work expands upon existing datasets by\nfocusing the action classes on gestures for human-robot teaming, as well as by\nenabling investigation of domain shift in both ground and aerial views. We\npresent baseline results using state-of-the-art action recognition and domain\nadaptation algorithms and offer initial insight on tackling the\nsynthetic-to-real and ground-to-air domain shifts.\n","authors":["Arun V. Reddy","Ketul Shah","William Paul","Rohita Mocharla","Judy Hoffman","Kapil D. Katyal","Dinesh Manocha","Celso M. de Melo","Rama Chellappa"],"pdf_url":"https://arxiv.org/pdf/2303.10280v2.pdf","comment":"ICRA 2023. The first two authors contributed equally. Dataset\n  available at: https://github.com/reddyav1/RoCoG-v2"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2212.03733v3","updated":"2024-08-01T17:47:24Z","published":"2022-12-07T15:55:00Z","title":"Tiered Reward: Designing Rewards for Specification and Fast Learning of\n  Desired Behavior","summary":"  Reinforcement-learning agents seek to maximize a reward signal through\nenvironmental interactions. As humans, our job in the learning process is to\ndesign reward functions to express desired behavior and enable the agent to\nlearn such behavior swiftly. However, designing good reward functions to induce\nthe desired behavior is generally hard, let alone the question of which rewards\nmake learning fast. In this work, we introduce a family of a reward structures\nwe call Tiered Reward that addresses both of these questions. We consider the\nreward-design problem in tasks formulated as reaching desirable states and\navoiding undesirable states. To start, we propose a strict partial ordering of\nthe policy space to resolve trade-offs in behavior preference. We prefer\npolicies that reach the good states faster and with higher probability while\navoiding the bad states longer. Next, we introduce Tiered Reward, a class of\nenvironment-independent reward functions and show it is guaranteed to induce\npolicies that are Pareto-optimal according to our preference relation. Finally,\nwe demonstrate that Tiered Reward leads to fast learning with multiple tabular\nand deep reinforcement-learning algorithms.\n","authors":["Zhiyuan Zhou","Shreyas Sundara Raman","Henry Sowerby","Michael L. Littman"],"pdf_url":"https://arxiv.org/pdf/2212.03733v3.pdf","comment":"For code, see https://github.com/zhouzypaul/tiered-reward"},{"id":"http://arxiv.org/abs/2407.14435v3","updated":"2024-08-01T17:42:04Z","published":"2024-07-19T16:07:19Z","title":"Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse\n  Autoencoders","summary":"  Sparse autoencoders (SAEs) are a promising unsupervised approach for\nidentifying causally relevant and interpretable linear features in a language\nmodel's (LM) activations. To be useful for downstream tasks, SAEs need to\ndecompose LM activations faithfully; yet to be interpretable the decomposition\nmust be sparse -- two objectives that are in tension. In this paper, we\nintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelity\nat a given sparsity level on Gemma 2 9B activations, compared to other recent\nadvances such as Gated and TopK SAEs. We also show that this improvement does\nnot come at the cost of interpretability through manual and automated\ninterpretability studies. JumpReLU SAEs are a simple modification of vanilla\n(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLU\nactivation function -- and are similarly efficient to train and run. By\nutilising straight-through-estimators (STEs) in a principled manner, we show\nhow it is possible to train JumpReLU SAEs effectively despite the discontinuous\nJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEs\nto directly train L0 to be sparse, instead of training on proxies such as L1,\navoiding problems like shrinkage.\n","authors":["Senthooran Rajamanoharan","Tom Lieberum","Nicolas Sonnerat","Arthur Conmy","Vikrant Varma","János Kramár","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2407.14435v3.pdf","comment":"v2: new appendix H comparing kernel functions & bug-fixes to\n  pseudo-code in Appendix J v3: further bug-fix to pseudo-code in Appendix J"},{"id":"http://arxiv.org/abs/2308.01674v4","updated":"2024-08-01T17:41:27Z","published":"2023-08-03T10:21:53Z","title":"End-to-End Reinforcement Learning of Koopman Models for Economic\n  Nonlinear Model Predictive Control","summary":"  (Economic) nonlinear model predictive control ((e)NMPC) requires dynamic\nmodels that are sufficiently accurate and computationally tractable.\nData-driven surrogate models for mechanistic models can reduce the\ncomputational burden of (e)NMPC; however, such models are typically trained by\nsystem identification for maximum prediction accuracy on simulation samples and\nperform suboptimally in (e)NMPC. We present a method for end-to-end\nreinforcement learning of Koopman surrogate models for optimal performance as\npart of (e)NMPC. We apply our method to two applications derived from an\nestablished nonlinear continuous stirred-tank reactor model. The controller\nperformance is compared to that of (e)NMPCs utilizing models trained using\nsystem identification, and model-free neural network controllers trained using\nreinforcement learning. We show that the end-to-end trained models outperform\nthose trained using system identification in (e)NMPC, and that, in contrast to\nthe neural network controllers, the (e)NMPC controllers can react to changes in\nthe control setting without retraining.\n","authors":["Daniel Mayfrank","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2308.01674v4.pdf","comment":"manuscript (20 pages, 7 figures, 6 tables), supplementary materials\n  (3 pages, 2 tables)"},{"id":"http://arxiv.org/abs/2407.16020v3","updated":"2024-08-01T17:40:36Z","published":"2024-07-22T19:55:44Z","title":"Sparks of Quantum Advantage and Rapid Retraining in Machine Learning","summary":"  The advent of quantum computing holds the potential to revolutionize various\nfields by solving complex problems more efficiently than classical computers.\nDespite this promise, practical quantum advantage is hindered by current\nhardware limitations, notably the small number of qubits and high noise levels.\nIn this study, we leverage adiabatic quantum computers to optimize\nKolmogorov-Arnold Networks, a powerful neural network architecture for\nrepresenting complex functions with minimal parameters. By modifying the\nnetwork to use Bezier curves as the basis functions and formulating the\noptimization problem into a Quadratic Unconstrained Binary Optimization\nproblem, we create a fixed-sized solution space, independent of the number of\ntraining samples. Our approach demonstrates sparks of quantum advantage through\nfaster training times compared to classical optimizers such as the Adam,\nStochastic Gradient Descent, Adaptive Gradient, and simulated annealing.\nAdditionally, we introduce a novel rapid retraining capability, enabling the\nnetwork to be retrained with new data without reprocessing old samples, thus\nenhancing learning efficiency in dynamic environments. Experimental results on\ninitial training of classification and regression tasks validate the efficacy\nof our approach, showcasing significant speedups and comparable performance to\nclassical methods. While experiments on retraining demonstrate a sixty times\nspeed up using adiabatic quantum computing based optimization compared to that\nof the gradient descent based optimizers, with theoretical models allowing this\nspeed up to be even larger! Our findings suggest that with further advancements\nin quantum hardware and algorithm optimization, quantum-optimized machine\nlearning models could have broad applications across various domains, with\ninitial focus on rapid retraining.\n","authors":["William Troy"],"pdf_url":"https://arxiv.org/pdf/2407.16020v3.pdf","comment":"Major updates to the paper for timings and explanations of\n  optimization strategies used. Further optimized the code and updated the\n  figures to reflect the faster timings for v3"},{"id":"http://arxiv.org/abs/2310.12428v2","updated":"2024-08-01T17:38:27Z","published":"2023-10-19T02:42:20Z","title":"Enhanced Local Explainability and Trust Scores with Random Forest\n  Proximities","summary":"  We initiate a novel approach to explain the predictions and out of sample\nperformance of random forest (RF) regression and classification models by\nexploiting the fact that any RF can be mathematically formulated as an adaptive\nweighted K nearest-neighbors model. Specifically, we employ a recent result\nthat, for both regression and classification tasks, any RF prediction can be\nrewritten exactly as a weighted sum of the training targets, where the weights\nare RF proximities between the corresponding pairs of data points. We show that\nthis linearity facilitates a local notion of explainability of RF predictions\nthat generates attributions for any model prediction across observations in the\ntraining set, and thereby complements established feature-based methods like\nSHAP, which generate attributions for a model prediction across input features.\nWe show how this proximity-based approach to explainability can be used in\nconjunction with SHAP to explain not just the model predictions, but also\nout-of-sample performance, in the sense that proximities furnish a novel means\nof assessing when a given model prediction is more or less likely to be\ncorrect. We demonstrate this approach in the modeling of US corporate bond\nprices and returns in both regression and classification cases.\n","authors":["Joshua Rosaler","Dhruv Desai","Bhaskarjit Sarmah","Dimitrios Vamvourellis","Deran Onay","Dhagash Mehta","Stefano Pasquali"],"pdf_url":"https://arxiv.org/pdf/2310.12428v2.pdf","comment":"5 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.15402v2","updated":"2024-08-01T16:31:00Z","published":"2024-02-23T16:05:51Z","title":"Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy\n  Structure Prior","summary":"  We focus on the task of unknown object rearrangement, where a robot is\nsupposed to re-configure the objects into a desired goal configuration\nspecified by an RGB-D image. Recent works explore unknown object rearrangement\nsystems by incorporating learning-based perception modules. However, they are\nsensitive to perception error, and pay less attention to task-level\nperformance. In this paper, we aim to develop an effective system for unknown\nobject rearrangement amidst perception noise. We theoretically reveal the noisy\nperception impacts grasp and place in a decoupled way, and show such a\ndecoupled structure is valuable to improve task optimality. We propose GSP, a\ndual-loop system with the decoupled structure as prior. For the inner loop, we\nlearn a see policy for self-confident in-hand object matching. For the outer\nloop, we learn a grasp policy aware of object matching and grasp capability\nguided by task-level rewards. We leverage the foundation model CLIP for object\nmatching, policy learning and self-termination. A series of experiments\nindicate that GSP can conduct unknown object rearrangement with higher\ncompletion rates and fewer steps.\n","authors":["Kechun Xu","Zhongxiang Zhou","Jun Wu","Haojian Lu","Rong Xiong","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2402.15402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00050v2","updated":"2024-08-01T16:14:27Z","published":"2024-03-25T15:11:15Z","title":"Grappa -- A Machine Learned Molecular Mechanics Force Field","summary":"  Simulating large molecular systems over long timescales requires force fields\nthat are both accurate and efficient. In recent years, E(3) equivariant neural\nnetworks have lifted the tension between computational efficiency and accuracy\nof force fields, but they are still several orders of magnitude more expensive\nthan established molecular mechanics (MM) force fields. Here, we propose\nGrappa, a machine learning framework to predict MM parameters from the\nmolecular graph, employing a graph attentional neural network and a transformer\nwith symmetry-preserving positional encoding. The resulting Grappa force field\noutperformstabulated and machine-learned MM force fields in terms of accuracy\nat the same computational efficiency and can be used in existing Molecular\nDynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forces\nof small molecules, peptides, RNA and - showcasing its extensibility to\nuncharted regions of chemical space - radicals at state-of-the-art MM accuracy.\nWe demonstrate Grappa's transferability to macromolecules in MD simulations\nfrom a small fast folding protein up to a whole virus particle. Our force field\nsets the stage for biomolecular simulations closer to chemical accuracy, but\nwith the same computational cost as established protein force fields.\n","authors":["Leif Seute","Eric Hartmann","Jan Stühmer","Frauke Gräter"],"pdf_url":"https://arxiv.org/pdf/2404.00050v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20021v3","updated":"2024-08-01T16:13:45Z","published":"2024-07-29T13:57:40Z","title":"MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with\n  Encouraging Inter-Head Attention Similarity","summary":"  Data-free quantization (DFQ) is a technique that creates a lightweight\nnetwork from its full-precision counterpart without the original training data,\noften through a synthetic dataset. Although several DFQ methods have been\nproposed for vision transformer (ViT) architectures, they fail to achieve\nefficacy in low-bit settings. Examining the existing methods, we identify that\ntheir synthetic data produce misaligned attention maps, while those of the real\nsamples are highly aligned. From the observation of aligned attention, we find\nthat aligning attention maps of synthetic data helps to improve the overall\nperformance of quantized ViTs. Motivated by this finding, we devise MimiQ, a\nnovel DFQ method designed for ViTs that focuses on inter-head attention\nsimilarity. First, we generate synthetic data by aligning head-wise attention\nresponses in relation to spatial query patches. Then, we apply head-wise\nstructural attention distillation to align the attention maps of the quantized\nnetwork to those of the full-precision teacher. The experimental results show\nthat the proposed method significantly outperforms baselines, setting a new\nstate-of-the-art performance for data-free ViT quantization.\n","authors":["Kanghyun Choi","Hye Yoon Lee","Dain Kwon","SunJong Park","Kyuyeun Kim","Noseong Park","Jinho Lee"],"pdf_url":"https://arxiv.org/pdf/2407.20021v3.pdf","comment":"Author Preprint"},{"id":"http://arxiv.org/abs/2307.09067v2","updated":"2024-08-01T16:09:50Z","published":"2023-07-18T08:37:58Z","title":"Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image\n  Segmentation with U-Net","summary":"  Fetal head segmentation is a crucial step in measuring the fetal head\ncircumference (HC) during gestation, an important biometric in obstetrics for\nmonitoring fetal growth. However, manual biometry generation is time-consuming\nand results in inconsistent accuracy. To address this issue, convolutional\nneural network (CNN) models have been utilized to improve the efficiency of\nmedical biometry. But training a CNN network from scratch is a challenging\ntask, we proposed a Transfer Learning (TL) method. Our approach involves\nfine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder to\nperform segmentation on a set of fetal head ultrasound (US) images with limited\neffort. This method addresses the challenges associated with training a CNN\nnetwork from scratch. It suggests that our proposed FT strategy yields\nsegmentation performance that is comparable when trained with a reduced number\nof parameters by 85.8%. And our proposed FT strategy outperforms other\nstrategies with smaller trainable parameter sizes below 4.4 million. Thus, we\ncontend that it can serve as a dependable FT approach for reducing the size of\nmodels in medical image analysis. Our key findings highlight the importance of\nthe balance between model performance and size in developing Artificial\nIntelligence (AI) applications by TL methods. Code is available at\nhttps://github.com/13204942/FT_Methods_for_Fetal_Head_Segmentation.\n","authors":["Fangyijie Wang","Guénolé Silvestre","Kathleen M. Curran"],"pdf_url":"https://arxiv.org/pdf/2307.09067v2.pdf","comment":"Irish Machine Vision and Image Processing Conference Proceedings 2023"},{"id":"http://arxiv.org/abs/2311.07315v2","updated":"2024-08-01T16:07:02Z","published":"2023-11-13T13:10:52Z","title":"An introduction to reinforcement learning for neuroscience","summary":"  Reinforcement learning has a rich history in neuroscience, from early work on\ndopamine as a reward prediction error signal for temporal difference learning\n(Schultz et al., 1997) to recent work suggesting that dopamine could implement\na form of 'distributional reinforcement learning' popularized in deep learning\n(Dabney et al., 2020). Throughout this literature, there has been a tight link\nbetween theoretical advances in reinforcement learning and neuroscientific\nexperiments and findings. As a result, the theories describing our experimental\ndata have become increasingly complex and difficult to navigate. In this\nreview, we cover the basic theory underlying classical work in reinforcement\nlearning and build up to an introductory overview of methods in modern deep\nreinforcement learning that have found applications in systems neuroscience. We\nstart with an overview of the reinforcement learning problem and classical\ntemporal difference algorithms, followed by a discussion of 'model-free' and\n'model-based' reinforcement learning together with methods such as DYNA and\nsuccessor representations that fall in between these two extremes. Throughout\nthese sections, we highlight the close parallels between such machine learning\nmethods and related work in both experimental and theoretical neuroscience. We\nthen provide an introduction to deep reinforcement learning with examples of\nhow these methods have been used to model different learning phenomena in\nsystems neuroscience, such as meta-reinforcement learning (Wang et al., 2018)\nand distributional reinforcement learning (Dabney et al., 2020). Code that\nimplements the methods discussed in this work and generates the figures is also\nprovided.\n","authors":["Kristopher T. Jensen"],"pdf_url":"https://arxiv.org/pdf/2311.07315v2.pdf","comment":"Code available at:\n  https://colab.research.google.com/drive/1ZC4lR8kTO48yySDZtcOEdMKd3NqY_ly1?usp=sharing"},{"id":"http://arxiv.org/abs/2403.05385v5","updated":"2024-08-01T16:02:06Z","published":"2024-03-08T15:30:58Z","title":"Switching the Loss Reduces the Cost in Batch (Offline) Reinforcement\n  Learning","summary":"  We propose training fitted Q-iteration with log-loss (FQI-log) for batch\nreinforcement learning (RL). We show that the number of samples needed to learn\na near-optimal policy with FQI-log scales with the accumulated cost of the\noptimal policy, which is zero in problems where acting optimally achieves the\ngoal and incurs no cost. In doing so, we provide a general framework for\nproving small-cost bounds, i.e. bounds that scale with the optimal achievable\ncost, in batch RL. Moreover, we empirically verify that FQI-log uses fewer\nsamples than FQI trained with squared loss on problems where the optimal policy\nreliably achieves the goal.\n","authors":["Alex Ayoub","Kaiwen Wang","Vincent Liu","Samuel Robertson","James McInerney","Dawen Liang","Nathan Kallus","Csaba Szepesvári"],"pdf_url":"https://arxiv.org/pdf/2403.05385v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13312v2","updated":"2024-08-01T15:54:29Z","published":"2023-04-26T06:33:31Z","title":"Technical Note: Defining and Quantifying AND-OR Interactions for\n  Faithful and Concise Explanation of DNNs","summary":"  In this technical note, we aim to explain a deep neural network (DNN) by\nquantifying the encoded interactions between input variables, which reflects\nthe DNN's inference logic. Specifically, we first rethink the definition of\ninteractions, and then formally define faithfulness and conciseness for\ninteraction-based explanation. To this end, we propose two kinds of\ninteractions, i.e., the AND interaction and the OR interaction. For\nfaithfulness, we prove the uniqueness of the AND (OR) interaction in\nquantifying the effect of the AND (OR) relationship between input variables.\nBesides, based on AND-OR interactions, we design techniques to boost the\nconciseness of the explanation, while not hurting the faithfulness. In this\nway, the inference logic of a DNN can be faithfully and concisely explained by\na set of symbolic concepts.\n","authors":["Mingjie Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.13312v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2111.06206"},{"id":"http://arxiv.org/abs/2304.13119v3","updated":"2024-08-01T15:52:32Z","published":"2023-04-25T19:48:54Z","title":"Application of Transformers for Nonlinear Channel Compensation in\n  Optical Systems","summary":"  In this paper, we introduce a new nonlinear optical channel equalizer based\non Transformers. By leveraging parallel computation and attending directly to\nthe memory across a sequence of symbols, we show that Transformers can be used\neffectively for nonlinear compensation (NLC) in coherent long-haul transmission\nsystems. For this application, we present an implementation of the encoder part\nof the Transformer and analyze its performance over a wide range of different\nhyper-parameters. It is shown that by proper embeddings and processing blocks\nof symbols at each iteration and also carefully selecting subsets of the\nencoder's output to be processed together, an efficient nonlinear equalization\ncan be achieved for different complexity constraints. To reduce the\ncomputational complexity of the attention mechanism, we further propose the use\nof a physic-informed mask inspired by nonlinear perturbation theory. We also\ncompare the Transformer-NLC with digital back-propagation (DBP) under different\ntransmission scenarios in order to demonstrate the flexibility and\ngeneralizability of the proposed data-driven solution.\n","authors":["Behnam Behinaein Hamgini","Hossein Najafi","Ali Bakhshali","Zhuhong Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.13119v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11911v2","updated":"2024-08-01T15:44:19Z","published":"2024-06-16T16:46:55Z","title":"A Notion of Complexity for Theory of Mind via Discrete World Models","summary":"  Theory of Mind (ToM) can be used to assess the capabilities of Large Language\nModels (LLMs) in complex scenarios where social reasoning is required. While\nthe research community has proposed many ToM benchmarks, their hardness varies\ngreatly, and their complexity is not well defined. This work proposes a\nframework to measure the complexity of ToM tasks. We quantify a problem's\ncomplexity as the number of states necessary to solve it correctly. Our\ncomplexity measure also accounts for spurious states of a ToM problem designed\nto make it apparently harder. We use our method to assess the complexity of\nfive widely adopted ToM benchmarks. On top of this framework, we design a\nprompting technique that augments the information available to a model with a\ndescription of how the environment changes with the agents' interactions. We\nname this technique Discrete World Models (DWM) and show how it elicits\nsuperior performance on ToM tasks.\n","authors":["X. Angelo Huang","Emanuele La Malfa","Samuele Marro","Andrea Asperti","Anthony Cohn","Michael Wooldridge"],"pdf_url":"https://arxiv.org/pdf/2406.11911v2.pdf","comment":"https://flecart.github.io/complexity-tom-dwm"},{"id":"http://arxiv.org/abs/2311.00048v2","updated":"2024-08-01T15:37:52Z","published":"2023-10-31T18:01:41Z","title":"SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image\n  Classification","summary":"  Multiple Instance Learning (MIL) has been widely used in weakly supervised\nwhole slide image (WSI) classification. Typical MIL methods include a feature\nembedding part, which embeds the instances into features via a pre-trained\nfeature extractor, and an MIL aggregator that combines instance embeddings into\npredictions. Most efforts have typically focused on improving these parts. This\ninvolves refining the feature embeddings through self-supervised pre-training\nas well as modeling the correlations between instances separately.\n  In this paper, we proposed a sparsely coding MIL (SC-MIL) method that\naddresses those two aspects at the same time by leveraging sparse dictionary\nlearning. The sparse dictionary learning captures the similarities of instances\nby expressing them as sparse linear combinations of atoms in an over-complete\ndictionary. In addition, imposing sparsity improves instance feature embeddings\nby suppressing irrelevant instances while retaining the most relevant ones. To\nmake the conventional sparse coding algorithm compatible with deep learning, we\nunrolled it into a sparsely coded module leveraging deep unrolling. The\nproposed SC module can be incorporated into any existing MIL framework in a\nplug-and-play manner with an acceptable computational cost. The experimental\nresults on multiple datasets demonstrated that the proposed SC module could\nsubstantially boost the performance of state-of-the-art MIL methods. The codes\nare available at\n\\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.\n","authors":["Peijie Qiu","Pan Xiao","Wenhui Zhu","Yalin Wang","Aristeidis Sotiras"],"pdf_url":"https://arxiv.org/pdf/2311.00048v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08448v2","updated":"2024-08-01T15:16:26Z","published":"2024-03-13T12:03:27Z","title":"Actor-Critic Physics-informed Neural Lyapunov Control","summary":"  Designing control policies for stabilization tasks with provable guarantees\nis a long-standing problem in nonlinear control. A crucial performance metric\nis the size of the resulting region of attraction, which essentially serves as\na robustness \"margin\" of the closed-loop system against uncertainties. In this\npaper, we propose a new method to train a stabilizing neural network controller\nalong with its corresponding Lyapunov certificate, aiming to maximize the\nresulting region of attraction while respecting the actuation constraints.\nCrucial to our approach is the use of Zubov's Partial Differential Equation\n(PDE), which precisely characterizes the true region of attraction of a given\ncontrol policy. Our framework follows an actor-critic pattern where we\nalternate between improving the control policy (actor) and learning a Zubov\nfunction (critic). Finally, we compute the largest certifiable region of\nattraction by invoking an SMT solver after the training procedure. Our\nnumerical experiments on several design problems show consistent and\nsignificant improvements in the size of the resulting region of attraction.\n","authors":["Jiarui Wang","Mahyar Fazlyab"],"pdf_url":"https://arxiv.org/pdf/2403.08448v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14814v3","updated":"2024-08-01T15:15:34Z","published":"2024-03-21T19:59:52Z","title":"The opportunities and risks of large language models in mental health","summary":"  Global rates of mental health concerns are rising, and there is increasing\nrealization that existing models of mental health care will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health related tasks. In this paper, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs' application\nto mental health and encourage the adoption of strategies to mitigate these\nrisks. The urgent need for mental health support must be balanced with\nresponsible development, testing, and deployment of mental health LLMs. It is\nespecially critical to ensure that mental health LLMs are fine-tuned for mental\nhealth, enhance mental health equity, and adhere to ethical standards and that\npeople, including those with lived experience with mental health concerns, are\ninvolved in all stages from development through deployment. Prioritizing these\nefforts will minimize potential harms to mental health and maximize the\nlikelihood that LLMs will positively impact mental health globally.\n","authors":["Hannah R. Lawrence","Renee A. Schneider","Susan B. Rubin","Maja J. Mataric","Daniel J. McDuff","Megan Jones Bell"],"pdf_url":"https://arxiv.org/pdf/2403.14814v3.pdf","comment":"15 pages, 2 tables, 4 figures"},{"id":"http://arxiv.org/abs/2404.10324v2","updated":"2024-08-01T15:10:45Z","published":"2024-04-16T07:08:04Z","title":"Graph neural network-based surrogate modelling for real-time hydraulic\n  prediction of urban drainage networks","summary":"  Physics-based models are computationally time-consuming and infeasible for\nreal-time scenarios of urban drainage networks, and a surrogate model is needed\nto accelerate the online predictive modelling. Fully-connected neural networks\n(NNs) are potential surrogate models, but may suffer from low interpretability\nand efficiency in fitting complex targets. Owing to the state-of-the-art\nmodelling power of graph neural networks (GNNs) and their match with urban\ndrainage networks in the graph structure, this work proposes a GNN-based\nsurrogate of the flow routing model for the hydraulic prediction problem of\ndrainage networks, which regards recent hydraulic states as initial conditions,\nand future runoff and control policy as boundary conditions. To incorporate\nhydraulic constraints and physical relationships into drainage modelling,\nphysics-guided mechanisms are designed on top of the surrogate model to\nrestrict the prediction variables with flow balance and flooding occurrence\nconstraints. According to case results in a stormwater network, the GNN-based\nmodel is more cost-effective with better hydraulic prediction accuracy than the\nNN-based model after equal training epochs, and the designed mechanisms further\nlimit prediction errors with interpretable domain knowledge. As the model\nstructure adheres to the flow routing mechanisms and hydraulic constraints in\nurban drainage networks, it provides an interpretable and effective solution\nfor data-driven surrogate modelling. Simultaneously, the surrogate model\naccelerates the predictive modelling of urban drainage networks for real-time\nuse compared with the physics-based model.\n","authors":["Zhiyu Zhang","Chenkaixiang Lu","Wenchong Tian","Zhenliang Liao","Zhiguo Yuan"],"pdf_url":"https://arxiv.org/pdf/2404.10324v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.04597v4","updated":"2024-08-01T14:38:06Z","published":"2021-11-08T16:09:39Z","title":"Neyman-Pearson Multi-class Classification via Cost-sensitive Learning","summary":"  Most existing classification methods aim to minimize the overall\nmisclassification error rate. However, in applications such as loan default\nprediction, different types of errors can have varying consequences. To address\nthis asymmetry issue, two popular paradigms have been developed: the\nNeyman-Pearson (NP) paradigm and the cost-sensitive (CS) paradigm. Previous\nstudies on the NP paradigm have primarily focused on the binary case, while the\nmulti-class NP problem poses a greater challenge due to its unknown\nfeasibility. In this work, we tackle the multi-class NP problem by establishing\na connection with the CS problem via strong duality and propose two algorithms.\nWe extend the concept of NP oracle inequalities, crucial in binary\nclassifications, to NP oracle properties in the multi-class context. Our\nalgorithms satisfy these NP oracle properties under certain conditions.\nFurthermore, we develop practical algorithms to assess the feasibility and\nstrong duality in multi-class NP problems, which can offer practitioners the\nlandscape of a multi-class NP problem with various target error levels.\nSimulations and real data studies validate the effectiveness of our algorithms.\nTo our knowledge, this is the first study to address the multi-class NP problem\nwith theoretical guarantees. The proposed algorithms have been implemented in\nthe R package \\texttt{npcs}, which is available on CRAN.\n","authors":["Ye Tian","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2111.04597v4.pdf","comment":"114 pages, 18 figures"},{"id":"http://arxiv.org/abs/2407.04822v3","updated":"2024-08-01T14:32:05Z","published":"2024-07-05T19:18:33Z","title":"YourMT3+: Multi-instrument Music Transcription with Enhanced Transformer\n  Architectures and Cross-dataset Stem Augmentation","summary":"  Multi-instrument music transcription aims to convert polyphonic music\nrecordings into musical scores assigned to each instrument. This task is\nchallenging for modeling as it requires simultaneously identifying multiple\ninstruments and transcribing their pitch and precise timing, and the lack of\nfully annotated data adds to the training difficulties. This paper introduces\nYourMT3+, a suite of models for enhanced multi-instrument music transcription\nbased on the recent language token decoding approach of MT3. We enhance its\nencoder by adopting a hierarchical attention transformer in the time-frequency\ndomain and integrating a mixture of experts. To address data limitations, we\nintroduce a new multi-channel decoding method for training with incomplete\nannotations and propose intra- and cross-stem augmentation for dataset mixing.\nOur experiments demonstrate direct vocal transcription capabilities,\neliminating the need for voice separation pre-processors. Benchmarks across ten\npublic datasets show our models' competitiveness with, or superiority to,\nexisting transcription models. Further testing on pop music recordings\nhighlights the limitations of current models. Fully reproducible code and\ndatasets are available with demos at \\url{https://github.com/mimbres/YourMT3}.\n","authors":["Sungkyun Chang","Emmanouil Benetos","Holger Kirchhoff","Simon Dixon"],"pdf_url":"https://arxiv.org/pdf/2407.04822v3.pdf","comment":"Accepted at IEEE International Workshop on Machine Learning for\n  Signal Processing (MLSP) 2024, London"},{"id":"http://arxiv.org/abs/2407.04724v2","updated":"2024-08-01T14:18:32Z","published":"2024-06-26T07:32:04Z","title":"A Likelihood-Based Generative Approach for Spatially Consistent\n  Precipitation Downscaling","summary":"  Deep learning has emerged as a promising tool for precipitation downscaling.\nHowever, current models rely on likelihood-based loss functions to properly\nmodel the precipitation distribution, leading to spatially inconsistent\nprojections when sampling. This work explores a novel approach by fusing the\nstrengths of likelihood-based and adversarial losses used in generative models.\nAs a result, we propose a likelihood-based generative approach for\nprecipitation downscaling, leveraging the benefits of both methods.\n","authors":["Jose González-Abad"],"pdf_url":"https://arxiv.org/pdf/2407.04724v2.pdf","comment":"Accepted at ICML 2024 Machine Learning for Earth System Modeling\n  workshop"},{"id":"http://arxiv.org/abs/2309.07716v2","updated":"2024-08-01T14:16:23Z","published":"2023-09-14T13:48:16Z","title":"Understanding Vector-Valued Neural Networks and Their Relationship with\n  Real and Hypercomplex-Valued Neural Networks","summary":"  Despite the many successful applications of deep learning models for\nmultidimensional signal and image processing, most traditional neural networks\nprocess data represented by (multidimensional) arrays of real numbers. The\nintercorrelation between feature channels is usually expected to be learned\nfrom the training data, requiring numerous parameters and careful training. In\ncontrast, vector-valued neural networks are conceived to process arrays of\nvectors and naturally consider the intercorrelation between feature channels.\nConsequently, they usually have fewer parameters and often undergo more robust\ntraining than traditional neural networks. This paper aims to present a broad\nframework for vector-valued neural networks, referred to as V-nets. In this\ncontext, hypercomplex-valued neural networks are regarded as vector-valued\nmodels with additional algebraic properties. Furthermore, this paper explains\nthe relationship between vector-valued and traditional neural networks.\nPrecisely, a vector-valued neural network can be obtained by placing\nrestrictions on a real-valued model to consider the intercorrelation between\nfeature channels. Finally, we show how V-nets, including hypercomplex-valued\nneural networks, can be implemented in current deep-learning libraries as\nreal-valued networks.\n","authors":["Marcos Eduardo Valle"],"pdf_url":"https://arxiv.org/pdf/2309.07716v2.pdf","comment":"Accepted for publication in IEEE Signal Processing Magazine"},{"id":"http://arxiv.org/abs/2407.11054v2","updated":"2024-08-01T14:10:22Z","published":"2024-07-09T09:25:27Z","title":"Generative AI for Health Technology Assessment: Opportunities,\n  Challenges, and Policy Considerations","summary":"  This review introduces the transformative potential of generative Artificial\nIntelligence (AI) and foundation models, including large language models\n(LLMs), for health technology assessment (HTA). We explore their applications\nin four critical areas, evidence synthesis, evidence generation, clinical\ntrials and economic modeling: (1) Evidence synthesis: Generative AI has the\npotential to assist in automating literature reviews and meta-analyses by\nproposing search terms, screening abstracts, and extracting data with notable\naccuracy; (2) Evidence generation: These models can potentially facilitate\nautomating the process and analyze the increasingly available large collections\nof real-world data (RWD), including unstructured clinical notes and imaging,\nenhancing the speed and quality of real-world evidence (RWE) generation; (3)\nClinical trials: Generative AI can be used to optimize trial design, improve\npatient matching, and manage trial data more efficiently; and (4) Economic\nmodeling: Generative AI can also aid in the development of health economic\nmodels, from conceptualization to validation, thus streamlining the overall HTA\nprocess. Despite their promise, these technologies, while rapidly improving,\nare still nascent and continued careful evaluation in their applications to HTA\nis required. To ensure their responsible use and implementation, both\ndevelopers and users of research incorporating these tools, should familiarize\nthemselves with their current limitations, including the issues related to\nscientific validity, risk of bias, and consider equity and ethical\nimplications. We also surveyed the current policy landscape and provide\nsuggestions for HTA agencies on responsibly integrating generative AI into\ntheir workflows, emphasizing the importance of human oversight and the\nfast-evolving nature of these tools.\n","authors":["Rachael Fleurence","Jiang Bian","Xiaoyan Wang","Hua Xu","Dalia Dawoud","Mitch Higashi","Jagpreet Chhatwal"],"pdf_url":"https://arxiv.org/pdf/2407.11054v2.pdf","comment":"24 pages, 1 figure, 1 table, 2 boxes, 103 references"},{"id":"http://arxiv.org/abs/2407.20678v2","updated":"2024-08-01T14:09:12Z","published":"2024-07-30T09:20:15Z","title":"The Susceptibility of Example-Based Explainability Methods to Class\n  Outliers","summary":"  This study explores the impact of class outliers on the effectiveness of\nexample-based explainability methods for black-box machine learning models. We\nreformulate existing explainability evaluation metrics, such as correctness and\nrelevance, specifically for example-based methods, and introduce a new metric,\ndistinguishability. Using these metrics, we highlight the shortcomings of\ncurrent example-based explainability methods, including those who attempt to\nsuppress class outliers. We conduct experiments on two datasets, a text\nclassification dataset and an image classification dataset, and evaluate the\nperformance of four state-of-the-art explainability methods. Our findings\nunderscore the need for robust techniques to tackle the challenges posed by\nclass outliers.\n","authors":["Ikhtiyor Nematov","Dimitris Sacharidis","Tomer Sagi","Katja Hose"],"pdf_url":"https://arxiv.org/pdf/2407.20678v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.16010"},{"id":"http://arxiv.org/abs/2407.03194v3","updated":"2024-08-01T14:08:53Z","published":"2024-07-03T15:26:02Z","title":"Prediction Instability in Machine Learning Ensembles","summary":"  In machine learning ensembles predictions from multiple models are\naggregated. Despite widespread use and strong performance of ensembles in\napplied problems little is known about the mathematical properties of\naggregating models and associated consequences for safe, explainable use of\nsuch models. In this paper we prove a theorem that shows that any ensemble will\nexhibit at least one of the following forms of prediction instability. It will\neither ignore agreement among all underlying models, change its mind when none\nof the underlying models have done so, or be manipulable through inclusion or\nexclusion of options it would never actually predict. As a consequence,\nensemble aggregation procedures will always need to balance the benefits of\ninformation use against the risk of these prediction instabilities. This\nanalysis also sheds light on what specific forms of prediction instability to\nexpect from particular ensemble algorithms; for example popular tree ensembles\nlike random forest, or xgboost will violate basic, intuitive fairness\nproperties. Finally, we show that this can be ameliorated by using consistent\nmodels in asymptotic conditions.\n","authors":["Jeremy Kedziora"],"pdf_url":"https://arxiv.org/pdf/2407.03194v3.pdf","comment":"15 pages, uses a modified version of ICML2024.sty"},{"id":"http://arxiv.org/abs/2312.02111v3","updated":"2024-08-01T14:01:56Z","published":"2023-12-04T18:43:45Z","title":"TriDeNT: Triple Deep Network Training for Privileged Knowledge\n  Distillation in Histopathology","summary":"  Computational pathology models rarely utilise data that will not be available\nfor inference. This means most models cannot learn from highly informative data\nsuch as additional immunohistochemical (IHC) stains and spatial\ntranscriptomics. We present TriDeNT, a novel self-supervised method for\nutilising privileged data that is not available during inference to improve\nperformance. We demonstrate the efficacy of this method for a range of\ndifferent paired data including immunohistochemistry, spatial transcriptomics\nand expert nuclei annotations. In all settings, TriDeNT outperforms other\nstate-of-the-art methods in downstream tasks, with observed improvements of up\nto 101%. Furthermore, we provide qualitative and quantitative measurements of\nthe features learned by these models and how they differ from baselines.\nTriDeNT offers a novel method to distil knowledge from scarce or costly data\nduring training, to create significantly better models for routine inputs.\n","authors":["Lucas Farndale","Robert Insall","Ke Yuan"],"pdf_url":"https://arxiv.org/pdf/2312.02111v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10821v2","updated":"2024-08-01T13:53:48Z","published":"2023-08-21T16:13:23Z","title":"Optimized Deep Learning Models for Malware Detection under Concept Drift","summary":"  Despite the promising results of machine learning models in malicious files\ndetection, they face the problem of concept drift due to their constant\nevolution. This leads to declining performance over time, as the data\ndistribution of the new files differs from the training one, requiring frequent\nmodel update. In this work, we propose a model-agnostic protocol to improve a\nbaseline neural network against drift. We show the importance of feature\nreduction and training with the most recent validation set possible, and\npropose a loss function named Drift-Resilient Binary Cross-Entropy, an\nimprovement to the classical Binary Cross-Entropy more effective against drift.\nWe train our model on the EMBER dataset, published in2018, and evaluate it on a\ndataset of recent malicious files, collected between 2020 and 2023. Our\nimproved model shows promising results, detecting 15.2% more malware than a\nbaseline model.\n","authors":["William Maillet","Benjamin Marais"],"pdf_url":"https://arxiv.org/pdf/2308.10821v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12715v2","updated":"2024-08-01T13:53:43Z","published":"2022-09-26T14:11:05Z","title":"Enhancing convolutional neural network generalizability via low-rank\n  weight approximation","summary":"  Noise is ubiquitous during image acquisition. Sufficient denoising is often\nan important first step for image processing. In recent decades, deep neural\nnetworks (DNNs) have been widely used for image denoising. Most DNN-based image\ndenoising methods require a large-scale dataset or focus on supervised\nsettings, in which single/pairs of clean images or a set of noisy images are\nrequired. This poses a significant burden on the image acquisition process.\nMoreover, denoisers trained on datasets of limited scale may incur\nover-fitting. To mitigate these issues, we introduce a new self-supervised\nframework for image denoising based on the Tucker low-rank tensor\napproximation. With the proposed design, we are able to characterize our\ndenoiser with fewer parameters and train it based on a single image, which\nconsiderably improves the model's generalizability and reduces the cost of data\nacquisition. Extensive experiments on both synthetic and real-world noisy\nimages have been conducted. Empirical results show that our proposed method\noutperforms existing non-learning-based methods (e.g., low-pass filter,\nnon-local mean), single-image unsupervised denoisers (e.g., DIP, NN+BM3D)\nevaluated on both in-sample and out-sample datasets. The proposed method even\nachieves comparable performances with some supervised methods (e.g., DnCNN).\n","authors":["Chenyin Gao","Shu Yang","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.12715v2.pdf","comment":"accepted by IET Image Processing"},{"id":"http://arxiv.org/abs/2401.14361v2","updated":"2024-08-01T13:21:24Z","published":"2024-01-25T18:07:50Z","title":"MoE-Infinity: Offloading-Efficient MoE Model Serving","summary":"  This paper presents MoE-Infinity, an offloading-efficient serving system for\nsparse mixture-of-experts (MoE) models. To optimize offloading, MoE-Infinity\nachieves novel request-level tracing for expert activation, capturing MoE's\nsparse execution patterns such as selective activation, group activation, and\nskewed reuse. Leveraging the request-level trace, MoE-Infinity performs\neffective expert prefetching and expert caching, achieving high efficiency in\ntransferring model parameters from host memory to GPU memory. Experimental\nresults demonstrate that MoE-Infinity achieves low latency comparable to\nexpensive full-GPU deployments, which require up to 4X more GPU resources than\nMoE-Infinity. Compared to offloading-supporting LLM serving systems such as\nDeepSpeed-Inference, Llama.cpp, Mixtral Offloading, and BrainStorm,\nMoE-Infinity exhibits superior latency performance, providing 2-20X\nimprovements when serving various MoE models for a large collection of LLM\ntasks. MoE-Infinity's source code is publicly available a\nhttps://github.com/TorchMoE/MoE-Infinity\n","authors":["Leyang Xue","Yao Fu","Zhan Lu","Luo Mai","Mahesh Marina"],"pdf_url":"https://arxiv.org/pdf/2401.14361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11749v3","updated":"2024-08-01T12:37:13Z","published":"2023-11-20T13:21:10Z","title":"A causal intervention framework for synthesizing mobility data and\n  evaluating predictive neural networks","summary":"  Deep neural networks are increasingly utilized in mobility prediction tasks,\nyet their intricate internal workings pose challenges for interpretability,\nespecially in comprehending how various aspects of mobility behavior affect\npredictions. This study introduces a causal intervention framework to assess\nthe impact of mobility-related factors on neural networks designed for next\nlocation prediction -- a task focusing on predicting the immediate next\nlocation of an individual. To achieve this, we employ individual mobility\nmodels to synthesize location visit sequences and control behavior dynamics by\nintervening in their data generation process. We evaluate the interventional\nlocation sequences using mobility metrics and input them into well-trained\nnetworks to analyze performance variations. The results demonstrate the\neffectiveness in producing location sequences with distinct mobility behaviors,\nthereby facilitating the simulation of diverse yet realistic spatial and\ntemporal changes. These changes result in performance fluctuations in next\nlocation prediction networks, revealing impacts of critical mobility behavior\nfactors, including sequential patterns in location transitions, proclivity for\nexploring new locations, and preferences in location choices at population and\nindividual levels. The gained insights hold value for the real-world\napplication of mobility prediction networks, and the framework is expected to\npromote the use of causal inference to enhance the interpretability and\nrobustness of neural networks in mobility applications.\n","authors":["Ye Hong","Yanan Xin","Simon Dirmeier","Fernando Perez-Cruz","Martin Raubal"],"pdf_url":"https://arxiv.org/pdf/2311.11749v3.pdf","comment":"34 pages, 8 figures"},{"id":"http://arxiv.org/abs/2307.13124v3","updated":"2024-08-01T11:51:44Z","published":"2023-07-24T20:45:39Z","title":"Conformal prediction for frequency-severity modeling","summary":"  We present a model-agnostic framework for the construction of prediction\nintervals of insurance claims, with finite sample statistical guarantees,\nextending the technique of split conformal prediction to the domain of\ntwo-stage frequency-severity modeling. The framework effectiveness is showcased\nwith simulated and real datasets using classical parametric models and\ncontemporary machine learning methods. When the underlying severity model is a\nrandom forest, we extend the two-stage split conformal prediction algorithm,\nshowing how the out-of-bag mechanism can be leveraged to eliminate the need for\na calibration set in the conformal procedure.\n","authors":["Helton Graziadei","Paulo C. Marques F.","Eduardo F. L. de Melo","Rodrigo S. Targino"],"pdf_url":"https://arxiv.org/pdf/2307.13124v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07484v6","updated":"2024-08-01T11:49:04Z","published":"2022-11-14T16:08:44Z","title":"Contextual Bandits with Packing and Covering Constraints: A Modular\n  Lagrangian Approach via Regression","summary":"  We consider contextual bandits with linear constraints (CBwLC), a variant of\ncontextual bandits in which the algorithm consumes multiple resources subject\nto linear constraints on total consumption. This problem generalizes contextual\nbandits with knapsacks (CBwK), allowing for packing and covering constraints,\nas well as positive and negative resource consumption. We provide the first\nalgorithm for CBwLC (or CBwK) that is based on regression oracles. The\nalgorithm is simple, computationally efficient, and statistically optimal under\nmild assumptions. Further, we provide the first vanishing-regret guarantees for\nCBwLC (or CBwK) that extend beyond the stochastic environment. We side-step\nstrong impossibility results from prior work by identifying a weaker (and,\narguably, fairer) benchmark to compare against. Our algorithm builds on\nLagrangeBwK (Immorlica et al., FOCS 2019), a Lagrangian-based technique for\nCBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based\ntechnique for contextual bandits. Our analysis leverages the inherent\nmodularity of both techniques.\n","authors":["Aleksandrs Slivkins","Xingyu Zhou","Karthik Abinav Sankararaman","Dylan J. Foster"],"pdf_url":"https://arxiv.org/pdf/2211.07484v6.pdf","comment":"A preliminary version of this paper, authored by A. Slivkins, K.A.\n  Sankararaman and D.J. Foster, has been published at COLT 2023. The present\n  version features an important improvement, due to Xingyu Zhou. Specifically,\n  the $\\sqrt{T}$-regret result in Theorem 3.6(a) holds under a much weaker\n  assumption, and is now positioned as the main guarantee"},{"id":"http://arxiv.org/abs/2407.16888v2","updated":"2024-08-01T11:46:26Z","published":"2024-06-08T12:46:12Z","title":"A Nested Model for AI Design and Validation","summary":"  The growing AI field faces trust, transparency, fairness, and discrimination\nchallenges. Despite the need for new regulations, there is a mismatch between\nregulatory science and AI, preventing a consistent framework. A five-layer\nnested model for AI design and validation aims to address these issues and\nstreamline AI application design and validation, improving fairness, trust, and\nAI adoption. This model aligns with regulations, addresses AI practitioner's\ndaily challenges, and offers prescriptive guidance for determining appropriate\nevaluation approaches by identifying unique validity threats. We have three\nrecommendations motivated by this model: authors should distinguish between\nlayers when claiming contributions to clarify the specific areas in which the\ncontribution is made and to avoid confusion, authors should explicitly state\nupstream assumptions to ensure that the context and limitations of their AI\nsystem are clearly understood, AI venues should promote thorough testing and\nvalidation of AI systems and their compliance with regulatory requirements.\n","authors":["Akshat Dubey","Zewen Yang","Georges Hattab"],"pdf_url":"https://arxiv.org/pdf/2407.16888v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12925v2","updated":"2024-08-01T10:09:15Z","published":"2024-06-14T13:54:29Z","title":"GLiNER multi-task: Generalist Lightweight Model for Various Information\n  Extraction Tasks","summary":"  Information extraction tasks require both accurate, efficient, and\ngeneralisable models. Classical supervised deep learning approaches can achieve\nthe required performance, but they need large datasets and are limited in their\nability to adapt to different tasks. On the other hand, large language models\n(LLMs) demonstrate good generalization, meaning that they can adapt to many\ndifferent tasks based on user requests. However, LLMs are computationally\nexpensive and tend to fail to generate structured outputs. In this article, we\nwill introduce a new kind of GLiNER model that can be used for various\ninformation extraction tasks while being a small encoder model. Our model\nachieved SoTA performance on zero-shot NER benchmarks and leading performance\non question-answering, summarization and relation extraction tasks.\nAdditionally, in this article, we will cover experimental results on\nself-learning approaches for named entity recognition using GLiNER models.\n","authors":["Ihor Stepanov","Mykhailo Shtopko"],"pdf_url":"https://arxiv.org/pdf/2406.12925v2.pdf","comment":"11 pages, 1 figure, 6 tables"},{"id":"http://arxiv.org/abs/2402.16105v4","updated":"2024-08-01T09:53:03Z","published":"2024-02-25T15:08:37Z","title":"Informed Meta-Learning","summary":"  In noisy and low-data regimes prevalent in real-world applications, a key\nchallenge of machine learning lies in effectively incorporating inductive\nbiases that promote data efficiency and robustness. Meta-learning and informed\nML stand out as two approaches for incorporating prior knowledge into ML\npipelines. While the former relies on a purely data-driven source of priors,\nthe latter is guided by prior domain knowledge. In this paper, we formalise a\nhybrid paradigm, informed meta-learning, facilitating the incorporation of\npriors from unstructured knowledge representations, such as natural language;\nthus, unlocking complementarity in cross-task knowledge sharing of humans and\nmachines. We establish the foundational components of informed meta-learning\nand present a concrete instantiation of this framework--the Informed Neural\nProcess. Through a series of experiments, we demonstrate the potential benefits\nof informed meta-learning in improving data efficiency, robustness to\nobservational noise and task distribution shifts.\n","authors":["Katarzyna Kobalczyk","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2402.16105v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18615v2","updated":"2024-08-01T09:43:57Z","published":"2023-10-28T06:46:03Z","title":"Temporally Disentangled Representation Learning under Unknown\n  Nonstationarity","summary":"  In unsupervised causal representation learning for sequential data with\ntime-delayed latent causal influences, strong identifiability results for the\ndisentanglement of causally-related latent variables have been established in\nstationary settings by leveraging temporal structure. However, in nonstationary\nsetting, existing work only partially addressed the problem by either utilizing\nobserved auxiliary variables (e.g., class labels and/or domain indexes) as side\ninformation or assuming simplified latent causal dynamics. Both constrain the\nmethod to a limited range of scenarios. In this study, we further explored the\nMarkov Assumption under time-delayed causally related process in nonstationary\nsetting and showed that under mild conditions, the independent latent\ncomponents can be recovered from their nonlinear mixture up to a permutation\nand a component-wise transformation, without the observation of auxiliary\nvariables. We then introduce NCTRL, a principled estimation framework, to\nreconstruct time-delayed latent causal variables and identify their relations\nfrom measured sequential data only. Empirical evaluations demonstrated the\nreliable identification of time-delayed latent causal influences, with our\nmethodology substantially outperforming existing baselines that fail to exploit\nthe nonstationarity adequately and then, consequently, cannot distinguish\ndistribution shifts.\n","authors":["Xiangchen Song","Weiran Yao","Yewen Fan","Xinshuai Dong","Guangyi Chen","Juan Carlos Niebles","Eric Xing","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.18615v2.pdf","comment":"NeurIPS 2023. arXiv admin note: text overlap with arXiv:2210.13647"},{"id":"http://arxiv.org/abs/2405.05638v3","updated":"2024-08-01T09:25:20Z","published":"2024-05-09T09:27:18Z","title":"A Correlation-induced Finite Difference Estimator","summary":"  Finite difference (FD) approximation is a classic approach to stochastic\ngradient estimation when only noisy function realizations are available. In\nthis paper, we first provide a sample-driven method via the bootstrap technique\nto estimate the optimal perturbation, and then propose an efficient FD\nestimator based on correlated samples at the estimated optimal perturbation.\nFurthermore, theoretical analyses of both the perturbation estimator and the FD\nestimator reveal that, {\\it surprisingly}, the correlation enables the proposed\nFD estimator to achieve a reduction in variance and, in some cases, a decrease\nin bias compared to the traditional optimal FD estimator. Numerical results\nconfirm the efficiency of our estimators and align well with the theory\npresented, especially in scenarios with small sample sizes. Finally, we apply\nthe estimator to solve derivative-free optimization (DFO) problems, and\nnumerical studies show that DFO problems with 100 dimensions can be effectively\nsolved.\n","authors":["Guo Liang","Guangwu Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.05638v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05012v2","updated":"2024-08-01T09:18:17Z","published":"2024-01-10T09:00:03Z","title":"HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with\n  Self-Distillation for Long-Term Forecasting","summary":"  Time series forecasting is a critical and challenging task in practical\napplication. Recent advancements in pre-trained foundation models for time\nseries forecasting have gained significant interest. However, current methods\noften overlook the multi-scale nature of time series, which is essential for\naccurate forecasting. To address this, we propose HiMTM, a hierarchical\nmulti-scale masked time series modeling with self-distillation for long-term\nforecasting. HiMTM integrates four key components: (1) hierarchical multi-scale\ntransformer (HMT) to capture temporal information at different scales; (2)\ndecoupled encoder-decoder (DED) that directs the encoder towards feature\nextraction while the decoder focuses on pretext tasks; (3) hierarchical\nself-distillation (HSD) for multi-stage feature-level supervision signals\nduring pre-training; and (4) cross-scale attention fine-tuning (CSA-FT) to\ncapture dependencies between different scales for downstream tasks. These\ncomponents collectively enhance multi-scale feature extraction in masked time\nseries modeling, improving forecasting accuracy. Extensive experiments on seven\nmainstream datasets show that HiMTM surpasses state-of-the-art self-supervised\nand end-to-end learning methods by a considerable margin of 3.16-68.54\\%.\nAdditionally, HiMTM outperforms the latest robust self-supervised learning\nmethod, PatchTST, in cross-domain forecasting by a significant margin of 2.3\\%.\nThe effectiveness of HiMTM is further demonstrated through its application in\nnatural gas demand forecasting.\n","authors":["Shubao Zhao","Ming Jin","Zhaoxiang Hou","Chengyi Yang","Zengxiang Li","Qingsong Wen","Yi Wang"],"pdf_url":"https://arxiv.org/pdf/2401.05012v2.pdf","comment":"accepted by CIKM 2024"},{"id":"http://arxiv.org/abs/2209.15224v3","updated":"2024-08-01T08:54:39Z","published":"2022-09-30T04:35:12Z","title":"Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture\n  Models","summary":"  Unsupervised learning has been widely used in many real-world applications.\nOne of the simplest and most important unsupervised learning models is the\nGaussian mixture model (GMM). In this work, we study the multi-task learning\nproblem on GMMs, which aims to leverage potentially similar GMM parameter\nstructures among tasks to obtain improved learning performance compared to\nsingle-task learning. We propose a multi-task GMM learning procedure based on\nthe EM algorithm that effectively utilizes unknown similarities between related\ntasks and is robust against a fraction of outlier tasks from arbitrary\ndistributions. The proposed procedure is shown to achieve the minimax optimal\nrate of convergence for both parameter estimation error and the excess\nmis-clustering error, in a wide range of regimes. Moreover, we generalize our\napproach to tackle the problem of transfer learning for GMMs, where similar\ntheoretical results are derived. Additionally, iterative unsupervised\nmulti-task and transfer learning methods may suffer from an initialization\nalignment problem, and two alignment algorithms are proposed to resolve the\nissue. Finally, we demonstrate the effectiveness of our methods through\nsimulations and real data examples. To the best of our knowledge, this is the\nfirst work studying multi-task and transfer learning on GMMs with theoretical\nguarantees.\n","authors":["Ye Tian","Haolei Weng","Lucy Xia","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2209.15224v3.pdf","comment":"162 pages, 15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2404.17591v2","updated":"2024-08-01T08:54:15Z","published":"2024-04-19T13:28:36Z","title":"Large Language Models for Next Point-of-Interest Recommendation","summary":"  The next Point of Interest (POI) recommendation task is to predict users'\nimmediate next POI visit given their historical data. Location-Based Social\nNetwork (LBSN) data, which is often used for the next POI recommendation task,\ncomes with challenges. One frequently disregarded challenge is how to\neffectively use the abundant contextual information present in LBSN data.\nPrevious methods are limited by their numerical nature and fail to address this\nchallenge. In this paper, we propose a framework that uses pretrained Large\nLanguage Models (LLMs) to tackle this challenge. Our framework allows us to\npreserve heterogeneous LBSN data in its original format, hence avoiding the\nloss of contextual information. Furthermore, our framework is capable of\ncomprehending the inherent meaning of contextual information due to the\ninclusion of commonsense knowledge. In experiments, we test our framework on\nthree real-world LBSN datasets. Our results show that the proposed framework\noutperforms the state-of-the-art models in all three datasets. Our analysis\ndemonstrates the effectiveness of the proposed framework in using contextual\ninformation as well as alleviating the commonly encountered cold-start and\nshort trajectory problems.\n","authors":["Peibo Li","Maarten de Rijke","Hao Xue","Shuang Ao","Yang Song","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2404.17591v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06925v2","updated":"2024-08-01T08:51:46Z","published":"2024-01-12T23:14:34Z","title":"Modeling Latent Selection with Structural Causal Models","summary":"  Selection bias is ubiquitous in real-world data, and can lead to misleading\nresults if not dealt with properly. We introduce a conditioning operation on\nStructural Causal Models (SCMs) to model latent selection from a causal\nperspective. We show that the conditioning operation transforms an SCM with the\npresence of an explicit latent selection mechanism into an SCM without such\nselection mechanism, which partially encodes the causal semantics of the\nselected subpopulation according to the original SCM. Furthermore, we show that\nthis conditioning operation preserves the simplicity, acyclicity, and linearity\nof SCMs, and commutes with marginalization. Thanks to these properties,\ncombined with marginalization and intervention, the conditioning operation\noffers a valuable tool for conducting causal reasoning tasks within causal\nmodels where latent details have been abstracted away. We demonstrate by\nexample how classical results of causal inference can be generalized to include\nselection bias and how the conditioning operation helps with modeling of\nreal-world problems.\n","authors":["Leihao Chen","Onno Zoeter","Joris M. Mooij"],"pdf_url":"https://arxiv.org/pdf/2401.06925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19872v2","updated":"2024-08-01T08:38:35Z","published":"2024-07-29T10:43:15Z","title":"OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city\n  Analysis of Area Usage Patterns","summary":"  We publicly release OpenUAS, a dataset of area embeddings based on urban\nusage patterns, including embeddings for over 1.3 million 50-meter square\nmeshes covering a total area of 3,300 square kilometers. This dataset is\nvaluable for analyzing area functions in fields such as market analysis, urban\nplanning, transportation infrastructure, and infection prediction. It captures\nthe characteristics of each area in the city, such as office districts and\nresidential areas, by employing an area embedding technique that utilizes\nlocation information typically obtained by GPS. Numerous area embedding\ntechniques have been proposed, and while the public release of such embedding\ndatasets is technically feasible, it has not been realized. One of the\nobstacles has been the integration of data from different cities and periods\ninto a unified space without sharing raw location data. We address this issue\nby developing an anchoring method that establishes anchors within a shared\nembedding space. We publicly release this anchor dataset along with area\nembedding datasets from several periods in eight major Japanese cities. This\ndataset allows users to analyze urban usage patterns in Japanese cities and\nembed their urban dataset into the same embedding space using the anchoring\nmethod. Our key contributions include the development of the anchoring method,\nreleasing area embedding datasets for Japanese cities, and providing tools for\neffective data utilization.\n","authors":["Naoki Tamura","Kazuyuki Shoji","Shin Katayama","Kenta Urano","Takuro Yonezawa","Nobuo Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2407.19872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08604v2","updated":"2024-08-01T07:55:49Z","published":"2024-06-12T19:17:17Z","title":"GRU-Net: Gaussian Attention Aided Dense Skip Connection Based\n  MultiResUNet for Breast Histopathology Image Segmentation","summary":"  Breast cancer is a major global health concern. Pathologists face challenges\nin analyzing complex features from pathological images, which is a\ntime-consuming and labor-intensive task. Therefore, efficient computer-based\ndiagnostic tools are needed for early detection and treatment planning. This\npaper presents a modified version of MultiResU-Net for histopathology image\nsegmentation, which is selected as the backbone for its ability to analyze and\nsegment complex features at multiple scales and ensure effective feature flow\nvia skip connections. The modified version also utilizes the Gaussian\ndistribution-based Attention Module (GdAM) to incorporate\nhistopathology-relevant text information in a Gaussian distribution. The\nsampled features from the Gaussian text feature-guided distribution highlight\nspecific spatial regions based on prior knowledge. Finally, using the\nControlled Dense Residual Block (CDRB) on skip connections of MultiResU-Net,\nthe information is transferred from the encoder layers to the decoder layers in\na controlled manner using a scaling parameter derived from the extracted\nspatial features. We validate our approach on two diverse breast cancer\nhistopathology image datasets: TNBC and MonuSeg, demonstrating superior\nsegmentation performance compared to state-of-the-art methods. The code for our\nproposed model is available on https://github.com/AyushRoy2001/GRU-Net.\n","authors":["Ayush Roy","Payel Pramanik","Sohom Ghosal","Daria Valenkova","Dmitrii Kaplun","Ram Sarkar"],"pdf_url":"https://arxiv.org/pdf/2406.08604v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15220v4","updated":"2024-08-01T07:51:25Z","published":"2024-02-23T09:29:19Z","title":"ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and\n  Two-Phase Partition","summary":"  Self-attention is an essential component of large language models (LLM) but a\nsignificant source of inference latency for long sequences. In multi-tenant LLM\nserving scenarios, the compute and memory operation cost of self-attention can\nbe optimized by using the probability that multiple LLM requests have shared\nsystem prompts in prefixes. In this paper, we introduce ChunkAttention, a\nprefix-aware self-attention module that can detect matching prompt prefixes\nacross multiple requests and share their key/value tensors in memory at runtime\nto improve the memory utilization of KV cache. This is achieved by breaking\nmonolithic key/value tensors into smaller chunks and structuring them into the\nauxiliary prefix tree. Consequently, on top of the prefix-tree based KV cache,\nwe design an efficient self-attention kernel, where a two-phase partition\nalgorithm is implemented to improve the data locality during self-attention\ncomputation in the presence of shared system prompts. Experiments show that\nChunkAttention can speed up the self-attention kernel by 3.2-4.8$\\times$\ncompared to the state-of-the-art implementation, with the length of the system\nprompt ranging from 1024 to 4096.\n","authors":["Lu Ye","Ze Tao","Yong Huang","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2402.15220v4.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2402.02563v3","updated":"2024-08-01T07:46:54Z","published":"2024-02-04T16:45:01Z","title":"DefInt: A Default-interventionist Framework for Efficient Reasoning with\n  Hybrid Large Language Models","summary":"  Large language models (LLMs) have shown impressive emergent abilities in a\nwide range of tasks, but still face challenges in handling complex reasoning\nproblems. Previous works like chain-of-thought (CoT) and tree-of-thoughts (ToT)\nhave predominately focused on enhancing accuracy, but overlook the rapidly\nincreasing token cost, which could be particularly problematic for open-ended\nreal-world tasks with huge solution spaces. Motivated by the dual process\ntheory of human cognition, we propose a Default-Interventionist framework\n(DefInt) to unleash the synergistic potential of hybrid LLMs. By default,\nDefInt uses smaller-scale language models to generate low-cost reasoning\nthoughts, which resembles the fast intuitions produced by System 1. If the\nintuitions are considered with low confidence, DefInt will invoke the\nreflective reasoning of scaled-up language models as the intervention of System\n2, which can override the default thoughts and rectify the reasoning process.\nExperiments on five representative reasoning tasks show that DefInt\nconsistently achieves state-of-the-art reasoning accuracy and solution\ndiversity. More importantly, it substantially reduces the token cost by 49%-79%\ncompared to the second accurate baselines. Specifically, the open-ended tasks\nhave an average 75% token cost reduction. Code repo with all prompts will be\nreleased upon publication.\n","authors":["Yu Shang","Yu Li","Fengli Xu","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2402.02563v3.pdf","comment":"18 pages, 10 figures, 14 tables"},{"id":"http://arxiv.org/abs/2406.03920v2","updated":"2024-08-01T07:29:42Z","published":"2024-06-06T10:02:49Z","title":"Towards Physically Consistent Deep Learning For Climate Model\n  Parameterizations","summary":"  Climate models play a critical role in understanding and projecting climate\nchange. Due to their complexity, their horizontal resolution of about 40-100 km\nremains too coarse to resolve processes such as clouds and convection, which\nneed to be approximated via parameterizations. These parameterizations are a\nmajor source of systematic errors and large uncertainties in climate\nprojections. Deep learning (DL)-based parameterizations, trained on data from\ncomputationally expensive short, high-resolution simulations, have shown great\npromise for improving climate models in that regard. However, their lack of\ninterpretability and tendency to learn spurious non-physical correlations\nresult in reduced trust in the climate simulation. We propose an efficient\nsupervised learning framework for DL-based parameterizations that leads to\nphysically consistent models with improved interpretability and negligible\ncomputational overhead compared to standard supervised training. First, key\nfeatures determining the target physical processes are uncovered. Subsequently,\nthe neural network is fine-tuned using only those relevant features. We show\nempirically that our method robustly identifies a small subset of the inputs as\nactual physical drivers, therefore, removing spurious non-physical\nrelationships. This results in by design physically consistent and\ninterpretable neural networks while maintaining the predictive performance of\nunconstrained black-box DL-based parameterizations.\n","authors":["Birgit Kühbacher","Fernando Iglesias-Suarez","Niki Kilbertus","Veronika Eyring"],"pdf_url":"https://arxiv.org/pdf/2406.03920v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09634v4","updated":"2024-08-01T05:09:34Z","published":"2022-10-18T07:03:14Z","title":"DPIS: An Enhanced Mechanism for Differentially Private SGD with\n  Importance Sampling","summary":"  Nowadays, differential privacy (DP) has become a well-accepted standard for\nprivacy protection, and deep neural networks (DNN) have been immensely\nsuccessful in machine learning. The combination of these two techniques, i.e.,\ndeep learning with differential privacy, promises the privacy-preserving\nrelease of high-utility models trained with sensitive data such as medical\nrecords. A classic mechanism for this purpose is DP-SGD, which is a\ndifferentially private version of the stochastic gradient descent (SGD)\noptimizer commonly used for DNN training. Subsequent approaches have improved\nvarious aspects of the model training process, including noise decay schedule,\nmodel architecture, feature engineering, and hyperparameter tuning. However,\nthe core mechanism for enforcing DP in the SGD optimizer remains unchanged ever\nsince the original DP-SGD algorithm, which has increasingly become a\nfundamental barrier limiting the performance of DP-compliant machine learning\nsolutions.\n  Motivated by this, we propose DPIS, a novel mechanism for differentially\nprivate SGD training that can be used as a drop-in replacement of the core\noptimizer of DP-SGD, with consistent and significant accuracy gains over the\nlatter. The main idea is to employ importance sampling (IS) in each SGD\niteration for mini-batch selection, which reduces both sampling variance and\nthe amount of random noise injected to the gradients that is required to\nsatisfy DP. Integrating IS into the complex mathematical machinery of DP-SGD is\nhighly non-trivial. DPIS addresses the challenge through novel mechanism\ndesigns, fine-grained privacy analysis, efficiency enhancements, and an\nadaptive gradient clipping optimization. Extensive experiments on four\nbenchmark datasets, namely MNIST, FMNIST, CIFAR-10 and IMDb, demonstrate the\nsuperior effectiveness of DPIS over existing solutions for deep learning with\ndifferential privacy.\n","authors":["Jianxin Wei","Ergute Bao","Xiaokui Xiao","Yin Yang"],"pdf_url":"https://arxiv.org/pdf/2210.09634v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12384v4","updated":"2024-08-01T03:32:49Z","published":"2024-03-19T02:49:32Z","title":"AlignRec: Aligning and Training in Multimodal Recommendations","summary":"  With the development of multimedia systems, multimodal recommendations are\nplaying an essential role, as they can leverage rich contexts beyond\ninteractions. Existing methods mainly regard multimodal information as an\nauxiliary, using them to help learn ID features; However, there exist semantic\ngaps among multimodal content features and ID-based features, for which\ndirectly using multimodal information as an auxiliary would lead to\nmisalignment in representations of users and items. In this paper, we first\nsystematically investigate the misalignment issue in multimodal\nrecommendations, and propose a solution named AlignRec. In AlignRec, the\nrecommendation objective is decomposed into three alignments, namely alignment\nwithin contents, alignment between content and categorical ID, and alignment\nbetween users and items. Each alignment is characterized by a specific\nobjective function and is integrated into our multimodal recommendation\nframework. To effectively train AlignRec, we propose starting from pre-training\nthe first alignment to obtain unified multimodal features and subsequently\ntraining the following two alignments together with these features as input. As\nit is essential to analyze whether each multimodal feature helps in training\nand accelerate the iteration cycle of recommendation models, we design three\nnew classes of metrics to evaluate intermediate performance. Our extensive\nexperiments on three real-world datasets consistently verify the superiority of\nAlignRec compared to nine baselines. We also find that the multimodal features\ngenerated by AlignRec are better than currently used ones, which are to be\nopen-sourced in our repository https://github.com/sjtulyf123/AlignRec_CIKM24.\n","authors":["Yifan Liu","Kangning Zhang","Xiangyuan Ren","Yanhua Huang","Jiarui Jin","Yingjie Qin","Ruilong Su","Ruiwen Xu","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.12384v4.pdf","comment":"9 page paper, 2 page appendix. Accepted by CIKM24"},{"id":"http://arxiv.org/abs/2406.01572v2","updated":"2024-08-01T03:29:32Z","published":"2024-06-03T17:51:54Z","title":"Unlocking Guidance for Discrete State-Space Diffusion and Flow Models","summary":"  Generative models on discrete state-spaces have a wide range of potential\napplications, particularly in the domain of natural sciences. In continuous\nstate-spaces, controllable and flexible generation of samples with desired\nproperties has been realized using guidance on diffusion and flow models.\nHowever, these guidance approaches are not readily amenable to discrete\nstate-space models. Consequently, we introduce a general and principled method\nfor applying guidance on such models. Our method depends on leveraging\ncontinuous-time Markov processes on discrete state-spaces, which unlocks\ncomputational tractability for sampling from a desired guided distribution. We\ndemonstrate the utility of our approach, Discrete Guidance, on a range of\napplications including guided generation of images, small-molecules, DNA\nsequences and protein sequences.\n","authors":["Hunter Nisonoff","Junhao Xiong","Stephan Allenspach","Jennifer Listgarten"],"pdf_url":"https://arxiv.org/pdf/2406.01572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11539v3","updated":"2024-08-01T03:19:03Z","published":"2023-12-15T23:34:05Z","title":"KGLens: Towards Efficient and Effective Knowledge Probing of Large\n  Language Models with Knowledge Graphs","summary":"  Large Language Models (LLMs) might hallucinate facts, while curated Knowledge\nGraph (KGs) are typically factually reliable especially with domain-specific\nknowledge. Measuring the alignment between KGs and LLMs can effectively probe\nthe factualness and identify the knowledge blind spots of LLMs. However,\nverifying the LLMs over extensive KGs can be expensive. In this paper, we\npresent KGLens, a Thompson-sampling-inspired framework aimed at effectively and\nefficiently measuring the alignment between KGs and LLMs. KGLens features a\ngraph-guided question generator for converting KGs into natural language, along\nwith a carefully designed importance sampling strategy based on parameterized\nKG structure to expedite KG traversal. Our simulation experiment compares the\nbrute force method with KGLens under six different sampling methods,\ndemonstrating that our approach achieves superior probing efficiency.\nLeveraging KGLens, we conducted in-depth analyses of the factual accuracy of\nten LLMs across three large domain-specific KGs from Wikidata, composing over\n19K edges, 700 relations, and 21K entities. Human evaluation results indicate\nthat KGLens can assess LLMs with a level of accuracy nearly equivalent to that\nof human annotators, achieving 95.7% of the accuracy rate.\n","authors":["Shangshang Zheng","He Bai","Yizhe Zhang","Yi Su","Xiaochuan Niu","Navdeep Jaitly"],"pdf_url":"https://arxiv.org/pdf/2312.11539v3.pdf","comment":"ACL 2024 Workshop Towards Knowledgeable Language Models"},{"id":"http://arxiv.org/abs/2407.21740v2","updated":"2024-08-01T03:16:43Z","published":"2024-07-31T16:52:00Z","title":"Contrastive Factor Analysis","summary":"  Factor analysis, often regarded as a Bayesian variant of matrix\nfactorization, offers superior capabilities in capturing uncertainty, modeling\ncomplex dependencies, and ensuring robustness. As the deep learning era\narrives, factor analysis is receiving less and less attention due to their\nlimited expressive ability. On the contrary, contrastive learning has emerged\nas a potent technique with demonstrated efficacy in unsupervised\nrepresentational learning. While the two methods are different paradigms,\nrecent theoretical analysis has revealed the mathematical equivalence between\ncontrastive learning and matrix factorization, providing a potential\npossibility for factor analysis combined with contrastive learning. Motivated\nby the interconnectedness of contrastive learning, matrix factorization, and\nfactor analysis, this paper introduces a novel Contrastive Factor Analysis\nframework, aiming to leverage factor analysis's advantageous properties within\nthe realm of contrastive learning. To further leverage the interpretability\nproperties of non-negative factor analysis, which can learn disentangled\nrepresentations, contrastive factor analysis is extended to a non-negative\nversion. Finally, extensive experimental validation showcases the efficacy of\nthe proposed contrastive (non-negative) factor analysis methodology across\nmultiple key properties, including expressiveness, robustness,\ninterpretability, and accurate uncertainty estimation.\n","authors":["Zhibin Duan","Tiansheng Wen","Yifei Wang","Chen Zhu","Bo Chen","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.21740v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07221v2","updated":"2024-08-01T03:02:44Z","published":"2024-03-23T00:49:40Z","title":"Improving Retrieval for RAG based Question Answering Models on Financial\n  Documents","summary":"  The effectiveness of Large Language Models (LLMs) in generating accurate\nresponses relies heavily on the quality of input provided, particularly when\nemploying Retrieval Augmented Generation (RAG) techniques. RAG enhances LLMs by\nsourcing the most relevant text chunk(s) to base queries upon. Despite the\nsignificant advancements in LLMs' response quality in recent years, users may\nstill encounter inaccuracies or irrelevant answers; these issues often stem\nfrom suboptimal text chunk retrieval by RAG rather than the inherent\ncapabilities of LLMs. To augment the efficacy of LLMs, it is crucial to refine\nthe RAG process. This paper explores the existing constraints of RAG pipelines\nand introduces methodologies for enhancing text retrieval. It delves into\nstrategies such as sophisticated chunking techniques, query expansion, the\nincorporation of metadata annotations, the application of re-ranking\nalgorithms, and the fine-tuning of embedding algorithms. Implementing these\napproaches can substantially improve the retrieval quality, thereby elevating\nthe overall performance and reliability of LLMs in processing and responding to\nqueries.\n","authors":["Spurthi Setty","Harsh Thakkar","Alyssa Lee","Eden Chung","Natan Vidra"],"pdf_url":"https://arxiv.org/pdf/2404.07221v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01614v2","updated":"2024-08-01T02:56:58Z","published":"2024-06-28T01:46:10Z","title":"Enhancing Stability for Large Models Training in Constrained Bandwidth\n  Networks","summary":"  Training extremely large language models with billions of parameters is a\ncomputationally intensive task that pushes the limits of current data parallel\ntraining systems. While techniques like ZeRO++ have enabled efficient\ndistributed training of such giant models on inexpensive low-bandwidth\nclusters, they can suffer from convergence issues due to potential race\nconditions in the hierarchical partitioning (hpZ) scheme employed to reduce\ncross-machine communication. In this work, we first show how these race\nconditions cause instability when training models with billions of parameters.\nWe then propose a modification to the partitioning algorithm that addresses\nthese convergence challenges while maintaining competitive training efficiency.\nEmpirical evaluation on training the multi-billion parameters Falcon Models and\nLlama-2 models demonstrates the updated algorithm's ability to achieve reliable\nconvergence on these massive models, where stock ZeRO++ hpZ fails to converge.\nThe updated algorithm enables robust training of larger models with 98\\%\nthroughput and model training speed improvement without sacrificing the quality\nof convergence.\n","authors":["Yun Dai","Tejas Dharamsi","Byron Hsu","Tao Song","Hamed Firooz"],"pdf_url":"https://arxiv.org/pdf/2407.01614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14055v2","updated":"2024-08-01T02:19:08Z","published":"2024-07-19T06:31:22Z","title":"Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers","summary":"  When applying quantum computing to machine learning tasks, one of the first\nconsiderations is the design of the quantum machine learning model itself.\nConventionally, the design of quantum machine learning algorithms relies on the\n``quantisation\" of classical learning algorithms, such as using quantum linear\nalgebra to implement important subroutines of classical algorithms, if not the\nentire algorithm, seeking to achieve quantum advantage through possible\nrun-time accelerations brought by quantum computing. However, recent research\nhas started questioning whether quantum advantage via speedup is the right goal\nfor quantum machine learning [1]. Research also has been undertaken to exploit\nproperties that are unique to quantum systems, such as quantum contextuality,\nto better design quantum machine learning models [2]. In this paper, we take an\nalternative approach by incorporating the heuristics and empirical evidences\nfrom the design of classical deep learning algorithms to the design of quantum\nneural networks. We first construct a model based on the data reuploading\ncircuit [3] with the quantum Hamiltonian data embedding unitary [4]. Through\nnumerical experiments on images datasets, including the famous MNIST and\nFashionMNIST datasets, we demonstrate that our model outperforms the quantum\nconvolutional neural network (QCNN)[5] by a large margin (up to over 40% on\nMNIST test set). Based on the model design process and numerical results, we\nthen laid out six principles for designing quantum machine learning models,\nespecially quantum neural networks.\n","authors":["Peiyong Wang","Casey R. Myers","Lloyd C. L. Hollenberg","Udaya Parampalli"],"pdf_url":"https://arxiv.org/pdf/2407.14055v2.pdf","comment":"11 figures, 31 pages. Code available on\n  https://github.com/peiyong-addwater/HamEmbedding. Author affiliation updated\n  for v2. Acknowledgements and funding information added for v2"},{"id":"http://arxiv.org/abs/2407.21266v2","updated":"2024-08-01T01:59:58Z","published":"2024-07-31T01:07:21Z","title":"DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image\n  Segmentation on Multiple GPUs","summary":"  The segmentation of ultra-high resolution images poses challenges such as\nloss of spatial information or computational inefficiency. In this work, a\nnovel approach that combines encoder-decoder architectures with domain\ndecomposition strategies to address these challenges is proposed. Specifically,\na domain decomposition-based U-Net (DDU-Net) architecture is introduced, which\npartitions input images into non-overlapping patches that can be processed\nindependently on separate devices. A communication network is added to\nfacilitate inter-patch information exchange to enhance the understanding of\nspatial context. Experimental validation is performed on a synthetic dataset\nthat is designed to measure the effectiveness of the communication network.\nThen, the performance is tested on the DeepGlobe land cover classification\ndataset as a real-world benchmark data set. The results demonstrate that the\napproach, which includes inter-patch communication for images divided into\n$16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher\nintersection over union (IoU) score compared to the same network without\ninter-patch communication. The performance of the network which includes\ncommunication is equivalent to that of a baseline U-Net trained on the full\nimage, showing that our model provides an effective solution for segmenting\nultra-high-resolution images while preserving spatial context. The code is\navailable at https://github.com/corne00/HiRes-Seg-CNN.\n","authors":["Corné Verburg","Alexander Heinlein","Eric C. Cyr"],"pdf_url":"https://arxiv.org/pdf/2407.21266v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.01593v6","updated":"2024-08-01T01:49:47Z","published":"2021-10-04T17:41:53Z","title":"Generalized Kernel Thinning","summary":"  The kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) compresses a\nprobability distribution more effectively than independent sampling by\ntargeting a reproducing kernel Hilbert space (RKHS) and leveraging a less\nsmooth square-root kernel. Here we provide four improvements. First, we show\nthat KT applied directly to the target RKHS yields tighter, dimension-free\nguarantees for any kernel, any distribution, and any fixed function in the\nRKHS. Second, we show that, for analytic kernels like Gaussian, inverse\nmultiquadric, and sinc, target KT admits maximum mean discrepancy (MMD)\nguarantees comparable to or better than those of square-root KT without making\nexplicit use of a square-root kernel. Third, we prove that KT with a fractional\npower kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth\nkernels, like Laplace and Mat\\'ern, that do not have square-roots. Fourth, we\nestablish that KT applied to a sum of the target and power kernels (a procedure\nwe call KT+) simultaneously inherits the improved MMD guarantees of power KT\nand the tighter individual function guarantees of target KT. In our experiments\nwith target KT and KT+, we witness significant improvements in integration\nerror even in $100$ dimensions and when compressing challenging differential\nequation posteriors.\n","authors":["Raaz Dwivedi","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2110.01593v6.pdf","comment":"Corrected B-spline and Sinc rates in Table 3"},{"id":"http://arxiv.org/abs/2202.05525v2","updated":"2024-08-01T01:42:10Z","published":"2022-02-11T09:45:11Z","title":"From Unsupervised to Few-shot Graph Anomaly Detection: A Multi-scale\n  Contrastive Learning Approach","summary":"  Anomaly detection from graph data is an important data mining task in many\napplications such as social networks, finance, and e-commerce. Existing efforts\nin graph anomaly detection typically only consider the information in a single\nscale (view), thus inevitably limiting their capability in capturing anomalous\npatterns in complex graph data. To address this limitation, we propose a novel\nframework, graph ANomaly dEtection framework with Multi-scale cONtrastive\nlEarning (ANEMONE in short). By using a graph neural network as a backbone to\nencode the information from multiple graph scales (views), we learn better\nrepresentation for nodes in a graph. In maximizing the agreements between\ninstances at both the patch and context levels concurrently, we estimate the\nanomaly score of each node with a statistical anomaly estimator according to\nthe degree of agreement from multiple perspectives. To further exploit a\nhandful of ground-truth anomalies (few-shot anomalies) that may be collected in\nreal-life applications, we further propose an extended algorithm, ANEMONE-FS,\nto integrate valuable information in our method. We conduct extensive\nexperiments under purely unsupervised settings and few-shot anomaly detection\nsettings, and we demonstrate that the proposed method ANEMONE and its variant\nANEMONE-FS consistently outperform state-of-the-art algorithms on six benchmark\ndatasets.\n","authors":["Yu Zheng","Ming Jin","Yixin Liu","Lianhua Chi","Khoa T. Phan","Yi-Ping Phoebe Chen"],"pdf_url":"https://arxiv.org/pdf/2202.05525v2.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2407.20299v2","updated":"2024-08-01T01:33:48Z","published":"2024-07-29T04:02:17Z","title":"Dataset Distillation for Offline Reinforcement Learning","summary":"  Offline reinforcement learning often requires a quality dataset that we can\ntrain a policy on. However, in many situations, it is not possible to get such\na dataset, nor is it easy to train a policy to perform well in the actual\nenvironment given the offline data. We propose using data distillation to train\nand distill a better dataset which can then be used for training a better\npolicy model. We show that our method is able to synthesize a dataset where a\nmodel trained on it achieves similar performance to a model trained on the full\ndataset or a model trained using percentile behavioral cloning. Our project\nsite is available at\n$\\href{https://datasetdistillation4rl.github.io}{\\text{here}}$. We also provide\nour implementation at $\\href{https://github.com/ggflow123/DDRL}{\\text{this\nGitHub repository}}$.\n","authors":["Jonathan Light","Yuanzhe Liu","Ziniu Hu"],"pdf_url":"https://arxiv.org/pdf/2407.20299v2.pdf","comment":"ICML 2024 DMLR Workshop"},{"id":"http://arxiv.org/abs/2407.12254v2","updated":"2024-08-01T01:21:57Z","published":"2024-07-17T01:51:27Z","title":"COKE: Causal Discovery with Chronological Order and Expert Knowledge in\n  High Proportion of Missing Manufacturing Data","summary":"  Understanding causal relationships between machines is crucial for fault\ndiagnosis and optimization in manufacturing processes. Real-world datasets\nfrequently exhibit up to 90% missing data and high dimensionality from hundreds\nof sensors. These datasets also include domain-specific expert knowledge and\nchronological order information, reflecting the recording order across\ndifferent machines, which is pivotal for discerning causal relationships within\nthe manufacturing data. However, previous methods for handling missing data in\nscenarios akin to real-world conditions have not been able to effectively\nutilize expert knowledge. Conversely, prior methods that can incorporate expert\nknowledge struggle with datasets that exhibit missing values. Therefore, we\npropose COKE to construct causal graphs in manufacturing datasets by leveraging\nexpert knowledge and chronological order among sensors without imputing missing\ndata. Utilizing the characteristics of the recipe, we maximize the use of\nsamples with missing values, derive embeddings from intersections with an\ninitial graph that incorporates expert knowledge and chronological order, and\ncreate a sensor ordering graph. The graph-generating process has been optimized\nby an actor-critic architecture to obtain a final graph that has a maximum\nreward. Experimental evaluations in diverse settings of sensor quantities and\nmissing proportions demonstrate that our approach compared with the benchmark\nmethods shows an average improvement of 39.9% in the F1-score. Moreover, the\nF1-score improvement can reach 62.6% when considering the configuration similar\nto real-world datasets, and 85.0% in real-world semiconductor datasets. The\nsource code is available at https://github.com/OuTingYun/COKE.\n","authors":["Ting-Yun Ou","Ching Chang","Wen-Chih Peng"],"pdf_url":"https://arxiv.org/pdf/2407.12254v2.pdf","comment":"This paper has been accepted by the ACM International Conference on\n  Information and Knowledge Management (CIKM) 2024"},{"id":"http://arxiv.org/abs/2401.10467v2","updated":"2024-08-01T01:07:35Z","published":"2024-01-19T03:39:43Z","title":"Learning Backdoors for Mixed Integer Linear Programs with Contrastive\n  Learning","summary":"  Many real-world problems can be efficiently modeled as Mixed Integer Linear\nPrograms (MILPs) and solved with the Branch-and-Bound method. Prior work has\nshown the existence of MILP backdoors, small sets of variables such that\nprioritizing branching on them when possible leads to faster running times.\nHowever, finding high-quality backdoors that improve running times remains an\nopen question. Previous work learns to estimate the relative solver speed of\nrandomly sampled backdoors through ranking and then decide whether to use the\nhighest-ranked backdoor candidate. In this paper, we utilize the Monte-Carlo\ntree search method to collect backdoors for training, rather than relying on\nrandom sampling, and adapt a contrastive learning framework to train a Graph\nAttention Network model to predict backdoors. Our method, evaluated on several\ncommon MILP problem domains, demonstrates performance improvements over both\nGurobi and previous models.\n","authors":["Junyang Cai","Taoan Huang","Bistra Dilkina"],"pdf_url":"https://arxiv.org/pdf/2401.10467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00764v1","updated":"2024-08-01T17:59:46Z","published":"2024-08-01T17:59:46Z","title":"AgentGen: Enhancing Planning Abilities for Large Language Model based\n  Agent via Environment and Task Generation","summary":"  Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.\n","authors":["Mengkang Hu","Pu Zhao","Can Xu","Qingfeng Sun","Jianguang Lou","Qingwei Lin","Ping Luo","Saravan Rajmohan","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00761v1","updated":"2024-08-01T17:59:12Z","published":"2024-08-01T17:59:12Z","title":"Tamper-Resistant Safeguards for Open-Weight LLMs","summary":"  Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.\n","authors":["Rishub Tamirisa","Bhrugu Bharathi","Long Phan","Andy Zhou","Alice Gatti","Tarun Suresh","Maxwell Lin","Justin Wang","Rowan Wang","Ron Arel","Andy Zou","Dawn Song","Bo Li","Dan Hendrycks","Mantas Mazeika"],"pdf_url":"https://arxiv.org/pdf/2408.00761v1.pdf","comment":"Website: https://www.tamper-resistant-safeguards.com"},{"id":"http://arxiv.org/abs/2408.00760v1","updated":"2024-08-01T17:59:09Z","published":"2024-08-01T17:59:09Z","title":"Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy\n  Curvature of Attention","summary":"  Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.\n","authors":["Susung Hong"],"pdf_url":"https://arxiv.org/pdf/2408.00760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00754v1","updated":"2024-08-01T17:57:12Z","published":"2024-08-01T17:57:12Z","title":"Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal\n  Language Model","summary":"  Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.\n","authors":["Benlin Liu","Yuhao Dong","Yiqin Wang","Yongming Rao","Yansong Tang","Wei-Chiu Ma","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2408.00754v1.pdf","comment":"project page: https://coarse-correspondence.github.io"},{"id":"http://arxiv.org/abs/2408.00751v1","updated":"2024-08-01T17:54:01Z","published":"2024-08-01T17:54:01Z","title":"A Policy-Gradient Approach to Solving Imperfect-Information Games with\n  Iterate Convergence","summary":"  Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.\n","authors":["Mingyang Liu","Gabriele Farina","Asuman Ozdaglar"],"pdf_url":"https://arxiv.org/pdf/2408.00751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00749v1","updated":"2024-08-01T17:52:10Z","published":"2024-08-01T17:52:10Z","title":"Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer","summary":"  Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.\n","authors":["Venkat Margapuri","Prapti Thapaliya","Trevor Rife"],"pdf_url":"https://arxiv.org/pdf/2408.00749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00728v1","updated":"2024-08-01T17:20:24Z","published":"2024-08-01T17:20:24Z","title":"CERT-ED: Certifiably Robust Text Classification for Edit Distance","summary":"  With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.\n","authors":["Zhuoqun Huang","Neil G Marchant","Olga Ohrimenko","Benjamin I. P. Rubinstein"],"pdf_url":"https://arxiv.org/pdf/2408.00728v1.pdf","comment":"22 pages, 3 figures, 12 tables. Include 11 pages of appendices"},{"id":"http://arxiv.org/abs/2408.00716v1","updated":"2024-08-01T17:01:29Z","published":"2024-08-01T17:01:29Z","title":"A Natural Language Processing Framework for Hotel Recommendation Based\n  on Users' Text Reviews","summary":"  Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.\n","authors":["Lavrentia Aravani","Emmanuel Pintelas","Christos Pierrakeas","Panagiotis Pintelas"],"pdf_url":"https://arxiv.org/pdf/2408.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00714v1","updated":"2024-08-01T17:00:08Z","published":"2024-08-01T17:00:08Z","title":"SAM 2: Segment Anything in Images and Videos","summary":"  We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.\n","authors":["Nikhila Ravi","Valentin Gabeur","Yuan-Ting Hu","Ronghang Hu","Chaitanya Ryali","Tengyu Ma","Haitham Khedr","Roman Rädle","Chloe Rolland","Laura Gustafson","Eric Mintun","Junting Pan","Kalyan Vasudev Alwala","Nicolas Carion","Chao-Yuan Wu","Ross Girshick","Piotr Dollár","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2408.00714v1.pdf","comment":"Website: https://ai.meta.com/sam2"},{"id":"http://arxiv.org/abs/2408.00713v1","updated":"2024-08-01T16:58:54Z","published":"2024-08-01T16:58:54Z","title":"Insurance Portfolio Pursuit with Reinforcement Learning","summary":"  When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. Given a\ntarget portfolio, we term the problem of modulating offers to achieve this\ntarget portfolio the portfolio pursuit problem. We give a formulation of\nportfolio pursuit as a sequential decision making problem, and devise a novel\nreinforcement learning algorithm for its solution. We test our method on a\ncomplex synthetic market environment, and demonstrate that it outperforms a\nbaseline method which mimics current industry approaches to portfolio pursuit.\n","authors":["Edward James Young","Alistair Rogers","Elliott Tong","James Jordon"],"pdf_url":"https://arxiv.org/pdf/2408.00713v1.pdf","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.00707v1","updated":"2024-08-01T16:54:11Z","published":"2024-08-01T16:54:11Z","title":"Synthetic dual image generation for reduction of labeling efforts in\n  semantic segmentation of micrographs with a customized metric function","summary":"  Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.\n","authors":["Matias Oscar Volman Stern","Dominic Hohs","Andreas Jansche","Timo Bernthaler","Gerhard Schneider"],"pdf_url":"https://arxiv.org/pdf/2408.00707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00706v1","updated":"2024-08-01T16:52:39Z","published":"2024-08-01T16:52:39Z","title":"Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM","summary":"  Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.\n","authors":["Xiaofeng Liu","Jonghye Woo","Chao Ma","Jinsong Ouyang","Georges El Fakhri"],"pdf_url":"https://arxiv.org/pdf/2408.00706v1.pdf","comment":"2024 IEEE Nuclear Science Symposium and Medical Imaging Conference"},{"id":"http://arxiv.org/abs/2408.00700v1","updated":"2024-08-01T16:43:55Z","published":"2024-08-01T16:43:55Z","title":"You Can't Ignore Either: Unifying Structure and Feature Denoising for\n  Robust Graph Learning","summary":"  Recent research on the robustness of Graph Neural Networks (GNNs) under\nnoises or attacks has attracted great attention due to its importance in\nreal-world applications. Most previous methods explore a single noise source,\nrecovering corrupt node embedding by reliable structures bias or developing\nstructure learning with reliable node features. However, the noises and attacks\nmay come from both structures and features in graphs, making the graph\ndenoising a dilemma and challenging problem. In this paper, we develop a\nunified graph denoising (UGD) framework to unravel the deadlock between\nstructure and feature denoising. Specifically, a high-order neighborhood\nproximity evaluation method is proposed to recognize noisy edges, considering\nfeatures may be perturbed simultaneously. Moreover, we propose to refine noisy\nfeatures with reconstruction based on a graph auto-encoder. An iterative\nupdating algorithm is further designed to optimize the framework and acquire a\nclean graph, thus enabling robust graph learning for downstream tasks. Our UGD\nframework is self-supervised and can be easily implemented as a plug-and-play\nmodule. We carry out extensive experiments, which proves the effectiveness and\nadvantages of our method. Code is avalaible at\nhttps://github.com/YoungTimmy/UGD.\n","authors":["Tianmeng Yang","Jiahao Meng","Min Zhou","Yaming Yang","Yujing Wang","Xiangtai Li","Yunhai Tong"],"pdf_url":"https://arxiv.org/pdf/2408.00700v1.pdf","comment":"Accepted by CIKM'2024"},{"id":"http://arxiv.org/abs/2408.00699v1","updated":"2024-08-01T16:43:21Z","published":"2024-08-01T16:43:21Z","title":"Granular-Balls based Fuzzy Twin Support Vector Machine for\n  Classification","summary":"  The twin support vector machine (TWSVM) classifier has attracted increasing\nattention because of its low computational complexity. However, its performance\ntends to degrade when samples are affected by noise. The granular-ball fuzzy\nsupport vector machine (GBFSVM) classifier partly alleviates the adverse\neffects of noise, but it relies solely on the distance between the\ngranular-ball's center and the class center to design the granular-ball\nmembership function. In this paper, we first introduce the granular-ball twin\nsupport vector machine (GBTWSVM) classifier, which integrates granular-ball\ncomputing (GBC) with the twin support vector machine (TWSVM) classifier. By\nreplacing traditional point inputs with granular-balls, we demonstrate how to\nderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solving\na quadratic programming problem. Subsequently, we design the membership and\nnon-membership functions of granular-balls using Pythagorean fuzzy sets to\ndifferentiate the contributions of granular-balls in various regions.\nAdditionally, we develop the granular-ball fuzzy twin support vector machine\n(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vector\nmachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallel\nhyperplanes for the GBFTSVM classifier by solving a quadratic programming\nproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVM\nclassifier. Finally, the superior classification performance of the GBTWSVM\nclassifier and the GBFTSVM classifier on 20 benchmark datasets underscores\ntheir scalability, efficiency, and robustness in tackling classification tasks.\n","authors":["Lixi Zhao","Weiping Ding","Duoqian Miao","Guangming Lang"],"pdf_url":"https://arxiv.org/pdf/2408.00699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00695v1","updated":"2024-08-01T16:39:06Z","published":"2024-08-01T16:39:06Z","title":"Accelerating Full Waveform Inversion By Transfer Learning","summary":"  Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.\n","authors":["Divya Shyam Singh","Leon Herrmann","Qing Sun","Tim Bürchner","Felix Dietrich","Stefan Kollmannsberger"],"pdf_url":"https://arxiv.org/pdf/2408.00695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00681v1","updated":"2024-08-01T16:22:03Z","published":"2024-08-01T16:22:03Z","title":"Alpha-VI DeepONet: A prior-robust variational Bayesian approach for\n  enhancing DeepONets with uncertainty quantification","summary":"  We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.\n","authors":["Soban Nasir Lone","Subhayan De","Rajdip Nayek"],"pdf_url":"https://arxiv.org/pdf/2408.00681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00676v1","updated":"2024-08-01T16:19:08Z","published":"2024-08-01T16:19:08Z","title":"An effect analysis of the balancing techniques on the counterfactual\n  explanations of student success prediction models","summary":"  In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.\n","authors":["Mustafa Cavus","Jakub Kuzilek"],"pdf_url":"https://arxiv.org/pdf/2408.00676v1.pdf","comment":"19 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.00674v1","updated":"2024-08-01T16:16:29Z","published":"2024-08-01T16:16:29Z","title":"ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio","summary":"  In the Western music tradition, chords are the main constituent components of\nharmony, a fundamental dimension of music. Despite its relevance for several\nMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets are\nlimited and need more diversity. One way to improve those resources is to\nleverage the large number of chord annotations available online, but this\nrequires aligning them with music audio. However, existing audio-to-score\nalignment techniques, which typically rely on Dynamic Time Warping (DTW), fail\nto address this challenge, as they require weakly aligned data for precise\nsynchronisation. In this paper, we introduce ChordSync, a novel conformer-based\nmodel designed to seamlessly align chord annotations with audio, eliminating\nthe need for weak alignment. We also provide a pre-trained model and a\nuser-friendly library, enabling users to synchronise chord annotations with\naudio tracks effortlessly. In this way, ChordSync creates opportunities for\nharnessing crowd-sourced chord data for MIR, especially in audio chord\nestimation, thereby facilitating the generation of novel datasets.\nAdditionally, our system extends its utility to music education, enhancing\nmusic learning experiences by providing accurately aligned annotations, thus\nenabling learners to engage in synchronised musical practices.\n","authors":["Andrea Poltronieri","Valentina Presutti","Martín Rocamora"],"pdf_url":"https://arxiv.org/pdf/2408.00674v1.pdf","comment":"8 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2408.00665v1","updated":"2024-08-01T16:01:51Z","published":"2024-08-01T16:01:51Z","title":"AutoM3L: An Automated Multimodal Machine Learning Framework with Large\n  Language Models","summary":"  Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.\n","authors":["Daqin Luo","Chengjian Feng","Yuxuan Nong","Yiqing Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00665v1.pdf","comment":"Accpeted by ACMMM2024"},{"id":"http://arxiv.org/abs/2408.00662v1","updated":"2024-08-01T15:58:05Z","published":"2024-08-01T15:58:05Z","title":"Aligning Multiple Knowledge Graphs in a Single Pass","summary":"  Entity alignment (EA) is to identify equivalent entities across different\nknowledge graphs (KGs), which can help fuse these KGs into a more comprehensive\none. Previous EA methods mainly focus on aligning a pair of KGs, and to the\nbest of our knowledge, no existing EA method considers aligning multiple (more\nthan two) KGs. To fill this research gap, in this work, we study a novel\nproblem of aligning multiple KGs and propose an effective framework named\nMultiEA to solve the problem. First, we embed the entities of all the candidate\nKGs into a common feature space by a shared KG encoder. Then, we explore three\nalignment strategies to minimize the distances among pre-aligned entities. In\nparticular, we propose an innovative inference enhancement technique to improve\nthe alignment performance by incorporating high-order similarities. Finally, to\nverify the effectiveness of MultiEA, we construct two new real-world benchmark\ndatasets and conduct extensive experiments on them. The results show that our\nMultiEA can effectively and efficiently align multiple KGs in a single pass.\n","authors":["Yaming Yang","Zhe Wang","Ziyu Guan","Wei Zhao","Weigang Lu","Xinyan Huang"],"pdf_url":"https://arxiv.org/pdf/2408.00662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00657v1","updated":"2024-08-01T15:46:22Z","published":"2024-08-01T15:46:22Z","title":"Disentangling Dense Embeddings with Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.\n","authors":["Charles O'Neill","Christine Ye","Kartheik Iyer","John F. Wu"],"pdf_url":"https://arxiv.org/pdf/2408.00657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00652v1","updated":"2024-08-01T15:41:08Z","published":"2024-08-01T15:41:08Z","title":"Enhancing Multistep Prediction of Multivariate Market Indices Using\n  Weighted Optical Reservoir Computing","summary":"  We propose and experimentally demonstrate an innovative stock index\nprediction method using a weighted optical reservoir computing system. We\nconstruct fundamental market data combined with macroeconomic data and\ntechnical indicators to capture the broader behavior of the stock market. Our\napproach shows significant higher performance than state-of-the-art methods\nsuch as linear regression, decision trees, and neural network architectures\nincluding long short-term memory. It captures well the market's high volatility\nand nonlinear behaviors despite limited data, demonstrating great potential for\nreal-time, parallel, multi-dimensional data processing and predictions.\n","authors":["Fang Wang","Ting Bu","Yuping Huang"],"pdf_url":"https://arxiv.org/pdf/2408.00652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00641v1","updated":"2024-08-01T15:30:43Z","published":"2024-08-01T15:30:43Z","title":"Enhancing Ethereum Fraud Detection via Generative and Contrastive\n  Self-supervision","summary":"  The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be released on GitHub soon.\n","authors":["Chenxiang Jin","Jiajun Zhou","Chenxuan Xie","Shanqing Yu","Qi Xuan","Xiaoniu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.00641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00639v1","updated":"2024-08-01T15:26:24Z","published":"2024-08-01T15:26:24Z","title":"Privacy-preserving datasets by capturing feature distributions with\n  Conditional VAEs","summary":"  Large and well-annotated datasets are essential for advancing deep learning\napplications, however often costly or impossible to obtain by a single entity.\nIn many areas, including the medical domain, approaches relying on data sharing\nhave become critical to address those challenges. While effective in increasing\ndataset size and diversity, data sharing raises significant privacy concerns.\nCommonly employed anonymization methods based on the k-anonymity paradigm often\nfail to preserve data diversity, affecting model robustness. This work\nintroduces a novel approach using Conditional Variational Autoencoders (CVAEs)\ntrained on feature vectors extracted from large pre-trained vision foundation\nmodels. Foundation models effectively detect and represent complex patterns\nacross diverse domains, allowing the CVAE to faithfully capture the embedding\nspace of a given data distribution to generate (sample) a diverse,\nprivacy-respecting, and potentially unbounded set of synthetic feature vectors.\nOur method notably outperforms traditional approaches in both medical and\nnatural image domains, exhibiting greater dataset diversity and higher\nrobustness against perturbations while preserving sample privacy. These results\nunderscore the potential of generative models to significantly impact deep\nlearning applications in data-scarce and privacy-sensitive environments. The\nsource code is available at\nhttps://github.com/francescodisalvo05/cvae-anonymization .\n","authors":["Francesco Di Salvo","David Tafler","Sebastian Doerrich","Christian Ledig"],"pdf_url":"https://arxiv.org/pdf/2408.00639v1.pdf","comment":"Accepted at BMVC 2024"},{"id":"http://arxiv.org/abs/2408.00613v1","updated":"2024-08-01T14:53:11Z","published":"2024-08-01T14:53:11Z","title":"Unlocking Fair Use in the Generative AI Supply Chain: A Systematized\n  Literature Review","summary":"  Through a systematization of generative AI (GenAI) stakeholder goals and\nexpectations, this work seeks to uncover what value different stakeholders see\nin their contributions to the GenAI supply line. This valuation enables us to\nunderstand whether fair use advocated by GenAI companies to train model\nprogresses the copyright law objective of promoting science and arts. While\nassessing the validity and efficacy of the fair use argument, we uncover\nresearch gaps and potential avenues for future works for researchers and\npolicymakers to address.\n","authors":["Amruta Mahuli","Asia Biega"],"pdf_url":"https://arxiv.org/pdf/2408.00613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00611v1","updated":"2024-08-01T14:49:43Z","published":"2024-08-01T14:49:43Z","title":"Using CSNNs to Perform Event-based Data Processing & Classification on\n  ASL-DVS","summary":"  Recent advancements in bio-inspired visual sensing and neuromorphic computing\nhave led to the development of various highly efficient bio-inspired solutions\nwith real-world applications. One notable application integrates event-based\ncameras with spiking neural networks (SNNs) to process event-based sequences\nthat are asynchronous and sparse, making them difficult to handle. In this\nproject, we develop a convolutional spiking neural network (CSNN) architecture\nthat leverages convolutional operations and recurrent properties of a spiking\nneuron to learn the spatial and temporal relations in the ASL-DVS gesture\ndataset. The ASL-DVS gesture dataset is a neuromorphic dataset containing hand\ngestures when displaying 24 letters (A to Y, excluding J and Z due to the\nnature of their symbols) from the American Sign Language (ASL). We performed\nclassification on a pre-processed subset of the full ASL-DVS dataset to\nidentify letter signs and achieved 100\\% training accuracy. Specifically, this\nwas achieved by training in the Google Cloud compute platform while using a\nlearning rate of 0.0005, batch size of 25 (total of 20 batches), 200\niterations, and 10 epochs.\n","authors":["Ria Patel","Sujit Tripathy","Zachary Sublett","Seoyoung An","Riya Patel"],"pdf_url":"https://arxiv.org/pdf/2408.00611v1.pdf","comment":"8 pages, 14 figures"},{"id":"http://arxiv.org/abs/2408.00601v1","updated":"2024-08-01T14:35:24Z","published":"2024-08-01T14:35:24Z","title":"AutoPV: Automatically Design Your Photovoltaic Power Forecasting Model","summary":"  Photovoltaic power forecasting (PVPF) is a critical area in time series\nforecasting (TSF), enabling the efficient utilization of solar energy. With\nadvancements in machine learning and deep learning, various models have been\napplied to PVPF tasks. However, constructing an optimal predictive architecture\nfor specific PVPF tasks remains challenging, as it requires cross-domain\nknowledge and significant labor costs. To address this challenge, we introduce\nAutoPV, a novel framework for the automated search and construction of PVPF\nmodels based on neural architecture search (NAS) technology. We develop a brand\nnew NAS search space that incorporates various data processing techniques from\nstate-of-the-art (SOTA) TSF models and typical PVPF deep learning models. The\neffectiveness of AutoPV is evaluated on diverse PVPF tasks using a dataset from\nthe Daqing Photovoltaic Station in China. Experimental results demonstrate that\nAutoPV can complete the predictive architecture construction process in a\nrelatively short time, and the newly constructed architecture is superior to\nSOTA predefined models. This work bridges the gap in applying NAS to TSF\nproblems, assisting non-experts and industries in automatically designing\neffective PVPF models.\n","authors":["Dayin Chen","Xiaodan Shi","Mingkun Jiang","Haoran Zhang","Dongxiao Zhang","Yuntian Chen","Jinyue Yan"],"pdf_url":"https://arxiv.org/pdf/2408.00601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00573v1","updated":"2024-08-01T14:06:34Z","published":"2024-08-01T14:06:34Z","title":"Convergence Analysis of Natural Gradient Descent for Over-parameterized\n  Physics-Informed Neural Networks","summary":"  First-order methods, such as gradient descent (GD) and stochastic gradient\ndescent (SGD) have been proven effective in training neural networks. In the\nsetting of over-parameterization, there is a line of work demonstrating that\nrandomly initialized (stochastic) gradient descent converges to a globally\noptimal solution at a linear convergence rate for the quadratic loss function.\nHowever, the learning rate of GD in training two-layer neural networks has a\npoor dependence on the sample size and the Gram matrix, resulting in a slow\ntraining process. In this paper, we show that for the $L^2$ regression\nproblems, the learning rate can be improved from $\\mathcal{O}(\\lambda_0/n^2)$\nto $\\mathcal{O}(1/\\|\\bm{H}^{\\infty}\\|_2)$, which implies that GD enjoys a\nfaster convergence rate. Moreover, we further generalize the method for GD in\ntraining two-layer Physics-Informed Neural Networks (PINNs), showing a similar\nimprovement for the learning rate. Although the improved learning rate depends\nmildly on the Gram matrix, we still need to set it small enough in practice due\nto the agnostic eigenvalues of the Gram matrix. More importantly, the\nconvergence rate relies on the least eigenvalue of the Gram matrix, leading to\nslow convergence. In this work, we provide the convergence analysis of natural\ngradient descent (NGD) in training two-layer PINNs. We show that the learning\nrate can be $\\mathcal{O}(1)$ and at this time, the convergence rate is\nindependent of the Gram matrix.\n","authors":["Xianliang Xu","Ting Du","Wang Kong","Ye Li","Zhongyi Huang"],"pdf_url":"https://arxiv.org/pdf/2408.00573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00570v1","updated":"2024-08-01T14:03:11Z","published":"2024-08-01T14:03:11Z","title":"Analyzing the Effectiveness of Quantum Annealing with Meta-Learning","summary":"  The field of Quantum Computing has gathered significant popularity in recent\nyears and a large number of papers have studied its effectiveness in tackling\nmany tasks. We focus in particular on Quantum Annealing (QA), a meta-heuristic\nsolver for Quadratic Unconstrained Binary Optimization (QUBO) problems. It is\nknown that the effectiveness of QA is dependent on the task itself, as is the\ncase for classical solvers, but there is not yet a clear understanding of which\nare the characteristics of a problem that makes it difficult to solve with QA.\nIn this work, we propose a new methodology to study the effectiveness of QA\nbased on meta-learning models. To do so, we first build a dataset composed of\nmore than five thousand instances of ten different optimization problems. We\ndefine a set of more than a hundred features to describe their characteristics,\nand solve them with both QA and three classical solvers. We publish this\ndataset online for future research. Then, we train multiple meta-models to\npredict whether QA would solve that instance effectively and use them to probe\nwhich are the features with the strongest impact on the effectiveness of QA.\nOur results indicate that it is possible to accurately predict the\neffectiveness of QA, validating our methodology. Furthermore, we observe that\nthe distribution of the problem coefficients representing the bias and coupling\nterms is very informative to identify the probability of finding good\nsolutions, while the density of these coefficients alone is not enough. The\nmethodology we propose allows to open new research directions to further our\nunderstanding of the effectiveness of QA, by probing specific dimensions or by\ndeveloping new QUBO formulations that are better suited for the particular\nnature of QA. Furthermore, the proposed methodology is flexible and can be\nextended or used to study other quantum or classical solvers.\n","authors":["Riccardo Pellini","Maurizio Ferrari Dacrema"],"pdf_url":"https://arxiv.org/pdf/2408.00570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00549v1","updated":"2024-08-01T13:34:19Z","published":"2024-08-01T13:34:19Z","title":"Learning to Embed Distributions via Maximum Kernel Entropy","summary":"  Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.\n","authors":["Oleksii Kachaiev","Stefano Recanatesi"],"pdf_url":"https://arxiv.org/pdf/2408.00549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00540v1","updated":"2024-08-01T13:23:15Z","published":"2024-08-01T13:23:15Z","title":"The Energy Cost of Artificial Intelligence of Things Lifecycle","summary":"  Artificial intelligence (AI)coupled with existing Internet of Things (IoT)\nenables more streamlined and autonomous operations across various economic\nsectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)\nhaving AI techniques at its core implies additional energy and carbon costs\nthat may become significant with more complex neural architectures. To better\nunderstand the energy and Carbon Footprint (CF) of some AIoT components, very\nrecent studies employ conventional metrics. However, these metrics are not\ndesigned to capture energy efficiency aspects of inference. In this paper, we\npropose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the\noverall energy cost of inference over the lifecycle of an AIoT system. We\ndevise a new methodology for determining eCAL of an AIoT system by analyzing\nthe complexity of data manipulation in individual components involved in the\nAIoT lifecycle and derive the overall and per bit energy consumption. With eCAL\nwe show that the better a model is and the more it is used, the more energy\nefficient an inference is. For an example AIoT configuration, eCAL for making\n$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also\nevaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$\nemissions based on the energy consumption and the Carbon Intensity (CI) across\ndifferent countries. Using 2023 renewable data, our analysis reveals that\ndeploying an AIoT system in Germany results in emitting $4.62$ times higher\nCO$_2$ than in Finland, due to latter using more low-CI energy sources.\n","authors":["Shih-Kai Chou","Jernej Hribar","Mihael Mohorčič","Carolina Fortuna"],"pdf_url":"https://arxiv.org/pdf/2408.00540v1.pdf","comment":"12 pages, 13 figures"},{"id":"http://arxiv.org/abs/2408.00531v1","updated":"2024-08-01T13:08:02Z","published":"2024-08-01T13:08:02Z","title":"ReSi: A Comprehensive Benchmark for Representational Similarity Measures","summary":"  Measuring the similarity of different representations of neural architectures\nis a fundamental task and an open research challenge for the machine learning\ncommunity. This paper presents the first comprehensive benchmark for evaluating\nrepresentational similarity measures based on well-defined groundings of\nsimilarity. The representational similarity (ReSi) benchmark consists of (i)\nsix carefully designed tests for similarity measures, (ii) 23 similarity\nmeasures, (iii) eleven neural network architectures, and (iv) six datasets,\nspanning over the graph, language, and vision domains. The benchmark opens up\nseveral important avenues of research on representational similarity that\nenable novel explorations and applications of neural architectures. We\ndemonstrate the utility of the ReSi benchmark by conducting experiments on\nvarious neural network architectures, real world datasets and similarity\nmeasures. All components of the benchmark are publicly available and thereby\nfacilitate systematic reproduction and production of research results. The\nbenchmark is extensible, future research can build on and further expand it. We\nbelieve that the ReSi benchmark can serve as a sound platform catalyzing future\nresearch that aims to systematically evaluate existing and explore novel ways\nof comparing representations of neural architectures.\n","authors":["Max Klabunde","Tassilo Wald","Tobias Schumacher","Klaus Maier-Hein","Markus Strohmaier","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2408.00531v1.pdf","comment":"Feedback welcome! Code and data at https://github.com/mklabunde/resi"},{"id":"http://arxiv.org/abs/2408.00527v1","updated":"2024-08-01T12:58:19Z","published":"2024-08-01T12:58:19Z","title":"Contrastive Learning with Dynamic Localized Repulsion for Brain Age\n  Prediction on 3D Stiffness Maps","summary":"  In the field of neuroimaging, accurate brain age prediction is pivotal for\nuncovering the complexities of brain aging and pinpointing early indicators of\nneurodegenerative conditions. Recent advancements in self-supervised learning,\nparticularly in contrastive learning, have demonstrated greater robustness when\ndealing with complex datasets. However, current approaches often fall short in\ngeneralizing across non-uniformly distributed data, prevalent in medical\nimaging scenarios. To bridge this gap, we introduce a novel contrastive loss\nthat adapts dynamically during the training process, focusing on the localized\nneighborhoods of samples. Moreover, we expand beyond traditional structural\nfeatures by incorporating brain stiffness, a mechanical property previously\nunderexplored yet promising due to its sensitivity to age-related changes. This\nwork presents the first application of self-supervised learning to brain\nmechanical properties, using compiled stiffness maps from various clinical\nstudies to predict brain age. Our approach, featuring dynamic localized loss,\nconsistently outperforms existing state-of-the-art methods, demonstrating\nsuperior performance and laying the way for new directions in brain aging\nresearch.\n","authors":["Jakob Träuble","Lucy Hiscox","Curtis Johnson","Carola-Bibiane Schönlieb","Gabriele Kaminski Schierle","Angelica Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2408.00527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00526v1","updated":"2024-08-01T12:57:35Z","published":"2024-08-01T12:57:35Z","title":"Hilbert curves for efficient exploratory landscape analysis\n  neighbourhood sampling","summary":"  Landscape analysis aims to characterise optimisation problems based on their\nobjective (or fitness) function landscape properties. The problem search space\nis typically sampled, and various landscape features are estimated based on the\nsamples. One particularly salient set of features is information content, which\nrequires the samples to be sequences of neighbouring solutions, such that the\nlocal relationships between consecutive sample points are preserved. Generating\nsuch spatially correlated samples that also provide good search space coverage\nis challenging. It is therefore common to first obtain an unordered sample with\ngood search space coverage, and then apply an ordering algorithm such as the\nnearest neighbour to minimise the distance between consecutive points in the\nsample. However, the nearest neighbour algorithm becomes computationally\nprohibitive in higher dimensions, thus there is a need for more efficient\nalternatives. In this study, Hilbert space-filling curves are proposed as a\nmethod to efficiently obtain high-quality ordered samples. Hilbert curves are a\nspecial case of fractal curves, and guarantee uniform coverage of a bounded\nsearch space while providing a spatially correlated sample. We study the\neffectiveness of Hilbert curves as samplers, and discover that they are capable\nof extracting salient features at a fraction of the computational cost compared\nto Latin hypercube sampling with post-factum ordering. Further, we investigate\nthe use of Hilbert curves as an ordering strategy, and find that they order the\nsample significantly faster than the nearest neighbour ordering, without\nsacrificing the saliency of the extracted features.\n","authors":["Johannes J. Pienaar","Anna S. Bosman","Katherine M. Malan"],"pdf_url":"https://arxiv.org/pdf/2408.00526v1.pdf","comment":"A version of this paper is published as conference proceedings of\n  EvoApps 2024"},{"id":"http://arxiv.org/abs/2408.00525v1","updated":"2024-08-01T12:57:12Z","published":"2024-08-01T12:57:12Z","title":"Identifying the Hierarchical Emotional Areas in the Human Brain Through\n  Information Fusion","summary":"  The brain basis of emotion has consistently received widespread attention,\nattracting a large number of studies to explore this cutting-edge topic.\nHowever, the methods employed in these studies typically only model the\npairwise relationship between two brain regions, while neglecting the\ninteractions and information fusion among multiple brain\nregions$\\unicode{x2014}$one of the key ideas of the psychological\nconstructionist hypothesis. To overcome the limitations of traditional methods,\nthis study provides an in-depth theoretical analysis of how to maximize\ninteractions and information fusion among brain regions. Building on the\nresults of this analysis, we propose to identify the hierarchical emotional\nareas in the human brain through multi-source information fusion and graph\nmachine learning methods. Comprehensive experiments reveal that the identified\nhierarchical emotional areas, from lower to higher levels, primarily facilitate\nthe fundamental process of emotion perception, the construction of basic\npsychological operations, and the coordination and integration of these\noperations. Overall, our findings provide unique insights into the brain\nmechanisms underlying specific emotions based on the psychological\nconstructionist hypothesis.\n","authors":["Zhongyu Huang","Changde Du","Chaozhuo Li","Kaicheng Fu","Huiguang He"],"pdf_url":"https://arxiv.org/pdf/2408.00525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00523v1","updated":"2024-08-01T12:54:46Z","published":"2024-08-01T12:54:46Z","title":"Jailbreaking Text-to-Image Models with LLM-Based Agents","summary":"  Recent advancements have significantly improved automated task-solving\ncapabilities using autonomous agents powered by large language models (LLMs).\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\ndomains, leaving gaps in addressing generative AI safety tasks. These gaps are\nprimarily due to the challenges posed by LLM hallucinations and the lack of\nclear guidelines. In this paper, we propose Atlas, an advanced LLM-based\nmulti-agent framework that integrates an efficient fuzzing workflow to target\ngenerative AI models, specifically focusing on jailbreak attacks against\ntext-to-image (T2I) models with safety filters. Atlas utilizes a\nvision-language model (VLM) to assess whether a prompt triggers the T2I model's\nsafety filter. It then iteratively collaborates with both LLM and VLM to\ngenerate an alternative prompt that bypasses the filter. Atlas also enhances\nthe reasoning abilities of LLMs in attack scenarios by leveraging multi-agent\ncommunication, in-context learning (ICL) memory mechanisms, and the\nchain-of-thought (COT) approach. Our evaluation demonstrates that Atlas\nsuccessfully jailbreaks several state-of-the-art T2I models in a black-box\nsetting, which are equipped with multi-modal safety filters. In addition, Atlas\noutperforms existing methods in both query efficiency and the quality of the\ngenerated images.\n","authors":["Yingkai Dong","Zheng Li","Xiangtao Meng","Ning Yu","Shanqing Guo"],"pdf_url":"https://arxiv.org/pdf/2408.00523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00516v1","updated":"2024-08-01T12:46:37Z","published":"2024-08-01T12:46:37Z","title":"Low-Power Vibration-Based Predictive Maintenance for Industry 4.0 using\n  Neural Networks: A Survey","summary":"  The advancements in smart sensors for Industry 4.0 offer ample opportunities\nfor low-powered predictive maintenance and condition monitoring. However,\ntraditional approaches in this field rely on processing in the cloud, which\nincurs high costs in energy and storage. This paper investigates the potential\nof neural networks for low-power on-device computation of vibration sensor data\nfor predictive maintenance. We review the literature on Spiking Neural Networks\n(SNNs) and Artificial Neuronal Networks (ANNs) for vibration-based predictive\nmaintenance by analyzing datasets, data preprocessing, network architectures,\nand hardware implementations. Our findings suggest that no satisfactory\nstandard benchmark dataset exists for evaluating neural networks in predictive\nmaintenance tasks. Furthermore frequency domain transformations are commonly\nemployed for preprocessing. SNNs mainly use shallow feed forward architectures,\nwhereas ANNs explore a wider range of models and deeper networks. Finally, we\nhighlight the need for future research on hardware implementations of neural\nnetworks for low-power predictive maintenance applications and the development\nof a standardized benchmark dataset.\n","authors":["Alexandru Vasilache","Sven Nitzsche","Daniel Floegel","Tobias Schuermann","Stefan von Dosky","Thomas Bierweiler","Marvin Mußler","Florian Kälber","Soeren Hohmann","Juergen Becker"],"pdf_url":"https://arxiv.org/pdf/2408.00516v1.pdf","comment":"The final version will be published at the ECML-PKDD 2024 joint\n  post-workshop proceeding in Springer Communications in Computer and\n  Information Science"},{"id":"http://arxiv.org/abs/2408.00513v1","updated":"2024-08-01T12:39:27Z","published":"2024-08-01T12:39:27Z","title":"VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for\n  Enhanced Detection","summary":"  Fraud detection presents a challenging task characterized by ever-evolving\nfraud patterns and scarce labeled data. Existing methods predominantly rely on\ngraph-based or sequence-based approaches. While graph-based approaches connect\nusers through shared entities to capture structural information, they remain\nvulnerable to fraudsters who can disrupt or manipulate these connections. In\ncontrast, sequence-based approaches analyze users' behavioral patterns,\noffering robustness against tampering but overlooking the interactions between\nsimilar users. Inspired by cohort analysis in retention and healthcare, this\npaper introduces VecAug, a novel cohort-augmented learning framework that\naddresses these challenges by enhancing the representation learning of target\nusers with personalized cohort information. To this end, we first propose a\nvector burn-in technique for automatic cohort identification, which retrieves a\ntask-specific cohort for each target user. Then, to fully exploit the cohort\ninformation, we introduce an attentive cohort aggregation technique for\naugmenting target user representations. To improve the robustness of such\ncohort augmentation, we also propose a novel label-aware cohort neighbor\nseparation mechanism to distance negative cohort neighbors and calibrate the\naggregated cohort information. By integrating this cohort information with\ntarget user representations, VecAug enhances the modeling capacity and\ngeneralization capabilities of the model to be augmented. Our framework is\nflexible and can be seamlessly integrated with existing fraud detection models.\nWe deploy our framework on e-commerce platforms and evaluate it on three fraud\ndetection datasets, and results show that VecAug improves the detection\nperformance of base models by up to 2.48\\% in AUC and 22.5\\% in R@P$_{0.9}$,\noutperforming state-of-the-art methods significantly.\n","authors":["Fei Xiao","Shaofeng Cai","Gang Chen","H. V. Jagadish","Beng Chin Ooi","Meihui Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00513v1.pdf","comment":"Accepted by KDD 2024"},{"id":"http://arxiv.org/abs/2408.00508v1","updated":"2024-08-01T12:28:22Z","published":"2024-08-01T12:28:22Z","title":"Block-Operations: Using Modular Routing to Improve Compositional\n  Generalization","summary":"  We explore the hypothesis that poor compositional generalization in neural\nnetworks is caused by difficulties with learning effective routing. To solve\nthis problem, we propose the concept of block-operations, which is based on\nsplitting all activation tensors in the network into uniformly sized blocks and\nusing an inductive bias to encourage modular routing and modification of these\nblocks. Based on this concept we introduce the Multiplexer, a new architectural\ncomponent that enhances the Feed Forward Neural Network (FNN). We\nexperimentally confirm that Multiplexers exhibit strong compositional\ngeneralization. On both a synthetic and a realistic task our model was able to\nlearn the underlying process behind the task, whereas both FNNs and\nTransformers were only able to learn heuristic approximations. We propose as\nfuture work to use the principles of block-operations to improve other existing\narchitectures.\n","authors":["Florian Dietz","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2408.00508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00490v1","updated":"2024-08-01T11:51:52Z","published":"2024-08-01T11:51:52Z","title":"Graph Representation Learning via Causal Diffusion for\n  Out-of-Distribution Recommendation","summary":"  Graph Neural Networks (GNNs)-based recommendation algorithms typically assume\nthat training and testing data are drawn from independent and identically\ndistributed (IID) spaces. However, this assumption often fails in the presence\nof out-of-distribution (OOD) data, resulting in significant performance\ndegradation. In this study, we construct a Structural Causal Model (SCM) to\nanalyze interaction data, revealing that environmental confounders (e.g., the\nCOVID-19 pandemic) lead to unstable correlations in GNN-based models, thus\nimpairing their generalization to OOD data. To address this issue, we propose a\nnovel approach, graph representation learning via causal diffusion\n(CausalDiffRec) for OOD recommendation. This method enhances the model's\ngeneralization on OOD data by eliminating environmental confounding factors and\nlearning invariant graph representations. Specifically, we use backdoor\nadjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This\ninferred distribution is then used as prior knowledge to guide the\nrepresentation learning in the reverse phase of the diffusion process to learn\nthe invariant representation. In addition, we provide a theoretical derivation\nthat proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby\nachieving excellent generalization performance in recommendations under\ndistribution shifts. Our extensive experiments validate the effectiveness of\nCausalDiffRec in improving the generalization of OOD data, and the average\nimprovement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and\n11.65% on Douban datasets.\n","authors":["Chu Zhao","Enneng Yang","Yuliang Liang","Pengxiang Lan","Yuting Liu","Jianzhe Zhao","Guibing Guo","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00490v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2408.00483v1","updated":"2024-08-01T11:39:45Z","published":"2024-08-01T11:39:45Z","title":"A Systematic Review on Long-Tailed Learning","summary":"  Long-tailed data is a special type of multi-class imbalanced data with a very\nlarge amount of minority/tail classes that have a very significant combined\ninfluence. Long-tailed learning aims to build high-performance models on\ndatasets with long-tailed distributions, which can identify all the classes\nwith high accuracy, in particular the minority/tail classes. It is a\ncutting-edge research direction that has attracted a remarkable amount of\nresearch effort in the past few years. In this paper, we present a\ncomprehensive survey of latest advances in long-tailed visual learning. We\nfirst propose a new taxonomy for long-tailed learning, which consists of eight\ndifferent dimensions, including data balancing, neural architecture, feature\nenrichment, logits adjustment, loss function, bells and whistles, network\noptimization, and post hoc processing techniques. Based on our proposed\ntaxonomy, we present a systematic review of long-tailed learning methods,\ndiscussing their commonalities and alignable differences. We also analyze the\ndifferences between imbalance learning and long-tailed learning approaches.\nFinally, we discuss prospects and future directions in this field.\n","authors":["Chongsheng Zhang","George Almpanidis","Gaojuan Fan","Binquan Deng","Yanbo Zhang","Ji Liu","Aouaidjia Kamel","Paolo Soda","João Gama"],"pdf_url":"https://arxiv.org/pdf/2408.00483v1.pdf","comment":"Current Under Revision at IEEE TNNLS. [This is the long/Full-length\n  version of our Long-Tailed Learning Survey paper]"},{"id":"http://arxiv.org/abs/2408.00465v1","updated":"2024-08-01T11:09:01Z","published":"2024-08-01T11:09:01Z","title":"Infrequent Resolving Algorithm for Online Linear Programming","summary":"  Online linear programming (OLP) has gained significant attention from both\nresearchers and practitioners due to its extensive applications, such as online\nauction, network revenue management and advertising. Existing OLP algorithms\nfall into two categories: LP-based algorithms and LP-free algorithms. The\nformer one typically guarantees better performance, even offering a constant\nregret, but requires solving a large number of LPs, which could be\ncomputationally expensive. In contrast, LP-free algorithm only requires\nfirst-order computations but induces a worse performance, lacking a constant\nregret bound. In this work, we bridge the gap between these two extremes by\nproposing an algorithm that achieves a constant regret while solving LPs only\n$O(\\log\\log T)$ times over the time horizon $T$. Moreover, when we are allowed\nto solve LPs only $M$ times, we propose an algorithm that can guarantee an\n$O\\left(T^{(1/2+\\epsilon)^{M-1}}\\right)$ regret. Furthermore, when the arrival\nprobabilities are known at the beginning, our algorithm can guarantee a\nconstant regret by solving LPs $O(\\log\\log T)$ times, and an\n$O\\left(T^{(1/2+\\epsilon)^{M}}\\right)$ regret by solving LPs only $M$ times.\nNumerical experiments are conducted to demonstrate the efficiency of the\nproposed algorithms.\n","authors":["Guokai Li","Zizhuo Wang","Jingwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00465v1.pdf","comment":"35 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.00462v1","updated":"2024-08-01T11:06:05Z","published":"2024-08-01T11:06:05Z","title":"Designing Efficient LLM Accelerators for Edge Devices","summary":"  The increase in open-source availability of Large Language Models (LLMs) has\nenabled users to deploy them on more and more resource-constrained edge devices\nto reduce reliance on network connections and provide more privacy. However,\nthe high computation and memory demands of LLMs make their execution on\nresource-constrained edge devices challenging and inefficient. To address this\nissue, designing new and efficient edge accelerators for LLM inference is\ncrucial. FPGA-based accelerators are ideal for LLM acceleration due to their\nreconfigurability, as they enable model-specific optimizations and higher\nperformance per watt. However, creating and integrating FPGA-based accelerators\nfor LLMs (particularly on edge devices) has proven challenging, mainly due to\nthe limited hardware design flows for LLMs in existing FPGA platforms.\n  To tackle this issue, in this paper we first propose a new design platform,\nnamed SECDA-LLM, that utilizes the SECDA methodology to streamline the process\nof designing, integrating, and deploying efficient FPGA-based LLM accelerators\nfor the llama.cpp inference framework. We then demonstrate, through a case\nstudy, the potential benefits of SECDA-LLM by creating a new MatMul accelerator\nthat supports block floating point quantized operations for LLMs. Our initial\naccelerator design, deployed on the PYNQ-Z1 board, reduces latency 1.7 seconds\nper token or ~2 seconds per word) by 11x over the dual-core Arm NEON-based CPU\nexecution for the TinyLlama model.\n","authors":["Jude Haris","Rappy Saha","Wenhao Hu","José Cano"],"pdf_url":"https://arxiv.org/pdf/2408.00462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00458v1","updated":"2024-08-01T10:55:20Z","published":"2024-08-01T10:55:20Z","title":"Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual\n  Inversion","summary":"  Recent years have seen a tremendous improvement in the quality of video\ngeneration and editing approaches. While several techniques focus on editing\nappearance, few address motion. Current approaches using text, trajectories, or\nbounding boxes are limited to simple motions, so we specify motions with a\nsingle motion reference video instead. We further propose to use a pre-trained\nimage-to-video model rather than a text-to-video model. This approach allows us\nto preserve the exact appearance and position of a target object or scene and\nhelps disentangle appearance from motion. Our method, called motion-textual\ninversion, leverages our observation that image-to-video models extract\nappearance mainly from the (latent) image input, while the text/image embedding\ninjected via cross-attention predominantly controls motion. We thus represent\nmotion using text/image embedding tokens. By operating on an inflated\nmotion-text embedding containing multiple text/image embedding tokens per\nframe, we achieve a high temporal motion granularity. Once optimized on the\nmotion reference video, this embedding can be applied to various target images\nto generate videos with semantically similar motions. Our approach does not\nrequire spatial alignment between the motion reference video and target image,\ngeneralizes across various domains, and can be applied to various tasks such as\nfull-body and face reenactment, as well as controlling the motion of inanimate\nobjects and the camera. We empirically demonstrate the effectiveness of our\nmethod in the semantic video motion transfer task, significantly outperforming\nexisting methods in this context.\n","authors":["Manuel Kansy","Jacek Naruniec","Christopher Schroers","Markus Gross","Romann M. Weber"],"pdf_url":"https://arxiv.org/pdf/2408.00458v1.pdf","comment":"Preprint. All videos in this paper are best viewed as animations with\n  Acrobat Reader by pressing the highlighted frame of each video"},{"id":"http://arxiv.org/abs/2408.00439v1","updated":"2024-08-01T10:19:25Z","published":"2024-08-01T10:19:25Z","title":"Rapid and Power-Aware Learned Optimization for Modular Receive\n  Beamforming","summary":"  Multiple-input multiple-output (MIMO) systems play a key role in wireless\ncommunication technologies. A widely considered approach to realize scalable\nMIMO systems involves architectures comprised of multiple separate modules,\neach with its own beamforming capability. Such models accommodate cell-free\nmassive MIMO and partially connected hybrid MIMO architectures. A core issue\nwith the implementation of modular MIMO arises from the need to rapidly set the\nbeampatterns of the modules, while maintaining their power efficiency. This\nleads to challenging constrained optimization that should be repeatedly solved\non each coherence duration. In this work, we propose a power-oriented\noptimization algorithm for beamforming in uplink modular hybrid MIMO systems,\nwhich learns from data to operate rapidly. We derive our learned optimizer by\ntackling the rate maximization objective using projected gradient ascent steps\nwith momentum. We then leverage data to tune the hyperparameters of the\noptimizer, allowing it to operate reliably in a fixed and small number of\niterations while completely preserving its interpretable operation. We show how\npower efficient beamforming can be encouraged by the learned optimizer, via\nboosting architectures with low-resolution phase shifts and with deactivated\nanalog components. Numerical results show that our learn-to-optimize method\nnotably reduces the number of iterations and computation latency required to\nreliably tune modular MIMO receivers, and that it allows obtaining desirable\nbalances between power efficient designs and throughput.\n","authors":["Ohad Levy","Nir Shlezinger"],"pdf_url":"https://arxiv.org/pdf/2408.00439v1.pdf","comment":"Under review for possible publication in the IEEE"},{"id":"http://arxiv.org/abs/2408.00437v1","updated":"2024-08-01T10:16:57Z","published":"2024-08-01T10:16:57Z","title":"Efficient Patient Fine-Tuned Seizure Detection with a Tensor Kernel\n  Machine","summary":"  Recent developments in wearable devices have made accurate and efficient\nseizure detection more important than ever. A challenge in seizure detection is\nthat patient-specific models typically outperform patient-independent models.\nHowever, in a wearable device one typically starts with a patient-independent\nmodel, until such patient-specific data is available. To avoid having to\nconstruct a new classifier with this data, as required in conventional kernel\nmachines, we propose a transfer learning approach with a tensor kernel machine.\nThis method learns the primal weights in a compressed form using the canonical\npolyadic decomposition, making it possible to efficiently update the weights of\nthe patient-independent model with patient-specific data. The results show that\nthis patient fine-tuned model reaches as high a performance as a\npatient-specific SVM model with a model size that is twice as small as the\npatient-specific model and ten times as small as the patient-independent model.\n","authors":["Seline J. S. de Rooij","Frederiek Wesel","Borbála Hunyadi"],"pdf_url":"https://arxiv.org/pdf/2408.00437v1.pdf","comment":"5 pages, to be published in the EUSIPCO2024 conference proceedings"},{"id":"http://arxiv.org/abs/2408.00426v1","updated":"2024-08-01T09:57:48Z","published":"2024-08-01T09:57:48Z","title":"A Cross-Domain Benchmark for Active Learning","summary":"  Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose \\emph{CDALBench}, the first active\nlearning benchmark which includes tasks in computer vision, natural language\nprocessing and tabular learning. Furthermore, by providing an efficient, greedy\noracle, \\emph{CDALBench} can be evaluated with 50 runs for each experiment. We\nshow, that both the cross-domain character and a large amount of repetitions\nare crucial for sophisticated evaluation of AL research. Concretely, we show\nthat the superiority of specific methods varies over the different domains,\nmaking it important to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.\n","authors":["Thorben Werner","Johannes Burchert","Maximilian Stubbemann","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2408.00426v1.pdf","comment":"Updated version of paper \"Toward Comparable Active Learning\"\n  (arXiv:2311.18356). \"Toward Comparable Active Learning\" is deprecated, please\n  use this version"},{"id":"http://arxiv.org/abs/2408.00421v1","updated":"2024-08-01T09:46:06Z","published":"2024-08-01T09:46:06Z","title":"Towards Evolutionary-based Automated Machine Learning for Small Molecule\n  Pharmacokinetic Prediction","summary":"  Machine learning (ML) is revolutionising drug discovery by expediting the\nprediction of small molecule properties essential for developing new drugs.\nThese properties -- including absorption, distribution, metabolism and\nexcretion (ADME)-- are crucial in the early stages of drug development since\nthey provide an understanding of the course of the drug in the organism, i.e.,\nthe drug's pharmacokinetics. However, existing methods lack personalisation and\nrely on manually crafted ML algorithms or pipelines, which can introduce\ninefficiencies and biases into the process. To address these challenges, we\npropose a novel evolutionary-based automated ML method (AutoML) specifically\ndesigned for predicting small molecule properties, with a particular focus on\npharmacokinetics. Leveraging the advantages of grammar-based genetic\nprogramming, our AutoML method streamlines the process by automatically\nselecting algorithms and designing predictive pipelines tailored to the\nparticular characteristics of input molecular data. Results demonstrate\nAutoML's effectiveness in selecting diverse ML algorithms, resulting in\ncomparable or even improved predictive performances compared to conventional\napproaches. By offering personalised ML-driven pipelines, our method promises\nto enhance small molecule research in drug discovery, providing researchers\nwith a valuable tool for accelerating the development of novel therapeutic\ndrugs.\n","authors":["Alex G. C. de Sá","David B. Ascher"],"pdf_url":"https://arxiv.org/pdf/2408.00421v1.pdf","comment":"Paper accepted and presented at the 14th Workshop on Evolutionary\n  Computation for the Automated Design of Algorithms (ECADA), which happened\n  during the Genetic and Evolutionary Computation Conference (GECCO)"},{"id":"http://arxiv.org/abs/2408.00399v1","updated":"2024-08-01T09:11:08Z","published":"2024-08-01T09:11:08Z","title":"Unsupervised Pairwise Causal Discovery on Heterogeneous Data using\n  Mutual Information Measures","summary":"  A fundamental task in science is to determine the underlying causal relations\nbecause it is the knowledge of this functional structure what leads to the\ncorrect interpretation of an effect given the apparent associations in the\nobserved data. In this sense, Causal Discovery is a technique that tackles this\nchallenge by analyzing the statistical properties of the constituent variables.\nIn this work, we target the generalizability of the discovery method by\nfollowing a reductionist approach that only involves two variables, i.e., the\npairwise or bi-variate setting. We question the current (possibly misleading)\nbaseline results on the basis that they were obtained through supervised\nlearning, which is arguably contrary to this genuinely exploratory endeavor. In\nconsequence, we approach this problem in an unsupervised way, using robust\nMutual Information measures, and observing the impact of the different variable\ntypes, which is oftentimes ignored in the design of solutions. Thus, we provide\na novel set of standard unbiased results that can serve as a reference to guide\nfuture discovery tasks in completely unknown environments.\n","authors":["Alexandre Trilla","Nenad Mijatovic"],"pdf_url":"https://arxiv.org/pdf/2408.00399v1.pdf","comment":"26th International Conference of the Catalan Association for\n  Artificial Intelligence"},{"id":"http://arxiv.org/abs/2408.00386v1","updated":"2024-08-01T08:50:25Z","published":"2024-08-01T08:50:25Z","title":"What comes after transformers? -- A selective survey connecting ideas in\n  deep learning","summary":"  Transformers have become the de-facto standard model in artificial\nintelligence since 2017 despite numerous shortcomings ranging from energy\ninefficiency to hallucinations. Research has made a lot of progress in\nimproving elements of transformers, and, more generally, deep learning\nmanifesting in many proposals for architectures, layers, optimization\nobjectives, and optimization techniques. For researchers it is difficult to\nkeep track of such developments on a broader level. We provide a comprehensive\noverview of the many important, recent works in these areas to those who\nalready have a basic understanding of deep learning. Our focus differs from\nother works, as we target specifically novel, alternative potentially\ndisruptive approaches to transformers as well as successful ideas of recent\ndeep learning. We hope that such a holistic and unified treatment of\ninfluential, recent works and novel ideas helps researchers to form new\nconnections between diverse areas of deep learning. We identify and discuss\nmultiple patterns that summarize the key strategies for successful innovations\nover the last decade as well as works that can be seen as rising stars.\nEspecially, we discuss attempts on how to improve on transformers covering\n(partially) proven methods such as state space models but also including\nfar-out ideas in deep learning that seem promising despite not achieving\nstate-of-the-art results. We also cover a discussion on recent state-of-the-art\nmodels such as OpenAI's GPT series and Meta's LLama models and, Google's Gemini\nmodel family.\n","authors":["Johannes Schneider"],"pdf_url":"https://arxiv.org/pdf/2408.00386v1.pdf","comment":"This is an extended version of the published paper by Johannes\n  Schneider and Michalis Vlachos titled \"A survey of deep learning: From\n  activations to transformers'' which appeared at the International Conference\n  on Agents and Artificial Intelligence(ICAART) in 2024. It was selected for\n  post-publication and has been submitted to the post-publication proceedings"},{"id":"http://arxiv.org/abs/2408.00380v1","updated":"2024-08-01T08:41:13Z","published":"2024-08-01T08:41:13Z","title":"Enhancing Whole Slide Pathology Foundation Models through Stain\n  Normalization","summary":"  Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nStain Normalized Pathology Foundational Model, a novel foundational model\ntrained on patches that have undergone stain normalization. Stain normalization\nhelps reduce color variability arising from different laboratories and\nscanners, enabling the model to learn more consistent features. Stain\nNormalized Pathology Foundational Model is trained using 285,153,903 patches\nextracted from a total of 34,795 WSIs, combining data from The Cancer Genome\nAtlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments\ndemonstrate that Stain Normalized Pathology Foundational Model significantly\nmitigates the feature collapse problem, indicating that the model has learned\nmore generalized features rather than overfitting to individual WSI\ncharacteristics. We compared Stain Normalized Pathology Foundational Model with\nstate-of-the-art models across six downstream task datasets, and our results\nshow that \\name{} achieves excellent performance relative to the number of WSIs\nused and the model's parameter count. This suggests that the application of\nstain normalization has substantially improved the model's efficiency and\ngeneralization capabilities.\n","authors":["Juseung Yun","Yi Hu","Jinhyung Kim","Jongseong Jang","Soonyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00380v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.00376v1","updated":"2024-08-01T08:35:40Z","published":"2024-08-01T08:35:40Z","title":"On the Limitations and Prospects of Machine Unlearning for Generative AI","summary":"  Generative AI (GenAI), which aims to synthesize realistic and diverse data\nsamples from latent variables or other data modalities, has achieved remarkable\nresults in various domains, such as natural language, images, audio, and\ngraphs. However, they also pose challenges and risks to data privacy, security,\nand ethics. Machine unlearning is the process of removing or weakening the\ninfluence of specific data samples or features from a trained model, without\naffecting its performance on other data or tasks. While machine unlearning has\nshown significant efficacy in traditional machine learning tasks, it is still\nunclear if it could help GenAI become safer and aligned with human desire. To\nthis end, this position paper provides an in-depth discussion of the machine\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\nunlearning tasks on GenAI and introduce the background. Subsequently, we\nsystematically examine the limitations of machine unlearning on GenAI models by\nfocusing on the two representative branches: LLMs and image generative\n(diffusion) models. Finally, we provide our prospects mainly from three\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\nconscientiously advocate for the future development of this field.\n","authors":["Shiji Zhou","Lianzhe Wang","Jiangnan Ye","Yongliang Wu","Heng Chang"],"pdf_url":"https://arxiv.org/pdf/2408.00376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00374v1","updated":"2024-08-01T08:32:03Z","published":"2024-08-01T08:32:03Z","title":"Conformal Trajectory Prediction with Multi-View Data Integration in\n  Cooperative Driving","summary":"  Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\n\\url{https://github.com/xichennn/V2I_trajectory_prediction}.\n","authors":["Xi Chen","Rahul Bhadani","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2408.00374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00359v1","updated":"2024-08-01T07:58:51Z","published":"2024-08-01T07:58:51Z","title":"Memorization Capacity for Additive Fine-Tuning with Small ReLU Networks","summary":"  Fine-tuning large pre-trained models is a common practice in machine learning\napplications, yet its mathematical analysis remains largely unexplored. In this\npaper, we study fine-tuning through the lens of memorization capacity. Our new\nmeasure, the Fine-Tuning Capacity (FTC), is defined as the maximum number of\nsamples a neural network can fine-tune, or equivalently, as the minimum number\nof neurons ($m$) needed to arbitrarily change $N$ labels among $K$ samples\nconsidered in the fine-tuning process. In essence, FTC extends the memorization\ncapacity concept to the fine-tuning scenario. We analyze FTC for the additive\nfine-tuning scenario where the fine-tuned network is defined as the summation\nof the frozen pre-trained network $f$ and a neural network $g$ (with $m$\nneurons) designed for fine-tuning. When $g$ is a ReLU network with either 2 or\n3 layers, we obtain tight upper and lower bounds on FTC; we show that $N$\nsamples can be fine-tuned with $m=\\Theta(N)$ neurons for 2-layer networks, and\nwith $m=\\Theta(\\sqrt{N})$ neurons for 3-layer networks, no matter how large $K$\nis. Our results recover the known memorization capacity results when $N = K$ as\na special case.\n","authors":["Jy-yong Sohn","Dohyun Kwon","Seoyeon An","Kangwook Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00359v1.pdf","comment":"10 pages, 9 figures, UAI 2024"},{"id":"http://arxiv.org/abs/2408.00346v1","updated":"2024-08-01T07:31:23Z","published":"2024-08-01T07:31:23Z","title":"Neural Graph Matching for Video Retrieval in Large-Scale Video-driven\n  E-commerce","summary":"  With the rapid development of the short video industry, traditional\ne-commerce has encountered a new paradigm, video-driven e-commerce, which\nleverages attractive videos for product showcases and provides both video and\nitem services for users. Benefitting from the dynamic and visualized\nintroduction of items,video-driven e-commerce has shown huge potential in\nstimulating consumer confidence and promoting sales. In this paper, we focus on\nthe video retrieval task, facing the following challenges: (1) Howto handle the\nheterogeneities among users, items, and videos? (2)How to mine the\ncomplementarity between items and videos for better user understanding? In this\npaper, we first leverage the dual graph to model the co-existing of user-video\nand user-item interactions in video-driven e-commerce and innovatively reduce\nuser preference understanding to a graph matching problem. To solve it, we\nfurther propose a novel bi-level Graph Matching Network(GMN), which mainly\nconsists of node- and preference-level graph matching. Given a user, node-level\ngraph matching aims to match videos and items, while preference-level graph\nmatching aims to match multiple user preferences extracted from both videos and\nitems. Then the proposed GMN can generate and improve user embedding by\naggregating matched nodes or preferences from the dual graph in a bi-level\nmanner. Comprehensive experiments show the superiority of the proposed GMN with\nsignificant improvements over state-of-the-art approaches (e.g., AUC+1.9% and\nCTR+7.15%). We have developed it on a well-known video-driven e-commerce\nplatform, serving hundreds of millions of users every day\n","authors":["Houye Ji","Ye Tang","Zhaoxin Chen","Lixi Deng","Jun Hu","Lei Su"],"pdf_url":"https://arxiv.org/pdf/2408.00346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00343v1","updated":"2024-08-01T07:27:54Z","published":"2024-08-01T07:27:54Z","title":"IN-Sight: Interactive Navigation through Sight","summary":"  Current visual navigation systems often treat the environment as static,\nlacking the ability to adaptively interact with obstacles. This limitation\nleads to navigation failure when encountering unavoidable obstructions. In\nresponse, we introduce IN-Sight, a novel approach to self-supervised path\nplanning, enabling more effective navigation strategies through interaction\nwith obstacles. Utilizing RGB-D observations, IN-Sight calculates\ntraversability scores and incorporates them into a semantic map, facilitating\nlong-range path planning in complex, maze-like environments. To precisely\nnavigate around obstacles, IN-Sight employs a local planner, trained\nimperatively on a differentiable costmap using representation learning\ntechniques. The entire framework undergoes end-to-end training within the\nstate-of-the-art photorealistic Intel SPEAR Simulator. We validate the\neffectiveness of IN-Sight through extensive benchmarking in a variety of\nsimulated scenarios and ablation studies. Moreover, we demonstrate the system's\nreal-world applicability with zero-shot sim-to-real transfer, deploying our\nplanner on the legged robot platform ANYmal, showcasing its practical potential\nfor interactive navigation in real environments.\n","authors":["Philipp Schoch","Fan Yang","Yuntao Ma","Stefan Leutenegger","Marco Hutter","Quentin Leboute"],"pdf_url":"https://arxiv.org/pdf/2408.00343v1.pdf","comment":"The 2024 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2024)"},{"id":"http://arxiv.org/abs/2408.00342v1","updated":"2024-08-01T07:27:18Z","published":"2024-08-01T07:27:18Z","title":"MuJoCo MPC for Humanoid Control: Evaluation on HumanoidBench","summary":"  We tackle the recently introduced benchmark for whole-body humanoid control\nHumanoidBench using MuJoCo MPC. We find that sparse reward functions of\nHumanoidBench yield undesirable and unrealistic behaviors when optimized;\ntherefore, we propose a set of regularization terms that stabilize the robot\nbehavior across tasks. Current evaluations on a subset of tasks demonstrate\nthat our proposed reward function allows achieving the highest HumanoidBench\nscores while maintaining realistic posture and smooth control signals. Our code\nis publicly available and will become a part of MuJoCo MPC, enabling rapid\nprototyping of robot behaviors.\n","authors":["Moritz Meser","Aditya Bhatt","Boris Belousov","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2408.00342v1.pdf","comment":"3 pages, 3 figures, submitted to IEEE Conference on Robotics and\n  Automation (ICRA@40)"},{"id":"http://arxiv.org/abs/2408.00330v1","updated":"2024-08-01T07:06:30Z","published":"2024-08-01T07:06:30Z","title":"\"Patriarchy Hurts Men Too.\" Does Your Model Agree? A Discussion on\n  Fairness Assumptions","summary":"  The pipeline of a fair ML practitioner is generally divided into three\nphases: 1) Selecting a fairness measure. 2) Choosing a model that minimizes\nthis measure. 3) Maximizing the model's performance on the data. In the context\nof group fairness, this approach often obscures implicit assumptions about how\nbias is introduced into the data. For instance, in binary classification, it is\noften assumed that the best model, with equal fairness, is the one with better\nperformance. However, this belief already imposes specific properties on the\nprocess that introduced bias. More precisely, we are already assuming that the\nbiasing process is a monotonic function of the fair scores, dependent solely on\nthe sensitive attribute. We formally prove this claim regarding several\nimplicit fairness assumptions. This leads, in our view, to two possible\nconclusions: either the behavior of the biasing process is more complex than\nmere monotonicity, which means we need to identify and reject our implicit\nassumptions in order to develop models capable of tackling more complex\nsituations; or the bias introduced in the data behaves predictably, implying\nthat many of the developed models are superfluous.\n","authors":["Marco Favier","Toon Calders"],"pdf_url":"https://arxiv.org/pdf/2408.00330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00329v1","updated":"2024-08-01T07:04:18Z","published":"2024-08-01T07:04:18Z","title":"OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial\n  Attack","summary":"  Deep neural networks (DNNs) are vulnerable to small adversarial perturbations\nof the inputs, posing a significant challenge to their reliability and\nrobustness. Empirical methods such as adversarial training can defend against\nparticular attacks but remain vulnerable to more powerful attacks.\nAlternatively, Lipschitz networks provide certified robustness to unseen\nperturbations but lack sufficient expressive power. To harness the advantages\nof both approaches, we design a novel two-step Optimal Transport induced\nAdversarial Defense (OTAD) model that can fit the training data accurately\nwhile preserving the local Lipschitz continuity. First, we train a DNN with a\nregularizer derived from optimal transport theory, yielding a discrete optimal\ntransport map linking data to its features. By leveraging the map's inherent\nregularity, we interpolate the map by solving the convex integration problem\n(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse\narchitectures of ResNet and Transformer, making it suitable for complex data.\nFor efficient computation, the CIP can be solved through training neural\nnetworks. OTAD opens a novel avenue for developing reliable and secure deep\nlearning systems through the regularity of optimal transport maps. Empirical\nresults demonstrate that OTAD can outperform other robust models on diverse\ndatasets.\n","authors":["Kuo Gai","Sicong Wang","Shihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00329v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.00326v1","updated":"2024-08-01T06:55:19Z","published":"2024-08-01T06:55:19Z","title":"Exploiting Preferences in Loss Functions for Sequential Recommendation\n  via Weak Transitivity","summary":"  A choice of optimization objective is immensely pivotal in the design of a\nrecommender system as it affects the general modeling process of a user's\nintent from previous interactions. Existing approaches mainly adhere to three\ncategories of loss functions: pairwise, pointwise, and setwise loss functions.\nDespite their effectiveness, a critical and common drawback of such objectives\nis viewing the next observed item as a unique positive while considering all\nremaining items equally negative. Such a binary label assignment is generally\nlimited to assuring a higher recommendation score of the positive item,\nneglecting potential structures induced by varying preferences between other\nunobserved items. To alleviate this issue, we propose a novel method that\nextends original objectives to explicitly leverage the different levels of\npreferences as relative orders between their scores. Finally, we demonstrate\nthe superior performance of our method compared to baseline objectives.\n","authors":["Hyunsoo Chung","Jungtaek Kim","Hyungeun Jo","Hyungwon Choi"],"pdf_url":"https://arxiv.org/pdf/2408.00326v1.pdf","comment":"Accepted to CIKM 2024, Short Research Paper Track"},{"id":"http://arxiv.org/abs/2408.00315v1","updated":"2024-08-01T06:26:05Z","published":"2024-08-01T06:26:05Z","title":"ADBM: Adversarial diffusion bridge model for reliable adversarial\n  purification","summary":"  Recently Diffusion-based Purification (DiffPure) has been recognized as an\neffective defense method against adversarial examples. However, we find\nDiffPure which directly employs the original pre-trained diffusion models for\nadversarial purification, to be suboptimal. This is due to an inherent\ntrade-off between noise purification performance and data recovery quality.\nAdditionally, the reliability of existing evaluations for DiffPure is\nquestionable, as they rely on weak adaptive attacks. In this work, we propose a\nnovel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs\na reverse bridge from the diffused adversarial data back to its original clean\nexamples, enhancing the purification capabilities of the original diffusion\nmodels. Through theoretical analysis and experimental validation across various\nscenarios, ADBM has proven to be a superior and robust defense mechanism,\noffering significant promise for practical applications.\n","authors":["Xiao Li","Wenxuan Sun","Huanran Chen","Qiongxiu Li","Yining Liu","Yingzhe He","Jie Shi","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2408.00315v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2408.00312v1","updated":"2024-08-01T06:14:42Z","published":"2024-08-01T06:14:42Z","title":"Adversarial Text Rewriting for Text-aware Recommender Systems","summary":"  Text-aware recommender systems incorporate rich textual features, such as\ntitles and descriptions, to generate item recommendations for users. The use of\ntextual features helps mitigate cold-start problems, and thus, such recommender\nsystems have attracted increased attention. However, we argue that the\ndependency on item descriptions makes the recommender system vulnerable to\nmanipulation by adversarial sellers on e-commerce platforms. In this paper, we\nexplore the possibility of such manipulation by proposing a new text rewriting\nframework to attack text-aware recommender systems. We show that the rewriting\nattack can be exploited by sellers to unfairly uprank their products, even\nthough the adversarially rewritten descriptions are perceived as realistic by\nhuman evaluators. Methodologically, we investigate two different variations to\ncarry out text rewriting attacks: (1) two-phase fine-tuning for greater attack\nperformance, and (2) in-context learning for higher text rewriting quality.\nExperiments spanning 3 different datasets and 4 existing approaches demonstrate\nthat recommender systems exhibit vulnerability against the proposed text\nrewriting attack. Our work adds to the existing literature around the\nrobustness of recommender systems, while highlighting a new dimension of\nvulnerability in the age of large-scale automated text generation.\n","authors":["Sejoon Oh","Gaurav Verma","Srijan Kumar"],"pdf_url":"https://arxiv.org/pdf/2408.00312v1.pdf","comment":"Accepted for publication at: 33rd ACM International Conference on\n  Information and Knowledge Management (CIKM 2024). Code and data at:\n  https://github.com/sejoonoh/ATR"},{"id":"http://arxiv.org/abs/2408.00310v1","updated":"2024-08-01T06:13:24Z","published":"2024-08-01T06:13:24Z","title":"Online Linear Programming with Batching","summary":"  We study Online Linear Programming (OLP) with batching. The planning horizon\nis cut into $K$ batches, and the decisions on customers arriving within a batch\ncan be delayed to the end of their associated batch. Compared with OLP without\nbatching, the ability to delay decisions brings better operational performance,\nas measured by regret. Two research questions of interest are: (1) What is a\nlower bound of the regret as a function of $K$? (2) What algorithms can achieve\nthe regret lower bound? These questions have been analyzed in the literature\nwhen the distribution of the reward and the resource consumption of the\ncustomers have finite support. By contrast, this paper analyzes these questions\nwhen the conditional distribution of the reward given the resource consumption\nis continuous, and we show the answers are different under this setting. When\nthere is only a single type of resource and the decision maker knows the total\nnumber of customers, we propose an algorithm with a $O(\\log K)$ regret upper\nbound and provide a $\\Omega(\\log K)$ regret lower bound. We also propose\nalgorithms with $O(\\log K)$ regret upper bound for the setting in which there\nare multiple types of resource and the setting in which customers arrive\nfollowing a Poisson process. All these regret upper and lower bounds are\nindependent of the length of the planning horizon, and all the proposed\nalgorithms delay decisions on customers arriving in only the first and the last\nbatch. We also take customer impatience into consideration and establish a way\nof selecting an appropriate batch size.\n","authors":["Haoran Xu","Peter W. Glynn","Yinyu Ye"],"pdf_url":"https://arxiv.org/pdf/2408.00310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00309v1","updated":"2024-08-01T06:06:53Z","published":"2024-08-01T06:06:53Z","title":"Discretizing Continuous Action Space with Unimodal Probability\n  Distributions for On-Policy Reinforcement Learning","summary":"  For on-policy reinforcement learning, discretizing action space for\ncontinuous control can easily express multiple modes and is straightforward to\noptimize. However, without considering the inherent ordering between the\ndiscrete atomic actions, the explosion in the number of discrete actions can\npossess undesired properties and induce a higher variance for the policy\ngradient estimator. In this paper, we introduce a straightforward architecture\nthat addresses this issue by constraining the discrete policy to be unimodal\nusing Poisson probability distributions. This unimodal architecture can better\nleverage the continuity in the underlying continuous action space using\nexplicit unimodal probability distributions. We conduct extensive experiments\nto show that the discrete policy with the unimodal probability distribution\nprovides significantly faster convergence and higher performance for on-policy\nreinforcement learning algorithms in challenging control tasks, especially in\nhighly complex tasks such as Humanoid. We provide theoretical analysis on the\nvariance of the policy gradient estimator, which suggests that our attentively\ndesigned unimodal discrete policy can retain a lower variance and yield a\nstable learning process.\n","authors":["Yuanyang Zhu","Zhi Wang","Yuanheng Zhu","Chunlin Chen","Dongbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.00309v1.pdf","comment":"IEEE Transactions on Neural Networks and Learning Systems"},{"id":"http://arxiv.org/abs/2408.00307v1","updated":"2024-08-01T06:06:25Z","published":"2024-08-01T06:06:25Z","title":"ABC Align: Large Language Model Alignment for Safety & Accuracy","summary":"  Alignment of Large Language Models (LLMs) remains an unsolved problem. Human\npreferences are highly distributed and can be captured at multiple levels of\nabstraction, from the individual to diverse populations. Organisational\npreferences, represented by standards and principles, are defined to mitigate\nreputational risk or meet legislative obligations. In this paper, we present\nABC Align, a novel alignment methodology for LLMs that enables integration of\nthe standards and preferences of a large media organisation into the LLM\nitself. We combine a set of data and methods that build on recent breakthroughs\nin synthetic data generation, preference optimisation, and post-training model\nquantisation. Our unified approach mitigates bias and improves accuracy, while\npreserving reasoning capability, as measured against standard benchmarks.\n","authors":["Gareth Seneque","Lap-Hang Ho","Ariel Kuperman","Nafise Erfanian Saeedi","Jeffrey Molendijk"],"pdf_url":"https://arxiv.org/pdf/2408.00307v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.00295v1","updated":"2024-08-01T05:45:21Z","published":"2024-08-01T05:45:21Z","title":"Contrastive Graph Representation Learning with Adversarial Cross-view\n  Reconstruction and Information Bottleneck","summary":"  Graph Neural Networks (GNNs) have received extensive research attention due\nto their powerful information aggregation capabilities. Despite the success of\nGNNs, most of them suffer from the popularity bias issue in a graph caused by a\nsmall number of popular categories. Additionally, real graph datasets always\ncontain incorrect node labels, which hinders GNNs from learning effective node\nrepresentations. Graph contrastive learning (GCL) has been shown to be\neffective in solving the above problems for node classification tasks. Most\nexisting GCL methods are implemented by randomly removing edges and nodes to\ncreate multiple contrasting views, and then maximizing the mutual information\n(MI) between these contrasting views to improve the node feature\nrepresentation. However, maximizing the mutual information between multiple\ncontrasting views may lead the model to learn some redundant information\nirrelevant to the node classification task. To tackle this issue, we propose an\neffective Contrastive Graph Representation Learning with Adversarial Cross-view\nReconstruction and Information Bottleneck (CGRL) for node classification, which\ncan adaptively learn to mask the nodes and edges in the graph to obtain the\noptimal graph structure representation. Furthermore, we innovatively introduce\nthe information bottleneck theory into GCLs to remove redundant information in\nmultiple contrasting views while retaining as much information as possible\nabout node classification. Moreover, we add noise perturbations to the original\nviews and reconstruct the augmented views by constructing adversarial views to\nimprove the robustness of node feature representation. Extensive experiments on\nreal-world public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art algorithms.\n","authors":["Yuntao Shou","Haozhi Lan","Xiangyong Cao"],"pdf_url":"https://arxiv.org/pdf/2408.00295v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.00288v1","updated":"2024-08-01T05:22:41Z","published":"2024-08-01T05:22:41Z","title":"Gradient Harmonization in Unsupervised Domain Adaptation","summary":"  Unsupervised domain adaptation (UDA) intends to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Many current methods focus\non learning feature representations that are both discriminative for\nclassification and invariant across domains by simultaneously optimizing domain\nalignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during\ngradient-based optimization. In this paper, we delve into this issue and\nintroduce two effective solutions known as Gradient Harmonization, including GH\nand GH++, to mitigate the conflict between domain alignment and classification\ntasks. GH operates by altering the gradient angle between different tasks from\nan obtuse angle to an acute angle, thus resolving the conflict and trade-offing\nthe two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an\nimproved version, GH++, which adjusts the gradient angle between tasks from an\nobtuse angle to a vertical angle. This not only eliminates the conflict but\nalso minimizes deviation from the original gradient directions. Finally, for\noptimization convenience and efficiency, we evolve the gradient harmonization\nstrategies into a dynamically weighted loss function using an integral operator\non the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be\nseamlessly integrated into most existing UDA models. Theoretical insights and\nexperimental analyses demonstrate that the proposed approaches not only enhance\npopular UDA baselines but also improve recent state-of-the-art models.\n","authors":["Fuxiang Huang","Suqi Song","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00288v1.pdf","comment":"IEEE TPAMI 2024"},{"id":"http://arxiv.org/abs/2408.00278v1","updated":"2024-08-01T04:37:03Z","published":"2024-08-01T04:37:03Z","title":"High Performance Im2win and Direct Convolutions using Three Tensor\n  Layouts on SIMD Architectures","summary":"  Convolution is the core component within deep neural networks and it is\ncomputationally intensive and time consuming. Tensor data layouts significantly\nimpact convolution operations in terms of memory access and computational\nefficiency. Yet, there is still a lack of comprehensive performance\ncharacterization on data layouts on SIMD architectures concerning convolution\nmethods. This paper proposes three novel data layouts for im2win convolution:\nNHWC, CHWN, and CHWN8, and introduces a set of general optimization techniques\nfor both direct and im2win convolutions. We compare the optimized im2win\nconvolution with the direct convolution and PyTorch's im2col-based convolution\nacross the aforementioned layouts on SIMD machines. The experiments\ndemonstrated that the im2win convolution with the new NHWC layout achieved up\nto 355% performance speedup over NCHW layout. Our optimizations also\nsignificantly improve the performance of both im2win and direct convolutions.\nOur optimized im2win and direct convolutions achieved up to 95% and 94% of\nmachine's theoretical peak performance, respectively.\n","authors":["Xiang Fu","Xinpeng Zhang","Jixiang Ma","Peng Zhao","Shuai Lu","Xu T. Liu"],"pdf_url":"https://arxiv.org/pdf/2408.00278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00264v1","updated":"2024-08-01T03:43:32Z","published":"2024-08-01T03:43:32Z","title":"Clover-2: Accurate Inference for Regressive Lightweight Speculative\n  Decoding","summary":"  Large Language Models (LLMs) frequently suffer from inefficiencies, largely\nattributable to the discord between the requirements of auto-regressive\ndecoding and the architecture of contemporary GPUs. Recently, regressive\nlightweight speculative decoding has garnered attention for its notable\nefficiency improvements in text generation tasks. This approach utilizes a\nlightweight regressive draft model, like a Recurrent Neural Network (RNN) or a\nsingle transformer decoder layer, leveraging sequential information to\niteratively predict potential tokens. Specifically, RNN draft models are\ncomputationally economical but tend to deliver lower accuracy, while attention\ndecoder layer models exhibit the opposite traits. This paper presents Clover-2,\nan advanced iteration of Clover, an RNN-based draft model designed to achieve\ncomparable accuracy to that of attention decoder layer models while maintaining\nminimal computational overhead. Clover-2 enhances the model architecture and\nincorporates knowledge distillation to increase Clover's accuracy and improve\noverall efficiency. We conducted experiments using the open-source Vicuna 7B\nand LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses\nexisting methods across various model architectures, showcasing its efficacy\nand robustness.\n","authors":["Bin Xiao","Lujun Gui","Lei Su","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2408.00264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00256v1","updated":"2024-08-01T03:28:10Z","published":"2024-08-01T03:28:10Z","title":"Mobility-Aware Federated Self-supervised Learning in Vehicular Network","summary":"  Federated Learning (FL) is an advanced distributed machine learning approach,\nthat protects the privacy of each vehicle by allowing the model to be trained\non multiple devices simultaneously without the need to upload all data to a\nroad side unit (RSU). This enables FL to handle scenarios with sensitive or\nwidely distributed data. However, in these fields, it is well known that the\nlabeling costs can be a significant expense, and models relying on labels are\nnot suitable for these rapidly evolving fields especially in vehicular\nnetworks, or mobile internet of things (MIoT), where new data emerges\nconstantly. To handle this issue, the self-supervised learning paves the way\nfor training without labels. Additionally, for vehicles with high velocity,\nowing to blurred images, simple aggregation not only impacts the accuracy of\nthe aggregated model but also reduces the convergence speed of FL. This paper\nproposes a FL algorithm based on image blur level to aggregation, called\nFLSimCo, which does not require labels and serves as a pre-training stage for\nself-supervised learning in the vehicular environment. Simulation results\ndemonstrate that the proposed algorithm exhibits fast and stable convergence.\n","authors":["Xueying Gu","Qiong Wu","Pingyi Fan","Qiang Fan"],"pdf_url":"https://arxiv.org/pdf/2408.00256v1.pdf","comment":"This paper has been submitted to urban lifeline. The source code has\n  been released at: The source code has been released at:\n  https://github.com/qiongwu86/FLSimCo"},{"id":"http://arxiv.org/abs/2408.00251v1","updated":"2024-08-01T03:15:08Z","published":"2024-08-01T03:15:08Z","title":"Discovering Car-following Dynamics from Trajectory Data through Deep\n  Learning","summary":"  This study aims to discover the governing mathematical expressions of\ncar-following dynamics from trajectory data directly using deep learning\ntechniques. We propose an expression exploration framework based on deep\nsymbolic regression (DSR) integrated with a variable intersection selection\n(VIS) method to find variable combinations that encourage interpretable and\nparsimonious mathematical expressions. In the exploration learning process, two\npenalty terms are added to improve the reward function: (i) a complexity\npenalty to regulate the complexity of the explored expressions to be\nparsimonious, and (ii) a variable interaction penalty to encourage the\nexpression exploration to focus on variable combinations that can best describe\nthe data. We show the performance of the proposed method to learn several\ncar-following dynamics models and discuss its limitations and future research\ndirections.\n","authors":["Ohay Angah","James Enouen"," Xuegang"," Ban","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2408.00251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00244v1","updated":"2024-08-01T02:49:58Z","published":"2024-08-01T02:49:58Z","title":"Enhanced Structured State Space Models via Grouped FIR Filtering and\n  Attention Sink Mechanisms","summary":"  Structured State Space Models (SSMs) have emerged as compelling alternatives\nto Transformer architectures, offering linear-time complexity and superior\nperformance in various sequence modeling tasks. Despite their advantages, SSMs\nlike the original Mamba-2 face training difficulties due to the sensitivities\nintroduced by the extended series of recurrent matrix multiplications. In this\npaper, we propose an advanced architecture that mitigates these challenges by\ndecomposing A-multiplications into multiple groups and optimizing positional\nencoding through Grouped Finite Impulse Response (FIR) filtering. This new\nstructure, denoted as Grouped FIR-enhanced SSM (GFSSM), employs semiseparable\nmatrices for efficient computation. Furthermore, inspired by the \"attention\nsink\" phenomenon identified in streaming language models, we incorporate a\nsimilar mechanism to enhance the stability and performance of our model over\nextended sequences. Our approach further bridges the gap between SSMs and\nTransformer architectures, offering a viable path forward for scalable and\nhigh-performing sequence modeling.\n","authors":["Tian Meng","Yang Tao","Wuliang Yin"],"pdf_url":"https://arxiv.org/pdf/2408.00244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00237v1","updated":"2024-08-01T02:13:11Z","published":"2024-08-01T02:13:11Z","title":"Empirical Bayes Linked Matrix Decomposition","summary":"  Data for several applications in diverse fields can be represented as\nmultiple matrices that are linked across rows or columns. This is particularly\ncommon in molecular biomedical research, in which multiple molecular \"omics\"\ntechnologies may capture different feature sets (e.g., corresponding to rows in\na matrix) and/or different sample populations (corresponding to columns). This\nhas motivated a large body of work on integrative matrix factorization\napproaches that identify and decompose low-dimensional signal that is shared\nacross multiple matrices or specific to a given matrix. We propose an empirical\nvariational Bayesian approach to this problem that has several advantages over\nexisting techniques, including the flexibility to accommodate shared signal\nover any number of row or column sets (i.e., bidimensional integration), an\nintuitive model-based objective function that yields appropriate shrinkage for\nthe inferred signals, and a relatively efficient estimation algorithm with no\ntuning parameters. A general result establishes conditions for the uniqueness\nof the underlying decomposition for a broad family of methods that includes the\nproposed approach. For scenarios with missing data, we describe an associated\niterative imputation approach that is novel for the single-matrix context and a\npowerful approach for \"blockwise\" imputation (in which an entire row or column\nis missing) in various linked matrix contexts. Extensive simulations show that\nthe method performs very well under different scenarios with respect to\nrecovering underlying low-rank signal, accurately decomposing shared and\nspecific signals, and accurately imputing missing data. The approach is applied\nto gene expression and miRNA data from breast cancer tissue and normal breast\ntissue, for which it gives an informative decomposition of variation and\noutperforms alternative strategies for missing data imputation.\n","authors":["Eric F. Lock"],"pdf_url":"https://arxiv.org/pdf/2408.00237v1.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.00232v1","updated":"2024-08-01T01:57:09Z","published":"2024-08-01T01:57:09Z","title":"CDFGNN: a Systematic Design of Cache-based Distributed Full-Batch Graph\n  Neural Network Training with Communication Reduction","summary":"  Graph neural network training is mainly categorized into mini-batch and\nfull-batch training methods. The mini-batch training method samples subgraphs\nfrom the original graph in each iteration. This sampling operation introduces\nextra computation overhead and reduces the training accuracy. Meanwhile, the\nfull-batch training method calculates the features and corresponding gradients\nof all vertices in each iteration, and therefore has higher convergence\naccuracy. However, in the distributed cluster, frequent remote accesses of\nvertex features and gradients lead to huge communication overhead, thus\nrestricting the overall training efficiency.\n  In this paper, we introduce the cached-based distributed full-batch graph\nneural network training framework (CDFGNN). We propose the adaptive cache\nmechanism to reduce the remote vertex access by caching the historical features\nand gradients of neighbor vertices. Besides, we further optimize the\ncommunication overhead by quantifying the messages and designing the graph\npartition algorithm for the hierarchical communication architecture.\nExperiments show that the adaptive cache mechanism reduces remote vertex\naccesses by 63.14% on average. Combined with communication quantization and\nhierarchical GP algorithm, CDFGNN outperforms the state-of-the-art distributed\nfull-batch training frameworks by 30.39% in our experiments. Our results\nindicate that CDFGNN has great potential in accelerating distributed full-batch\nGNN training tasks.\n","authors":["Shuai Zhang","Zite Jiang","Haihang You"],"pdf_url":"https://arxiv.org/pdf/2408.00232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00229v1","updated":"2024-08-01T01:48:46Z","published":"2024-08-01T01:48:46Z","title":"Invariant Discovery of Features Across Multiple Length Scales:\n  Applications in Microscopy and Autonomous Materials Characterization","summary":"  Physical imaging is a foundational characterization method in areas from\ncondensed matter physics and chemistry to astronomy and spans length scales\nfrom atomic to universe. Images encapsulate crucial data regarding atomic\nbonding, materials microstructures, and dynamic phenomena such as\nmicrostructural evolution and turbulence, among other phenomena. The challenge\nlies in effectively extracting and interpreting this information. Variational\nAutoencoders (VAEs) have emerged as powerful tools for identifying underlying\nfactors of variation in image data, providing a systematic approach to\ndistilling meaningful patterns from complex datasets. However, a significant\nhurdle in their application is the definition and selection of appropriate\ndescriptors reflecting local structure. Here we introduce the scale-invariant\nVAE approach (SI-VAE) based on the progressive training of the VAE with the\ndescriptors sampled at different length scales. The SI-VAE allows the discovery\nof the length scale dependent factors of variation in the system. Here, we\nillustrate this approach using the ferroelectric domain images and generalize\nit to the movies of the electron-beam induced phenomena in graphene and\ntopography evolution across combinatorial libraries. This approach can further\nbe used to initialize the decision making in automated experiments including\nstructure-property discovery and can be applied across a broad range of imaging\nmethods. This approach is universal and can be applied to any spatially\nresolved data including both experimental imaging studies and simulations, and\ncan be particularly useful for exploration of phenomena such as turbulence,\nscale-invariant transformation fronts, etc.\n","authors":["Aditya Raghavan","Utkarsh Pratiush","Mani Valleti","Richard Liu","Reece Emery","Hiroshi Funakubo","Yongtao Liu","Philip Rack","Sergei Kalinin"],"pdf_url":"https://arxiv.org/pdf/2408.00229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00220v1","updated":"2024-08-01T01:15:52Z","published":"2024-08-01T01:15:52Z","title":"Persistent de Rham-Hodge Laplacians in the Eulerian representation","summary":"  Recently, topological data analysis (TDA) has become a trending topic in data\nscience and engineering. However, the key technique of TDA, i.e., persistent\nhomology, is defined on point cloud data, which restricts its scope. In this\nwork, we propose persistent de Rham-Hodge Laplacian, or persistent Hodge\nLaplacian (PHL) for abbreviation, for the TDA on manifolds with boundaries, or\nvolumetric data. Specifically, we extended the evolutionary de Rham-Hodge\ntheory from the Lagrangian formulation to the Eulerian formulation via\nstructure-persevering Cartesian grids, and extended the persistent Laplacian on\npoint clouds to persistent (de Rham-)Hodge Laplacian on nested families of\nmanifolds with appropriate boundary conditions. The proposed PHL facilitates\nthe machine learning and deep learning prediction of volumetric data. For a\nproof-of-principle application of the proposed PHL, we propose a persistent\nHodge Laplacian learning (PHLL) algorithm for data on manifolds or volumetric\ndata. To this end, we showcase the PHLL prediction of protein-ligand binding\naffinities in two benchmark datasets. Our numerical experiments highlight the\npower and promise of PHLL.\n","authors":["Zhe Su","Yiying Tong","Guo-Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2408.00220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00217v1","updated":"2024-08-01T00:56:36Z","published":"2024-08-01T00:56:36Z","title":"Load Balancing in Federated Learning","summary":"  Federated Learning (FL) is a decentralized machine learning framework that\nenables learning from data distributed across multiple remote devices,\nenhancing communication efficiency and data privacy. Due to limited\ncommunication resources, a scheduling policy is often applied to select a\nsubset of devices for participation in each FL round. The scheduling process\nconfronts significant challenges due to the need for fair workload\ndistribution, efficient resource utilization, scalability in environments with\nnumerous edge devices, and statistically heterogeneous data across devices.\nThis paper proposes a load metric for scheduling policies based on the Age of\nInformation and addresses the above challenges by minimizing the load metric\nvariance across the clients. Furthermore, a decentralized Markov scheduling\npolicy is presented, that ensures a balanced workload distribution while\neliminating the management overhead irrespective of the network size due to\nindependent client decision-making. We establish the optimal parameters of the\nMarkov chain model and validate our approach through simulations. The results\ndemonstrate that reducing the load metric variance not only promotes fairness\nand improves operational efficiency, but also enhances the convergence rate of\nthe learning models.\n","authors":["Alireza Javani","Zhiying Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00211v1","updated":"2024-08-01T00:45:37Z","published":"2024-08-01T00:45:37Z","title":"Penzai + Treescope: A Toolkit for Interpreting, Visualizing, and Editing\n  Models As Data","summary":"  Much of today's machine learning research involves interpreting, modifying or\nvisualizing models after they are trained. I present Penzai, a neural network\nlibrary designed to simplify model manipulation by representing models as\nsimple data structures, and Treescope, an interactive pretty-printer and array\nvisualizer that can visualize both model inputs/outputs and the models\nthemselves. Penzai models are built using declarative combinators that expose\nthe model forward pass in the structure of the model object itself, and use\nnamed axes to ensure each operation is semantically meaningful. With Penzai's\ntree-editing selector system, users can both insert and replace model\ncomponents, allowing them to intervene on intermediate values or make other\nedits to the model structure. Users can then get immediate feedback by\nvisualizing the modified model with Treescope. I describe the motivation and\nmain features of Penzai and Treescope, and discuss how treating the model as\ndata enables a variety of analyses and interventions to be implemented as\ndata-structure transformations, without requiring model designers to add\nexplicit hooks.\n","authors":["Daniel D. Johnson"],"pdf_url":"https://arxiv.org/pdf/2408.00211v1.pdf","comment":"Presented at the ICML 2024 Mechanistic Interpretability workshop\n  (Spotlight). 5 pages"},{"id":"http://arxiv.org/abs/2408.00208v1","updated":"2024-08-01T00:33:32Z","published":"2024-08-01T00:33:32Z","title":"Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review\n  and Meta-analysis","summary":"  Purpose: Artificial intelligence (AI) techniques have been extensively\nutilized for diagnosing and prognosis of several diseases in recent years. This\nstudy identifies, appraises and synthesizes published studies on the use of AI\nfor the prognosis of COVID-19. Method: Electronic search was performed using\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\nexamined machine learning or deep learning methods to determine the prognosis\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\nspecificity area under the curve and diagnostic odds ratio were calculated.\nResult: A total of 36 articles were included; various prognosis-related issues,\nincluding disease severity, mechanical ventilation or admission to the\nintensive care unit and mortality, were investigated. Several AI models and\narchitectures were employed, such as the Siamense model, support vector\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\nseverity assessment and need for ventilation, respectively. The specificity of\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\nBased on the included articles, machine learning and deep learning methods used\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\nimages can help clinicians manage patients and allocate resources more\neffectively. These studies also demonstrate that combining patient demographic,\nclinical data, laboratory tests and radiomic features improves model\nperformances.\n","authors":["SaeedReza Motamedian","Sadra Mohaghegh","Elham Babadi Oregani","Mahrsa Amjadi","Parnian Shobeiri","Negin Cheraghi","Niusha Solouki","Nikoo Ahmadi","Hossein Mohammad-Rahimi","Yassine Bouchareb","Arman Rahmim"],"pdf_url":"https://arxiv.org/pdf/2408.00208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00203v1","updated":"2024-08-01T00:00:43Z","published":"2024-08-01T00:00:43Z","title":"OmniParser for Pure Vision Based GUI Agent","summary":"  The recent success of large vision language models shows great potential in\ndriving the agent system operating on user interfaces. However, we argue that\nthe power multimodal models like GPT-4V as a general agent on multiple\noperating systems across different applications is largely underestimated due\nto the lack of a robust screen parsing technique capable of: 1) reliably\nidentifying interactable icons within the user interface, and 2) understanding\nthe semantics of various elements in a screenshot and accurately associate the\nintended action with the corresponding region on the screen. To fill these\ngaps, we introduce \\textsc{OmniParser}, a comprehensive method for parsing user\ninterface screenshots into structured elements, which significantly enhances\nthe ability of GPT-4V to generate actions that can be accurately grounded in\nthe corresponding regions of the interface. We first curated an interactable\nicon detection dataset using popular webpages and an icon description dataset.\nThese datasets were utilized to fine-tune specialized models: a detection model\nto parse interactable regions on the screen and a caption model to extract the\nfunctional semantics of the detected elements. \\textsc{OmniParser}\nsignificantly improves GPT-4V's performance on ScreenSpot benchmark. And on\nMind2Web and AITW benchmark, \\textsc{OmniParser} with screenshot only input\noutperforms the GPT-4V baselines requiring additional information outside of\nscreenshot.\n","authors":["Yadong Lu","Jianwei Yang","Yelong Shen","Ahmed Awadallah"],"pdf_url":"https://arxiv.org/pdf/2408.00203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00955v1","updated":"2024-08-01T23:32:14Z","published":"2024-08-01T23:32:14Z","title":"Aggregation Models with Optimal Weights for Distributed Gaussian\n  Processes","summary":"  Gaussian process (GP) models have received increasingly attentions in recent\nyears due to their superb prediction accuracy and modeling flexibility. To\naddress the computational burdens of GP models for large-scale datasets,\ndistributed learning for GPs are often adopted. Current aggregation models for\ndistributed GPs are not time-efficient when incorporating correlations between\nGP experts. In this work, we propose a novel approach for aggregated prediction\nin distributed GPs. The technique is suitable for both the exact and sparse\nvariational GPs. The proposed method incorporates correlations among experts,\nleading to better prediction accuracy with manageable computational\nrequirements. As demonstrated by empirical studies, the proposed approach\nresults in more stable predictions in less time than state-of-the-art\nconsistent aggregation models.\n","authors":["Haoyuan Chen","Rui Tuo"],"pdf_url":"https://arxiv.org/pdf/2408.00955v1.pdf","comment":"25 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.19092v2","updated":"2024-08-01T23:12:50Z","published":"2024-07-26T21:18:26Z","title":"Boosted generalized normal distributions: Integrating machine learning\n  with operations knowledge","summary":"  Applications of machine learning (ML) techniques to operational settings\noften face two challenges: i) ML methods mostly provide point predictions\nwhereas many operational problems require distributional information; and ii)\nThey typically do not incorporate the extensive body of knowledge in the\noperations literature, particularly the theoretical and empirical findings that\ncharacterize specific distributions. We introduce a novel and rigorous\nmethodology, the Boosted Generalized Normal Distribution ($b$GND), to address\nthese challenges. The Generalized Normal Distribution (GND) encompasses a wide\nrange of parametric distributions commonly encountered in operations, and\n$b$GND leverages gradient boosting with tree learners to flexibly estimate the\nparameters of the GND as functions of covariates. We establish $b$GND's\nstatistical consistency, thereby extending this key property to special cases\nstudied in the ML literature that lacked such guarantees. Using data from a\nlarge academic emergency department in the United States, we show that the\ndistributional forecasting of patient wait and service times can be\nmeaningfully improved by leveraging findings from the healthcare operations\nliterature. Specifically, $b$GND performs 6% and 9% better than the\ndistribution-agnostic ML benchmark used to forecast wait and service times\nrespectively. Further analysis suggests that these improvements translate into\na 9% increase in patient satisfaction and a 4% reduction in mortality for\nmyocardial infarction patients. Our work underscores the importance of\nintegrating ML with operations knowledge to enhance distributional forecasts.\n","authors":["Ragip Gurlek","Francis de Vericourt","Donald K. K. Lee"],"pdf_url":"https://arxiv.org/pdf/2407.19092v2.pdf","comment":"28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.00949v1","updated":"2024-08-01T23:08:37Z","published":"2024-08-01T23:08:37Z","title":"Equivariant neural networks and piecewise linear representation theory","summary":"  Equivariant neural networks are neural networks with symmetry. Motivated by\nthe theory of group representations, we decompose the layers of an equivariant\nneural network into simple representations. The nonlinear activation functions\nlead to interesting nonlinear equivariant maps between simple representations.\nFor example, the rectified linear unit (ReLU) gives rise to piecewise linear\nmaps. We show that these considerations lead to a filtration of equivariant\nneural networks, generalizing Fourier series. This observation might provide a\nuseful tool for interpreting equivariant neural networks.\n","authors":["Joel Gibson","Daniel Tubbenhauer","Geordie Williamson"],"pdf_url":"https://arxiv.org/pdf/2408.00949v1.pdf","comment":"24 pages, many figures, comments welcome"},{"id":"http://arxiv.org/abs/2405.05480v4","updated":"2024-08-01T22:57:53Z","published":"2024-05-09T00:37:56Z","title":"FloorSet -- a VLSI Floorplanning Dataset with Design Constraints of\n  Real-World SoCs","summary":"  Floorplanning for systems-on-a-chip (SoCs) and its sub-systems is a crucial\nand non-trivial step of the physical design flow. It represents a difficult\ncombinatorial optimization problem. A typical large scale SoC with 120\npartitions generates a search-space of nearly 10E250. As novel machine learning\n(ML) approaches emerge to tackle such problems, there is a growing need for a\nmodern benchmark that comprises a large training dataset and performance\nmetrics that better reflect real-world constraints and objectives compared to\nexisting benchmarks. To address this need, we present FloorSet -- two\ncomprehensive datasets of synthetic fixed-outline floorplan layouts that\nreflect the distribution of real SoCs. Each dataset has 1M training samples and\n100 test samples where each sample is a synthetic floor-plan. FloorSet-Prime\ncomprises fully-abutted rectilinear partitions and near-optimal wire-length. A\nsimplified dataset that reflects early design phases, FloorSet-Lite comprises\nrectangular partitions, with under 5 percent white-space and near-optimal\nwire-length. Both datasets define hard constraints seen in modern design flows\nsuch as shape constraints, edge-affinity, grouping constraints, and\npre-placement constraints. FloorSet is intended to spur fundamental research on\nlarge-scale constrained optimization problems. Crucially, FloorSet alleviates\nthe core issue of reproducibility in modern ML driven solutions to such\nproblems. FloorSet is available as an open-source repository for the research\ncommunity.\n","authors":["Uday Mallappa","Hesham Mostafa","Mikhail Galkin","Mariano Phielipp","Somdeb Majumdar"],"pdf_url":"https://arxiv.org/pdf/2405.05480v4.pdf","comment":"10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2408.00946v1","updated":"2024-08-01T22:55:40Z","published":"2024-08-01T22:55:40Z","title":"Generalisation of Total Uncertainty in AI: A Theoretical Study","summary":"  AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.\n","authors":["Keivan Shariatmadar"],"pdf_url":"https://arxiv.org/pdf/2408.00946v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2304.11880v2","updated":"2024-08-01T22:49:23Z","published":"2023-04-24T07:50:35Z","title":"The State of the Art in transformer fault diagnosis with artificial\n  intelligence and Dissolved Gas Analysis: A Review of the Literature","summary":"  Transformer fault diagnosis (TFD) is a critical aspect of power system\nmaintenance and management. This review paper provides a comprehensive overview\nof the current state of the art in TFD using artificial intelligence (AI) and\ndissolved gas analysis (DGA). The paper presents an analysis of recent\nadvancements in this field, including the use of deep learning algorithms and\nadvanced data analytics techniques, and their potential impact on TFD and the\npower industry as a whole. The review also highlights the benefits and\nlimitations of different approaches to transformer fault diagnosis, including\nrule-based systems, expert systems, neural networks, and machine learning\nalgorithms. Overall, this review aims to provide valuable insights into the\nimportance of TFD and the role of AI in ensuring the reliable operation of\npower systems.\n","authors":["Yuyan Li"],"pdf_url":"https://arxiv.org/pdf/2304.11880v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19024v3","updated":"2024-08-01T22:45:45Z","published":"2024-05-29T12:07:17Z","title":"Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory","summary":"  We consider inverse reinforcement learning problems with concave utilities.\nConcave Utility Reinforcement Learning (CURL) is a generalisation of the\nstandard RL objective, which employs a concave function of the state occupancy\nmeasure, rather than a linear function. CURL has garnered recent attention for\nits ability to represent instances of many important applications including the\nstandard RL such as imitation learning, pure exploration, constrained MDPs,\noffline RL, human-regularized RL, and others. Inverse reinforcement learning is\na powerful paradigm that focuses on recovering an unknown reward function that\ncan rationalize the observed behaviour of an agent. There has been recent\ntheoretical advances in inverse RL where the problem is formulated as\nidentifying the set of feasible reward functions. However, inverse RL for CURL\nproblems has not been considered previously. In this paper we show that most of\nthe standard IRL results do not apply to CURL in general, since CURL\ninvalidates the classical Bellman equations. This calls for a new theoretical\nframework for the inverse CURL problem. Using a recent equivalence result\nbetween CURL and Mean-field Games, we propose a new definition for the feasible\nrewards for I-CURL by proving that this problem is equivalent to an inverse\ngame theory problem in a subclass of mean-field games. We outline future\ndirections and applications in human--AI collaboration enabled by our results.\n","authors":["Mustafa Mert Çelikok","Frans A. Oliehoek","Jan-Willem van de Meent"],"pdf_url":"https://arxiv.org/pdf/2405.19024v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02652v2","updated":"2024-08-01T22:39:20Z","published":"2024-06-04T16:14:19Z","title":"RepCNN: Micro-sized, Mighty Models for Wakeword Detection","summary":"  Always-on machine learning models require a very low memory and compute\nfootprint. Their restricted parameter count limits the model's capacity to\nlearn, and the effectiveness of the usual training algorithms to find the best\nparameters. Here we show that a small convolutional model can be better trained\nby first refactoring its computation into a larger redundant multi-branched\narchitecture. Then, for inference, we algebraically re-parameterize the trained\nmodel into the single-branched form with fewer parameters for a lower memory\nfootprint and compute cost. Using this technique, we show that our always-on\nwake-word detector model, RepCNN, provides a good trade-off between latency and\naccuracy during inference. RepCNN re-parameterized models are 43% more accurate\nthan a uni-branch convolutional model while having the same runtime. RepCNN\nalso meets the accuracy of complex architectures like BC-ResNet, while having\n2x lesser peak memory usage and 10x faster runtime.\n","authors":["Arnav Kundu","Prateeth Nayak","Priyanka Padmanabhan","Devang Naik"],"pdf_url":"https://arxiv.org/pdf/2406.02652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07292v4","updated":"2024-08-01T21:51:58Z","published":"2023-06-09T21:01:29Z","title":"SARN: Structurally-Aware Recurrent Network for Spatio-Temporal\n  Disaggregation","summary":"  Open data is frequently released spatially aggregated, usually to comply with\nprivacy policies. But coarse, heterogeneous aggregations complicate learning\nand integration for downstream AI/ML systems. In this work, we consider models\nto disaggregate spatio-temporal data from a low-resolution, irregular partition\n(e.g., census tract) to a high-resolution, irregular partition (e.g., city\nblock). We propose an overarching model named the Structurally-Aware Recurrent\nNetwork (SARN), which integrates structurally-aware spatial attention (SASA)\nlayers into the Gated Recurrent Unit (GRU) model. The spatial attention layers\ncapture spatial interactions among regions, while the gated recurrent module\ncaptures the temporal dependencies. Each SASA layer calculates both global and\nstructural attention -- global attention facilitates comprehensive interactions\nbetween different geographic levels, while structural attention leverages the\ncontainment relationship between different geographic levels (e.g., a city\nblock being wholly contained within a census tract) to ensure coherent and\nconsistent results. For scenarios with limited historical training data, we\nexplore transfer learning and show that a model pre-trained on one city\nvariable can be fine-tuned for another city variable using only a few hundred\nsamples. Evaluating these techniques on two mobility datasets, we find that on\nboth datasets, SARN significantly outperforms other neural models (5% and 1%)\nand typical heuristic methods (40% and 14%), enabling us to generate realistic,\nhigh-quality fine-grained data for downstream applications.\n","authors":["Bin Han","Bill Howe"],"pdf_url":"https://arxiv.org/pdf/2306.07292v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01651v3","updated":"2024-08-01T21:41:44Z","published":"2023-10-02T21:27:57Z","title":"Fool Your (Vision and) Language Model With Embarrassingly Simple\n  Permutations","summary":"  Large language and vision-language models are rapidly being deployed in\npractice thanks to their impressive capabilities in instruction following,\nin-context learning, and so on. This raises an urgent need to carefully analyse\ntheir robustness so that stakeholders can understand if and when such models\nare trustworthy enough to be relied upon in any given application. In this\npaper, we highlight a specific vulnerability in popular models, namely\npermutation sensitivity in multiple-choice question answering (MCQA).\nSpecifically, we show empirically that popular models are vulnerable to\nadversarial permutation in answer sets for multiple-choice prompting, which is\nsurprising as models should ideally be as invariant to prompt permutation as\nhumans are. These vulnerabilities persist across various model sizes, and exist\nin very recent language and vision-language models. Code is available at\nhttps://github.com/ys-zong/FoolyourVLLMs.\n","authors":["Yongshuo Zong","Tingyang Yu","Ruchika Chavhan","Bingchen Zhao","Timothy Hospedales"],"pdf_url":"https://arxiv.org/pdf/2310.01651v3.pdf","comment":"ICML 2024; v3 fix typo"},{"id":"http://arxiv.org/abs/2407.00730v2","updated":"2024-08-01T21:39:05Z","published":"2024-06-30T15:38:38Z","title":"D-CDLF: Decomposition of Common and Distinctive Latent Factors for\n  Multi-view High-dimensional Data","summary":"  A typical approach to the joint analysis of multiple high-dimensional data\nviews is to decompose each view's data matrix into three parts: a low-rank\ncommon-source matrix generated by common latent factors of all data views, a\nlow-rank distinctive-source matrix generated by distinctive latent factors of\nthe corresponding data view, and an additive noise matrix. Existing\ndecomposition methods often focus on the uncorrelatedness between the common\nlatent factors and distinctive latent factors, but inadequately address the\nequally necessary uncorrelatedness between distinctive latent factors from\ndifferent data views. We propose a novel decomposition method, called\nDecomposition of Common and Distinctive Latent Factors (D-CDLF), to effectively\nachieve both types of uncorrelatedness for two-view data. We also discuss the\nestimation of the D-CDLF under high-dimensional settings.\n","authors":["Hai Shu"],"pdf_url":"https://arxiv.org/pdf/2407.00730v2.pdf","comment":"This revision updates only Paragraph 1 of Section 2.1 and Remark 2 of\n  Section 3.2 from version 1"},{"id":"http://arxiv.org/abs/2408.00930v1","updated":"2024-08-01T21:38:09Z","published":"2024-08-01T21:38:09Z","title":"Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain\n  Agnostic Framework for Data-Driven Scientific Research","summary":"  We introduce WarpSci, a domain agnostic framework designed to overcome\ncrucial system bottlenecks encountered in the application of reinforcement\nlearning to intricate environments with vast datasets featuring\nhigh-dimensional observation or action spaces. Notably, our framework\neliminates the need for data transfer between the CPU and GPU, enabling the\nconcurrent execution of thousands of simulations on a single or multiple GPUs.\nThis high data throughput architecture proves particularly advantageous for\ndata-driven scientific research, where intricate environment models are\ncommonly essential.\n","authors":["Tian Lan","Huan Wang","Caiming Xiong","Silvio Savarese"],"pdf_url":"https://arxiv.org/pdf/2408.00930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00929v1","updated":"2024-08-01T21:37:10Z","published":"2024-08-01T21:37:10Z","title":"Verification of Machine Unlearning is Fragile","summary":"  As privacy concerns escalate in the realm of machine learning, data owners\nnow have the option to utilize machine unlearning to remove their data from\nmachine learning models, following recent legislation. To enhance transparency\nin machine unlearning and avoid potential dishonesty by model providers,\nvarious verification strategies have been proposed. These strategies enable\ndata owners to ascertain whether their target data has been effectively\nunlearned from the model. However, our understanding of the safety issues of\nmachine unlearning verification remains nascent. In this paper, we explore the\nnovel research question of whether model providers can circumvent verification\nstrategies while retaining the information of data supposedly unlearned. Our\ninvestigation leads to a pessimistic answer: \\textit{the verification of\nmachine unlearning is fragile}. Specifically, we categorize the current\nverification strategies regarding potential dishonesty among model providers\ninto two types. Subsequently, we introduce two novel adversarial unlearning\nprocesses capable of circumventing both types. We validate the efficacy of our\nmethods through theoretical analysis and empirical experiments using real-world\ndatasets. This study highlights the vulnerabilities and limitations in machine\nunlearning verification, paving the way for further research into the safety of\nmachine unlearning.\n","authors":["Binchi Zhang","Zihan Chen","Cong Shen","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2408.00929v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2408.00921v1","updated":"2024-08-01T21:22:16Z","published":"2024-08-01T21:22:16Z","title":"Automatic Pull Request Description Generation Using LLMs: A T5 Model\n  Approach","summary":"  Developers create pull request (PR) descriptions to provide an overview of\ntheir changes and explain the motivations behind them. These descriptions help\nreviewers and fellow developers quickly understand the updates. Despite their\nimportance, some developers omit these descriptions. To tackle this problem, we\npropose an automated method for generating PR descriptions based on commit\nmessages and source code comments. This method frames the task as a text\nsummarization problem, for which we utilized the T5 text-to-text transfer\nmodel. We fine-tuned a pre-trained T5 model using a dataset containing 33,466\nPRs. The model's effectiveness was assessed using ROUGE metrics, which are\nrecognized for their strong alignment with human evaluations. Our findings\nreveal that the T5 model significantly outperforms LexRank, which served as our\nbaseline for comparison.\n","authors":["Md Nazmus Sakib","Md Athikul Islam","Md Mashrur Arifin"],"pdf_url":"https://arxiv.org/pdf/2408.00921v1.pdf","comment":"Accepted to 2nd International Conference on Artificial Intelligence,\n  Blockchain, and Internet of Things (AIBThings-2024), September 07-08, 2024,\n  Michigan, USA"},{"id":"http://arxiv.org/abs/2408.00920v1","updated":"2024-08-01T21:22:10Z","published":"2024-08-01T21:22:10Z","title":"Towards Certified Unlearning for Deep Neural Networks","summary":"  In the field of machine unlearning, certified unlearning has been extensively\nstudied in convex machine learning models due to its high efficiency and strong\ntheoretical guarantees. However, its application to deep neural networks\n(DNNs), known for their highly nonconvex nature, still poses challenges. To\nbridge the gap between certified unlearning and DNNs, we propose several simple\ntechniques to extend certified unlearning methods to nonconvex objectives. To\nreduce the time complexity, we develop an efficient computation method by\ninverse Hessian approximation without compromising certification guarantees. In\naddition, we extend our discussion of certification to nonconvergence training\nand sequential unlearning, considering that real-world users can send\nunlearning requests at different time points. Extensive experiments on three\nreal-world datasets demonstrate the efficacy of our method and the advantages\nof certified unlearning in DNNs.\n","authors":["Binchi Zhang","Yushun Dong","Tianhao Wang","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2408.00920v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2404.00859v2","updated":"2024-08-01T21:21:28Z","published":"2024-04-01T02:01:28Z","title":"Do language models plan ahead for future tokens?","summary":"  Do transformers \"think ahead\" during inference at a given position? It is\nknown transformers prepare information in the hidden states of the forward pass\nat time step $t$ that is then used in future forward passes $t+\\tau$. We posit\ntwo explanations for this phenomenon: pre-caching, in which off-diagonal\ngradient terms present during training result in the model computing features\nat $t$ irrelevant to the present inference task but useful for the future, and\nbreadcrumbs, in which features most relevant to time step $t$ are already the\nsame as those that would most benefit inference at time $t+\\tau$. We test these\nhypotheses by training language models without propagating gradients to past\ntimesteps, a scheme we formalize as myopic training. In a constructed synthetic\ndata setting, we find clear evidence for pre-caching. In the autoregressive\nlanguage modeling setting, our experiments are more suggestive of the\nbreadcrumbs hypothesis, though pre-caching increases with model scale.\n","authors":["Wilson Wu","John X. Morris","Lionel Levine"],"pdf_url":"https://arxiv.org/pdf/2404.00859v2.pdf","comment":"24 pages, 11 figures. Camera-ready for COLM 2024"},{"id":"http://arxiv.org/abs/2408.00911v1","updated":"2024-08-01T21:04:27Z","published":"2024-08-01T21:04:27Z","title":"Distance-Preserving Generative Modeling of Spatial Transcriptomics","summary":"  Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.\n","authors":["Wenbin Zhou","Jin-Hong Du"],"pdf_url":"https://arxiv.org/pdf/2408.00911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00908v1","updated":"2024-08-01T20:58:07Z","published":"2024-08-01T20:58:07Z","title":"Early Stopping Based on Repeated Significance","summary":"  For a bucket test with a single criterion for success and a fixed number of\nsamples or testing period, requiring a $p$-value less than a specified value of\n$\\alpha$ for the success criterion produces statistical confidence at level $1\n- \\alpha$. For multiple criteria, a Bonferroni correction that partitions\n$\\alpha$ among the criteria produces statistical confidence, at the cost of\nrequiring lower $p$-values for each criterion. The same concept can be applied\nto decisions about early stopping, but that can lead to strict requirements for\n$p$-values. We show how to address that challenge by requiring criteria to be\nsuccessful at multiple decision points.\n","authors":["Eric Bax","Arundhyoti Sarkar","Alex Shtoff"],"pdf_url":"https://arxiv.org/pdf/2408.00908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15847v2","updated":"2024-08-01T20:54:46Z","published":"2024-06-22T13:26:14Z","title":"Enhancing Solar Driver Forecasting with Multivariate Transformers","summary":"  In this work, we develop a comprehensive framework for F10.7, S10.7, M10.7,\nand Y10.7 solar driver forecasting with a time series Transformer (PatchTST).\nTo ensure an equal representation of high and low levels of solar activity, we\nconstruct a custom loss function to weight samples based on the distance\nbetween the solar driver's historical distribution and the training set. The\nsolar driver forecasting framework includes an 18-day lookback window and\nforecasts 6 days into the future. When benchmarked against the Space\nEnvironment Technologies (SET) dataset, our model consistently produces\nforecasts with a lower standard mean error in nearly all cases, with improved\nprediction accuracy during periods of high solar activity. All the code is\navailable on Github https://github.com/ARCLab-MIT/sw-driver-forecaster.\n","authors":["Sergio Sanchez-Hurtado","Victor Rodriguez-Fernandez","Julia Briden","Peng Mun Siew","Richard Linares"],"pdf_url":"https://arxiv.org/pdf/2406.15847v2.pdf","comment":"Short paper accepted for oral presentation at the SPAICE Conference\n  2024 (https://spaice.esa.int/)"},{"id":"http://arxiv.org/abs/2408.00906v1","updated":"2024-08-01T20:54:33Z","published":"2024-08-01T20:54:33Z","title":"Parkinson's Disease Detection from Resting State EEG using Multi-Head\n  Graph Structure Learning with Gradient Weighted Graph Attention Explanations","summary":"  Parkinson's disease (PD) is a debilitating neurodegenerative disease that has\nsevere impacts on an individual's quality of life. Compared with structural and\nfunctional MRI-based biomarkers for the disease, electroencephalography (EEG)\ncan provide more accessible alternatives for clinical insights. While deep\nlearning (DL) techniques have provided excellent outcomes, many techniques fail\nto model spatial information and dynamic brain connectivity, and face\nchallenges in robust feature learning, limited data sizes, and poor\nexplainability. To address these issues, we proposed a novel graph neural\nnetwork (GNN) technique for explainable PD detection using resting state EEG.\nSpecifically, we employ structured global convolutions with contrastive\nlearning to better model complex features with limited data, a novel multi-head\ngraph structure learner to capture the non-Euclidean structure of EEG data, and\na head-wise gradient-weighted graph attention explainer to offer neural\nconnectivity insights. We developed and evaluated our method using the UC San\nDiego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy\nin subject-wise leave-one-out cross-validation while generating intuitive\nexplanations for the learnt graph topology.\n","authors":["Christopher Neves","Yong Zeng","Yiming Xiao"],"pdf_url":"https://arxiv.org/pdf/2408.00906v1.pdf","comment":"Accepted at MLCN 2024"},{"id":"http://arxiv.org/abs/2406.02529v2","updated":"2024-08-01T20:53:09Z","published":"2024-06-04T17:51:08Z","title":"ReLUs Are Sufficient for Learning Implicit Neural Representations","summary":"  Motivated by the growing theoretical understanding of neural networks that\nemploy the Rectified Linear Unit (ReLU) as their activation function, we\nrevisit the use of ReLU activation functions for learning implicit neural\nrepresentations (INRs). Inspired by second order B-spline wavelets, we\nincorporate a set of simple constraints to the ReLU neurons in each layer of a\ndeep neural network (DNN) to remedy the spectral bias. This in turn enables its\nuse for various INR tasks. Empirically, we demonstrate that, contrary to\npopular belief, one can learn state-of-the-art INRs based on a DNN composed of\nonly ReLU neurons. Next, by leveraging recent theoretical works which\ncharacterize the kinds of functions ReLU neural networks learn, we provide a\nway to quantify the regularity of the learned function. This offers a\nprincipled approach to selecting the hyperparameters in INR architectures. We\nsubstantiate our claims through experiments in signal representation, super\nresolution, and computed tomography, demonstrating the versatility and\neffectiveness of our method. The code for all experiments can be found at\nhttps://github.com/joeshenouda/relu-inrs.\n","authors":["Joseph Shenouda","Yamin Zhou","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2406.02529v2.pdf","comment":"Accepted to ICML 2024"},{"id":"http://arxiv.org/abs/2407.10886v2","updated":"2024-08-01T20:34:18Z","published":"2024-07-15T16:37:55Z","title":"SLIP: Securing LLMs IP Using Weights Decomposition","summary":"  Large language models (LLMs) have recently seen widespread adoption, in both\nacademia and industry. As these models grow, they become valuable intellectual\nproperty (IP), reflecting enormous investments by their owners. Moreover, the\nhigh cost of cloud-based deployment has driven interest towards deployment to\nedge devices, yet this risks exposing valuable parameters to theft and\nunauthorized use. Current methods to protect models' IP on the edge have\nlimitations in terms of practicality, loss in accuracy, or suitability to\nrequirements. In this paper, we introduce a novel hybrid inference algorithm,\nnamed SLIP, designed to protect edge-deployed models from theft. SLIP is the\nfirst hybrid protocol that is both practical for real-world applications and\nprovably secure, while having zero accuracy degradation and minimal impact on\nlatency. It involves partitioning the model between two computing resources,\none secure but expensive, and another cost-effective but vulnerable. This is\nachieved through matrix decomposition, ensuring that the secure resource\nretains a maximally sensitive portion of the model's IP while performing a\nminimal amount of computations, and vice versa for the vulnerable resource.\nImportantly, the protocol includes security guarantees that prevent attackers\nfrom exploiting the partition to infer the secured information. Finally, we\npresent experimental results that show the robustness and effectiveness of our\nmethod, positioning it as a compelling solution for protecting LLMs.\n","authors":["Yehonathan Refael","Adam Hakim","Lev Greenberg","Tal Aviv","Satya Lokam","Ben Fishman","Shachar Seidman"],"pdf_url":"https://arxiv.org/pdf/2407.10886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00895v1","updated":"2024-08-01T20:21:52Z","published":"2024-08-01T20:21:52Z","title":"Discrete Randomized Smoothing Meets Quantum Computing","summary":"  Breakthroughs in machine learning (ML) and advances in quantum computing (QC)\ndrive the interdisciplinary field of quantum machine learning to new levels.\nHowever, due to the susceptibility of ML models to adversarial attacks,\npractical use raises safety-critical concerns. Existing Randomized Smoothing\n(RS) certification methods for classical machine learning models are\ncomputationally intensive. In this paper, we propose the combination of QC and\nthe concept of discrete randomized smoothing to speed up the stochastic\ncertification of ML models for discrete data. We show how to encode all the\nperturbations of the input binary data in superposition and use Quantum\nAmplitude Estimation (QAE) to obtain a quadratic reduction in the number of\ncalls to the model that are required compared to traditional randomized\nsmoothing techniques. In addition, we propose a new binary threat model to\nallow for an extensive evaluation of our approach on images, graphs, and text.\n","authors":["Tom Wollschläger","Aman Saxena","Nicola Franco","Jeanette Miriam Lorenz","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2408.00895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09436v2","updated":"2024-08-01T20:19:29Z","published":"2023-11-27T21:18:06Z","title":"Temporal Transfer Learning for Traffic Optimization with Coarse-grained\n  Advisory Autonomy","summary":"  The recent development of connected and automated vehicle (CAV) technologies\nhas spurred investigations to optimize dense urban traffic to maximize vehicle\nspeed and throughput. This paper explores advisory autonomy, in which real-time\ndriving advisories are issued to the human drivers, thus achieving near-term\nperformance of automated vehicles. Due to the complexity of traffic systems,\nrecent studies of coordinating CAVs have resorted to leveraging deep\nreinforcement learning (RL). Coarse-grained advisory is formalized as\nzero-order holds, and we consider a range of hold duration from 0.1 to 40\nseconds. However, despite the similarity of the higher frequency tasks on CAVs,\na direct application of deep RL fails to be generalized to advisory autonomy\ntasks. To overcome this, we utilize zero-shot transfer, training policies on a\nset of source tasks--specific traffic scenarios with designated hold\ndurations--and then evaluating the efficacy of these policies on different\ntarget tasks. We introduce Temporal Transfer Learning (TTL) algorithms to\nselect source tasks for zero-shot transfer, systematically leveraging the\ntemporal structure to solve the full range of tasks. TTL selects the most\nsuitable source tasks to maximize the performance of the range of tasks. We\nvalidate our algorithms on diverse mixed-traffic scenarios, demonstrating that\nTTL more reliably solves the tasks than baselines. This paper underscores the\npotential of coarse-grained advisory autonomy with TTL in traffic flow\noptimization.\n","authors":["Jung-Hoon Cho","Sirui Li","Jeongyun Kim","Cathy Wu"],"pdf_url":"https://arxiv.org/pdf/2312.09436v2.pdf","comment":"18 pages, 12 figures"},{"id":"http://arxiv.org/abs/2407.00741v5","updated":"2024-08-01T20:15:37Z","published":"2024-06-30T16:05:31Z","title":"Diffusion Models for Offline Multi-agent Reinforcement Learning with\n  Safety Constraints","summary":"  In recent advancements in Multi-agent Reinforcement Learning (MARL), its\napplication has extended to various safety-critical scenarios. However, most\nmethods focus on online learning, which presents substantial risks when\ndeployed in real-world settings. Addressing this challenge, we introduce an\ninnovative framework integrating diffusion models within the MARL paradigm.\nThis approach notably enhances the safety of actions taken by multiple agents\nthrough risk mitigation while modeling coordinated action. Our framework is\ngrounded in the Centralized Training with Decentralized Execution (CTDE)\narchitecture, augmented by a Diffusion Model for prediction trajectory\ngeneration. Additionally, we incorporate a specialized algorithm to further\nensure operational safety. We evaluate our model against baselines on the DSRL\nbenchmark. Experiment results demonstrate that our model not only adheres to\nstringent safety constraints but also achieves superior performance compared to\nexisting methodologies. This underscores the potential of our approach in\nadvancing the safety and efficacy of MARL in real-world applications.\n","authors":["Jianuo Huang"],"pdf_url":"https://arxiv.org/pdf/2407.00741v5.pdf","comment":"arXiv admin note: text overlap with arXiv:2101.05436 by other authors"},{"id":"http://arxiv.org/abs/2408.00892v1","updated":"2024-08-01T20:12:49Z","published":"2024-08-01T20:12:49Z","title":"Peptide Sequencing Via Protein Language Models","summary":"  We introduce a protein language model for determining the complete sequence\nof a peptide based on measurement of a limited set of amino acids. To date,\nprotein sequencing relies on mass spectrometry, with some novel edman\ndegregation based platforms able to sequence non-native peptides. Current\nprotein sequencing techniques face limitations in accurately identifying all\namino acids, hindering comprehensive proteome analysis. Our method simulates\npartial sequencing data by selectively masking amino acids that are\nexperimentally difficult to identify in protein sequences from the UniRef\ndatabase. This targeted masking mimics real-world sequencing limitations. We\nthen modify and finetune a ProtBert derived transformer-based model, for a new\ndownstream task predicting these masked residues, providing an approximation of\nthe complete sequence. Evaluating on three bacterial Escherichia species, we\nachieve per-amino-acid accuracy up to 90.5% when only four amino acids ([KCYM])\nare known. Structural assessment using AlphaFold and TM-score validates the\nbiological relevance of our predictions. The model also demonstrates potential\nfor evolutionary analysis through cross-species performance. This integration\nof simulated experimental constraints with computational predictions offers a\npromising avenue for enhancing protein sequence analysis, potentially\naccelerating advancements in proteomics and structural biology by providing a\nprobabilistic reconstruction of the complete protein sequence from limited\nexperimental data.\n","authors":["Thuong Le Hoai Pham","Jillur Rahman Saurav","Aisosa A. Omere","Calvin J. Heyl","Mohammad Sadegh Nasr","Cody Tyler Reynolds","Jai Prakash Yadav Veerla","Helen H Shang","Justyn Jaworski","Alison Ravenscraft","Joseph Anthony Buonomo","Jacob M. Luber"],"pdf_url":"https://arxiv.org/pdf/2408.00892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17701v4","updated":"2024-08-01T19:41:07Z","published":"2024-04-26T20:59:23Z","title":"Embedded FPGA Developments in 130nm and 28nm CMOS for Machine Learning\n  in Particle Detector Readout","summary":"  Embedded field programmable gate array (eFPGA) technology allows the\nimplementation of reconfigurable logic within the design of an\napplication-specific integrated circuit (ASIC). This approach offers the low\npower and efficiency of an ASIC along with the ease of FPGA configuration,\nparticularly beneficial for the use case of machine learning in the data\npipeline of next-generation collider experiments. An open-source framework\ncalled \"FABulous\" was used to design eFPGAs using 130 nm and 28 nm CMOS\ntechnology nodes, which were subsequently fabricated and verified through\ntesting. The capability of an eFPGA to act as a front-end readout chip was\nassessed using simulation of high energy particles passing through a silicon\npixel sensor. A machine learning-based classifier, designed for reduction of\nsensor data at the source, was synthesized and configured onto the eFPGA. A\nsuccessful proof-of-concept was demonstrated through reproduction of the\nexpected algorithm result on the eFPGA with perfect accuracy. Further\ndevelopment of the eFPGA technology and its application to collider detector\nreadout is discussed.\n","authors":["Julia Gonski","Aseem Gupta","Haoyi Jia","Hyunjoon Kim","Lorenzo Rota","Larry Ruckman","Angelo Dragone","Ryan Herbst"],"pdf_url":"https://arxiv.org/pdf/2404.17701v4.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2408.00876v1","updated":"2024-08-01T18:56:08Z","published":"2024-08-01T18:56:08Z","title":"On the Relationship Between Monotone and Squared Probabilistic Circuits","summary":"  Probabilistic circuits are a unifying representation of functions as\ncomputation graphs of weighted sums and products. Their primary application is\nin probabilistic modeling, where circuits with non-negative weights (monotone\ncircuits) can be used to represent and learn density/mass functions, with\ntractable marginal inference. Recently, it was proposed to instead represent\ndensities as the square of the circuit function (squared circuits); this allows\nthe use of negative weights while retaining tractability, and can be\nexponentially more compact than monotone circuits. Unfortunately, we show the\nreverse also holds, meaning that monotone circuits and squared circuits are\nincomparable in general. This raises the question of whether we can reconcile,\nand indeed improve upon the two modeling approaches. We answer in the positive\nby proposing InceptionPCs, a novel type of circuit that naturally encompasses\nboth monotone circuits and squared circuits as special cases, and employs\ncomplex parameters. Empirically, we validate that InceptionPCs can outperform\nboth monotone and squared circuits on image datasets.\n","authors":["Benjie Wang","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2408.00876v1.pdf","comment":"7th Workshop on Tractable Probabilistic Modeling"},{"id":"http://arxiv.org/abs/2408.00872v1","updated":"2024-08-01T18:46:05Z","published":"2024-08-01T18:46:05Z","title":"Online Detection of Anomalies in Temporal Knowledge Graphs with\n  Interpretability","summary":"  Temporal knowledge graphs (TKGs) are valuable resources for capturing\nevolving relationships among entities, yet they are often plagued by noise,\nnecessitating robust anomaly detection mechanisms. Existing dynamic graph\nanomaly detection approaches struggle to capture the rich semantics introduced\nby node and edge categories within TKGs, while TKG embedding methods lack\ninterpretability, undermining the credibility of anomaly detection. Moreover,\nthese methods falter in adapting to pattern changes and semantic drifts\nresulting from knowledge updates. To tackle these challenges, we introduce\nAnoT, an efficient TKG summarization method tailored for interpretable online\nanomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule\ngraph, enabling flexible inference of complex patterns in TKGs. When new\nknowledge emerges, AnoT maps it onto a node in the rule graph and traverses the\nrule graph recursively to derive the anomaly score of the knowledge. The\ntraversal yields reachable nodes that furnish interpretable evidence for the\nvalidity or the anomalous of the new knowledge. Overall, AnoT embodies a\ndetector-updater-monitor architecture, encompassing a detector for offline TKG\nsummarization and online scoring, an updater for real-time rule graph updates\nbased on emerging knowledge, and a monitor for estimating the approximation\nerror of the rule graph. Experimental results on four real-world datasets\ndemonstrate that AnoT surpasses existing methods significantly in terms of\naccuracy and interoperability. All of the raw datasets and the implementation\nof AnoT are provided in https://github.com/zjs123/ANoT.\n","authors":["Jiasheng Zhang","Jie Shao","Rex Ying"],"pdf_url":"https://arxiv.org/pdf/2408.00872v1.pdf","comment":"15 pages, 8 figures. Accepted by SIGMOD 2025 Round 2"},{"id":"http://arxiv.org/abs/2408.00863v1","updated":"2024-08-01T18:31:31Z","published":"2024-08-01T18:31:31Z","title":"UniMoT: Unified Molecule-Text Language Model with Discrete Token\n  Representation","summary":"  The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.\n","authors":["Juzheng Zhang","Yatao Bian","Yongqiang Chen","Quanming Yao"],"pdf_url":"https://arxiv.org/pdf/2408.00863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00856v1","updated":"2024-08-01T18:10:05Z","published":"2024-08-01T18:10:05Z","title":"Deep Learning Approach for Changepoint Detection: Penalty Parameter\n  Optimization","summary":"  Changepoint detection, a technique for identifying significant shifts within\ndata sequences, is crucial in various fields such as finance, genomics,\nmedicine, etc. Dynamic programming changepoint detection algorithms are\nemployed to identify the locations of changepoints within a sequence, which\nrely on a penalty parameter to regulate the number of changepoints. To estimate\nthis penalty parameter, previous work uses simple models such as linear models\nor decision trees. This study introduces a novel deep learning method for\npredicting penalty parameters, leading to demonstrably improved changepoint\ndetection accuracy on large benchmark supervised labeled datasets compared to\nprevious methods.\n","authors":["Tung L Nguyen","Toby Dylan Hocking"],"pdf_url":"https://arxiv.org/pdf/2408.00856v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.00845v1","updated":"2024-08-01T18:01:14Z","published":"2024-08-01T18:01:14Z","title":"A Novel Use of Pseudospectra in Mathematical Biology: Understanding HPA\n  Axis Sensitivity","summary":"  The Hypothalamic-Pituitary-Adrenal (HPA) axis is a major neuroendocrine\nsystem, and its dysregulation is implicated in various diseases. This system\nalso presents interesting mathematical challenges for modeling. We consider a\nnonlinear delay differential equation model and calculate pseudospectra of\nthree different linearizations: a time-dependent Jacobian, linearization around\nthe limit cycle, and dynamic mode decomposition (DMD) analysis of Koopman\noperators (global linearization). The time-dependent Jacobian provided insight\ninto experimental phenomena, explaining why rats respond differently to\nperturbations during corticosterone secretion's upward versus downward slopes.\nWe developed new mathematical techniques for the other two linearizations to\ncalculate pseudospectra on Banach spaces and apply DMD to delay differential\nequations, respectively. These methods helped establish local and global limit\ncycle stability and study transients. Additionally, we discuss using\npseudospectra to substantiate the model in experimental contexts and establish\nbio-variability via data-driven methods. This work is the first to utilize\npseudospectra to explore the HPA axis.\n","authors":["Catherine Drysdale","Matthew J. Colbrook"],"pdf_url":"https://arxiv.org/pdf/2408.00845v1.pdf","comment":"15 pages, keywords: HPA axis, pseudospectra, nonlinear delay\n  differential equations, dynamic mode decomposition (DMD)"},{"id":"http://arxiv.org/abs/2408.00838v1","updated":"2024-08-01T18:00:05Z","published":"2024-08-01T18:00:05Z","title":"Calibrating Bayesian Generative Machine Learning for Bayesiamplification","summary":"  Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.\n","authors":["Sebastian Bieringer","Sascha Diefenbacher","Gregor Kasieczka","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2408.00838v1.pdf","comment":"15 pages, 6 figures"}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2407.16020v3","updated":"2024-08-01T17:40:36Z","published":"2024-07-22T19:55:44Z","title":"Sparks of Quantum Advantage and Rapid Retraining in Machine Learning","summary":"  The advent of quantum computing holds the potential to revolutionize various\nfields by solving complex problems more efficiently than classical computers.\nDespite this promise, practical quantum advantage is hindered by current\nhardware limitations, notably the small number of qubits and high noise levels.\nIn this study, we leverage adiabatic quantum computers to optimize\nKolmogorov-Arnold Networks, a powerful neural network architecture for\nrepresenting complex functions with minimal parameters. By modifying the\nnetwork to use Bezier curves as the basis functions and formulating the\noptimization problem into a Quadratic Unconstrained Binary Optimization\nproblem, we create a fixed-sized solution space, independent of the number of\ntraining samples. Our approach demonstrates sparks of quantum advantage through\nfaster training times compared to classical optimizers such as the Adam,\nStochastic Gradient Descent, Adaptive Gradient, and simulated annealing.\nAdditionally, we introduce a novel rapid retraining capability, enabling the\nnetwork to be retrained with new data without reprocessing old samples, thus\nenhancing learning efficiency in dynamic environments. Experimental results on\ninitial training of classification and regression tasks validate the efficacy\nof our approach, showcasing significant speedups and comparable performance to\nclassical methods. While experiments on retraining demonstrate a sixty times\nspeed up using adiabatic quantum computing based optimization compared to that\nof the gradient descent based optimizers, with theoretical models allowing this\nspeed up to be even larger! Our findings suggest that with further advancements\nin quantum hardware and algorithm optimization, quantum-optimized machine\nlearning models could have broad applications across various domains, with\ninitial focus on rapid retraining.\n","authors":["William Troy"],"pdf_url":"https://arxiv.org/pdf/2407.16020v3.pdf","comment":"Major updates to the paper for timings and explanations of\n  optimization strategies used. Further optimized the code and updated the\n  figures to reflect the faster timings for v3"},{"id":"http://arxiv.org/abs/2310.12428v2","updated":"2024-08-01T17:38:27Z","published":"2023-10-19T02:42:20Z","title":"Enhanced Local Explainability and Trust Scores with Random Forest\n  Proximities","summary":"  We initiate a novel approach to explain the predictions and out of sample\nperformance of random forest (RF) regression and classification models by\nexploiting the fact that any RF can be mathematically formulated as an adaptive\nweighted K nearest-neighbors model. Specifically, we employ a recent result\nthat, for both regression and classification tasks, any RF prediction can be\nrewritten exactly as a weighted sum of the training targets, where the weights\nare RF proximities between the corresponding pairs of data points. We show that\nthis linearity facilitates a local notion of explainability of RF predictions\nthat generates attributions for any model prediction across observations in the\ntraining set, and thereby complements established feature-based methods like\nSHAP, which generate attributions for a model prediction across input features.\nWe show how this proximity-based approach to explainability can be used in\nconjunction with SHAP to explain not just the model predictions, but also\nout-of-sample performance, in the sense that proximities furnish a novel means\nof assessing when a given model prediction is more or less likely to be\ncorrect. We demonstrate this approach in the modeling of US corporate bond\nprices and returns in both regression and classification cases.\n","authors":["Joshua Rosaler","Dhruv Desai","Bhaskarjit Sarmah","Dimitrios Vamvourellis","Deran Onay","Dhagash Mehta","Stefano Pasquali"],"pdf_url":"https://arxiv.org/pdf/2310.12428v2.pdf","comment":"5 pages, 6 figures"},{"id":"http://arxiv.org/abs/2209.08273v2","updated":"2024-08-01T17:07:03Z","published":"2022-09-17T08:03:46Z","title":"Low-Rank Covariance Completion for Graph Quilting with Applications to\n  Functional Connectivity","summary":"  As a tool for estimating networks in high dimensions, graphical models are\ncommonly applied to calcium imaging data to estimate functional neuronal\nconnectivity, i.e. relationships between the activities of neurons. However, in\nmany calcium imaging data sets, the full population of neurons is not recorded\nsimultaneously, but instead in partially overlapping blocks. This leads to the\nGraph Quilting problem, as first introduced by (Vinci et.al. 2019), in which\nthe goal is to infer the structure of the full graph when only subsets of\nfeatures are jointly observed. In this paper, we study a novel two-step\napproach to Graph Quilting, which first imputes the complete covariance matrix\nusing low-rank covariance completion techniques before estimating the graph\nstructure. We introduce three approaches to solve this problem: block singular\nvalue decomposition, nuclear norm penalization, and non-convex low-rank\nfactorization. While prior works have studied low-rank matrix completion, we\naddress the challenges brought by the block-wise missingness and are the first\nto investigate the problem in the context of graph learning. We discuss\ntheoretical properties of the two-step procedure, showing graph selection\nconsistency of one proposed approach by proving novel L infinity-norm error\nbounds for matrix completion with block-missingness. We then investigate the\nempirical performance of the proposed methods on simulations and on real-world\ndata examples, through which we show the efficacy of these methods for\nestimating functional connectivity from calcium imaging data.\n","authors":["Andersen Chang","Lili Zheng","Genevera I. Allen"],"pdf_url":"https://arxiv.org/pdf/2209.08273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10158v4","updated":"2024-08-01T16:03:44Z","published":"2023-07-19T17:39:30Z","title":"A Unified Framework for Pattern Recovery in Penalized and Thresholded\n  Estimation and its Geometry","summary":"  We consider the framework of penalized estimation where the penalty term is\ngiven by a real-valued polyhedral gauge, which encompasses methods such as\nLASSO, generalized LASSO, SLOPE, OSCAR, PACS and others. Each of these\nestimators can uncover a different structure or ``pattern'' of the unknown\nparameter vector. We define a novel and general notion of patterns based on\nsubdifferentials and formalize an approach to measure pattern complexity. For\npattern recovery, we provide a minimal condition for a particular pattern to be\ndetected by the procedure with positive probability, the so-called\naccessibility condition. Using our approach, we also introduce the stronger\nnoiseless recovery condition. For the LASSO, it is well known that the\nirrepresentability condition is necessary for pattern recovery with probability\nlarger than $1/2$ and we show that the noiseless recovery plays exactly the\nsame role in our general framework, thereby unifying and extending the\nirrepresentability condition to a broad class of penalized estimators. We also\nshow that the noiseless recovery condition can be relaxed when turning to\nso-called thresholded penalized estimators: we prove that the accessibility\ncondition is already sufficient (and necessary) for sure pattern recovery by\nthresholded penalized estimation provided that the signal of the pattern is\nlarge enough. Throughout the article, we demonstrate how our findings can be\ninterpreted through a geometrical lens.\n","authors":["Piotr Graczyk","Ulrike Schneider","Tomasz Skalski","Patrick Tardivel"],"pdf_url":"https://arxiv.org/pdf/2307.10158v4.pdf","comment":"new Proposition 4.7"},{"id":"http://arxiv.org/abs/2111.04597v4","updated":"2024-08-01T14:38:06Z","published":"2021-11-08T16:09:39Z","title":"Neyman-Pearson Multi-class Classification via Cost-sensitive Learning","summary":"  Most existing classification methods aim to minimize the overall\nmisclassification error rate. However, in applications such as loan default\nprediction, different types of errors can have varying consequences. To address\nthis asymmetry issue, two popular paradigms have been developed: the\nNeyman-Pearson (NP) paradigm and the cost-sensitive (CS) paradigm. Previous\nstudies on the NP paradigm have primarily focused on the binary case, while the\nmulti-class NP problem poses a greater challenge due to its unknown\nfeasibility. In this work, we tackle the multi-class NP problem by establishing\na connection with the CS problem via strong duality and propose two algorithms.\nWe extend the concept of NP oracle inequalities, crucial in binary\nclassifications, to NP oracle properties in the multi-class context. Our\nalgorithms satisfy these NP oracle properties under certain conditions.\nFurthermore, we develop practical algorithms to assess the feasibility and\nstrong duality in multi-class NP problems, which can offer practitioners the\nlandscape of a multi-class NP problem with various target error levels.\nSimulations and real data studies validate the effectiveness of our algorithms.\nTo our knowledge, this is the first study to address the multi-class NP problem\nwith theoretical guarantees. The proposed algorithms have been implemented in\nthe R package \\texttt{npcs}, which is available on CRAN.\n","authors":["Ye Tian","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2111.04597v4.pdf","comment":"114 pages, 18 figures"},{"id":"http://arxiv.org/abs/2407.04724v2","updated":"2024-08-01T14:18:32Z","published":"2024-06-26T07:32:04Z","title":"A Likelihood-Based Generative Approach for Spatially Consistent\n  Precipitation Downscaling","summary":"  Deep learning has emerged as a promising tool for precipitation downscaling.\nHowever, current models rely on likelihood-based loss functions to properly\nmodel the precipitation distribution, leading to spatially inconsistent\nprojections when sampling. This work explores a novel approach by fusing the\nstrengths of likelihood-based and adversarial losses used in generative models.\nAs a result, we propose a likelihood-based generative approach for\nprecipitation downscaling, leveraging the benefits of both methods.\n","authors":["Jose González-Abad"],"pdf_url":"https://arxiv.org/pdf/2407.04724v2.pdf","comment":"Accepted at ICML 2024 Machine Learning for Earth System Modeling\n  workshop"},{"id":"http://arxiv.org/abs/2209.12715v2","updated":"2024-08-01T13:53:43Z","published":"2022-09-26T14:11:05Z","title":"Enhancing convolutional neural network generalizability via low-rank\n  weight approximation","summary":"  Noise is ubiquitous during image acquisition. Sufficient denoising is often\nan important first step for image processing. In recent decades, deep neural\nnetworks (DNNs) have been widely used for image denoising. Most DNN-based image\ndenoising methods require a large-scale dataset or focus on supervised\nsettings, in which single/pairs of clean images or a set of noisy images are\nrequired. This poses a significant burden on the image acquisition process.\nMoreover, denoisers trained on datasets of limited scale may incur\nover-fitting. To mitigate these issues, we introduce a new self-supervised\nframework for image denoising based on the Tucker low-rank tensor\napproximation. With the proposed design, we are able to characterize our\ndenoiser with fewer parameters and train it based on a single image, which\nconsiderably improves the model's generalizability and reduces the cost of data\nacquisition. Extensive experiments on both synthetic and real-world noisy\nimages have been conducted. Empirical results show that our proposed method\noutperforms existing non-learning-based methods (e.g., low-pass filter,\nnon-local mean), single-image unsupervised denoisers (e.g., DIP, NN+BM3D)\nevaluated on both in-sample and out-sample datasets. The proposed method even\nachieves comparable performances with some supervised methods (e.g., DnCNN).\n","authors":["Chenyin Gao","Shu Yang","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.12715v2.pdf","comment":"accepted by IET Image Processing"},{"id":"http://arxiv.org/abs/2307.13124v3","updated":"2024-08-01T11:51:44Z","published":"2023-07-24T20:45:39Z","title":"Conformal prediction for frequency-severity modeling","summary":"  We present a model-agnostic framework for the construction of prediction\nintervals of insurance claims, with finite sample statistical guarantees,\nextending the technique of split conformal prediction to the domain of\ntwo-stage frequency-severity modeling. The framework effectiveness is showcased\nwith simulated and real datasets using classical parametric models and\ncontemporary machine learning methods. When the underlying severity model is a\nrandom forest, we extend the two-stage split conformal prediction algorithm,\nshowing how the out-of-bag mechanism can be leveraged to eliminate the need for\na calibration set in the conformal procedure.\n","authors":["Helton Graziadei","Paulo C. Marques F.","Eduardo F. L. de Melo","Rodrigo S. Targino"],"pdf_url":"https://arxiv.org/pdf/2307.13124v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07484v6","updated":"2024-08-01T11:49:04Z","published":"2022-11-14T16:08:44Z","title":"Contextual Bandits with Packing and Covering Constraints: A Modular\n  Lagrangian Approach via Regression","summary":"  We consider contextual bandits with linear constraints (CBwLC), a variant of\ncontextual bandits in which the algorithm consumes multiple resources subject\nto linear constraints on total consumption. This problem generalizes contextual\nbandits with knapsacks (CBwK), allowing for packing and covering constraints,\nas well as positive and negative resource consumption. We provide the first\nalgorithm for CBwLC (or CBwK) that is based on regression oracles. The\nalgorithm is simple, computationally efficient, and statistically optimal under\nmild assumptions. Further, we provide the first vanishing-regret guarantees for\nCBwLC (or CBwK) that extend beyond the stochastic environment. We side-step\nstrong impossibility results from prior work by identifying a weaker (and,\narguably, fairer) benchmark to compare against. Our algorithm builds on\nLagrangeBwK (Immorlica et al., FOCS 2019), a Lagrangian-based technique for\nCBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based\ntechnique for contextual bandits. Our analysis leverages the inherent\nmodularity of both techniques.\n","authors":["Aleksandrs Slivkins","Xingyu Zhou","Karthik Abinav Sankararaman","Dylan J. Foster"],"pdf_url":"https://arxiv.org/pdf/2211.07484v6.pdf","comment":"A preliminary version of this paper, authored by A. Slivkins, K.A.\n  Sankararaman and D.J. Foster, has been published at COLT 2023. The present\n  version features an important improvement, due to Xingyu Zhou. Specifically,\n  the $\\sqrt{T}$-regret result in Theorem 3.6(a) holds under a much weaker\n  assumption, and is now positioned as the main guarantee"},{"id":"http://arxiv.org/abs/2310.18615v2","updated":"2024-08-01T09:43:57Z","published":"2023-10-28T06:46:03Z","title":"Temporally Disentangled Representation Learning under Unknown\n  Nonstationarity","summary":"  In unsupervised causal representation learning for sequential data with\ntime-delayed latent causal influences, strong identifiability results for the\ndisentanglement of causally-related latent variables have been established in\nstationary settings by leveraging temporal structure. However, in nonstationary\nsetting, existing work only partially addressed the problem by either utilizing\nobserved auxiliary variables (e.g., class labels and/or domain indexes) as side\ninformation or assuming simplified latent causal dynamics. Both constrain the\nmethod to a limited range of scenarios. In this study, we further explored the\nMarkov Assumption under time-delayed causally related process in nonstationary\nsetting and showed that under mild conditions, the independent latent\ncomponents can be recovered from their nonlinear mixture up to a permutation\nand a component-wise transformation, without the observation of auxiliary\nvariables. We then introduce NCTRL, a principled estimation framework, to\nreconstruct time-delayed latent causal variables and identify their relations\nfrom measured sequential data only. Empirical evaluations demonstrated the\nreliable identification of time-delayed latent causal influences, with our\nmethodology substantially outperforming existing baselines that fail to exploit\nthe nonstationarity adequately and then, consequently, cannot distinguish\ndistribution shifts.\n","authors":["Xiangchen Song","Weiran Yao","Yewen Fan","Xinshuai Dong","Guangyi Chen","Juan Carlos Niebles","Eric Xing","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.18615v2.pdf","comment":"NeurIPS 2023. arXiv admin note: text overlap with arXiv:2210.13647"},{"id":"http://arxiv.org/abs/2209.15224v3","updated":"2024-08-01T08:54:39Z","published":"2022-09-30T04:35:12Z","title":"Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture\n  Models","summary":"  Unsupervised learning has been widely used in many real-world applications.\nOne of the simplest and most important unsupervised learning models is the\nGaussian mixture model (GMM). In this work, we study the multi-task learning\nproblem on GMMs, which aims to leverage potentially similar GMM parameter\nstructures among tasks to obtain improved learning performance compared to\nsingle-task learning. We propose a multi-task GMM learning procedure based on\nthe EM algorithm that effectively utilizes unknown similarities between related\ntasks and is robust against a fraction of outlier tasks from arbitrary\ndistributions. The proposed procedure is shown to achieve the minimax optimal\nrate of convergence for both parameter estimation error and the excess\nmis-clustering error, in a wide range of regimes. Moreover, we generalize our\napproach to tackle the problem of transfer learning for GMMs, where similar\ntheoretical results are derived. Additionally, iterative unsupervised\nmulti-task and transfer learning methods may suffer from an initialization\nalignment problem, and two alignment algorithms are proposed to resolve the\nissue. Finally, we demonstrate the effectiveness of our methods through\nsimulations and real data examples. To the best of our knowledge, this is the\nfirst work studying multi-task and transfer learning on GMMs with theoretical\nguarantees.\n","authors":["Ye Tian","Haolei Weng","Lucy Xia","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2209.15224v3.pdf","comment":"162 pages, 15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2401.06925v2","updated":"2024-08-01T08:51:46Z","published":"2024-01-12T23:14:34Z","title":"Modeling Latent Selection with Structural Causal Models","summary":"  Selection bias is ubiquitous in real-world data, and can lead to misleading\nresults if not dealt with properly. We introduce a conditioning operation on\nStructural Causal Models (SCMs) to model latent selection from a causal\nperspective. We show that the conditioning operation transforms an SCM with the\npresence of an explicit latent selection mechanism into an SCM without such\nselection mechanism, which partially encodes the causal semantics of the\nselected subpopulation according to the original SCM. Furthermore, we show that\nthis conditioning operation preserves the simplicity, acyclicity, and linearity\nof SCMs, and commutes with marginalization. Thanks to these properties,\ncombined with marginalization and intervention, the conditioning operation\noffers a valuable tool for conducting causal reasoning tasks within causal\nmodels where latent details have been abstracted away. We demonstrate by\nexample how classical results of causal inference can be generalized to include\nselection bias and how the conditioning operation helps with modeling of\nreal-world problems.\n","authors":["Leihao Chen","Onno Zoeter","Joris M. Mooij"],"pdf_url":"https://arxiv.org/pdf/2401.06925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.01593v6","updated":"2024-08-01T01:49:47Z","published":"2021-10-04T17:41:53Z","title":"Generalized Kernel Thinning","summary":"  The kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) compresses a\nprobability distribution more effectively than independent sampling by\ntargeting a reproducing kernel Hilbert space (RKHS) and leveraging a less\nsmooth square-root kernel. Here we provide four improvements. First, we show\nthat KT applied directly to the target RKHS yields tighter, dimension-free\nguarantees for any kernel, any distribution, and any fixed function in the\nRKHS. Second, we show that, for analytic kernels like Gaussian, inverse\nmultiquadric, and sinc, target KT admits maximum mean discrepancy (MMD)\nguarantees comparable to or better than those of square-root KT without making\nexplicit use of a square-root kernel. Third, we prove that KT with a fractional\npower kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth\nkernels, like Laplace and Mat\\'ern, that do not have square-roots. Fourth, we\nestablish that KT applied to a sum of the target and power kernels (a procedure\nwe call KT+) simultaneously inherits the improved MMD guarantees of power KT\nand the tighter individual function guarantees of target KT. In our experiments\nwith target KT and KT+, we witness significant improvements in integration\nerror even in $100$ dimensions and when compressing challenging differential\nequation posteriors.\n","authors":["Raaz Dwivedi","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2110.01593v6.pdf","comment":"Corrected B-spline and Sinc rates in Table 3"},{"id":"http://arxiv.org/abs/2408.00751v1","updated":"2024-08-01T17:54:01Z","published":"2024-08-01T17:54:01Z","title":"A Policy-Gradient Approach to Solving Imperfect-Information Games with\n  Iterate Convergence","summary":"  Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.\n","authors":["Mingyang Liu","Gabriele Farina","Asuman Ozdaglar"],"pdf_url":"https://arxiv.org/pdf/2408.00751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00713v1","updated":"2024-08-01T16:58:54Z","published":"2024-08-01T16:58:54Z","title":"Insurance Portfolio Pursuit with Reinforcement Learning","summary":"  When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. Given a\ntarget portfolio, we term the problem of modulating offers to achieve this\ntarget portfolio the portfolio pursuit problem. We give a formulation of\nportfolio pursuit as a sequential decision making problem, and devise a novel\nreinforcement learning algorithm for its solution. We test our method on a\ncomplex synthetic market environment, and demonstrate that it outperforms a\nbaseline method which mimics current industry approaches to portfolio pursuit.\n","authors":["Edward James Young","Alistair Rogers","Elliott Tong","James Jordon"],"pdf_url":"https://arxiv.org/pdf/2408.00713v1.pdf","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.00681v1","updated":"2024-08-01T16:22:03Z","published":"2024-08-01T16:22:03Z","title":"Alpha-VI DeepONet: A prior-robust variational Bayesian approach for\n  enhancing DeepONets with uncertainty quantification","summary":"  We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.\n","authors":["Soban Nasir Lone","Subhayan De","Rajdip Nayek"],"pdf_url":"https://arxiv.org/pdf/2408.00681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00676v1","updated":"2024-08-01T16:19:08Z","published":"2024-08-01T16:19:08Z","title":"An effect analysis of the balancing techniques on the counterfactual\n  explanations of student success prediction models","summary":"  In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.\n","authors":["Mustafa Cavus","Jakub Kuzilek"],"pdf_url":"https://arxiv.org/pdf/2408.00676v1.pdf","comment":"19 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.00651v1","updated":"2024-08-01T15:41:07Z","published":"2024-08-01T15:41:07Z","title":"A Dirichlet stochastic block model for composition-weighted networks","summary":"  Network data are observed in various applications where the individual\nentities of the system interact with or are connected to each other, and often\nthese interactions are defined by their associated strength or importance.\nClustering is a common task in network analysis that involves finding groups of\nnodes displaying similarities in the way they interact with the rest of the\nnetwork. However, most clustering methods use the strengths of connections\nbetween entities in their original form, ignoring the possible differences in\nthe capacities of individual nodes to send or receive edges. This often leads\nto clustering solutions that are heavily influenced by the nodes' capacities.\nOne way to overcome this is to analyse the strengths of connections in relative\nrather than absolute terms, expressing each edge weight as a proportion of the\nsending (or receiving) capacity of the respective node. This, however, induces\nadditional modelling constraints that most existing clustering methods are not\ndesigned to handle. In this work we propose a stochastic block model for\ncomposition-weighted networks based on direct modelling of compositional weight\nvectors using a Dirichlet mixture, with the parameters determined by the\ncluster labels of the sender and the receiver nodes. Inference is implemented\nvia an extension of the classification expectation-maximisation algorithm that\nuses a working independence assumption, expressing the complete data likelihood\nof each node of the network as a function of fixed cluster labels of the\nremaining nodes. A model selection criterion is derived to aid the choice of\nthe number of clusters. The model is validated using simulation studies, and\nshowcased on network data from the Erasmus exchange program and a bike sharing\nnetwork for the city of London.\n","authors":["Iuliia Promskaia","Adrian O'Hagan","Michael Fop"],"pdf_url":"https://arxiv.org/pdf/2408.00651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00549v1","updated":"2024-08-01T13:34:19Z","published":"2024-08-01T13:34:19Z","title":"Learning to Embed Distributions via Maximum Kernel Entropy","summary":"  Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.\n","authors":["Oleksii Kachaiev","Stefano Recanatesi"],"pdf_url":"https://arxiv.org/pdf/2408.00549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00437v1","updated":"2024-08-01T10:16:57Z","published":"2024-08-01T10:16:57Z","title":"Efficient Patient Fine-Tuned Seizure Detection with a Tensor Kernel\n  Machine","summary":"  Recent developments in wearable devices have made accurate and efficient\nseizure detection more important than ever. A challenge in seizure detection is\nthat patient-specific models typically outperform patient-independent models.\nHowever, in a wearable device one typically starts with a patient-independent\nmodel, until such patient-specific data is available. To avoid having to\nconstruct a new classifier with this data, as required in conventional kernel\nmachines, we propose a transfer learning approach with a tensor kernel machine.\nThis method learns the primal weights in a compressed form using the canonical\npolyadic decomposition, making it possible to efficiently update the weights of\nthe patient-independent model with patient-specific data. The results show that\nthis patient fine-tuned model reaches as high a performance as a\npatient-specific SVM model with a model size that is twice as small as the\npatient-specific model and ten times as small as the patient-independent model.\n","authors":["Seline J. S. de Rooij","Frederiek Wesel","Borbála Hunyadi"],"pdf_url":"https://arxiv.org/pdf/2408.00437v1.pdf","comment":"5 pages, to be published in the EUSIPCO2024 conference proceedings"},{"id":"http://arxiv.org/abs/2408.00359v1","updated":"2024-08-01T07:58:51Z","published":"2024-08-01T07:58:51Z","title":"Memorization Capacity for Additive Fine-Tuning with Small ReLU Networks","summary":"  Fine-tuning large pre-trained models is a common practice in machine learning\napplications, yet its mathematical analysis remains largely unexplored. In this\npaper, we study fine-tuning through the lens of memorization capacity. Our new\nmeasure, the Fine-Tuning Capacity (FTC), is defined as the maximum number of\nsamples a neural network can fine-tune, or equivalently, as the minimum number\nof neurons ($m$) needed to arbitrarily change $N$ labels among $K$ samples\nconsidered in the fine-tuning process. In essence, FTC extends the memorization\ncapacity concept to the fine-tuning scenario. We analyze FTC for the additive\nfine-tuning scenario where the fine-tuned network is defined as the summation\nof the frozen pre-trained network $f$ and a neural network $g$ (with $m$\nneurons) designed for fine-tuning. When $g$ is a ReLU network with either 2 or\n3 layers, we obtain tight upper and lower bounds on FTC; we show that $N$\nsamples can be fine-tuned with $m=\\Theta(N)$ neurons for 2-layer networks, and\nwith $m=\\Theta(\\sqrt{N})$ neurons for 3-layer networks, no matter how large $K$\nis. Our results recover the known memorization capacity results when $N = K$ as\na special case.\n","authors":["Jy-yong Sohn","Dohyun Kwon","Seoyeon An","Kangwook Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00359v1.pdf","comment":"10 pages, 9 figures, UAI 2024"},{"id":"http://arxiv.org/abs/2408.00329v1","updated":"2024-08-01T07:04:18Z","published":"2024-08-01T07:04:18Z","title":"OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial\n  Attack","summary":"  Deep neural networks (DNNs) are vulnerable to small adversarial perturbations\nof the inputs, posing a significant challenge to their reliability and\nrobustness. Empirical methods such as adversarial training can defend against\nparticular attacks but remain vulnerable to more powerful attacks.\nAlternatively, Lipschitz networks provide certified robustness to unseen\nperturbations but lack sufficient expressive power. To harness the advantages\nof both approaches, we design a novel two-step Optimal Transport induced\nAdversarial Defense (OTAD) model that can fit the training data accurately\nwhile preserving the local Lipschitz continuity. First, we train a DNN with a\nregularizer derived from optimal transport theory, yielding a discrete optimal\ntransport map linking data to its features. By leveraging the map's inherent\nregularity, we interpolate the map by solving the convex integration problem\n(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse\narchitectures of ResNet and Transformer, making it suitable for complex data.\nFor efficient computation, the CIP can be solved through training neural\nnetworks. OTAD opens a novel avenue for developing reliable and secure deep\nlearning systems through the regularity of optimal transport maps. Empirical\nresults demonstrate that OTAD can outperform other robust models on diverse\ndatasets.\n","authors":["Kuo Gai","Sicong Wang","Shihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00329v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.00237v1","updated":"2024-08-01T02:13:11Z","published":"2024-08-01T02:13:11Z","title":"Empirical Bayes Linked Matrix Decomposition","summary":"  Data for several applications in diverse fields can be represented as\nmultiple matrices that are linked across rows or columns. This is particularly\ncommon in molecular biomedical research, in which multiple molecular \"omics\"\ntechnologies may capture different feature sets (e.g., corresponding to rows in\na matrix) and/or different sample populations (corresponding to columns). This\nhas motivated a large body of work on integrative matrix factorization\napproaches that identify and decompose low-dimensional signal that is shared\nacross multiple matrices or specific to a given matrix. We propose an empirical\nvariational Bayesian approach to this problem that has several advantages over\nexisting techniques, including the flexibility to accommodate shared signal\nover any number of row or column sets (i.e., bidimensional integration), an\nintuitive model-based objective function that yields appropriate shrinkage for\nthe inferred signals, and a relatively efficient estimation algorithm with no\ntuning parameters. A general result establishes conditions for the uniqueness\nof the underlying decomposition for a broad family of methods that includes the\nproposed approach. For scenarios with missing data, we describe an associated\niterative imputation approach that is novel for the single-matrix context and a\npowerful approach for \"blockwise\" imputation (in which an entire row or column\nis missing) in various linked matrix contexts. Extensive simulations show that\nthe method performs very well under different scenarios with respect to\nrecovering underlying low-rank signal, accurately decomposing shared and\nspecific signals, and accurately imputing missing data. The approach is applied\nto gene expression and miRNA data from breast cancer tissue and normal breast\ntissue, for which it gives an informative decomposition of variation and\noutperforms alternative strategies for missing data imputation.\n","authors":["Eric F. Lock"],"pdf_url":"https://arxiv.org/pdf/2408.00237v1.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.00206v1","updated":"2024-08-01T00:19:36Z","published":"2024-08-01T00:19:36Z","title":"Gaussian Processes Sampling with Sparse Grids under Additive Schwarz\n  Preconditioner","summary":"  Gaussian processes (GPs) are widely used in non-parametric Bayesian modeling,\nand play an important role in various statistical and machine learning\napplications. In a variety tasks of uncertainty quantification, generating\nrandom sample paths of GPs is of interest. As GP sampling requires generating\nhigh-dimensional Gaussian random vectors, it is computationally challenging if\na direct method, such as the Cholesky decomposition, is used. In this paper, we\npropose a scalable algorithm for sampling random realizations of the prior and\nposterior of GP models. The proposed algorithm leverages inducing points\napproximation with sparse grids, as well as additive Schwarz preconditioners,\nwhich reduce computational complexity, and ensure fast convergence. We\ndemonstrate the efficacy and accuracy of the proposed method through a series\nof experiments and comparisons with other recent works.\n","authors":["Haoyuan Chen","Rui Tuo"],"pdf_url":"https://arxiv.org/pdf/2408.00206v1.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2408.00955v1","updated":"2024-08-01T23:32:14Z","published":"2024-08-01T23:32:14Z","title":"Aggregation Models with Optimal Weights for Distributed Gaussian\n  Processes","summary":"  Gaussian process (GP) models have received increasingly attentions in recent\nyears due to their superb prediction accuracy and modeling flexibility. To\naddress the computational burdens of GP models for large-scale datasets,\ndistributed learning for GPs are often adopted. Current aggregation models for\ndistributed GPs are not time-efficient when incorporating correlations between\nGP experts. In this work, we propose a novel approach for aggregated prediction\nin distributed GPs. The technique is suitable for both the exact and sparse\nvariational GPs. The proposed method incorporates correlations among experts,\nleading to better prediction accuracy with manageable computational\nrequirements. As demonstrated by empirical studies, the proposed approach\nresults in more stable predictions in less time than state-of-the-art\nconsistent aggregation models.\n","authors":["Haoyuan Chen","Rui Tuo"],"pdf_url":"https://arxiv.org/pdf/2408.00955v1.pdf","comment":"25 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.19092v2","updated":"2024-08-01T23:12:50Z","published":"2024-07-26T21:18:26Z","title":"Boosted generalized normal distributions: Integrating machine learning\n  with operations knowledge","summary":"  Applications of machine learning (ML) techniques to operational settings\noften face two challenges: i) ML methods mostly provide point predictions\nwhereas many operational problems require distributional information; and ii)\nThey typically do not incorporate the extensive body of knowledge in the\noperations literature, particularly the theoretical and empirical findings that\ncharacterize specific distributions. We introduce a novel and rigorous\nmethodology, the Boosted Generalized Normal Distribution ($b$GND), to address\nthese challenges. The Generalized Normal Distribution (GND) encompasses a wide\nrange of parametric distributions commonly encountered in operations, and\n$b$GND leverages gradient boosting with tree learners to flexibly estimate the\nparameters of the GND as functions of covariates. We establish $b$GND's\nstatistical consistency, thereby extending this key property to special cases\nstudied in the ML literature that lacked such guarantees. Using data from a\nlarge academic emergency department in the United States, we show that the\ndistributional forecasting of patient wait and service times can be\nmeaningfully improved by leveraging findings from the healthcare operations\nliterature. Specifically, $b$GND performs 6% and 9% better than the\ndistribution-agnostic ML benchmark used to forecast wait and service times\nrespectively. Further analysis suggests that these improvements translate into\na 9% increase in patient satisfaction and a 4% reduction in mortality for\nmyocardial infarction patients. Our work underscores the importance of\nintegrating ML with operations knowledge to enhance distributional forecasts.\n","authors":["Ragip Gurlek","Francis de Vericourt","Donald K. K. Lee"],"pdf_url":"https://arxiv.org/pdf/2407.19092v2.pdf","comment":"28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.00949v1","updated":"2024-08-01T23:08:37Z","published":"2024-08-01T23:08:37Z","title":"Equivariant neural networks and piecewise linear representation theory","summary":"  Equivariant neural networks are neural networks with symmetry. Motivated by\nthe theory of group representations, we decompose the layers of an equivariant\nneural network into simple representations. The nonlinear activation functions\nlead to interesting nonlinear equivariant maps between simple representations.\nFor example, the rectified linear unit (ReLU) gives rise to piecewise linear\nmaps. We show that these considerations lead to a filtration of equivariant\nneural networks, generalizing Fourier series. This observation might provide a\nuseful tool for interpreting equivariant neural networks.\n","authors":["Joel Gibson","Daniel Tubbenhauer","Geordie Williamson"],"pdf_url":"https://arxiv.org/pdf/2408.00949v1.pdf","comment":"24 pages, many figures, comments welcome"},{"id":"http://arxiv.org/abs/2408.00946v1","updated":"2024-08-01T22:55:40Z","published":"2024-08-01T22:55:40Z","title":"Generalisation of Total Uncertainty in AI: A Theoretical Study","summary":"  AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.\n","authors":["Keivan Shariatmadar"],"pdf_url":"https://arxiv.org/pdf/2408.00946v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2407.00730v2","updated":"2024-08-01T21:39:05Z","published":"2024-06-30T15:38:38Z","title":"D-CDLF: Decomposition of Common and Distinctive Latent Factors for\n  Multi-view High-dimensional Data","summary":"  A typical approach to the joint analysis of multiple high-dimensional data\nviews is to decompose each view's data matrix into three parts: a low-rank\ncommon-source matrix generated by common latent factors of all data views, a\nlow-rank distinctive-source matrix generated by distinctive latent factors of\nthe corresponding data view, and an additive noise matrix. Existing\ndecomposition methods often focus on the uncorrelatedness between the common\nlatent factors and distinctive latent factors, but inadequately address the\nequally necessary uncorrelatedness between distinctive latent factors from\ndifferent data views. We propose a novel decomposition method, called\nDecomposition of Common and Distinctive Latent Factors (D-CDLF), to effectively\nachieve both types of uncorrelatedness for two-view data. We also discuss the\nestimation of the D-CDLF under high-dimensional settings.\n","authors":["Hai Shu"],"pdf_url":"https://arxiv.org/pdf/2407.00730v2.pdf","comment":"This revision updates only Paragraph 1 of Section 2.1 and Remark 2 of\n  Section 3.2 from version 1"},{"id":"http://arxiv.org/abs/2408.00920v1","updated":"2024-08-01T21:22:10Z","published":"2024-08-01T21:22:10Z","title":"Towards Certified Unlearning for Deep Neural Networks","summary":"  In the field of machine unlearning, certified unlearning has been extensively\nstudied in convex machine learning models due to its high efficiency and strong\ntheoretical guarantees. However, its application to deep neural networks\n(DNNs), known for their highly nonconvex nature, still poses challenges. To\nbridge the gap between certified unlearning and DNNs, we propose several simple\ntechniques to extend certified unlearning methods to nonconvex objectives. To\nreduce the time complexity, we develop an efficient computation method by\ninverse Hessian approximation without compromising certification guarantees. In\naddition, we extend our discussion of certification to nonconvergence training\nand sequential unlearning, considering that real-world users can send\nunlearning requests at different time points. Extensive experiments on three\nreal-world datasets demonstrate the efficacy of our method and the advantages\nof certified unlearning in DNNs.\n","authors":["Binchi Zhang","Yushun Dong","Tianhao Wang","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2408.00920v1.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2408.00911v1","updated":"2024-08-01T21:04:27Z","published":"2024-08-01T21:04:27Z","title":"Distance-Preserving Generative Modeling of Spatial Transcriptomics","summary":"  Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.\n","authors":["Wenbin Zhou","Jin-Hong Du"],"pdf_url":"https://arxiv.org/pdf/2408.00911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10886v2","updated":"2024-08-01T20:34:18Z","published":"2024-07-15T16:37:55Z","title":"SLIP: Securing LLMs IP Using Weights Decomposition","summary":"  Large language models (LLMs) have recently seen widespread adoption, in both\nacademia and industry. As these models grow, they become valuable intellectual\nproperty (IP), reflecting enormous investments by their owners. Moreover, the\nhigh cost of cloud-based deployment has driven interest towards deployment to\nedge devices, yet this risks exposing valuable parameters to theft and\nunauthorized use. Current methods to protect models' IP on the edge have\nlimitations in terms of practicality, loss in accuracy, or suitability to\nrequirements. In this paper, we introduce a novel hybrid inference algorithm,\nnamed SLIP, designed to protect edge-deployed models from theft. SLIP is the\nfirst hybrid protocol that is both practical for real-world applications and\nprovably secure, while having zero accuracy degradation and minimal impact on\nlatency. It involves partitioning the model between two computing resources,\none secure but expensive, and another cost-effective but vulnerable. This is\nachieved through matrix decomposition, ensuring that the secure resource\nretains a maximally sensitive portion of the model's IP while performing a\nminimal amount of computations, and vice versa for the vulnerable resource.\nImportantly, the protocol includes security guarantees that prevent attackers\nfrom exploiting the partition to infer the secured information. Finally, we\npresent experimental results that show the robustness and effectiveness of our\nmethod, positioning it as a compelling solution for protecting LLMs.\n","authors":["Yehonathan Refael","Adam Hakim","Lev Greenberg","Tal Aviv","Satya Lokam","Ben Fishman","Shachar Seidman"],"pdf_url":"https://arxiv.org/pdf/2407.10886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00856v1","updated":"2024-08-01T18:10:05Z","published":"2024-08-01T18:10:05Z","title":"Deep Learning Approach for Changepoint Detection: Penalty Parameter\n  Optimization","summary":"  Changepoint detection, a technique for identifying significant shifts within\ndata sequences, is crucial in various fields such as finance, genomics,\nmedicine, etc. Dynamic programming changepoint detection algorithms are\nemployed to identify the locations of changepoints within a sequence, which\nrely on a penalty parameter to regulate the number of changepoints. To estimate\nthis penalty parameter, previous work uses simple models such as linear models\nor decision trees. This study introduces a novel deep learning method for\npredicting penalty parameters, leading to demonstrably improved changepoint\ndetection accuracy on large benchmark supervised labeled datasets compared to\nprevious methods.\n","authors":["Tung L Nguyen","Toby Dylan Hocking"],"pdf_url":"https://arxiv.org/pdf/2408.00856v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.02684v1","updated":"2024-08-01T04:21:14Z","published":"2024-08-01T04:21:14Z","title":"Open Set Recognition for Random Forest","summary":"  In many real-world classification or recognition tasks, it is often difficult\nto collect training examples that exhaust all possible classes due to, for\nexample, incomplete knowledge during training or ever changing regimes.\nTherefore, samples from unknown/novel classes may be encountered in\ntesting/deployment. In such scenarios, the classifiers should be able to i)\nperform classification on known classes, and at the same time, ii) identify\nsamples from unknown classes. This is known as open-set recognition. Although\nrandom forest has been an extremely successful framework as a general-purpose\nclassification (and regression) method, in practice, it usually operates under\nthe closed-set assumption and is not able to identify samples from new classes\nwhen run out of the box. In this work, we propose a novel approach to enabling\nopen-set recognition capability for random forest classifiers by incorporating\ndistance metric learning and distance-based open-set recognition. The proposed\nmethod is validated on both synthetic and real-world datasets. The experimental\nresults indicate that the proposed approach outperforms state-of-the-art\ndistance-based open-set recognition methods.\n","authors":["Guanchao Feng","Dhruv Desai","Stefano Pasquali","Dhagash Mehta"],"pdf_url":"https://arxiv.org/pdf/2408.02684v1.pdf","comment":null}]},"2024-08-02T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.01417v1","updated":"2024-08-02T17:51:57Z","published":"2024-08-02T17:51:57Z","title":"Talk Less, Interact Better: Evaluating In-context Conversational\n  Adaptation in Multimodal LLMs","summary":"  Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.\n","authors":["Yilun Hua","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2408.01417v1.pdf","comment":"Accepted to COLM 2024"},{"id":"http://arxiv.org/abs/2408.01384v1","updated":"2024-08-02T16:41:34Z","published":"2024-08-02T16:41:34Z","title":"NOLO: Navigate Only Look Once","summary":"  The in-context learning ability of Transformer models has brought new\npossibilities to visual navigation. In this paper, we focus on the video\nnavigation setting, where an in-context navigation policy needs to be learned\npurely from videos in an offline manner, without access to the actual\nenvironment. For this setting, we propose Navigate Only Look Once (NOLO), a\nmethod for learning a navigation policy that possesses the in-context ability\nand adapts to new scenes by taking corresponding context videos as input\nwithout finetuning or re-training. To enable learning from videos, we first\npropose a pseudo action labeling procedure using optical flow to recover the\naction label from egocentric videos. Then, offline reinforcement learning is\napplied to learn the navigation policy. Through extensive experiments on\ndifferent scenes, we show that our algorithm outperforms baselines by a large\nmargin, which demonstrates the in-context learning ability of the learned\npolicy.\n","authors":["Bohan Zhou","Jiangxing Wang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2408.01384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11652v3","updated":"2024-08-02T16:30:55Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v3.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2408.01372v1","updated":"2024-08-02T16:28:51Z","published":"2024-08-02T16:28:51Z","title":"Spatial-Spectral Morphological Mamba for Hyperspectral Image\n  Classification","summary":"  In recent years, Transformers have garnered significant attention for\nHyperspectral Image Classification (HSIC) due to their self-attention\nmechanism, which provides strong classification performance. However, these\nmodels face major challenges in computational efficiency, as their complexity\nincreases quadratically with the sequence length. The Mamba architecture,\nleveraging a State Space Model, offers a more efficient alternative to\nTransformers. This paper introduces the Spatial-Spectral Morphological Mamba\n(MorpMamba) model. In the MorpMamba model, a token generation module first\nconverts the Hyperspectral Image (HSI) patch into spatial-spectral tokens.\nThese tokens are then processed by a morphology block, which computes\nstructural and shape information using depthwise separable convolutional\noperations. The extracted information is enhanced in a feature enhancement\nmodule that adjusts the spatial and spectral tokens based on the center region\nof the HSI sample, allowing for effective information fusion within each block.\nSubsequently, the tokens are refined in a multi-head self-attention block to\nfurther improve the feature space. Finally, the combined information is fed\ninto the state space block for classification and the creation of the ground\ntruth map. Experiments on widely used Hyperspectral (HS) datasets demonstrate\nthat the MorpMamba model outperforms (parametric efficiency) both CNN and\nTransformer models.\n","authors":["Muhammad Ahmad","Muhammad Hassaan Farooq Butt","Muhammad Usama","Adil Mehmood Khan","Manual Mazzara","Salvatore Distenano"],"pdf_url":"https://arxiv.org/pdf/2408.01372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01370v1","updated":"2024-08-02T16:24:55Z","published":"2024-08-02T16:24:55Z","title":"EVIT: Event-based Visual-Inertial Tracking in Semi-Dense Maps Using\n  Windowed Nonlinear Optimization","summary":"  Event cameras are an interesting visual exteroceptive sensor that reacts to\nbrightness changes rather than integrating absolute image intensities. Owing to\nthis design, the sensor exhibits strong performance in situations of\nchallenging dynamics and illumination conditions. While event-based\nsimultaneous tracking and mapping remains a challenging problem, a number of\nrecent works have pointed out the sensor's suitability for prior map-based\ntracking. By making use of cross-modal registration paradigms, the camera's\nego-motion can be tracked across a large spectrum of illumination and dynamics\nconditions on top of accurate maps that have been created a priori by more\ntraditional sensors. The present paper follows up on a recently introduced\nevent-based geometric semi-dense tracking paradigm, and proposes the addition\nof inertial signals in order to robustify the estimation. More specifically,\nthe added signals provide strong cues for pose initialization as well as\nregularization during windowed, multi-frame tracking. As a result, the proposed\nframework achieves increased performance under challenging illumination\nconditions as well as a reduction of the rate at which intermediate event\nrepresentations need to be registered in order to maintain stable tracking\nacross highly dynamic sequences. Our evaluation focuses on a diverse set of\nreal world sequences and comprises a comparison of our proposed method against\na purely event-based alternative running at different rates.\n","authors":["Runze Yuan","Tao Liu","Zijia Dai","Yi-Fan Zuo","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2408.01370v1.pdf","comment":"8 pages, 5 figures, 3 tables, International Conference on Intelligent\n  Robots and Systems 2024"},{"id":"http://arxiv.org/abs/2408.01366v1","updated":"2024-08-02T16:20:56Z","published":"2024-08-02T16:20:56Z","title":"Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic\n  Manipulation","summary":"  Humans possess a remarkable talent for flexibly alternating to different\nsenses when interacting with the environment. Picture a chef skillfully gauging\nthe timing of ingredient additions and controlling the heat according to the\ncolors, sounds, and aromas, seamlessly navigating through every stage of the\ncomplex cooking process. This ability is founded upon a thorough comprehension\nof task stages, as achieving the sub-goal within each stage can necessitate the\nutilization of different senses. In order to endow robots with similar ability,\nwe incorporate the task stages divided by sub-goals into the imitation learning\nprocess to accordingly guide dynamic multi-sensory fusion. We propose MS-Bot, a\nstage-guided dynamic multi-sensory fusion method with coarse-to-fine stage\nunderstanding, which dynamically adjusts the priority of modalities based on\nthe fine-grained state within the predicted current stage. We train a robot\nsystem equipped with visual, auditory, and tactile sensors to accomplish\nchallenging robotic manipulation tasks: pouring and peg insertion with keyway.\nExperimental results indicate that our approach enables more effective and\nexplainable dynamic fusion, aligning more closely with the human fusion process\nthan existing methods.\n","authors":["Ruoxuan Feng","Di Hu","Wenke Ma","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.01366v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17804v3","updated":"2024-08-02T16:17:35Z","published":"2023-11-29T16:54:25Z","title":"The Importance of Downstream Networks in Digital Pathology Foundation\n  Models","summary":"  Digital pathology has significantly advanced disease detection and\npathologist efficiency through the analysis of gigapixel whole-slide images\n(WSI). In this process, WSIs are first divided into patches, for which a\nfeature extractor model is applied to obtain feature vectors, which are\nsubsequently processed by an aggregation model to predict the respective WSI\nlabel. With the rapid evolution of representation learning, numerous new\nfeature extractor models, often termed foundational models, have emerged.\nTraditional evaluation methods rely on a static downstream aggregation model\nsetup, encompassing a fixed architecture and hyperparameters, a practice we\nidentify as potentially biasing the results. Our study uncovers a sensitivity\nof feature extractor models towards aggregation model configurations,\nindicating that performance comparability can be skewed based on the chosen\nconfigurations. By accounting for this sensitivity, we find that the\nperformance of many current feature extractor models is notably similar. We\nsupport this insight by evaluating seven feature extractor models across three\ndifferent datasets with 162 different aggregation model configurations. This\ncomprehensive approach provides a more nuanced understanding of the feature\nextractors' sensitivity to various aggregation model configurations, leading to\na fairer and more accurate assessment of new foundation models in digital\npathology.\n","authors":["Gustav Bredell","Marcel Fischer","Przemyslaw Szostak","Samaneh Abbasi-Sureshjani","Alvaro Gomariz"],"pdf_url":"https://arxiv.org/pdf/2311.17804v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01363v1","updated":"2024-08-02T16:15:25Z","published":"2024-08-02T16:15:25Z","title":"Toward Automatic Relevance Judgment using Vision--Language Models for\n  Image--Text Retrieval Evaluation","summary":"  Vision--Language Models (VLMs) have demonstrated success across diverse\napplications, yet their potential to assist in relevance judgments remains\nuncertain. This paper assesses the relevance estimation capabilities of VLMs,\nincluding CLIP, LLaVA, and GPT-4V, within a large-scale \\textit{ad hoc}\nretrieval task tailored for multimedia content creation in a zero-shot fashion.\nPreliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,\nencompassing open-source and closed-source visual-instruction-tuned Large\nLanguage Models (LLMs), achieve notable Kendall's $\\tau \\sim 0.4$ when compared\nto human relevance judgments, surpassing the CLIPScore metric. (2) While\nCLIPScore is strongly preferred, LLMs are less biased towards CLIP-based\nretrieval systems. (3) GPT-4V's score distribution aligns more closely with\nhuman judgments than other models, achieving a Cohen's $\\kappa$ value of around\n0.08, which outperforms CLIPScore at approximately -0.096. These findings\nunderscore the potential of LLM-powered VLMs in enhancing relevance judgments.\n","authors":["Jheng-Hong Yang","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2408.01363v1.pdf","comment":"Accepted by ACM SIGIR 2024 LLM4Eval Workshop:\n  https://llm4eval.github.io/papers"},{"id":"http://arxiv.org/abs/2404.13534v3","updated":"2024-08-02T16:14:46Z","published":"2024-04-21T05:09:56Z","title":"Motion-aware Latent Diffusion Models for Video Frame Interpolation","summary":"  With the advancement of AIGC, video frame interpolation (VFI) has become a\ncrucial component in existing video generation frameworks, attracting\nwidespread research interest. For the VFI task, the motion estimation between\nneighboring frames plays a crucial role in avoiding motion ambiguity. However,\nexisting VFI methods always struggle to accurately predict the motion\ninformation between consecutive frames, and this imprecise estimation leads to\nblurred and visually incoherent interpolated frames. In this paper, we propose\na novel diffusion framework, motion-aware latent diffusion models (MADiff),\nwhich is specifically designed for the VFI task. By incorporating motion priors\nbetween the conditional neighboring frames with the target interpolated frame\npredicted throughout the diffusion sampling procedure, MADiff progressively\nrefines the intermediate outcomes, culminating in generating both visually\nsmooth and realistic results. Extensive experiments conducted on benchmark\ndatasets demonstrate that our method achieves state-of-the-art performance\nsignificantly outperforming existing approaches, especially under challenging\nscenarios involving dynamic textures with complex motion.\n","authors":["Zhilin Huang","Yijie Yu","Ling Yang","Chujun Qin","Bing Zheng","Xiawu Zheng","Zikun Zhou","Yaowei Wang","Wenming Yang"],"pdf_url":"https://arxiv.org/pdf/2404.13534v3.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.18849v2","updated":"2024-08-02T16:13:40Z","published":"2024-04-29T16:42:58Z","title":"MiPa: Mixed Patch Infrared-Visible Modality Agnostic Object Detection","summary":"  In real-world scenarios, using multiple modalities like visible (RGB) and\ninfrared (IR) can greatly improve the performance of a predictive task such as\nobject detection (OD). Multimodal learning is a common way to leverage these\nmodalities, where multiple modality-specific encoders and a fusion module are\nused to improve performance. In this paper, we tackle a different way to employ\nRGB and IR modalities, where only one modality or the other is observed by a\nsingle shared vision encoder. This realistic setting requires a lower memory\nfootprint and is more suitable for applications such as autonomous driving and\nsurveillance, which commonly rely on RGB and IR data. However, when learning a\nsingle encoder on multiple modalities, one modality can dominate the other,\nproducing uneven recognition results. This work investigates how to efficiently\nleverage RGB and IR modalities to train a common transformer-based OD vision\nencoder, while countering the effects of modality imbalance. For this, we\nintroduce a novel training technique to Mix Patches (MiPa) from the two\nmodalities, in conjunction with a patch-wise modality agnostic module, for\nlearning a common representation of both modalities. Our experiments show that\nMiPa can learn a representation to reach competitive results on traditional\nRGB/IR benchmarks while only requiring a single modality during inference. Our\ncode is available at: https://github.com/heitorrapela/MiPa.\n","authors":["Heitor R. Medeiros","David Latortue","Eric Granger","Marco Pedersoli"],"pdf_url":"https://arxiv.org/pdf/2404.18849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04551v2","updated":"2024-08-02T16:09:49Z","published":"2024-06-06T23:35:51Z","title":"Improving Geo-diversity of Generated Images with Contextualized Vendi\n  Score Guidance","summary":"  With the growing popularity of text-to-image generative models, there has\nbeen increasing focus on understanding their risks and biases. Recent work has\nfound that state-of-the-art models struggle to depict everyday objects with the\ntrue diversity of the real world and have notable gaps between geographic\nregions. In this work, we aim to increase the diversity of generated images of\ncommon objects such that per-region variations are representative of the real\nworld. We introduce an inference time intervention, contextualized Vendi Score\nGuidance (c-VSG), that guides the backwards steps of latent diffusion models to\nincrease the diversity of a sample as compared to a \"memory bank\" of previously\ngenerated images while constraining the amount of variation within that of an\nexemplar set of real-world contextualizing images. We evaluate c-VSG with two\ngeographically representative datasets and find that it substantially increases\nthe diversity of generated images, both for the worst performing regions and on\naverage, while simultaneously maintaining or improving image quality and\nconsistency. Additionally, qualitative analyses reveal that diversity of\ngenerated images is significantly improved, including along the lines of\nreductive region portrayals present in the original model. We hope that this\nwork is a step towards text-to-image generative models that reflect the true\ngeographic diversity of the world.\n","authors":["Reyhane Askari Hemmat","Melissa Hall","Alicia Sun","Candace Ross","Michal Drozdzal","Adriana Romero-Soriano"],"pdf_url":"https://arxiv.org/pdf/2406.04551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01356v1","updated":"2024-08-02T16:09:06Z","published":"2024-08-02T16:09:06Z","title":"Balanced Residual Distillation Learning for 3D Point Cloud\n  Class-Incremental Semantic Segmentation","summary":"  Class-incremental learning (CIL) thrives due to its success in processing the\ninflux of information by learning from continuously added new classes while\npreventing catastrophic forgetting about the old ones. It is essential for the\nperformance breakthrough of CIL to effectively refine past knowledge from the\nbase model and balance it with new learning. However, such an issue has not yet\nbeen considered in current research. In this work, we explore the potential of\nCIL from these perspectives and propose a novel balanced residual distillation\nframework (BRD-CIL) to push the performance bar of CIL to a new higher level.\nSpecifically, BRD-CIL designs a residual distillation learning strategy, which\ncan dynamically expand the network structure to capture the residuals between\nthe base and target models, effectively refining the past knowledge.\nFurthermore, BRD-CIL designs a balanced pseudo-label learning strategy by\ngenerating a guidance mask to reduce the preference for old classes, ensuring\nbalanced learning from new and old classes. We apply the proposed BRD-CIL to a\nchallenging 3D point cloud semantic segmentation task where the data are\nunordered and unstructured. Extensive experimental results demonstrate that\nBRD-CIL sets a new benchmark with an outstanding balance capability in\nclass-biased scenarios.\n","authors":["Yuanzhi Su","Siyuan Chen","Yuan-Gen Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01355v1","updated":"2024-08-02T16:07:15Z","published":"2024-08-02T16:07:15Z","title":"Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models\n  within Perturbed Inputs","summary":"  Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on various visual-language understanding and generation tasks.\nHowever, MLLMs occasionally generate content inconsistent with the given\nimages, which is known as \"hallucination\". Prior works primarily center on\nevaluating hallucination using standard, unperturbed benchmarks, which overlook\nthe prevalent occurrence of perturbed inputs in real-world scenarios-such as\nimage cropping or blurring-that are critical for a comprehensive assessment of\nMLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI,\nthe first benchmark designed to evaluate Hallucination in MLLMs within\nPerturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios,\ncontaining 1,260 perturbed images from 11 object types. Each image is\naccompanied by detailed annotations, which include fine-grained hallucination\ntypes, such as existence, attribute, and relation. We equip these annotations\nwith a rich set of questions, making Hallu-PI suitable for both discriminative\nand generative tasks. Extensive experiments on 12 mainstream MLLMs, such as\nGPT-4V and Gemini-Pro Vision, demonstrate that these models exhibit significant\nhallucinations on Hallu-PI, which is not observed in unperturbed scenarios.\nFurthermore, our research reveals a severe bias in MLLMs' ability to handle\ndifferent types of hallucinations. We also design two baselines specifically\nfor perturbed scenarios, namely Perturbed-Reminder and Perturbed-ICL. We hope\nthat our study will bring researchers' attention to the limitations of MLLMs\nwhen dealing with perturbed inputs, and spur further investigations to address\nthis issue. Our code and datasets are publicly available at\nhttps://github.com/NJUNLP/Hallu-PI.\n","authors":["Peng Ding","Jingyu Wu","Jun Kuang","Dan Ma","Xuezhi Cao","Xunliang Cai","Shi Chen","Jiajun Chen","Shujian Huang"],"pdf_url":"https://arxiv.org/pdf/2408.01355v1.pdf","comment":"Acccepted by ACM MM 2024, 14 pages, 11 figures, 9 tables"},{"id":"http://arxiv.org/abs/2408.01349v1","updated":"2024-08-02T15:54:49Z","published":"2024-08-02T15:54:49Z","title":"PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy\n  Correspondence Learning in Cross-Modal Retrieval","summary":"  In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.\n","authors":["Yue Duan","Zhangxuan Gu","Zhenzhe Ying","Lei Qi","Changhua Meng","Yinghuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.01349v1.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2304.11857v3","updated":"2024-08-02T15:43:33Z","published":"2023-04-24T07:12:50Z","title":"Accurate and Efficient Event-based Semantic Segmentation Using Adaptive\n  Spiking Encoder-Decoder Network","summary":"  Spiking neural networks (SNNs), known for their low-power, event-driven\ncomputation and intrinsic temporal dynamics, are emerging as promising\nsolutions for processing dynamic, asynchronous signals from event-based\nsensors. Despite their potential, SNNs face challenges in training and\narchitectural design, resulting in limited performance in challenging\nevent-based dense prediction tasks compared to artificial neural networks\n(ANNs). In this work, we develop an efficient spiking encoder-decoder network\n(SpikingEDN) for large-scale event-based semantic segmentation tasks. To\nenhance the learning efficiency from dynamic event streams, we harness the\nadaptive threshold which improves network accuracy, sparsity and robustness in\nstreaming inference. Moreover, we develop a dual-path Spiking\nSpatially-Adaptive Modulation module, which is specifically tailored to enhance\nthe representation of sparse events and multi-modal inputs, thereby\nconsiderably improving network performance. Our SpikingEDN attains a mean\nintersection over union (MIoU) of 72.57\\% on the DDD17 dataset and 58.32\\% on\nthe larger DSEC-Semantic dataset, showing competitive results to the\nstate-of-the-art ANNs while requiring substantially fewer computational\nresources. Our results shed light on the untapped potential of SNNs in\nevent-based vision applications. The source code will be made publicly\navailable.\n","authors":["Rui Zhang","Luziwei Leng","Kaiwei Che","Hu Zhang","Jie Cheng","Qinghai Guo","Jiangxing Liao","Ran Cheng"],"pdf_url":"https://arxiv.org/pdf/2304.11857v3.pdf","comment":"Accepted for publication in IEEE Transactions on Neural Networks and\n  Learning Systems"},{"id":"http://arxiv.org/abs/2408.01343v1","updated":"2024-08-02T15:41:16Z","published":"2024-08-02T15:41:16Z","title":"StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal\n  Semantic Segmentation","summary":"  Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.\n","authors":["Bingyu Li","Da Zhang","Zhiyuan Zhao","Junyu Gao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.01343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01334v1","updated":"2024-08-02T15:32:42Z","published":"2024-08-02T15:32:42Z","title":"A Backbone for Long-Horizon Robot Task Understanding","summary":"  End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot\ntask understanding and transferability. This framework uses therbligs (basic\naction elements) as the backbone to decompose high-level robot tasks into\nelemental robot configurations, which are then integrated with current\nfoundation models to improve task understanding. The approach consists of two\nstages: offline training and online testing. During the offline training stage,\nwe developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, the Large Language Model\n(LLM)-Alignment Policy for Visual Correction (LAP-VC) is employed to ensure\nprecise action execution, facilitating trajectory transfer in novel robot\nscenarios. Experimental results validate these methods, achieving 94.37% recall\nin therblig segmentation and success rates of 94.4% and 80% in real-world\nonline robot testing for simple and complex scenarios, respectively.\nSupplementary material is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home\n","authors":["Xiaoshuai Chen","Wei Chen","Dongmyoung Lee","Yukun Ge","Nicolas Rojas","Petar Kormushev"],"pdf_url":"https://arxiv.org/pdf/2408.01334v1.pdf","comment":"8 pages, 8 figures. This work is intended to be submitted to IEEE\n  Robotics and Automation Letters (RA-L) for possible publication"},{"id":"http://arxiv.org/abs/2404.12501v2","updated":"2024-08-02T15:28:19Z","published":"2024-04-18T20:43:33Z","title":"SPIdepth: Strengthened Pose Information for Self-supervised Monocular\n  Depth Estimation","summary":"  Self-supervised monocular depth estimation has garnered considerable\nattention for its applications in autonomous driving and robotics. While recent\nmethods have made strides in leveraging techniques like the Self Query Layer\n(SQL) to infer depth from motion, they often overlook the potential of\nstrengthening pose information. In this paper, we introduce SPIdepth, a novel\napproach that prioritizes enhancing the pose network for improved depth\nestimation. Building upon the foundation laid by SQL, SPIdepth emphasizes the\nimportance of pose information in capturing fine-grained scene structures. By\nenhancing the pose network's capabilities, SPIdepth achieves remarkable\nadvancements in scene understanding and depth estimation. Experimental results\non benchmark datasets such as KITTI, Cityscapes, and Make3D showcase SPIdepth's\nstate-of-the-art performance, surpassing previous methods by significant\nmargins. Specifically, SPIdepth tops the self-supervised KITTI benchmark.\nAdditionally, SPIdepth achieves the lowest AbsRel (0.029), SqRel (0.069), and\nRMSE (1.394) on KITTI, establishing new state-of-the-art results. On\nCityscapes, SPIdepth shows improvements over SQLdepth of 21.7% in AbsRel, 36.8%\nin SqRel, and 16.5% in RMSE, even without using motion masks. On Make3D,\nSPIdepth in zero-shot outperforms all other models. Remarkably, SPIdepth\nachieves these results using only a single image for inference, surpassing even\nmethods that utilize video sequences for inference, thus demonstrating its\nefficacy and efficiency in real-world applications. Our approach represents a\nsignificant leap forward in self-supervised monocular depth estimation,\nunderscoring the importance of strengthening pose information for advancing\nscene understanding in real-world applications.\n","authors":["Mykola Lavreniuk"],"pdf_url":"https://arxiv.org/pdf/2404.12501v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01322v1","updated":"2024-08-02T15:20:34Z","published":"2024-08-02T15:20:34Z","title":"A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty\n  and Semantic Object Cues for Gaze Guidance in Dynamic Scenes","summary":"  How we perceive objects around us depends on what we actively attend to, yet\nour eye movements depend on the perceived objects. Still, object segmentation\nand gaze behavior are typically treated as two independent processes. Drawing\non an information processing pattern from robotics, we present a mechanistic\nmodel that simulates these processes for dynamic real-world scenes. Our\nimage-computable model uses the current scene segmentation for object-based\nsaccadic decision-making while using the foveated object to refine its scene\nsegmentation recursively. To model this refinement, we use a Bayesian filter,\nwhich also provides an uncertainty estimate for the segmentation that we use to\nguide active scene exploration. We demonstrate that this model closely\nresembles observers' free viewing behavior, measured by scanpath statistics,\nincluding foveation duration and saccade amplitude distributions used for\nparameter fitting and higher-level statistics not used for fitting. These\ninclude how object detections, inspections, and returns are balanced and a\ndelay of returning saccades without an explicit implementation of such temporal\ninhibition of return. Extensive simulations and ablation studies show that\nuncertainty promotes balanced exploration and that semantic object cues are\ncrucial to form the perceptual units used in object-based attention. Moreover,\nwe show how our model's modular design allows for extensions, such as\nincorporating saccadic momentum or pre-saccadic attention, to further align its\noutput with human scanpaths.\n","authors":["Vito Mengers","Nicolas Roth","Oliver Brock","Klaus Obermayer","Martin Rolfs"],"pdf_url":"https://arxiv.org/pdf/2408.01322v1.pdf","comment":"35+16 pages, 8+4 figures"},{"id":"http://arxiv.org/abs/2406.07867v2","updated":"2024-08-02T15:05:47Z","published":"2024-06-12T04:48:36Z","title":"Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation","summary":"  In this paper, we introduce a novel Face-to-Face spoken dialogue model. It\nprocesses audio-visual speech from user input and generates audio-visual speech\nas the response, marking the initial step towards creating an avatar chatbot\nsystem without relying on intermediate text. To this end, we newly introduce\nMultiDialog, the first large-scale multimodal (i.e., audio and visual) spoken\ndialogue corpus containing 340 hours of approximately 9,000 dialogues, recorded\nbased on the open domain dialogue dataset, TopicalChat. The MultiDialog\ncontains parallel audio-visual recordings of conversation partners acting\naccording to the given script with emotion annotations, which we expect to open\nup research opportunities in multimodal synthesis. Our Face-to-Face spoken\ndialogue model incorporates a textually pretrained large language model and\nadapts it into the audio-visual spoken dialogue domain by incorporating\nspeech-text joint pretraining. Through extensive experiments, we validate the\neffectiveness of our model in facilitating a face-to-face conversation. Demo\nand data are available at https://multidialog.github.io and\nhttps://huggingface.co/datasets/IVLLab/MultiDialog, respectively.\n","authors":["Se Jin Park","Chae Won Kim","Hyeongseop Rha","Minsu Kim","Joanna Hong","Jeong Hun Yeo","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2406.07867v2.pdf","comment":"Accepted to ACL 2024 (Oral)"},{"id":"http://arxiv.org/abs/2408.01311v1","updated":"2024-08-02T15:01:29Z","published":"2024-08-02T15:01:29Z","title":"TopoNAS: Boosting Search Efficiency of Gradient-based NAS via\n  Topological Simplification","summary":"  Improving search efficiency serves as one of the crucial objectives of Neural\nArchitecture Search (NAS). However, many current approaches ignore the\nuniversality of the search strategy and fail to reduce the computational\nredundancy during the search process, especially in one-shot NAS architectures.\nBesides, current NAS methods show invalid reparameterization in non-linear\nsearch space, leading to poor efficiency in common search spaces like DARTS. In\nthis paper, we propose TopoNAS, a model-agnostic approach for gradient-based\none-shot NAS that significantly reduces searching time and memory usage by\ntopological simplification of searchable paths. Firstly, we model the\nnon-linearity in search spaces to reveal the parameterization difficulties. To\nimprove the search efficiency, we present a topological simplification method\nand iteratively apply module-sharing strategies to simplify the topological\nstructure of searchable paths. In addition, a kernel normalization technique is\nalso proposed to preserve the search accuracy. Experimental results on the\nNASBench201 benchmark with various search spaces demonstrate the effectiveness\nof our method. It proves the proposed TopoNAS enhances the performance of\nvarious architectures in terms of search efficiency while maintaining a high\nlevel of accuracy. The project page is available at\nhttps://xdedss.github.io/topo_simplification.\n","authors":["Danpei Zhao","Zhuoran Liu","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.01311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01293v1","updated":"2024-08-02T14:28:49Z","published":"2024-08-02T14:28:49Z","title":"Underwater Object Detection Enhancement via Channel Stabilization","summary":"  The complex marine environment exacerbates the challenges of object detection\nmanifold. Marine trash endangers the aquatic ecosystem, presenting a persistent\nchallenge. Accurate detection of marine deposits is crucial for mitigating this\nharm. Our work addresses underwater object detection by enhancing image quality\nand evaluating detection methods. We use Detectron2's backbone with various\nbase models and configurations for this task.\n  We propose a novel channel stabilization technique alongside a simplified\nimage enhancement model to reduce haze and color cast in training images,\nimproving multi-scale object detection. Following image processing, we test\ndifferent Detectron2 backbones for optimal detection accuracy. Additionally, we\napply a sharpening filter with augmentation techniques to highlight object\nprofiles for easier recognition.\n  Results are demonstrated on the TrashCan Dataset, both instance and material\nversions. The best-performing backbone method incorporates our channel\nstabilization and augmentation techniques. We also compare our Detectron2\ndetection results with the Deformable Transformer. In the instance version of\nTrashCan 1.0, our method achieves a 9.53% absolute increase in average\nprecision for small objects and a 7% absolute gain in bounding box detection\ncompared to the baseline. The code will be available on Code:\nhttps://github.com/aliman80/Underwater-\nObject-Detection-via-Channel-Stablization\n","authors":["Muhammad Ali","Salman Khan"],"pdf_url":"https://arxiv.org/pdf/2408.01293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01292v1","updated":"2024-08-02T14:28:10Z","published":"2024-08-02T14:28:10Z","title":"3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN\n  Networks","summary":"  Panoramic X-ray (PX) is a prevalent modality in dental practice for its wide\navailability and low cost. However, as a 2D projection image, PX does not\ncontain 3D anatomical information, and therefore has limited use in dental\napplications that can benefit from 3D information, e.g., tooth angular\nmisa-lignment detection and classification. Reconstructing 3D structures\ndirectly from 2D PX has recently been explored to address limitations with\nexisting methods primarily reliant on Convolutional Neural Networks (CNNs) for\ndirect 2D-to-3D mapping. These methods, however, are unable to correctly infer\ndepth-axis spatial information. In addition, they are limited by the in-trinsic\nlocality of convolution operations, as the convolution kernels only capture the\ninformation of immediate neighborhood pixels. In this study, we propose a\nprogressive hybrid Multilayer Perceptron (MLP)-CNN pyra-mid network (3DPX) for\n2D-to-3D oral PX reconstruction. We introduce a progressive reconstruction\nstrategy, where 3D images are progressively re-constructed in the 3DPX with\nguidance imposed on the intermediate recon-struction result at each pyramid\nlevel. Further, motivated by the recent ad-vancement of MLPs that show promise\nin capturing fine-grained long-range dependency, our 3DPX integrates MLPs and\nCNNs to improve the semantic understanding during reconstruction. Extensive\nexperiments on two large datasets involving 464 studies demonstrate that our\n3DPX outperforms state-of-the-art 2D-to-3D oral reconstruction methods,\nincluding standalone MLP and transformers, in reconstruction quality, and also\nim-proves the performance of downstream angular misalignment classification\ntasks.\n","authors":["Xiaoshuang Li","Mingyuan Meng","Zimo Huang","Lei Bi","Eduardo Delamare","Dagan Feng","Bin Sheng","Jinman Kim"],"pdf_url":"https://arxiv.org/pdf/2408.01292v1.pdf","comment":"accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2408.01291v1","updated":"2024-08-02T14:24:40Z","published":"2024-08-02T14:24:40Z","title":"TexGen: Text-Guided 3D Texture Generation with Multi-view Sampling and\n  Resampling","summary":"  Given a 3D mesh, we aim to synthesize 3D textures that correspond to\narbitrary textual descriptions. Current methods for generating and assembling\ntextures from sampled views often result in prominent seams or excessive\nsmoothing. To tackle these issues, we present TexGen, a novel multi-view\nsampling and resampling framework for texture generation leveraging a\npre-trained text-to-image diffusion model. For view consistent sampling, first\nof all we maintain a texture map in RGB space that is parameterized by the\ndenoising step and updated after each sampling step of the diffusion model to\nprogressively reduce the view discrepancy. An attention-guided multi-view\nsampling strategy is exploited to broadcast the appearance information across\nviews. To preserve texture details, we develop a noise resampling technique\nthat aids in the estimation of noise, generating inputs for subsequent\ndenoising steps, as directed by the text prompt and current texture map.\nThrough an extensive amount of qualitative and quantitative evaluations, we\ndemonstrate that our proposed method produces significantly better texture\nquality for diverse 3D objects with a high degree of view consistency and rich\nappearance details, outperforming current state-of-the-art methods.\nFurthermore, our proposed texture generation technique can also be applied to\ntexture editing while preserving the original identity. More experimental\nresults are available at https://dong-huo.github.io/TexGen/\n","authors":["Dong Huo","Zixin Guo","Xinxin Zuo","Zhihao Shi","Juwei Lu","Peng Dai","Songcen Xu","Li Cheng","Yee-Hong Yang"],"pdf_url":"https://arxiv.org/pdf/2408.01291v1.pdf","comment":"European Conference on Computer Vision (ECCV) 2024"},{"id":"http://arxiv.org/abs/2408.01287v1","updated":"2024-08-02T14:19:34Z","published":"2024-08-02T14:19:34Z","title":"Deep Learning based Visually Rich Document Content Understanding: A\n  Survey","summary":"  Visually Rich Documents (VRDs) are essential in academia, finance, medical\nfields, and marketing due to their multimodal information content. Traditional\nmethods for extracting information from VRDs depend on expert knowledge and\nmanual labor, making them costly and inefficient. The advent of deep learning\nhas revolutionized this process, introducing models that leverage multimodal\ninformation vision, text, and layout along with pretraining tasks to develop\ncomprehensive document representations. These models have achieved\nstate-of-the-art performance across various downstream tasks, significantly\nenhancing the efficiency and accuracy of information extraction from VRDs. In\nresponse to the growing demands and rapid developments in Visually Rich\nDocument Understanding (VRDU), this paper provides a comprehensive review of\ndeep learning-based VRDU frameworks. We systematically survey and analyze\nexisting methods and benchmark datasets, categorizing them based on adopted\nstrategies and downstream tasks. Furthermore, we compare different techniques\nused in VRDU models, focusing on feature representation and fusion, model\narchitecture, and pretraining methods, while highlighting their strengths,\nlimitations, and appropriate scenarios. Finally, we identify emerging trends\nand challenges in VRDU, offering insights into future research directions and\npractical applications. This survey aims to provide a thorough understanding of\nVRDU advancements, benefiting both academic and industrial sectors.\n","authors":["Yihao Ding","Jean Lee","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2408.01287v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2408.01284v1","updated":"2024-08-02T14:10:20Z","published":"2024-08-02T14:10:20Z","title":"Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot\n  Learning: A General Framework","summary":"  Generalized Zero-Shot Learning (GZSL) is a challenging task requiring\naccurate classification of both seen and unseen classes. Within this domain,\nAudio-visual GZSL emerges as an extremely exciting yet difficult task, given\nthe inclusion of both visual and acoustic features as multi-modal inputs.\nExisting efforts in this field mostly utilize either embedding-based or\ngenerative-based methods. However, generative training is difficult and\nunstable, while embedding-based methods often encounter domain shift problem.\nThus, we find it promising to integrate both methods into a unified framework\nto leverage their advantages while mitigating their respective disadvantages.\nOur study introduces a general framework employing out-of-distribution (OOD)\ndetection, aiming to harness the strengths of both approaches. We first employ\ngenerative adversarial networks to synthesize unseen features, enabling the\ntraining of an OOD detector alongside classifiers for seen and unseen classes.\nThis detector determines whether a test feature belongs to seen or unseen\nclasses, followed by classification utilizing separate classifiers for each\nfeature type. We test our framework on three popular audio-visual datasets and\nobserve a significant improvement comparing to existing state-of-the-art works.\nCodes can be found in https://github.com/liuyuan-wen/AV-OOD-GZSL.\n","authors":["Liuyuan Wen"],"pdf_url":"https://arxiv.org/pdf/2408.01284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01276v1","updated":"2024-08-02T14:01:34Z","published":"2024-08-02T14:01:34Z","title":"Wave-Mamba: Wavelet State Space Model for Ultra-High-Definition\n  Low-Light Image Enhancement","summary":"  Ultra-high-definition (UHD) technology has attracted widespread attention due\nto its exceptional visual quality, but it also poses new challenges for\nlow-light image enhancement (LLIE) techniques. UHD images inherently possess\nhigh computational complexity, leading existing UHD LLIE methods to employ\nhigh-magnification downsampling to reduce computational costs, which in turn\nresults in information loss. The wavelet transform not only allows downsampling\nwithout loss of information, but also separates the image content from the\nnoise. It enables state space models (SSMs) to avoid being affected by noise\nwhen modeling long sequences, thus making full use of the long-sequence\nmodeling capability of SSMs. On this basis, we propose Wave-Mamba, a novel\napproach based on two pivotal insights derived from the wavelet domain: 1) most\nof the content information of an image exists in the low-frequency component,\nless in the high-frequency component. 2) The high-frequency component exerts a\nminimal influence on the outcomes of low-light enhancement. Specifically, to\nefficiently model global content information on UHD images, we proposed a\nlow-frequency state space block (LFSSBlock) by improving SSMs to focus on\nrestoring the information of low-frequency sub-bands. Moreover, we propose a\nhigh-frequency enhance block (HFEBlock) for high-frequency sub-band\ninformation, which uses the enhanced low-frequency information to correct the\nhigh-frequency information and effectively restore the correct high-frequency\ndetails. Through comprehensive evaluation, our method has demonstrated superior\nperformance, significantly outshining current leading techniques while\nmaintaining a more streamlined architecture. The code is available at\nhttps://github.com/AlexZou14/Wave-Mamba.\n","authors":["Wenbin Zou","Hongxia Gao","Weipeng Yang","Tongtong Liu"],"pdf_url":"https://arxiv.org/pdf/2408.01276v1.pdf","comment":"10 pages, 8 figures, ACMMM2024 accepted"},{"id":"http://arxiv.org/abs/2408.01269v1","updated":"2024-08-02T13:46:15Z","published":"2024-08-02T13:46:15Z","title":"A General Framework to Boost 3D GS Initialization for Text-to-3D\n  Generation by Lexical Richness","summary":"  Text-to-3D content creation has recently received much attention, especially\nwith the prevalence of 3D Gaussians Splatting. In general, GS-based methods\ncomprise two key stages: initialization and rendering optimization. To achieve\ninitialization, existing works directly apply random sphere initialization or\n3D diffusion models, e.g., Point-E, to derive the initial shapes. However, such\nstrategies suffer from two critical yet challenging problems: 1) the final\nshapes are still similar to the initial ones even after training; 2) shapes can\nbe produced only from simple texts, e.g., \"a dog\", not for lexically richer\ntexts, e.g., \"a dog is sitting on the top of the airplane\". To address these\nproblems, this paper proposes a novel general framework to boost the 3D GS\nInitialization for text-to-3D generation upon the lexical richness. Our key\nidea is to aggregate 3D Gaussians into spatially uniform voxels to represent\ncomplex shapes while enabling the spatial interaction among the 3D Gaussians\nand semantic interaction between Gaussians and texts. Specifically, we first\nconstruct a voxelized representation, where each voxel holds a 3D Gaussian with\nits position, scale, and rotation fixed while setting opacity as the sole\nfactor to determine a position's occupancy. We then design an initialization\nnetwork mainly consisting of two novel components: 1) Global Information\nPerception (GIP) block and 2) Gaussians-Text Fusion (GTF) block. Such a design\nenables each 3D Gaussian to assimilate the spatial information from other areas\nand semantic information from texts. Extensive experiments show the superiority\nof our framework of high-quality 3D GS initialization against the existing\nmethods, e.g., Shap-E, by taking lexically simple, medium, and hard texts.\nAlso, our framework can be seamlessly plugged into SoTA training frameworks,\ne.g., LucidDreamer, for semantically consistent text-to-3D generation.\n","authors":["Lutao Jiang","Hangyu Li","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09004v2","updated":"2024-08-02T13:27:09Z","published":"2023-11-15T14:46:20Z","title":"Incremental Object-Based Novelty Detection with Feedback Loop","summary":"  Object-based Novelty Detection (ND) aims to identify unknown objects that do\nnot belong to classes seen during training by an object detection model. The\ntask is particularly crucial in real-world applications, as it allows to avoid\npotentially harmful behaviours, e.g. as in the case of object detection models\nadopted in a self-driving car or in an autonomous robot. Traditional approaches\nto ND focus on one time offline post processing of the pretrained object\ndetection output, leaving no possibility to improve the model robustness after\ntraining and discarding the abundant amount of out-of-distribution data\nencountered during deployment. In this work, we propose a novel framework for\nobject-based ND, assuming that human feedback can be requested on the predicted\noutput and later incorporated to refine the ND model without negatively\naffecting the main object detection performance. This refinement operation is\nrepeated whenever new feedback is available. To tackle this new formulation of\nthe problem for object detection, we propose a lightweight ND module attached\non top of a pre-trained object detection model, which is incrementally updated\nthrough a feedback loop. We also propose a new benchmark to evaluate methods on\nthis new setting and test extensively our ND approach against baselines,\nshowing increased robustness and a successful incorporation of the received\nfeedback.\n","authors":["Simone Caldarella","Elisa Ricci","Rahaf Aljundi"],"pdf_url":"https://arxiv.org/pdf/2311.09004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09339v4","updated":"2024-08-02T13:13:47Z","published":"2022-07-19T15:49:35Z","title":"Vision Transformers: From Semantic Segmentation to Dense Prediction","summary":"  The emergence of vision transformers (ViTs) in image classification has\nshifted the methodologies for visual representation learning. In particular,\nViTs learn visual representation at full receptive field per layer across all\nthe image patches, in comparison to the increasing receptive fields of CNNs\nacross layers and other alternatives (e.g., large kernels and atrous\nconvolution). In this work, for the first time we explore the global context\nlearning potentials of ViTs for dense visual prediction (e.g., semantic\nsegmentation). Our motivation is that through learning global context at full\nreceptive field layer by layer, ViTs may capture stronger long-range dependency\ninformation, critical for dense prediction tasks. We first demonstrate that\nencoding an image as a sequence of patches, a vanilla ViT without local\nconvolution and resolution reduction can yield stronger visual representation\nfor semantic segmentation. For example, our model, termed as SEgmentation\nTRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the\ntest leaderboard on the day of submission) and performs competitively on\nCityscapes. However, the basic ViT architecture falls short in broader dense\nprediction applications, such as object detection and instance segmentation,\ndue to its lack of a pyramidal structure, high computational demand, and\ninsufficient local context. For tackling general dense visual prediction tasks\nin a cost-effective manner, we further formulate a family of Hierarchical\nLocal-Global (HLG) Transformers, characterized by local attention within\nwindows and global-attention across windows in a pyramidal architecture.\nExtensive experiments show that our methods achieve appealing performance on a\nvariety of dense prediction tasks (e.g., object detection and instance\nsegmentation and semantic segmentation) as well as image classification.\n","authors":["Li Zhang","Jiachen Lu","Sixiao Zheng","Xinxuan Zhao","Xiatian Zhu","Yanwei Fu","Tao Xiang","Jianfeng Feng","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2207.09339v4.pdf","comment":"Extended version of CVPR 2021 paper arXiv:2012.15840 Published on\n  International Journal of Computer Vision (2024)"},{"id":"http://arxiv.org/abs/2408.00374v2","updated":"2024-08-02T13:00:46Z","published":"2024-08-01T08:32:03Z","title":"Conformal Trajectory Prediction with Multi-View Data Integration in\n  Cooperative Driving","summary":"  Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\n\\url{https://github.com/xichennn/V2I_trajectory_prediction}.\n","authors":["Xi Chen","Rahul Bhadani","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2408.00374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01233v1","updated":"2024-08-02T12:48:36Z","published":"2024-08-02T12:48:36Z","title":"CLIP4Sketch: Enhancing Sketch to Mugshot Matching through Dataset\n  Augmentation using Diffusion Models","summary":"  Forensic sketch-to-mugshot matching is a challenging task in face\nrecognition, primarily hindered by the scarcity of annotated forensic sketches\nand the modality gap between sketches and photographs. To address this, we\npropose CLIP4Sketch, a novel approach that leverages diffusion models to\ngenerate a large and diverse set of sketch images, which helps in enhancing the\nperformance of face recognition systems in sketch-to-mugshot matching. Our\nmethod utilizes Denoising Diffusion Probabilistic Models (DDPMs) to generate\nsketches with explicit control over identity and style. We combine CLIP and\nAdaface embeddings of a reference mugshot, along with textual descriptions of\nstyle, as the conditions to the diffusion model. We demonstrate the efficacy of\nour approach by generating a comprehensive dataset of sketches corresponding to\nmugshots and training a face recognition model on our synthetic data. Our\nresults show significant improvements in sketch-to-mugshot matching accuracy\nover training on an existing, limited amount of real face sketch data,\nvalidating the potential of diffusion models in enhancing the performance of\nface recognition systems across modalities. We also compare our dataset with\ndatasets generated using GAN-based methods to show its superiority.\n","authors":["Kushal Kumar Jain","Steve Grosz","Anoop M. Namboodiri","Anil K. Jain"],"pdf_url":"https://arxiv.org/pdf/2408.01233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01231v1","updated":"2024-08-02T12:44:07Z","published":"2024-08-02T12:44:07Z","title":"WaveMamba: Spatial-Spectral Wavelet Mamba for Hyperspectral Image\n  Classification","summary":"  Hyperspectral Imaging (HSI) has proven to be a powerful tool for capturing\ndetailed spectral and spatial information across diverse applications. Despite\nthe advancements in Deep Learning (DL) and Transformer architectures for HSI\nClassification (HSIC), challenges such as computational efficiency and the need\nfor extensive labeled data persist. This paper introduces WaveMamba, a novel\napproach that integrates wavelet transformation with the Spatial-Spectral Mamba\narchitecture to enhance HSIC. WaveMamba captures both local texture patterns\nand global contextual relationships in an end-to-end trainable model. The\nWavelet-based enhanced features are then processed through the state-space\narchitecture to model spatial-spectral relationships and temporal dependencies.\nThe experimental results indicate that WaveMamba surpasses existing models,\nachieving an accuracy improvement of 4.5\\% on the University of Houston dataset\nand a 2.0\\% increase on the Pavia University dataset. These findings validate\nits effectiveness in addressing the complex data interactions inherent in HSIs.\n","authors":["Muhammad Ahmad","Muhammad Usama","Manual Mazzara"],"pdf_url":"https://arxiv.org/pdf/2408.01231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01228v1","updated":"2024-08-02T12:36:13Z","published":"2024-08-02T12:36:13Z","title":"The Phantom Menace: Unmasking Privacy Leakages in Vision-Language Models","summary":"  Vision-Language Models (VLMs) combine visual and textual understanding,\nrendering them well-suited for diverse tasks like generating image captions and\nanswering visual questions across various domains. However, these capabilities\nare built upon training on large amount of uncurated data crawled from the web.\nThe latter may include sensitive information that VLMs could memorize and leak,\nraising significant privacy concerns. In this paper, we assess whether these\nvulnerabilities exist, focusing on identity leakage. Our study leads to three\nkey findings: (i) VLMs leak identity information, even when the vision-language\nalignment and the fine-tuning use anonymized data; (ii) context has little\ninfluence on identity leakage; (iii) simple, widely used anonymization\ntechniques, like blurring, are not sufficient to address the problem. These\nfindings underscore the urgent need for robust privacy protection strategies\nwhen deploying VLMs. Ethical awareness and responsible development practices\nare essential to mitigate these risks.\n","authors":["Simone Caldarella","Massimiliano Mancini","Elisa Ricci","Rahaf Aljundi"],"pdf_url":"https://arxiv.org/pdf/2408.01228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01224v1","updated":"2024-08-02T12:27:15Z","published":"2024-08-02T12:27:15Z","title":"Multi-head Spatial-Spectral Mamba for Hyperspectral Image Classification","summary":"  Spatial-Spectral Mamba (SSM) improves computational efficiency and captures\nlong-range dependencies, addressing Transformer limitations. However,\ntraditional Mamba models overlook rich spectral information in HSIs and\nstruggle with high dimensionality and sequential data. To address these issues,\nwe propose the SSM with multi-head self-attention and token enhancement\n(MHSSMamba). This model integrates spectral and spatial information by\nenhancing spectral tokens and using multi-head attention to capture complex\nrelationships between spectral bands and spatial locations. It also manages\nlong-range dependencies and the sequential nature of HSI data, preserving\ncontextual information across spectral bands. MHSSMamba achieved remarkable\nclassification accuracies of 97.62\\% on Pavia University, 96.92\\% on the\nUniversity of Houston, 96.85\\% on Salinas, and 99.49\\% on Wuhan-longKou\ndatasets.\n","authors":["Muhammad Ahmad","Muhammad Hassaan Farooq Butt","Muhammad Usama","Hamad Ahmed Altuwaijri","Manual Mazzara","Salvatore Distenano"],"pdf_url":"https://arxiv.org/pdf/2408.01224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01218v1","updated":"2024-08-02T12:16:07Z","published":"2024-08-02T12:16:07Z","title":"S2TD-Face: Reconstruct a Detailed 3D Face with Controllable Texture from\n  a Single Sketch","summary":"  3D textured face reconstruction from sketches applicable in many scenarios\nsuch as animation, 3D avatars, artistic design, missing people search, etc., is\na highly promising but underdeveloped research topic. On the one hand, the\nstylistic diversity of sketches leads to existing sketch-to-3D-face methods\nonly being able to handle pose-limited and realistically shaded sketches. On\nthe other hand, texture plays a vital role in representing facial appearance,\nyet sketches lack this information, necessitating additional texture control in\nthe reconstruction process. This paper proposes a novel method for\nreconstructing controllable textured and detailed 3D faces from sketches, named\nS2TD-Face. S2TD-Face introduces a two-stage geometry reconstruction framework\nthat directly reconstructs detailed geometry from the input sketch. To keep\ngeometry consistent with the delicate strokes of the sketch, we propose a novel\nsketch-to-geometry loss that ensures the reconstruction accurately fits the\ninput features like dimples and wrinkles. Our training strategies do not rely\non hard-to-obtain 3D face scanning data or labor-intensive hand-drawn sketches.\nFurthermore, S2TD-Face introduces a texture control module utilizing text\nprompts to select the most suitable textures from a library and seamlessly\nintegrate them into the geometry, resulting in a 3D detailed face with\ncontrollable texture. S2TD-Face surpasses existing state-of-the-art methods in\nextensive quantitative and qualitative experiments. Our project is available at\nhttps://github.com/wang-zidu/S2TD-Face .\n","authors":["Zidu Wang","Xiangyu Zhu","Jiang Yu","Tianshuo Zhang","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2408.01218v1.pdf","comment":"ACM MM 2024"},{"id":"http://arxiv.org/abs/2408.01191v1","updated":"2024-08-02T11:18:32Z","published":"2024-08-02T11:18:32Z","title":"A Weakly Supervised and Globally Explainable Learning Framework for\n  Brain Tumor Segmentation","summary":"  Machine-based brain tumor segmentation can help doctors make better\ndiagnoses. However, the complex structure of brain tumors and expensive\npixel-level annotations present challenges for automatic tumor segmentation. In\nthis paper, we propose a counterfactual generation framework that not only\nachieves exceptional brain tumor segmentation performance without the need for\npixel-level annotations, but also provides explainability. Our framework\neffectively separates class-related features from class-unrelated features of\nthe samples, and generate new samples that preserve identity features while\naltering class attributes by embedding different class-related features. We\nperform topological data analysis on the extracted class-related features and\nobtain a globally explainable manifold, and for each abnormal sample to be\nsegmented, a meaningful normal sample could be effectively generated with the\nguidance of the rule-based paths designed within the manifold for comparison\nfor identifying the tumor regions. We evaluate our proposed method on two\ndatasets, which demonstrates superior performance of brain tumor segmentation.\nThe code is available at https://github.com/xrt11/tumor-segmentation.\n","authors":["Ruitao Xie","Limai Jiang","Xiaoxi He","Yi Pan","Yunpeng Cai"],"pdf_url":"https://arxiv.org/pdf/2408.01191v1.pdf","comment":"2024 IEEE International Conference on Multimedia and Expo"},{"id":"http://arxiv.org/abs/2408.01181v1","updated":"2024-08-02T11:03:22Z","published":"2024-08-02T11:03:22Z","title":"VAR-CLIP: Text-to-Image Generator with Visual Auto-Regressive Modeling","summary":"  VAR is a new generation paradigm that employs 'next-scale prediction' as\nopposed to 'next-token prediction'. This innovative transformation enables\nauto-regressive (AR) transformers to rapidly learn visual distributions and\nachieve robust generalization. However, the original VAR model is constrained\nto class-conditioned synthesis, relying solely on textual captions for\nguidance. In this paper, we introduce VAR-CLIP, a novel text-to-image model\nthat integrates Visual Auto-Regressive techniques with the capabilities of\nCLIP. The VAR-CLIP framework encodes captions into text embeddings, which are\nthen utilized as textual conditions for image generation. To facilitate\ntraining on extensive datasets, such as ImageNet, we have constructed a\nsubstantial image-text dataset leveraging BLIP2. Furthermore, we delve into the\nsignificance of word positioning within CLIP for the purpose of caption\nguidance. Extensive experiments confirm VAR-CLIP's proficiency in generating\nfantasy images with high fidelity, textual congruence, and aesthetic\nexcellence. Our project page are https://github.com/daixiangzi/VAR-CLIP\n","authors":["Qian Zhang","Xiangzi Dai","Ninghua Yang","Xiang An","Ziyong Feng","Xingyu Ren"],"pdf_url":"https://arxiv.org/pdf/2408.01181v1.pdf","comment":"total 10 pages, code:https://github.com/daixiangzi/VAR-CLIP"},{"id":"http://arxiv.org/abs/2407.19546v2","updated":"2024-08-02T10:53:37Z","published":"2024-07-28T17:38:21Z","title":"XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image\n  Pre-Training","summary":"  Vision-and-language pretraining (VLP) in the medical field utilizes\ncontrastive learning on image-text pairs to achieve effective transfer across\ntasks. Yet, current VLP approaches with the masked modelling strategy face two\nchallenges when applied to the medical domain. First, current models struggle\nto accurately reconstruct key pathological features due to the scarcity of\nmedical data. Second, most methods only adopt either paired image-text or\nimage-only data, failing to exploit the combination of both paired and unpaired\ndata. To this end, this paper proposes a XLIP (Masked modelling for medical\nLanguage-Image Pre-training) framework to enhance pathological learning and\nfeature learning via unpaired data. First, we introduce the attention-masked\nimage modelling (AttMIM) and entity-driven masked language modelling module\n(EntMLM), which learns to reconstruct pathological visual and textual tokens\nvia multi-modal feature interaction, thus improving medical-enhanced features.\nThe AttMIM module masks a portion of the image features that are highly\nresponsive to textual features. This allows XLIP to improve the reconstruction\nof highly similar image data in medicine efficiency. Second, our XLIP\ncapitalizes unpaired data to enhance multimodal learning by introducing\ndisease-kind prompts. The experimental results show that XLIP achieves SOTA for\nzero-shot and fine-tuning classification performance on five datasets. Our code\nwill be available at https://github.com/White65534/XLIP\n","authors":["Biao Wu","Yutong Xie","Zeyu Zhang","Minh Hieu Phan","Qi Chen","Ling Chen","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2407.19546v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01167v1","updated":"2024-08-02T10:34:23Z","published":"2024-08-02T10:34:23Z","title":"Rethinking Pre-trained Feature Extractor Selection in Multiple Instance\n  Learning for Whole Slide Image Classification","summary":"  Multiple instance learning (MIL) has become a preferred method for\nclassifying gigapixel whole slide images (WSIs), without requiring patch label\nannotation. The focus of the current MIL research stream is on the\nembedding-based MIL approach, which involves extracting feature vectors from\npatches using a pre-trained feature extractor. These feature vectors are then\nfed into an MIL aggregator for slide-level prediction. Despite prior research\nsuggestions on enhancing the most commonly used ResNet50 supervised model\npre-trained on ImageNet-1K, there remains a lack of clear guidance on selecting\nthe optimal feature extractor to maximize WSI performance. This study aims at\naddressing this gap by examining MIL feature extractors across three\ndimensions: pre-training dataset, backbone model, and pre-training method.\nExtensive experiments were carried out on the two public WSI datasets\n(TCGA-NSCLC and Camelyon16) using four SOTA MIL models. The main findings\nindicate the following: 1) Performance significantly improves with larger and\nmore varied pre-training datasets in both CNN and Transformer backbones. 2)\n`Modern and deeper' backbones greatly outperform `standard' backbones (ResNet\nand ViT), with performance improvements more guaranteed in Transformer-based\nbackbones. 3) The choice of self-supervised learning (SSL) method is crucial,\nwith the most significant benefits observed when applied to the Transformer\n(ViT) backbone. The study findings have practical implications, including\ndesigning more effective pathological foundation models. Our code is available\nat: https://anonymous.4open.science/r/MIL-Feature-Extractor-Selection\n","authors":["Bryan Wong","Mun Yong Yi"],"pdf_url":"https://arxiv.org/pdf/2408.01167v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2408.01162v1","updated":"2024-08-02T10:24:35Z","published":"2024-08-02T10:24:35Z","title":"PreMix: Boosting Multiple Instance Learning in Digital Histopathology\n  through Pre-training with Intra-Batch Slide Mixing","summary":"  The classification of gigapixel-sized whole slide images (WSIs), digital\nrepresentations of histological slides obtained via a high-resolution scanner,\nfaces significant challenges associated with the meticulous and time-consuming\nnature of fine-grained labeling. While weakly-supervised multiple instance\nlearning (MIL) has emerged as a promising approach, current MIL methods are\nconstrained by their limited ability to leverage the wealth of information\nembedded within unlabeled WSIs. This limitation often necessitates training MIL\nfeature aggregators from scratch after the feature extraction process,\nhindering efficiency and accuracy. PreMix extends the general MIL framework by\npre-training the MIL aggregator with an intra-batch slide mixing approach.\nSpecifically, PreMix incorporates Barlow Twins Slide Mixing during\npre-training, enhancing its ability to handle diverse WSI sizes and maximizing\nthe utility of unlabeled WSIs. Combined with Mixup and Manifold Mixup during\nfine-tuning, PreMix achieves a mean of 4.7% performance improvement over the\nbaseline MIL framework, the hierarchical image pyramid transformer (HIPT), on\nthe Camelyon16 dataset. The observed improvement across a range of active\nlearning acquisition functions and WSI-labeled training budgets highlights the\nframework's adaptability to diverse datasets and varying resource constraints.\nUltimately, PreMix paves the way for more efficient and accurate WSI\nclassification under limited WSI-labeled datasets, encouraging the broader\nadoption of unlabeled WSI data in histopathological research. The code is\navailable at https://anonymous.4open.science/r/PreMix\n","authors":["Bryan Wong","Mun Yong Yi"],"pdf_url":"https://arxiv.org/pdf/2408.01162v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2408.01159v1","updated":"2024-08-02T10:21:10Z","published":"2024-08-02T10:21:10Z","title":"Robust Curve Detection in Volumetric Medical Imaging via Attraction\n  Field","summary":"  Understanding body part geometry is crucial for precise medical diagnostics.\nCurves effectively describe anatomical structures and are widely used in\nmedical imaging applications related to cardiovascular, respiratory, and\nskeletal diseases. Traditional curve detection methods are often task-specific,\nrelying heavily on domain-specific features, limiting their broader\napplicability. This paper introduces a novel approach for detecting\nnon-branching curves, which does not require prior knowledge of the object's\norientation, shape, or position. Our method uses neural networks to predict (1)\nan attraction field, which offers subpixel accuracy, and (2) a closeness map,\nwhich limits the region of interest and essentially eliminates outliers far\nfrom the desired curve. We tested our curve detector on several clinically\nrelevant tasks with diverse morphologies and achieved impressive subpixel-level\naccuracy results that surpass existing methods, highlighting its versatility\nand robustness. Additionally, to support further advancements in this field, we\nprovide our private annotations of aortic centerlines and masks, which can\nserve as a benchmark for future research. The dataset can be found at\nhttps://github.com/neuro-ml/curve-detection.\n","authors":["Farukh Yaushev","Daria Nogina","Valentin Samokhin","Mariya Dugova","Ekaterina Petrash","Dmitry Sevryukov","Mikhail Belyaev","Maxim Pisov"],"pdf_url":"https://arxiv.org/pdf/2408.01159v1.pdf","comment":"Accepted to ShapeMI MICCAI 2024"},{"id":"http://arxiv.org/abs/2403.15559v2","updated":"2024-08-02T10:19:34Z","published":"2024-03-22T18:28:04Z","title":"An Optimization Framework to Enforce Multi-View Consistency for\n  Texturing 3D Meshes","summary":"  A fundamental problem in the texturing of 3D meshes using pre-trained\ntext-to-image models is to ensure multi-view consistency. State-of-the-art\napproaches typically use diffusion models to aggregate multi-view inputs, where\ncommon issues are the blurriness caused by the averaging operation in the\naggregation step or inconsistencies in local features. This paper introduces an\noptimization framework that proceeds in four stages to achieve multi-view\nconsistency. Specifically, the first stage generates an over-complete set of 2D\ntextures from a predefined set of viewpoints using an MV-consistent diffusion\nprocess. The second stage selects a subset of views that are mutually\nconsistent while covering the underlying 3D model. We show how to achieve this\ngoal by solving semi-definite programs. The third stage performs non-rigid\nalignment to align the selected views across overlapping regions. The fourth\nstage solves an MRF problem to associate each mesh face with a selected view.\nIn particular, the third and fourth stages are iterated, with the cuts obtained\nin the fourth stage encouraging non-rigid alignment in the third stage to focus\non regions close to the cuts. Experimental results show that our approach\nsignificantly outperforms baseline approaches both qualitatively and\nquantitatively. Project page: https://aigc3d.github.io/ConsistenTex.\n","authors":["Zhengyi Zhao","Chen Song","Xiaodong Gu","Yuan Dong","Qi Zuo","Weihao Yuan","Liefeng Bo","Zilong Dong","Qixing Huang"],"pdf_url":"https://arxiv.org/pdf/2403.15559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19394v3","updated":"2024-08-02T10:05:03Z","published":"2024-07-28T04:23:40Z","title":"Depth-Wise Convolutions in Vision Transformers for Efficient Training on\n  Small Datasets","summary":"  The Vision Transformer (ViT) leverages the Transformer's encoder to capture\nglobal information by dividing images into patches and achieves superior\nperformance across various computer vision tasks. However, the self-attention\nmechanism of ViT captures the global context from the outset, overlooking the\ninherent relationships between neighboring pixels in images or videos.\nTransformers mainly focus on global information while ignoring the fine-grained\nlocal details. Consequently, ViT lacks inductive bias during image or video\ndataset training. In contrast, convolutional neural networks (CNNs), with their\nreliance on local filters, possess an inherent inductive bias, making them more\nefficient and quicker to converge than ViT with less data. In this paper, we\npresent a lightweight Depth-Wise Convolution module as a shortcut in ViT\nmodels, bypassing entire Transformer blocks to ensure the models capture both\nlocal and global information with minimal overhead. Additionally, we introduce\ntwo architecture variants, allowing the Depth-Wise Convolution modules to be\napplied to multiple Transformer blocks for parameter savings, and incorporating\nindependent parallel Depth-Wise Convolution modules with different kernels to\nenhance the acquisition of local information. The proposed approach\nsignificantly boosts the performance of ViT models on image classification,\nobject detection and instance segmentation by a large margin, especially on\nsmall datasets, as evaluated on CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet\nfor image classification, and COCO for object detection and instance\nsegmentation. The source code can be accessed at\nhttps://github.com/ZTX-100/Efficient_ViT_with_DW.\n","authors":["Tianxiao Zhang","Wenju Xu","Bo Luo","Guanghui Wang"],"pdf_url":"https://arxiv.org/pdf/2407.19394v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06542v2","updated":"2024-08-02T10:04:09Z","published":"2024-01-12T12:35:45Z","title":"Robustness-Aware 3D Object Detection in Autonomous Driving: A Review and\n  Outlook","summary":"  In the realm of modern autonomous driving, the perception system is\nindispensable for accurately assessing the state of the surrounding\nenvironment, thereby enabling informed prediction and planning. The key step to\nthis system is related to 3D object detection that utilizes vehicle-mounted\nsensors such as LiDAR and cameras to identify the size, the category, and the\nlocation of nearby objects. Despite the surge in 3D object detection methods\naimed at enhancing detection precision and efficiency, there is a gap in the\nliterature that systematically examines their resilience against environmental\nvariations, noise, and weather changes. This study emphasizes the importance of\nrobustness, alongside accuracy and latency, in evaluating perception systems\nunder practical scenarios. Our work presents an extensive survey of\ncamera-only, LiDAR-only, and multi-modal 3D object detection algorithms,\nthoroughly evaluating their trade-off between accuracy, latency, and\nrobustness, particularly on datasets like KITTI-C and nuScenes-C to ensure fair\ncomparisons. Among these, multi-modal 3D detection approaches exhibit superior\nrobustness, and a novel taxonomy is introduced to reorganize the literature for\nenhanced clarity. This survey aims to offer a more practical perspective on the\ncurrent capabilities and the constraints of 3D object detection algorithms in\nreal-world applications, thus steering future research towards\nrobustness-centric advancements.\n","authors":["Ziying Song","Lin Liu","Feiyang Jia","Yadan Luo","Guoxin Zhang","Lei Yang","Li Wang","Caiyan Jia"],"pdf_url":"https://arxiv.org/pdf/2401.06542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08372v3","updated":"2024-08-02T09:56:14Z","published":"2023-12-13T18:59:58Z","title":"SAM-guided Graph Cut for 3D Instance Segmentation","summary":"  This paper addresses the challenge of 3D instance segmentation by\nsimultaneously leveraging 3D geometric and multi-view image information. Many\nprevious works have applied deep learning techniques to 3D point clouds for\ninstance segmentation. However, these methods often failed to generalize to\nvarious types of scenes due to the scarcity and low-diversity of labeled 3D\npoint cloud data. Some recent works have attempted to lift 2D instance\nsegmentations to 3D within a bottom-up framework. The inconsistency in 2D\ninstance segmentations among views can substantially degrade the performance of\n3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to\neffectively exploit 2D segmentation models for 3D instance segmentation.\nSpecifically, we pre-segment the scene into several superpoints in 3D,\nformulating the task into a graph cut problem. The superpoint graph is\nconstructed based on 2D segmentation models, where node features are obtained\nfrom multi-view image features and edge weights are computed based on\nmulti-view segmentation results, enabling the better generalization ability. To\nprocess the graph, we train a graph neural network using pseudo 3D labels from\n2D segmentation models. Experimental results on the ScanNet, ScanNet++ and\nKITTI-360 datasets demonstrate that our method achieves robust segmentation\nperformance and can generalize across different types of scenes. Our project\npage is available at https://zju3dv.github.io/sam_graph.\n","authors":["Haoyu Guo","He Zhu","Sida Peng","Yuang Wang","Yujun Shen","Ruizhen Hu","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2312.08372v3.pdf","comment":"Project page: https://zju3dv.github.io/sam_graph"},{"id":"http://arxiv.org/abs/2408.01139v1","updated":"2024-08-02T09:35:06Z","published":"2024-08-02T09:35:06Z","title":"Interpreting Global Perturbation Robustness of Image Models using\n  Axiomatic Spectral Importance Decomposition","summary":"  Perturbation robustness evaluates the vulnerabilities of models, arising from\na variety of perturbations, such as data corruptions and adversarial attacks.\nUnderstanding the mechanisms of perturbation robustness is critical for global\ninterpretability. We present a model-agnostic, global mechanistic\ninterpretability method to interpret the perturbation robustness of image\nmodels. This research is motivated by two key aspects. First, previous global\ninterpretability works, in tandem with robustness benchmarks, e.g. mean\ncorruption error (mCE), are not designed to directly interpret the mechanisms\nof perturbation robustness within image models. Second, we notice that the\nspectral signal-to-noise ratios (SNR) of perturbed natural images exponentially\ndecay over the frequency. This power-law-like decay implies that: Low-frequency\nsignals are generally more robust than high-frequency signals -- yet high\nclassification accuracy can not be achieved by low-frequency signals alone. By\napplying Shapley value theory, our method axiomatically quantifies the\npredictive powers of robust features and non-robust features within an\ninformation theory framework. Our method, dubbed as \\textbf{I-ASIDE}\n(\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance\n\\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into\nmodel robustness mechanisms. We conduct extensive experiments over a variety of\nvision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not\nonly \\textbf{measure} the perturbation robustness but also \\textbf{provide\ninterpretations} of its mechanisms.\n","authors":["Róisín Luo","James McDermott","Colm O'Riordan"],"pdf_url":"https://arxiv.org/pdf/2408.01139v1.pdf","comment":"Accepted by Transactions on Machine Learning Research (TMLR 2024)"},{"id":"http://arxiv.org/abs/2408.01137v1","updated":"2024-08-02T09:31:21Z","published":"2024-08-02T09:31:21Z","title":"PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting\n  Network","summary":"  We present an advanced study on more challenging high-resolution salient\nobject detection (HRSOD) from both dataset and network framework perspectives.\nTo compensate for the lack of HRSOD dataset, we thoughtfully collect a\nlarge-scale high resolution salient object detection dataset, called UHRSD,\ncontaining 5,920 images from real-world complex scenarios at 4K-8K resolutions.\nAll the images are finely annotated in pixel-level, far exceeding previous\nlow-resolution SOD datasets. Aiming at overcoming the contradiction between the\nsampling depth and the receptive field size in the past methods, we propose a\nnovel one-stage framework for HR-SOD task using pyramid grafting mechanism. In\ngeneral, transformer-based and CNN-based backbones are adopted to extract\nfeatures from different resolution images independently and then these features\nare grafted from transformer branch to CNN branch. An attention-based\nCross-Model Grafting Module (CMGM) is proposed to enable CNN branch to combine\nbroken detailed information more holistically, guided by different source\nfeature during decoding process. Moreover, we design an Attention Guided Loss\n(AGL) to explicitly supervise the attention matrix generated by CMGM to help\nthe network better interact with the attention from different branches.\nComprehensive experiments on UHRSD and widely-used SOD datasets demonstrate\nthat our method can simultaneously locate salient object and preserve rich\ndetails, outperforming state-of-the-art methods. To verify the generalization\nability of the proposed framework, we apply it to the camouflaged object\ndetection (COD) task. Notably, our method performs superior to most\nstate-of-the-art COD methods without bells and whistles.\n","authors":["Changqun Xia","Chenxi Xie","Zhentao He","Tianshu Yu","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2408.01137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01126v1","updated":"2024-08-02T09:07:31Z","published":"2024-08-02T09:07:31Z","title":"IG-SLAM: Instant Gaussian SLAM","summary":"  3D Gaussian Splatting has recently shown promising results as an alternative\nscene representation in SLAM systems to neural implicit representations.\nHowever, current methods either lack dense depth maps to supervise the mapping\nprocess or detailed training designs that consider the scale of the\nenvironment. To address these drawbacks, we present IG-SLAM, a dense RGB-only\nSLAM system that employs robust Dense-SLAM methods for tracking and combines\nthem with Gaussian Splatting. A 3D map of the environment is constructed using\naccurate pose and dense depth provided by tracking. Additionally, we utilize\ndepth uncertainty in map optimization to improve 3D reconstruction. Our decay\nstrategy in map optimization enhances convergence and allows the system to run\nat 10 fps in a single process. We demonstrate competitive performance with\nstate-of-the-art RGB-only SLAM systems while achieving faster operation speeds.\nWe present our experiments on the Replica, TUM-RGBD, ScanNet, and EuRoC\ndatasets. The system achieves photo-realistic 3D reconstruction in large-scale\nsequences, particularly in the EuRoC dataset.\n","authors":["Furkan Aykut Sarikamis","Abdullah Aydin Alatan"],"pdf_url":"https://arxiv.org/pdf/2408.01126v1.pdf","comment":"8 pages, 3 page ref, 5 figures, 3DV submission"},{"id":"http://arxiv.org/abs/2408.01120v1","updated":"2024-08-02T09:01:05Z","published":"2024-08-02T09:01:05Z","title":"An Efficient and Effective Transformer Decoder-Based Framework for\n  Multi-Task Visual Grounding","summary":"  Most advanced visual grounding methods rely on Transformers for\nvisual-linguistic feature fusion. However, these Transformer-based approaches\nencounter a significant drawback: the computational costs escalate\nquadratically due to the self-attention mechanism in the Transformer Encoder,\nparticularly when dealing with high-resolution images or long context\nsentences. This quadratic increase in computational burden restricts the\napplicability of visual grounding to more intricate scenes, such as\nconversation-based reasoning segmentation, which involves lengthy language\nexpressions. In this paper, we propose an efficient and effective multi-task\nvisual grounding (EEVG) framework based on Transformer Decoder to address this\nissue, which reduces the cost in both language and visual aspects. In the\nlanguage aspect, we employ the Transformer Decoder to fuse visual and\nlinguistic features, where linguistic features are input as memory and visual\nfeatures as queries. This allows fusion to scale linearly with language\nexpression length. In the visual aspect, we introduce a parameter-free approach\nto reduce computation by eliminating background visual tokens based on\nattention scores. We then design a light mask head to directly predict\nsegmentation masks from the remaining sparse feature maps. Extensive results\nand ablation studies on benchmarks demonstrate the efficiency and effectiveness\nof our approach. Code is available in https://github.com/chenwei746/EEVG.\n","authors":["Wei Chen","Long Chen","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2408.01120v1.pdf","comment":"21pages, 10 figures, 9 tables. Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2408.01099v1","updated":"2024-08-02T08:24:05Z","published":"2024-08-02T08:24:05Z","title":"Contribution-based Low-Rank Adaptation with Pre-training Model for Real\n  Image Restoration","summary":"  Recently, pre-trained model and efficient parameter tuning have achieved\nremarkable success in natural language processing and high-level computer\nvision with the aid of masked modeling and prompt tuning. In low-level computer\nvision, however, there have been limited investigations on pre-trained models\nand even efficient fine-tuning strategy has not yet been explored despite its\nimportance and benefit in various real-world tasks such as alleviating memory\ninflation issue when integrating new tasks on AI edge devices. Here, we propose\na novel efficient parameter tuning approach dubbed contribution-based low-rank\nadaptation (CoLoRA) for multiple image restorations along with effective\npre-training method with random order degradations (PROD). Unlike prior arts\nthat tune all network parameters, our CoLoRA effectively fine-tunes small\namount of parameters by leveraging LoRA (low-rank adaptation) for each new\nvision task with our contribution-based method to adaptively determine layer by\nlayer capacity for that task to yield comparable performance to full tuning.\nFurthermore, our PROD strategy allows to extend the capability of pre-trained\nmodels with improved performance as well as robustness to bridge synthetic\npre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated\nits superior performance in various image restoration tasks across diverse\ndegradation types on both synthetic and real-world datasets for known and novel\ntasks.\n","authors":["Donwon Park","Hayeon Kim","Se Young Chun"],"pdf_url":"https://arxiv.org/pdf/2408.01099v1.pdf","comment":"33 pages, 15 figures, for homepage see this url :\n  https://janeyeon.github.io/colora/"},{"id":"http://arxiv.org/abs/2405.04788v3","updated":"2024-08-02T08:22:12Z","published":"2024-05-08T03:43:58Z","title":"SemiCD-VL: Visual-Language Model Guidance Makes Better Semi-supervised\n  Change Detector","summary":"  Change Detection (CD) aims to identify pixels with semantic changes between\nimages. However, annotating massive numbers of pixel-level images is\nlabor-intensive and costly, especially for multi-temporal images, which require\npixel-wise comparisons by human experts. Considering the excellent performance\nof visual language models (VLMs) for zero-shot, open-vocabulary, etc. with\nprompt-based reasoning, it is promising to utilize VLMs to make better CD under\nlimited labeled data. In this paper, we propose a VLM guidance-based\nsemi-supervised CD method, namely SemiCD-VL. The insight of SemiCD-VL is to\nsynthesize free change labels using VLMs to provide additional supervision\nsignals for unlabeled data. However, almost all current VLMs are designed for\nsingle-temporal images and cannot be directly applied to bi- or multi-temporal\nimages. Motivated by this, we first propose a VLM-based mixed change event\ngeneration (CEG) strategy to yield pseudo labels for unlabeled CD data. Since\nthe additional supervised signals provided by these VLM-driven pseudo labels\nmay conflict with the pseudo labels from the consistency regularization\nparadigm (e.g. FixMatch), we propose the dual projection head for de-entangling\ndifferent signal sources. Further, we explicitly decouple the bi-temporal\nimages semantic representation through two auxiliary segmentation decoders,\nwhich are also guided by VLM. Finally, to make the model more adequately\ncapture change representations, we introduce metric-aware supervision by\nfeature-level contrastive loss in auxiliary branches. Extensive experiments\nshow the advantage of SemiCD-VL. For instance, SemiCD-VL improves the FixMatch\nbaseline by +5.3 IoU on WHU-CD and by +2.4 IoU on LEVIR-CD with 5% labels. In\naddition, our CEG strategy, in an un-supervised manner, can achieve performance\nfar superior to state-of-the-art un-supervised CD methods.\n","authors":["Kaiyu Li","Xiangyong Cao","Yupeng Deng","Junmin Liu","Deyu Meng","Zhi Wang"],"pdf_url":"https://arxiv.org/pdf/2405.04788v3.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.01089v1","updated":"2024-08-02T08:08:56Z","published":"2024-08-02T08:08:56Z","title":"Prototypical Partial Optimal Transport for Universal Domain Adaptation","summary":"  Universal domain adaptation (UniDA) aims to transfer knowledge from a labeled\nsource domain to an unlabeled target domain without requiring the same label\nsets of both domains. The existence of domain and category shift makes the task\nchallenging and requires us to distinguish \"known\" samples (i.e., samples whose\nlabels exist in both domains) and \"unknown\" samples (i.e., samples whose labels\nexist in only one domain) in both domains before reducing the domain gap. In\nthis paper, we consider the problem from the point of view of distribution\nmatching which we only need to align two distributions partially. A novel\napproach, dubbed mini-batch Prototypical Partial Optimal Transport (m-PPOT), is\nproposed to conduct partial distribution alignment for UniDA. In training\nphase, besides minimizing m-PPOT, we also leverage the transport plan of m-PPOT\nto reweight source prototypes and target samples, and design reweighted entropy\nloss and reweighted cross-entropy loss to distinguish \"known\" and \"unknown\"\nsamples. Experiments on four benchmarks show that our method outperforms the\nprevious state-of-the-art UniDA methods.\n","authors":["Yucheng Yang","Xiang Gu","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2408.01089v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01085v1","updated":"2024-08-02T08:06:12Z","published":"2024-08-02T08:06:12Z","title":"Effect of Fog Particle Size Distribution on 3D Object Detection Under\n  Adverse Weather Conditions","summary":"  LiDAR-based sensors employing optical spectrum signals play a vital role in\nproviding significant information about the target objects in autonomous\ndriving vehicle systems. However, the presence of fog in the atmosphere\nseverely degrades the overall system's performance. This manuscript analyzes\nthe role of fog particle size distributions in 3D object detection under\nadverse weather conditions. We utilise Mie theory and meteorological optical\nrange (MOR) to calculate the attenuation and backscattering coefficient values\nfor point cloud generation and analyze the overall system's accuracy in Car,\nCyclist, and Pedestrian case scenarios under easy, medium and hard detection\ndifficulties. Gamma and Junge (Power-Law) distributions are employed to\nmathematically model the fog particle size distribution under strong and\nmoderate advection fog environments. Subsequently, we modified the KITTI\ndataset based on the backscattering coefficient values and trained it on the\nPV-RCNN++ deep neural network model for Car, Cyclist, and Pedestrian cases\nunder different detection difficulties. The result analysis shows a significant\nvariation in the system's accuracy concerning the changes in target object\ndimensionality, the nature of the fog environment and increasing detection\ndifficulties, with the Car exhibiting the highest accuracy of around 99% and\nthe Pedestrian showing the lowest accuracy of around 73%.\n","authors":["Ajinkya Shinde","Gaurav Sharma","Manisha Pattanaik","Sri Niwas Singh"],"pdf_url":"https://arxiv.org/pdf/2408.01085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01080v1","updated":"2024-08-02T07:57:06Z","published":"2024-08-02T07:57:06Z","title":"FCDFusion: a Fast, Low Color Deviation Method for Fusing Visible and\n  Infrared Image Pairs","summary":"  Visible and infrared image fusion (VIF) aims to combine information from\nvisible and infrared images into a single fused image. Previous VIF methods\nusually employ a color space transformation to keep the hue and saturation from\nthe original visible image. However, for fast VIF methods, this operation\naccounts for the majority of the calculation and is the bottleneck preventing\nfaster processing. In this paper, we propose a fast fusion method, FCDFusion,\nwith little color deviation. It preserves color information without color space\ntransformations, by directly operating in RGB color space. It incorporates\ngamma correction at little extra cost, allowing color and contrast to be\nrapidly improved. We regard the fusion process as a scaling operation on 3D\ncolor vectors, greatly simplifying the calculations. A theoretical analysis and\nexperiments show that our method can achieve satisfactory results in only 7\nFLOPs per pixel. Compared to state-of-the-art fast, color-preserving methods\nusing HSV color space, our method provides higher contrast at only half of the\ncomputational cost. We further propose a new metric, color deviation, to\nmeasure the ability of a VIF method to preserve color. It is specifically\ndesigned for VIF tasks with color visible-light images, and overcomes\ndeficiencies of existing VIF metrics used for this purpose. Our code is\navailable at https://github.com/HeasonLee/FCDFusion.\n","authors":["Hesong Li","Ying Fu"],"pdf_url":"https://arxiv.org/pdf/2408.01080v1.pdf","comment":"This article has been accepted by Computational Visual Media"},{"id":"http://arxiv.org/abs/2408.01077v1","updated":"2024-08-02T07:52:28Z","published":"2024-08-02T07:52:28Z","title":"PhysMamba: Leveraging Dual-Stream Cross-Attention SSD for Remote\n  Physiological Measurement","summary":"  Remote Photoplethysmography (rPPG) is a non-contact technique for extracting\nphysiological signals from facial videos, used in applications like emotion\nmonitoring, medical assistance, and anti-face spoofing. Unlike controlled\nlaboratory settings, real-world environments often contain motion artifacts and\nnoise, affecting the performance of existing methods. To address this, we\npropose PhysMamba, a dual-stream time-frequency interactive model based on\nMamba. PhysMamba integrates the state-of-the-art Mamba-2 model and employs a\ndual-stream architecture to learn diverse rPPG features, enhancing robustness\nin noisy conditions. Additionally, we designed the Cross-Attention State Space\nDuality (CASSD) module to improve information exchange and feature\ncomplementarity between the two streams. We validated PhysMamba using PURE,\nUBFC-rPPG and MMPD. Experimental results show that PhysMamba achieves\nstate-of-the-art performance across various scenarios, particularly in complex\nenvironments, demonstrating its potential in practical remote heart rate\nmonitoring applications.\n","authors":["Zhixin Yan","Yan Zhong","Wenjun Zhang","Lin Shu","Hongbin Xu","Wenxiong Kang"],"pdf_url":"https://arxiv.org/pdf/2408.01077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01076v1","updated":"2024-08-02T07:51:44Z","published":"2024-08-02T07:51:44Z","title":"Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for\n  Continual Learning","summary":"  Deep neural networks (DNNs) excel on fixed datasets but struggle with\nincremental and shifting data in real-world scenarios. Continual learning\naddresses this challenge by allowing models to learn from new data while\nretaining previously learned knowledge. Existing methods mainly rely on visual\nfeatures, often neglecting the rich semantic information encoded in text. The\nsemantic knowledge available in the label information of the images, offers\nimportant semantic information that can be related with previously acquired\nknowledge of semantic classes. Consequently, effectively leveraging this\ninformation throughout continual learning is expected to be beneficial. To\naddress this, we propose integrating semantic guidance within and across tasks\nby capturing semantic similarity using text embeddings. We start from a\npre-trained CLIP model, employ the \\emph{Semantically-guided Representation\nLearning (SG-RL)} module for a soft-assignment towards all current task\nclasses, and use the Semantically-guided Knowledge Distillation (SG-KD) module\nfor enhanced knowledge transfer. Experimental results demonstrate the\nsuperiority of our method on general and fine-grained datasets. Our code can be\nfound in\nhttps://github.com/aprilsveryown/semantically-guided-continual-learning.\n","authors":["Lu Yu","Zhe Tao","Hantao Yao","Joost Van de Weijer","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2408.01076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01067v1","updated":"2024-08-02T07:40:34Z","published":"2024-08-02T07:40:34Z","title":"Amodal Segmentation for Laparoscopic Surgery Video Instruments","summary":"  Segmentation of surgical instruments is crucial for enhancing surgeon\nperformance and ensuring patient safety. Conventional techniques such as\nbinary, semantic, and instance segmentation share a common drawback: they do\nnot accommodate the parts of instruments obscured by tissues or other\ninstruments. Precisely predicting the full extent of these occluded instruments\ncan significantly improve laparoscopic surgeries by providing critical guidance\nduring operations and assisting in the analysis of potential surgical errors,\nas well as serving educational purposes. In this paper, we introduce Amodal\nSegmentation to the realm of surgical instruments in the medical field. This\ntechnique identifies both the visible and occluded parts of an object. To\nachieve this, we introduce a new Amoal Instruments Segmentation (AIS) dataset,\nwhich was developed by reannotating each instrument with its complete mask,\nutilizing the 2017 MICCAI EndoVis Robotic Instrument Segmentation Challenge\ndataset. Additionally, we evaluate several leading amodal segmentation methods\nto establish a benchmark for this new dataset.\n","authors":["Ruohua Shi","Zhaochen Liu","Lingyu Duan","Tingting Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.01067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02371v2","updated":"2024-08-02T07:14:59Z","published":"2024-07-02T15:40:29Z","title":"OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video\n  Generation","summary":"  Text-to-video (T2V) generation has recently garnered significant attention\nthanks to the large multi-modality model Sora. However, T2V generation still\nfaces two important challenges: 1) Lacking a precise open sourced high-quality\ndataset. The previous popular video datasets, e.g. WebVid-10M and Panda-70M,\nare either with low quality or too large for most research institutions.\nTherefore, it is challenging but crucial to collect a precise high-quality\ntext-video pairs for T2V generation. 2) Ignoring to fully utilize textual\ninformation. Recent T2V methods have focused on vision transformers, using a\nsimple cross attention module for video generation, which falls short of\nthoroughly extracting semantic information from text prompt. To address these\nissues, we introduce OpenVid-1M, a precise high-quality dataset with expressive\ncaptions. This open-scenario dataset contains over 1 million text-video pairs,\nfacilitating research on T2V generation. Furthermore, we curate 433K 1080p\nvideos from OpenVid-1M to create OpenVidHD-0.4M, advancing high-definition\nvideo generation. Additionally, we propose a novel Multi-modal Video Diffusion\nTransformer (MVDiT) capable of mining both structure information from visual\ntokens and semantic information from text tokens. Extensive experiments and\nablation studies verify the superiority of OpenVid-1M over previous datasets\nand the effectiveness of our MVDiT.\n","authors":["Kepan Nan","Rui Xie","Penghao Zhou","Tiehan Fan","Zhenheng Yang","Zhijie Chen","Xiang Li","Jian Yang","Ying Tai"],"pdf_url":"https://arxiv.org/pdf/2407.02371v2.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2407.19397v2","updated":"2024-08-02T06:53:08Z","published":"2024-07-28T04:46:55Z","title":"Domain Adaptive Lung Nodule Detection in X-ray Image","summary":"  Medical images from different healthcare centers exhibit varied data\ndistributions, posing significant challenges for adapting lung nodule detection\ndue to the domain shift between training and application phases. Traditional\nunsupervised domain adaptive detection methods often struggle with this shift,\nleading to suboptimal outcomes. To overcome these challenges, we introduce a\nnovel domain adaptive approach for lung nodule detection that leverages mean\nteacher self-training and contrastive learning. First, we propose a\nhierarchical contrastive learning strategy to refine nodule representations and\nenhance the distinction between nodules and background. Second, we introduce a\nnodule-level domain-invariant feature learning (NDL) module to capture\ndomain-invariant features through adversarial learning across different\ndomains. Additionally, we propose a new annotated dataset of X-ray images to\naid in advancing lung nodule detection research. Extensive experiments\nconducted on multiple X-ray datasets demonstrate the efficacy of our approach\nin mitigating domain shift impacts.\n","authors":["Haifeng Zhao","Lixiang Jiang","Leilei Ma","Dengdi Sun","Yanping Fu"],"pdf_url":"https://arxiv.org/pdf/2407.19397v2.pdf","comment":"This paper will submit to IEEE SMC 2024"},{"id":"http://arxiv.org/abs/2408.01044v1","updated":"2024-08-02T06:32:45Z","published":"2024-08-02T06:32:45Z","title":"Boosting Gaze Object Prediction via Pixel-level Supervision from Vision\n  Foundation Model","summary":"  Gaze object prediction (GOP) aims to predict the category and location of the\nobject that a human is looking at. Previous methods utilized box-level\nsupervision to identify the object that a person is looking at, but struggled\nwith semantic ambiguity, ie, a single box may contain several items since\nobjects are close together. The Vision foundation model (VFM) has improved in\nobject segmentation using box prompts, which can reduce confusion by more\nprecisely locating objects, offering advantages for fine-grained prediction of\ngaze objects. This paper presents a more challenging gaze object segmentation\n(GOS) task, which involves inferring the pixel-level mask corresponding to the\nobject captured by human gaze behavior. In particular, we propose that the\npixel-level supervision provided by VFM can be integrated into gaze object\nprediction to mitigate semantic ambiguity. This leads to our gaze object\ndetection and segmentation framework that enables accurate pixel-level\npredictions. Different from previous methods that require additional head input\nor ignore head features, we propose to automatically obtain head features from\nscene features to ensure the model's inference efficiency and flexibility in\nthe real world. Moreover, rather than directly fuse features to predict gaze\nheatmap as in existing methods, which may overlook spatial location and subtle\ndetails of the object, we develop a space-to-object gaze regression method to\nfacilitate human-object gaze interaction. Specifically, it first constructs an\ninitial human-object spatial connection, then refines this connection by\ninteracting with semantically clear features in the segmentation branch,\nultimately predicting a gaze heatmap for precise localization. Extensive\nexperiments on GOO-Synth and GOO-Real datasets demonstrate the effectiveness of\nour method.\n","authors":["Yang Jin","Lei Zhang","Shi Yan","Bin Fan","Binglu Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01044v1.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2408.01040v1","updated":"2024-08-02T06:24:39Z","published":"2024-08-02T06:24:39Z","title":"Privacy-Preserving Split Learning with Vision Transformers using\n  Patch-Wise Random and Noisy CutMix","summary":"  In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.\n","authors":["Seungeun Oh","Sihun Baek","Jihong Park","Hyelin Nam","Praneeth Vepakomma","Ramesh Raskar","Mehdi Bennis","Seong-Lyun Kim"],"pdf_url":"https://arxiv.org/pdf/2408.01040v1.pdf","comment":"23 pages, 11 figures, 8 tables, to be published in Transactions on\n  Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2408.01037v1","updated":"2024-08-02T06:20:48Z","published":"2024-08-02T06:20:48Z","title":"MambaST: A Plug-and-Play Cross-Spectral Spatial-Temporal Fuser for\n  Efficient Pedestrian Detection","summary":"  This paper proposes MambaST, a plug-and-play cross-spectral spatial-temporal\nfusion pipeline for efficient pedestrian detection. Several challenges exist\nfor pedestrian detection in autonomous driving applications. First, it is\ndifficult to perform accurate detection using RGB cameras under dark or\nlow-light conditions. Cross-spectral systems must be developed to integrate\ncomplementary information from multiple sensor modalities, such as thermal and\nvisible cameras, to improve the robustness of the detections. Second,\npedestrian detection models are latency-sensitive. Efficient and easy-to-scale\ndetection models with fewer parameters are highly desirable for real-time\napplications such as autonomous driving. Third, pedestrian video data provides\nspatial-temporal correlations of pedestrian movement. It is beneficial to\nincorporate temporal as well as spatial information to enhance pedestrian\ndetection. This work leverages recent advances in the state space model (Mamba)\nand proposes a novel Multi-head Hierarchical Patching and Aggregation (MHHPA)\nstructure to extract both fine-grained and coarse-grained information from both\nRGB and thermal imagery. Experimental results show that the proposed MHHPA is\nan effective and efficient alternative to a Transformer model for\ncross-spectral pedestrian detection. Our proposed model also achieves superior\nperformance on small-scale pedestrian detection. The code is available at\nhttps://github.com/XiangboGaoBarry/MambaST}{https://github.com/XiangboGaoBarry/MambaST.\n","authors":["Xiangbo Gao","Asiegbu Miracle Kanu-Asiegbu","Xiaoxiao Du"],"pdf_url":"https://arxiv.org/pdf/2408.01037v1.pdf","comment":"ITSC 2024 Accepted"},{"id":"http://arxiv.org/abs/2408.01035v1","updated":"2024-08-02T06:18:39Z","published":"2024-08-02T06:18:39Z","title":"Structure from Motion-based Motion Estimation and 3D Reconstruction of\n  Unknown Shaped Space Debris","summary":"  With the boost in the number of spacecraft launches in the current decades,\nthe space debris problem is daily becoming significantly crucial. For\nsustainable space utilization, the continuous removal of space debris is the\nmost severe problem for humanity. To maximize the reliability of the debris\ncapture mission in orbit, accurate motion estimation of the target is\nessential. Space debris has lost its attitude and orbit control capabilities,\nand its shape is unknown due to the break. This paper proposes the Structure\nfrom Motion-based algorithm to perform unknown shaped space debris motion\nestimation with limited resources, where only 2D images are required as input.\nThe method then outputs the reconstructed shape of the unknown object and the\nrelative pose trajectory between the target and the camera simultaneously,\nwhich are exploited to estimate the target's motion. The method is\nquantitatively validated with the realistic image dataset generated by the\nmicrogravity experiment in a 2D air-floating testbed and 3D kinematic\nsimulation.\n","authors":["Kentaro Uno","Takehiro Matsuoka","Akiyoshi Uchida","Kazuya Yoshida"],"pdf_url":"https://arxiv.org/pdf/2408.01035v1.pdf","comment":"6 pages, 10 figures. Manuscript accepted at the 2024 IEEE 20th\n  International Conference on Automation Science and Engineerin (CASE 2024)"},{"id":"http://arxiv.org/abs/2408.01031v1","updated":"2024-08-02T06:13:29Z","published":"2024-08-02T06:13:29Z","title":"POA: Pre-training Once for Models of All Sizes","summary":"  Large-scale self-supervised pre-training has paved the way for one foundation\nmodel to handle many different vision tasks. Most pre-training methodologies\ntrain a single model of a certain size at one time. Nevertheless, various\ncomputation or storage constraints in real-world scenarios require substantial\nefforts to develop a series of models with different sizes to deploy. Thus, in\nthis study, we propose a novel tri-branch self-supervised training framework,\ntermed as POA (Pre-training Once for All), to tackle this aforementioned issue.\nOur approach introduces an innovative elastic student branch into a modern\nself-distillation paradigm. At each pre-training step, we randomly sample a\nsub-network from the original student to form the elastic student and train all\nbranches in a self-distilling fashion. Once pre-trained, POA allows the\nextraction of pre-trained models of diverse sizes for downstream tasks.\nRemarkably, the elastic student facilitates the simultaneous pre-training of\nmultiple models with different sizes, which also acts as an additional ensemble\nof models of various sizes to enhance representation learning. Extensive\nexperiments, including k-nearest neighbors, linear probing evaluation and\nassessments on multiple downstream tasks demonstrate the effectiveness and\nadvantages of our POA. It achieves state-of-the-art performance using ViT, Swin\nTransformer and ResNet backbones, producing around a hundred models with\ndifferent sizes through a single pre-training session. The code is available\nat: https://github.com/Qichuzyy/POA.\n","authors":["Yingying Zhang","Xin Guo","Jiangwei Lao","Lei Yu","Lixiang Ru","Jian Wang","Guo Ye","Huimei He","Jingdong Chen","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2408.01031v1.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2408.01026v1","updated":"2024-08-02T05:50:49Z","published":"2024-08-02T05:50:49Z","title":"PINNs for Medical Image Analysis: A Survey","summary":"  The incorporation of physical information in machine learning frameworks is\ntransforming medical image analysis (MIA). By integrating fundamental knowledge\nand governing physical laws, these models achieve enhanced robustness and\ninterpretability. In this work, we explore the utility of physics-informed\napproaches for MIA (PIMIA) tasks such as registration, generation,\nclassification, and reconstruction. We present a systematic literature review\nof over 80 papers on physics-informed methods dedicated to MIA. We propose a\nunified taxonomy to investigate what physics knowledge and processes are\nmodelled, how they are represented, and the strategies to incorporate them into\nMIA models. We delve deep into a wide range of image analysis tasks, from\nimaging, generation, prediction, inverse imaging (super-resolution and\nreconstruction), registration, and image analysis (segmentation and\nclassification). For each task, we thoroughly examine and present in a tabular\nformat the central physics-guided operation, the region of interest (with\nrespect to human anatomy), the corresponding imaging modality, the dataset used\nfor model training, the deep network architecture employed, and the primary\nphysical process, equation, or principle utilized. Additionally, we also\nintroduce a novel metric to compare the performance of PIMIA methods across\ndifferent tasks and datasets. Based on this review, we summarize and distil our\nperspectives on the challenges, open research questions, and directions for\nfuture research. We highlight key open challenges in PIMIA, including selecting\nsuitable physics priors and establishing a standardized benchmarking platform.\n","authors":["Chayan Banerjee","Kien Nguyen","Olivier Salvado","Truyen Tran","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2408.01026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03298v2","updated":"2024-08-02T05:26:14Z","published":"2024-06-05T14:08:13Z","title":"L-PR: Exploiting LiDAR Fiducial Marker for Unordered Low Overlap\n  Multiview Point Cloud Registration","summary":"  Point cloud registration is a prerequisite for many applications in computer\nvision and robotics. Most existing methods focus on pairwise registration of\ntwo point clouds with high overlap. Although there have been some methods for\nlow overlap cases, they struggle in degraded scenarios. This paper introduces a\nnovel framework dubbed L-PR, designed to register unordered low overlap\nmultiview point clouds leveraging LiDAR fiducial markers. We refer to them as\nLiDAR fiducial markers, but they are the same as the popular AprilTag and ArUco\nmarkers, thin sheets of paper that do not affect the 3D geometry of the\nenvironment. We first propose an improved adaptive threshold marker detection\nmethod to provide robust detection results when the viewpoints among point\nclouds change dramatically. Then, we formulate the unordered multiview point\ncloud registration problem as a maximum a-posteriori (MAP) problem and develop\na framework consisting of two levels of graphs to address it. The first-level\ngraph, constructed as a weighted graph, is designed to efficiently and\noptimally infer initial values of scan poses from the unordered set. The\nsecond-level graph is constructed as a factor graph. By globally optimizing the\nvariables on the graph, including scan poses, marker poses, and marker corner\npositions, we tackle the MAP problem. We conduct both qualitative and\nquantitative experiments to demonstrate that the proposed method surpasses\nprevious state-of-the-art (SOTA) methods and to showcase that L-PR can serve as\na low-cost and efficient tool for 3D asset collection and training data\ncollection. In particular, we collect a new dataset named Livox-3DMatch using\nL-PR and incorporate it into the training of the SOTA learning-based method,\nSGHR, which brings evident improvements for SGHR on various benchmarks.\n","authors":["Yibo Liu","Jinjun Shan","Amaldev Haridevan","Shuo Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.03298v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2408.01014v1","updated":"2024-08-02T05:17:14Z","published":"2024-08-02T05:17:14Z","title":"EIUP: A Training-Free Approach to Erase Non-Compliant Concepts\n  Conditioned on Implicit Unsafe Prompts","summary":"  Text-to-image diffusion models have shown the ability to learn a diverse\nrange of concepts. However, it is worth noting that they may also generate\nundesirable outputs, consequently giving rise to significant security concerns.\nSpecifically, issues such as Not Safe for Work (NSFW) content and potential\nviolations of style copyright may be encountered. Since image generation is\nconditioned on text, prompt purification serves as a straightforward solution\nfor content safety. Similar to the approach taken by LLM, some efforts have\nbeen made to control the generation of safe outputs by purifying prompts.\nHowever, it is also important to note that even with these efforts, non-toxic\ntext still carries a risk of generating non-compliant images, which is referred\nto as implicit unsafe prompts. Furthermore, some existing works fine-tune the\nmodels to erase undesired concepts from model weights. This type of method\nnecessitates multiple training iterations whenever the concept is updated,\nwhich can be time-consuming and may potentially lead to catastrophic\nforgetting. To address these challenges, we propose a simple yet effective\napproach that incorporates non-compliant concepts into an erasure prompt. This\nerasure prompt proactively participates in the fusion of image spatial features\nand text embeddings. Through attention mechanisms, our method is capable of\nidentifying feature representations of non-compliant concepts in the image\nspace. We re-weight these features to effectively suppress the generation of\nunsafe images conditioned on original implicit unsafe prompts. Our method\nexhibits superior erasure effectiveness while achieving high scores in image\nfidelity compared to the state-of-the-art baselines. WARNING: This paper\ncontains model outputs that may be offensive.\n","authors":["Die Chen","Zhiwen Li","Mingyuan Fan","Cen Chen","Wenmeng Zhou","Yaliang Li"],"pdf_url":"https://arxiv.org/pdf/2408.01014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00228v3","updated":"2024-08-02T05:17:10Z","published":"2024-03-01T02:19:40Z","title":"DISORF: A Distributed Online 3D Reconstruction Framework for Mobile\n  Robots","summary":"  We present a framework, DISORF, to enable online 3D reconstruction and\nvisualization of scenes captured by resource-constrained mobile robots and edge\ndevices. To address the limited computing capabilities of edge devices and\npotentially limited network availability, we design a framework that\nefficiently distributes computation between the edge device and the remote\nserver. We leverage on-device SLAM systems to generate posed keyframes and\ntransmit them to remote servers that can perform high-quality 3D reconstruction\nand visualization at runtime by leveraging recent advances in neural 3D\nmethods. We identify a key challenge with online training where naive image\nsampling strategies can lead to significant degradation in rendering quality.\nWe propose a novel shifted exponential frame sampling method that addresses\nthis challenge for online training. We demonstrate the effectiveness of our\nframework in enabling high-quality real-time reconstruction and visualization\nof unknown scenes as they are captured and streamed from cameras in mobile\nrobots and edge devices.\n","authors":["Chunlin Li","Hanrui Fan","Xiaorui Huang","Ruofan Liang","Sankeerth Durvasula","Nandita Vijaykumar"],"pdf_url":"https://arxiv.org/pdf/2403.00228v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21450v2","updated":"2024-08-02T05:01:38Z","published":"2024-07-31T08:54:50Z","title":"Forecasting Future Videos from Novel Views via Disentangled 3D Scene\n  Representation","summary":"  Video extrapolation in space and time (VEST) enables viewers to forecast a 3D\nscene into the future and view it from novel viewpoints. Recent methods propose\nto learn an entangled representation, aiming to model layered scene geometry,\nmotion forecasting and novel view synthesis together, while assuming simplified\naffine motion and homography-based warping at each scene layer, leading to\ninaccurate video extrapolation. Instead of entangled scene representation and\nrendering, our approach chooses to disentangle scene geometry from scene\nmotion, via lifting the 2D scene to 3D point clouds, which enables high quality\nrendering of future videos from novel views. To model future 3D scene motion,\nwe propose a disentangled two-stage approach that initially forecasts\nego-motion and subsequently the residual motion of dynamic objects (e.g., cars,\npeople). This approach ensures more precise motion predictions by reducing\ninaccuracies from entanglement of ego-motion with dynamic object motion, where\nbetter ego-motion forecasting could significantly enhance the visual outcomes.\nExtensive experimental analysis on two urban scene datasets demonstrate\nsuperior performance of our proposed method in comparison to strong baselines.\n","authors":["Sudhir Yarram","Junsong Yuan"],"pdf_url":"https://arxiv.org/pdf/2407.21450v2.pdf","comment":"Accepted to ECCV 2024. Project Page:\n  https://skrya.github.io/projects/ffn-dsr/"},{"id":"http://arxiv.org/abs/2408.00998v1","updated":"2024-08-02T04:13:38Z","published":"2024-08-02T04:13:38Z","title":"FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features\n  for Highly Controllable Text-Driven Image Translation","summary":"  Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nextraordinary image generation based on natural-language text prompts. However,\nthe issue of lacking controllability of such models restricts their practical\napplicability for real-life content creation, for which attention has been\nfocused on leveraging a reference image to control text-to-image synthesis. Due\nto the close correlation between the reference image and the generated image,\nthis problem can also be regarded as the task of manipulating (or editing) the\nreference image as per the text, namely text-driven image-to-image translation.\nThis paper contributes a novel, concise, and efficient approach that adapts the\npre-trained large-scale text-to-image (T2I) diffusion model to the\nimage-to-image (I2I) paradigm in a plug-and-play manner, realizing high-quality\nand versatile text-driven I2I translation without any model training, model\nfine-tuning, or online optimization process. To guide T2I generation with a\nreference image, we propose to model diverse guiding factors with\ncorrespondingly different frequency bands of diffusion features in the DCT\nspectral space, and accordingly devise a novel frequency band substitution\nlayer that dynamically substitutes a certain DCT frequency band of the\ndiffusion features with the corresponding counterpart of the reference image\nalong the reverse sampling process. We demonstrate that our method flexibly\nenables highly controllable text-driven I2I translation both in the guiding\nfactor and guiding intensity of the reference image, simply by tuning the type\nand bandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify the superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability.\n","authors":["Xiang Gao","Jiaying Liu"],"pdf_url":"https://arxiv.org/pdf/2408.00998v1.pdf","comment":"Accepted conference paper of ACM MM 2024"},{"id":"http://arxiv.org/abs/2407.12939v3","updated":"2024-08-02T03:33:17Z","published":"2024-07-17T18:10:40Z","title":"GenRC: Generative 3D Room Completion from Sparse Image Collections","summary":"  Sparse RGBD scene completion is a challenging task especially when\nconsidering consistent textures and geometries throughout the entire scene.\nDifferent from existing solutions that rely on human-designed text prompts or\npredefined camera trajectories, we propose GenRC, an automated training-free\npipeline to complete a room-scale 3D mesh with high-fidelity textures. To\nachieve this, we first project the sparse RGBD images to a highly incomplete 3D\nmesh. Instead of iteratively generating novel views to fill in the void, we\nutilized our proposed E-Diffusion to generate a view-consistent panoramic RGBD\nimage which ensures global geometry and appearance consistency. Furthermore, we\nmaintain the input-output scene stylistic consistency through textual inversion\nto replace human-designed text prompts. To bridge the domain gap among\ndatasets, E-Diffusion leverages models trained on large-scale datasets to\ngenerate diverse appearances. GenRC outperforms state-of-the-art methods under\nmost appearance and geometric metrics on ScanNet and ARKitScenes datasets, even\nthough GenRC is not trained on these datasets nor using predefined camera\ntrajectories. Project page: https://minfenli.github.io/GenRC\n","authors":["Ming-Feng Li","Yueh-Feng Ku","Hong-Xuan Yen","Chi Liu","Yu-Lun Liu","Albert Y. C. Chen","Cheng-Hao Kuo","Min Sun"],"pdf_url":"https://arxiv.org/pdf/2407.12939v3.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2406.08782v2","updated":"2024-08-02T01:56:17Z","published":"2024-06-13T03:27:01Z","title":"Hybrid Spatial-spectral Neural Network for Hyperspectral Image Denoising","summary":"  Hyperspectral image (HSI) denoising is an essential procedure for HSI\napplications. Unfortunately, the existing Transformer-based methods mainly\nfocus on non-local modeling, neglecting the importance of locality in image\ndenoising. Moreover, deep learning methods employ complex spectral learning\nmechanisms, thus introducing large computation costs.\n  To address these problems, we propose a hybrid spatial-spectral denoising\nnetwork (HSSD), in which we design a novel hybrid dual-path network inspired by\nCNN and Transformer characteristics, leading to capturing both local and\nnon-local spatial details while suppressing noise efficiently. Furthermore, to\nreduce computational complexity, we adopt a simple but effective decoupling\nstrategy that disentangles the learning of space and spectral channels, where\nmultilayer perception with few parameters is utilized to learn the global\ncorrelations among spectra. The synthetic and real experiments demonstrate that\nour proposed method outperforms state-of-the-art methods on spatial and\nspectral reconstruction. The code and details are available on\nhttps://github.com/HLImg/HSSD.\n","authors":["Hao Liang"," Chengjie","Kun Li","Xin Tian"],"pdf_url":"https://arxiv.org/pdf/2406.08782v2.pdf","comment":"There are some errors in professional theory"},{"id":"http://arxiv.org/abs/2407.11590v3","updated":"2024-08-02T01:36:59Z","published":"2024-07-16T10:50:10Z","title":"Rethinking Learned Image Compression: Context is All You Need","summary":"  Since LIC has made rapid progress recently compared to traditional methods,\nthis paper attempts to discuss the question about 'Where is the boundary of\nLearned Image Compression(LIC)?'. Thus this paper splits the above problem into\ntwo sub-problems:1)Where is the boundary of rate-distortion performance of\nPSNR? 2)How to further improve the compression gain and achieve the boundary?\nTherefore this paper analyzes the effectiveness of scaling parameters for\nencoder, decoder and context model, which are the three components of LIC. Then\nwe conclude that scaling for LIC is to scale for context model and decoder\nwithin LIC. Extensive experiments demonstrate that overfitting can actually\nserve as an effective context. By optimizing the context, this paper further\nimproves PSNR and achieves state-of-the-art performance, showing a performance\ngain of 14.39% with BD-RATE over VVC.\n","authors":["Jixiang Luo"],"pdf_url":"https://arxiv.org/pdf/2407.11590v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.03452v2","updated":"2024-08-02T01:33:25Z","published":"2023-09-07T02:26:55Z","title":"Multimodal Guidance Network for Missing-Modality Inference in Content\n  Moderation","summary":"  Multimodal deep learning, especially vision-language models, have gained\nsignificant traction in recent years, greatly improving performance on many\ndownstream tasks, including content moderation and violence detection. However,\nstandard multimodal approaches often assume consistent modalities between\ntraining and inference, limiting applications in many real-world use cases, as\nsome modalities may not be available during inference. While existing research\nmitigates this problem through reconstructing the missing modalities, they\nunavoidably increase unnecessary computational cost, which could be just as\ncritical, especially for large, deployed infrastructures in industry. To this\nend, we propose a novel guidance network that promotes knowledge sharing during\ntraining, taking advantage of the multimodal representations to train better\nsingle-modality models to be used for inference. Real-world experiments in\nviolence detection shows that our proposed framework trains single-modality\nmodels that significantly outperform traditionally trained counterparts, while\navoiding increases in computational cost for inference.\n","authors":["Zhuokai Zhao","Harish Palani","Tianyi Liu","Lena Evans","Ruth Toner"],"pdf_url":"https://arxiv.org/pdf/2309.03452v2.pdf","comment":"ICME 2024 Camera Ready. Code is available at\n  https://github.com/zhuokaizhao/multimodal-guidance-network"},{"id":"http://arxiv.org/abs/2408.00969v1","updated":"2024-08-02T01:29:43Z","published":"2024-08-02T01:29:43Z","title":"Visible-Thermal Multiple Object Tracking: Large-scale Video Dataset and\n  Progressive Fusion Approach","summary":"  The complementary benefits from visible and thermal infrared data are widely\nutilized in various computer vision task, such as visual tracking, semantic\nsegmentation and object detection, but rarely explored in Multiple Object\nTracking (MOT). In this work, we contribute a large-scale Visible-Thermal video\nbenchmark for MOT, called VT-MOT. VT-MOT has the following main advantages. 1)\nThe data is large scale and high diversity. VT-MOT includes 582 video sequence\npairs, 401k frame pairs from surveillance, drone, and handheld platforms. 2)\nThe cross-modal alignment is highly accurate. We invite several professionals\nto perform both spatial and temporal alignment frame by frame. 3) The\nannotation is dense and high-quality. VT-MOT has 3.99 million annotation boxes\nannotated and double-checked by professionals, including heavy occlusion and\nobject re-acquisition (object disappear and reappear) challenges. To provide a\nstrong baseline, we design a simple yet effective tracking framework, which\neffectively fuses temporal information and complementary information of two\nmodalities in a progressive manner, for robust visible-thermal MOT. A\ncomprehensive experiment are conducted on VT-MOT and the results prove the\nsuperiority and effectiveness of the proposed method compared with\nstate-of-the-art methods. From the evaluation results and analysis, we specify\nseveral potential future directions for visible-thermal MOT. The project is\nreleased in https://github.com/wqw123wqw/PFTrack.\n","authors":["Yabin Zhu","Qianwu Wang","Chenglong Li","Jin Tang","Zhixiang Huang"],"pdf_url":"https://arxiv.org/pdf/2408.00969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00967v1","updated":"2024-08-02T01:24:01Z","published":"2024-08-02T01:24:01Z","title":"Extracting Object Heights From LiDAR & Aerial Imagery","summary":"  This work shows a procedural method for extracting object heights from LiDAR\nand aerial imagery. We discuss how to get heights and the future of LiDAR and\nimagery processing. SOTA object segmentation allows us to take get object\nheights with no deep learning background. Engineers will be keeping track of\nworld data across generations and reprocessing them. They will be using older\nprocedural methods like this paper and newer ones discussed here. SOTA methods\nare going beyond analysis and into generative AI. We cover both a procedural\nmethodology and the newer ones performed with language models. These include\npoint cloud, imagery and text encoding allowing for spatially aware AI.\n","authors":["Jesus Guerrero"],"pdf_url":"https://arxiv.org/pdf/2408.00967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09786v5","updated":"2024-08-02T01:22:46Z","published":"2024-01-18T08:10:34Z","title":"Adaptive Self-training Framework for Fine-grained Scene Graph Generation","summary":"  Scene graph generation (SGG) models have suffered from inherent problems\nregarding the benchmark datasets such as the long-tailed predicate distribution\nand missing annotation problems. In this work, we aim to alleviate the\nlong-tailed problem of SGG by utilizing unannotated triplets. To this end, we\nintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels\nfor unannotated triplets based on which the SGG models are trained. While there\nhas been significant progress in self-training for image recognition, designing\na self-training framework for the SGG task is more challenging due to its\ninherent nature such as the semantic ambiguity and the long-tailed distribution\nof predicate classes. Hence, we propose a novel pseudo-labeling technique for\nSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is\na model-agnostic framework that can be applied to any existing SGG models.\nFurthermore, we devise a graph structure learner (GSL) that is beneficial when\nadopting our proposed self-training framework to the state-of-the-art\nmessage-passing neural network (MPNN)-based SGG models. Our extensive\nexperiments verify the effectiveness of ST-SGG on various SGG models,\nparticularly in enhancing the performance on fine-grained predicate classes.\n","authors":["Kibum Kim","Kanghoon Yoon","Yeonjun In","Jinyoung Moon","Donghyun Kim","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2401.09786v5.pdf","comment":"9 pages; ICLR 2024"},{"id":"http://arxiv.org/abs/2311.13186v2","updated":"2024-08-02T00:56:39Z","published":"2023-11-22T06:26:24Z","title":"Applications of Spiking Neural Networks in Visual Place Recognition","summary":"  In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for\ntheir largely-unrealized potential energy efficiency and low latency\nparticularly when implemented on neuromorphic hardware. Our paper highlights\nthree advancements for SNNs in Visual Place Recognition (VPR). Firstly, we\npropose Modular SNNs, where each SNN represents a set of non-overlapping\ngeographically distinct places, enabling scalable networks for large\nenvironments. Secondly, we present Ensembles of Modular SNNs, where multiple\nnetworks represent the same place, significantly enhancing accuracy compared to\nsingle-network models. Each of our Modular SNN modules is compact, comprising\nonly 1500 neurons and 474k synapses, making them ideally suited for ensembling\ndue to their small size. Lastly, we investigate the role of sequence matching\nin SNN-based VPR, a technique where consecutive images are used to refine place\nrecognition. We analyze the responsiveness of SNNs to ensembling and sequence\nmatching compared to other VPR techniques. Our contributions highlight the\nviability of SNNs for VPR, offering scalable and robust solutions, and paving\nthe way for their application in various energy-sensitive robotic tasks.\n","authors":["Somayeh Hussaini","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2311.13186v2.pdf","comment":"20 pages, 10 figures, under review"},{"id":"http://arxiv.org/abs/2408.00963v1","updated":"2024-08-02T00:35:18Z","published":"2024-08-02T00:35:18Z","title":"MIS-ME: A Multi-modal Framework for Soil Moisture Estimation","summary":"  Soil moisture estimation is an important task to enable precision agriculture\nin creating optimal plans for irrigation, fertilization, and harvest. It is\ncommon to utilize statistical and machine learning models to estimate soil\nmoisture from traditional data sources such as weather forecasts, soil\nproperties, and crop properties. However, there is a growing interest in\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\nthese images capture high-resolution crop details, they are expensive to curate\nand challenging to interpret. Imagine, an AI-enhanced software tool that\npredicts soil moisture using visual cues captured by smartphones and\nstatistical data given by weather forecasts. This work is a first step towards\nthat goal of developing a multi-modal approach for soil moisture estimation. In\nparticular, we curate a dataset consisting of real-world images taken from\nground stations and their corresponding weather data. We also propose MIS-ME -\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\ndata, highlighting the effectiveness of tailored multi-modal approaches.\n","authors":["Mohammed Rakib","Adil Aman Mohammed","Cole Diggins","Sumit Sharma","Jeff Michael Sadler","Tyson Ochsner","Arun Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2408.00963v1.pdf","comment":"Accepted by DSAA2024"},{"id":"http://arxiv.org/abs/2404.07514v2","updated":"2024-08-02T00:06:55Z","published":"2024-04-11T07:11:43Z","title":"Generalization Gap in Data Augmentation: Insights from Illumination","summary":"  In the field of computer vision, data augmentation is widely used to enrich\nthe feature complexity of training datasets with deep learning techniques.\nHowever, regarding the generalization capabilities of models, the difference in\nartificial features generated by data augmentation and natural visual features\nhas not been fully revealed. This study introduces the concept of \"visual\nrepresentation variables\" to define the possible visual variations in a task as\na joint distribution of these variables. We focus on the visual representation\nvariable \"illumination\", by simulating its distribution degradation and\nexamining how data augmentation techniques enhance model performance on a\nclassification task. Our goal is to investigate the differences in\ngeneralization between models trained with augmented data and those trained\nunder real-world illumination conditions. Results indicate that after applying\nvarious data augmentation methods, model performance has significantly\nimproved. Yet, a noticeable generalization gap still exists after utilizing\nvarious data augmentation methods, emphasizing the critical role of feature\ndiversity in the training set for enhancing model generalization.\n","authors":["Jianqiang Xiao","Weiwen Guo","Junfeng Liu","Mengze Li"],"pdf_url":"https://arxiv.org/pdf/2404.07514v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2402.16827v3","updated":"2024-08-02T17:59:31Z","published":"2024-02-26T18:54:35Z","title":"A Survey on Data Selection for Language Models","summary":"  A major factor in the recent success of large language models is the use of\nenormous and ever-growing text datasets for unsupervised pre-training. However,\nnaively training a model on all available data may not be optimal (or\nfeasible), as the quality of available text data can vary. Filtering out data\ncan also decrease the carbon footprint and financial costs of training models\nby reducing the amount of training required. Data selection methods aim to\ndetermine which candidate data points to include in the training dataset and\nhow to appropriately sample from the selected data points. The promise of\nimproved data selection methods has caused the volume of research in the area\nto rapidly expand. However, because deep learning is mostly driven by empirical\nevidence and experimentation on large-scale data is expensive, few\norganizations have the resources for extensive data selection research.\nConsequently, knowledge of effective data selection practices has become\nconcentrated within a few organizations, many of which do not openly share\ntheir findings and methodologies. To narrow this gap in knowledge, we present a\ncomprehensive review of existing literature on data selection methods and\nrelated research areas, providing a taxonomy of existing approaches. By\ndescribing the current landscape of research, this work aims to accelerate\nprogress in data selection by establishing an entry point for new and\nestablished researchers. Additionally, throughout this review we draw attention\nto noticeable holes in the literature and conclude the paper by proposing\npromising avenues for future research.\n","authors":["Alon Albalak","Yanai Elazar","Sang Michael Xie","Shayne Longpre","Nathan Lambert","Xinyi Wang","Niklas Muennighoff","Bairu Hou","Liangming Pan","Haewon Jeong","Colin Raffel","Shiyu Chang","Tatsunori Hashimoto","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2402.16827v3.pdf","comment":"Paper list available at\n  https://github.com/alon-albalak/data-selection-survey"},{"id":"http://arxiv.org/abs/2408.01420v1","updated":"2024-08-02T17:55:50Z","published":"2024-08-02T17:55:50Z","title":"Mission Impossible: A Statistical Perspective on Jailbreaking LLMs","summary":"  Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.\n","authors":["Jingtong Su","Julia Kempe","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2408.01420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01417v1","updated":"2024-08-02T17:51:57Z","published":"2024-08-02T17:51:57Z","title":"Talk Less, Interact Better: Evaluating In-context Conversational\n  Adaptation in Multimodal LLMs","summary":"  Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.\n","authors":["Yilun Hua","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2408.01417v1.pdf","comment":"Accepted to COLM 2024"},{"id":"http://arxiv.org/abs/2408.01416v1","updated":"2024-08-02T17:51:42Z","published":"2024-08-02T17:51:42Z","title":"The Quest for the Right Mediator: A History, Survey, and Theoretical\n  Grounding of Causal Interpretability","summary":"  Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.\n","authors":["Aaron Mueller","Jannik Brinkmann","Millicent Li","Samuel Marks","Koyena Pal","Nikhil Prakash","Can Rager","Aruna Sankaranarayanan","Arnab Sen Sharma","Jiuding Sun","Eric Todd","David Bau","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2408.01416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01415v1","updated":"2024-08-02T17:43:34Z","published":"2024-08-02T17:43:34Z","title":"Conditional LoRA Parameter Generation","summary":"  Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.\n","authors":["Xiaolong Jin","Kai Wang","Dongwen Tang","Wangbo Zhao","Yukun Zhou","Junshu Tang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2408.01415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01408v1","updated":"2024-08-02T17:33:52Z","published":"2024-08-02T17:33:52Z","title":"Derivation of Back-propagation for Graph Convolutional Networks using\n  Matrix Calculus and its Application to Explainable Artificial Intelligence","summary":"  This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.\n","authors":["Yen-Che Hsiao","Rongting Yue","Abhishek Dutta"],"pdf_url":"https://arxiv.org/pdf/2408.01408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15501v4","updated":"2024-08-02T17:31:24Z","published":"2021-10-29T02:38:54Z","title":"Doubly Robust Interval Estimation for Optimal Policy Evaluation in\n  Online Learning","summary":"  Evaluating the performance of an ongoing policy plays a vital role in many\nareas such as medicine and economics, to provide crucial instructions on the\nearly-stop of the online experiment and timely feedback from the environment.\nPolicy evaluation in online learning thus attracts increasing attention by\ninferring the mean outcome of the optimal policy (i.e., the value) in\nreal-time. Yet, such a problem is particularly challenging due to the dependent\ndata generated in the online environment, the unknown optimal policy, and the\ncomplex exploration and exploitation trade-off in the adaptive experiment. In\nthis paper, we aim to overcome these difficulties in policy evaluation for\nonline learning. We explicitly derive the probability of exploration that\nquantifies the probability of exploring non-optimal actions under commonly used\nbandit algorithms. We use this probability to conduct valid inference on the\nonline conditional mean estimator under each action and develop the doubly\nrobust interval estimation (DREAM) method to infer the value under the\nestimated optimal policy in online learning. The proposed value estimator\nprovides double protection for consistency and is asymptotically normal with a\nWald-type confidence interval provided. Extensive simulation studies and real\ndata applications are conducted to demonstrate the empirical validity of the\nproposed DREAM method.\n","authors":["Ye Shen","Hengrui Cai","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2110.15501v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01402v1","updated":"2024-08-02T17:25:34Z","published":"2024-08-02T17:25:34Z","title":"Pre-trained Language Models Improve the Few-shot Prompt Ability of\n  Decision Transformer","summary":"  Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.\n","authors":["Yu Yang","Pan Xu"],"pdf_url":"https://arxiv.org/pdf/2408.01402v1.pdf","comment":"2 figures, 8 tables. Accepted by the Training Agents with Foundation\n  Models Workshop at RLC 2024"},{"id":"http://arxiv.org/abs/2407.19631v2","updated":"2024-08-02T17:10:43Z","published":"2024-07-29T01:22:04Z","title":"\"A Good Bot Always Knows Its Limitations\": Assessing Autonomous System\n  Decision-making Competencies through Factorized Machine Self-confidence","summary":"  How can intelligent machines assess their competencies in completing tasks?\nThis question has come into focus for autonomous systems that algorithmically\nreason and make decisions under uncertainty. It is argued here that machine\nself-confidence - a form of meta-reasoning based on self-assessments of an\nagent's knowledge about the state of the world and itself, as well as its\nability to reason about and execute tasks - leads to many eminently computable\nand useful competency indicators for such agents. This paper presents a\nculmination of work on this concept in the form of a computational framework\ncalled Factorized Machine Self-confidence (FaMSeC), which provides a holistic\nengineering-focused description of factors driving an algorithmic\ndecision-making process, including: outcome assessment, solver quality, model\nquality, alignment quality, and past experience. In FaMSeC, self confidence\nindicators are derived from hierarchical `problem-solving statistics' embedded\nwithin broad classes of probabilistic decision-making algorithms such as Markov\ndecision processes. The problem-solving statistics are obtained by evaluating\nand grading probabilistic exceedance margins with respect to given competency\nstandards, which are specified for each of the various decision-making\ncompetency factors by the informee (e.g. a non-expert user or an expert system\ndesigner). This approach allows `algorithmic goodness of fit' evaluations to be\neasily incorporated into the design of many kinds of autonomous agents in the\nform of human-interpretable competency self-assessment reports. Detailed\ndescriptions and application examples for a Markov decision process agent show\nhow two of the FaMSeC factors (outcome assessment and solver quality) can be\ncomputed and reported for a range of possible tasking contexts through novel\nuse of meta-utility functions, behavior simulations, and surrogate prediction\nmodels.\n","authors":["Brett Israelsen","Nisar R. Ahmed","Matthew Aitken","Eric W. Frew","Dale A. Lawrence","Brian M. Argrow"],"pdf_url":"https://arxiv.org/pdf/2407.19631v2.pdf","comment":"59 pages, 22 figures, draft to be submitted for journal review"},{"id":"http://arxiv.org/abs/2408.01391v1","updated":"2024-08-02T17:01:36Z","published":"2024-08-02T17:01:36Z","title":"FT K-Means: A High-Performance K-Means on GPU with Fault Tolerance","summary":"  K-Means is a widely used algorithm in clustering, however, its efficiency is\nprimarily constrained by the computational cost of distance computing. Existing\nimplementations suffer from suboptimal utilization of computational units and\nlack resilience against soft errors. To address these challenges, we introduce\nFT K-Means, a high-performance GPU-accelerated implementation of K-Means with\nonline fault tolerance. We first present a stepwise optimization strategy that\nachieves competitive performance compared to NVIDIA's cuML library. We further\nimprove FT K-Means with a template-based code generation framework that\nsupports different data types and adapts to different input shapes. A novel\nwarp-level tensor-core error correction scheme is proposed to address the\nfailure of existing fault tolerance methods due to memory asynchronization\nduring copy operations. Our experimental evaluations on NVIDIA T4 GPU and A100\nGPU demonstrate that FT K-Means without fault tolerance outperforms cuML's\nK-Means implementation, showing a performance increase of 10\\%-300\\% in\nscenarios involving irregular data shapes. Moreover, the fault tolerance\nfeature of FT K-Means introduces only an overhead of 11\\%, maintaining robust\nperformance even with tens of errors injected per second.\n","authors":["Shixun Wu","Yitong Ding","Yujia Zhai","Jinyang Liu","Jiajun Huang","Zizhe Jian","Huangliang Dai","Sheng Di","Bryan M. Wong","Zizhong Chen","Franck Cappello"],"pdf_url":"https://arxiv.org/pdf/2408.01391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01387v1","updated":"2024-08-02T16:55:08Z","published":"2024-08-02T16:55:08Z","title":"NeuralBeta: Estimating Beta Using Deep Learning","summary":"  Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.\n","authors":["Yuxin Liu","Jimin Lin","Achintya Gopal"],"pdf_url":"https://arxiv.org/pdf/2408.01387v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.20328v2","updated":"2024-08-02T16:51:52Z","published":"2024-03-29T17:59:05Z","title":"Learning Visual Quadrupedal Loco-Manipulation from Demonstrations","summary":"  Quadruped robots are progressively being integrated into human environments.\nDespite the growing locomotion capabilities of quadrupedal robots, their\ninteraction with objects in realistic scenes is still limited. While additional\nrobotic arms on quadrupedal robots enable manipulating objects, they are\nsometimes redundant given that a quadruped robot is essentially a mobile unit\nequipped with four limbs, each possessing 3 degrees of freedom (DoFs). Hence,\nwe aim to empower a quadruped robot to execute real-world manipulation tasks\nusing only its legs. We decompose the loco-manipulation process into a\nlow-level reinforcement learning (RL)-based controller and a high-level\nBehavior Cloning (BC)-based planner. By parameterizing the manipulation\ntrajectory, we synchronize the efforts of the upper and lower layers, thereby\nleveraging the advantages of both RL and BC. Our approach is validated through\nsimulations and real-world experiments, demonstrating the robot's ability to\nperform tasks that demand mobility and high precision, such as lifting a basket\nfrom the ground while moving, closing a dishwasher, pressing a button, and\npushing a door. Project website: https://zhengmaohe.github.io/leg-manip\n","authors":["Zhengmao He","Kun Lei","Yanjie Ze","Koushil Sreenath","Zhongyu Li","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2403.20328v2.pdf","comment":"Published at IROS 2024. Project website:\n  https://zhengmaohe.github.io/leg-manip"},{"id":"http://arxiv.org/abs/2408.01382v1","updated":"2024-08-02T16:40:58Z","published":"2024-08-02T16:40:58Z","title":"Explaining a probabilistic prediction on the simplex with Shapley\n  compositions","summary":"  Originating in game theory, Shapley values are widely used for explaining a\nmachine learning model's prediction by quantifying the contribution of each\nfeature's value to the prediction. This requires a scalar prediction as in\nbinary classification, whereas a multiclass probabilistic prediction is a\ndiscrete probability distribution, living on a multidimensional simplex. In\nsuch a multiclass setting the Shapley values are typically computed separately\non each class in a one-vs-rest manner, ignoring the compositional nature of the\noutput distribution. In this paper, we introduce Shapley compositions as a\nwell-founded way to properly explain a multiclass probabilistic prediction,\nusing the Aitchison geometry from compositional data analysis. We prove that\nthe Shapley composition is the unique quantity satisfying linearity, symmetry\nand efficiency on the Aitchison simplex, extending the corresponding axiomatic\nproperties of the standard Shapley value. We demonstrate this proper multiclass\ntreatment in a range of scenarios.\n","authors":["Paul-Gauthier Noé","Miquel Perelló-Nieto","Jean-François Bonastre","Peter Flach"],"pdf_url":"https://arxiv.org/pdf/2408.01382v1.pdf","comment":"To be published in ECAI2024's proceedings"},{"id":"http://arxiv.org/abs/2408.01379v1","updated":"2024-08-02T16:37:33Z","published":"2024-08-02T16:37:33Z","title":"Resampling and averaging coordinates on data","summary":"  We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.\n","authors":["Andrew J. Blumberg","Mathieu Carriere","Jun Hou Fung","Michael A. Mandell"],"pdf_url":"https://arxiv.org/pdf/2408.01379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01375v1","updated":"2024-08-02T16:32:30Z","published":"2024-08-02T16:32:30Z","title":"Adaptive Recruitment Resource Allocation to Improve Cohort\n  Representativeness in Participatory Biomedical Datasets","summary":"  Large participatory biomedical studies, studies that recruit individuals to\njoin a dataset, are gaining popularity and investment, especially for analysis\nby modern AI methods. Because they purposively recruit participants, these\nstudies are uniquely able to address a lack of historical representation, an\nissue that has affected many biomedical datasets. In this work, we define\nrepresentativeness as the similarity to a target population distribution of a\nset of attributes and our goal is to mirror the U.S. population across\ndistributions of age, gender, race, and ethnicity. Many participatory studies\nrecruit at several institutions, so we introduce a computational approach to\nadaptively allocate recruitment resources among sites to improve\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\nmedical centers in the STAR Clinical Research Network, we show that our\napproach yields a more representative cohort than existing baselines. Thus, we\nhighlight the value of computational modeling in guiding recruitment efforts.\n","authors":["Victor Borza","Andrew Estornell","Ellen Wright Clayton","Chien-Ju Ho","Russell Rothman","Yevgeniy Vorobeychik","Bradley Malin"],"pdf_url":"https://arxiv.org/pdf/2408.01375v1.pdf","comment":"Accepted for publication at the American Medical Informatics\n  Association Annual Symposium 2024, 10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.11652v3","updated":"2024-08-02T16:30:55Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v3.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2408.01374v1","updated":"2024-08-02T16:29:54Z","published":"2024-08-02T16:29:54Z","title":"Hybrid Coordinate Descent for Efficient Neural Network Learning Using\n  Line Search and Gradient Descent","summary":"  This paper presents a novel coordinate descent algorithm leveraging a\ncombination of one-directional line search and gradient information for\nparameter updates for a squared error loss function. Each parameter undergoes\nupdates determined by either the line search or gradient method, contingent\nupon whether the modulus of the gradient of the loss with respect to that\nparameter surpasses a predefined threshold. Notably, a larger threshold value\nenhances algorithmic efficiency. Despite the potentially slower nature of the\nline search method relative to gradient descent, its parallelizability\nfacilitates computational time reduction. Experimental validation conducted on\na 2-layer Rectified Linear Unit network with synthetic data elucidates the\nimpact of hyperparameters on convergence rates and computational efficiency.\n","authors":["Yen-Che Hsiao","Abhishek Dutta"],"pdf_url":"https://arxiv.org/pdf/2408.01374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01365v1","updated":"2024-08-02T16:17:59Z","published":"2024-08-02T16:17:59Z","title":"Data Debugging is NP-hard for Classifiers Trained with SGD","summary":"  Data debugging is to find a subset of the training data such that the model\nobtained by retraining on the subset has a better accuracy. A bunch of\nheuristic approaches are proposed, however, none of them are guaranteed to\nsolve this problem effectively. This leaves an open issue whether there exists\nan efficient algorithm to find the subset such that the model obtained by\nretraining on it has a better accuracy. To answer this open question and\nprovide theoretical basis for further study on developing better algorithms for\ndata debugging, we investigate the computational complexity of the problem\nnamed Debuggable. Given a machine learning model $\\mathcal{M}$ obtained by\ntraining on dataset $D$ and a test instance\n$(\\mathbf{x}_\\text{test},y_\\text{test})$ where\n$\\mathcal{M}(\\mathbf{x}_\\text{test})\\neq y_\\text{test}$, Debuggable is to\ndetermine whether there exists a subset $D^\\prime$ of $D$ such that the model\n$\\mathcal{M}^\\prime$ obtained by retraining on $D^\\prime$ satisfies\n$\\mathcal{M}^\\prime(\\mathbf{x}_\\text{test})=y_\\text{test}$. To cover a wide\nrange of commonly used models, we take SGD-trained linear classifier as the\nmodel and derive the following main results. (1) If the loss function and the\ndimension of the model are not fixed, Debuggable is NP-complete regardless of\nthe training order in which all the training samples are processed during SGD.\n(2) For hinge-like loss functions, a comprehensive analysis on the\ncomputational complexity of Debuggable is provided; (3) If the loss function is\na linear function, Debuggable can be solved in linear time, that is, data\ndebugging can be solved easily in this case. These results not only highlight\nthe limitations of current approaches but also offer new insights into data\ndebugging.\n","authors":["Zizheng Guo","Pengyu Chen","Yanzhang Fu","Dongjing Miao"],"pdf_url":"https://arxiv.org/pdf/2408.01365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01362v1","updated":"2024-08-02T16:13:51Z","published":"2024-08-02T16:13:51Z","title":"Autoencoders in Function Space","summary":"  Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.\n","authors":["Justin Bunker","Mark Girolami","Hefin Lambley","Andrew M. Stuart","T. J. Sullivan"],"pdf_url":"https://arxiv.org/pdf/2408.01362v1.pdf","comment":"56 pages, 25 figures"},{"id":"http://arxiv.org/abs/2406.04551v2","updated":"2024-08-02T16:09:49Z","published":"2024-06-06T23:35:51Z","title":"Improving Geo-diversity of Generated Images with Contextualized Vendi\n  Score Guidance","summary":"  With the growing popularity of text-to-image generative models, there has\nbeen increasing focus on understanding their risks and biases. Recent work has\nfound that state-of-the-art models struggle to depict everyday objects with the\ntrue diversity of the real world and have notable gaps between geographic\nregions. In this work, we aim to increase the diversity of generated images of\ncommon objects such that per-region variations are representative of the real\nworld. We introduce an inference time intervention, contextualized Vendi Score\nGuidance (c-VSG), that guides the backwards steps of latent diffusion models to\nincrease the diversity of a sample as compared to a \"memory bank\" of previously\ngenerated images while constraining the amount of variation within that of an\nexemplar set of real-world contextualizing images. We evaluate c-VSG with two\ngeographically representative datasets and find that it substantially increases\nthe diversity of generated images, both for the worst performing regions and on\naverage, while simultaneously maintaining or improving image quality and\nconsistency. Additionally, qualitative analyses reveal that diversity of\ngenerated images is significantly improved, including along the lines of\nreductive region portrayals present in the original model. We hope that this\nwork is a step towards text-to-image generative models that reflect the true\ngeographic diversity of the world.\n","authors":["Reyhane Askari Hemmat","Melissa Hall","Alicia Sun","Candace Ross","Michal Drozdzal","Adriana Romero-Soriano"],"pdf_url":"https://arxiv.org/pdf/2406.04551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05737v3","updated":"2024-08-02T16:09:14Z","published":"2023-02-11T16:26:57Z","title":"A Reparameterized Discrete Diffusion Model for Text Generation","summary":"  This work studies discrete diffusion probabilistic models with applications\nto natural language generation. We derive an alternative yet equivalent\nformulation of the sampling from discrete diffusion processes and leverage this\ninsight to develop a family of reparameterized discrete diffusion models. The\nderived generic framework is highly flexible, offers a fresh perspective of the\ngeneration process in discrete diffusion models, and features more effective\ntraining and decoding techniques. We conduct extensive experiments to evaluate\nthe text generation capability of our model, demonstrating significant\nimprovements over existing diffusion models.\n","authors":["Lin Zheng","Jianbo Yuan","Lei Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05737v3.pdf","comment":"COLM 2024; Code available at\n  https://github.com/hkunlp/reparam-discrete-diffusion"},{"id":"http://arxiv.org/abs/2408.01349v1","updated":"2024-08-02T15:54:49Z","published":"2024-08-02T15:54:49Z","title":"PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy\n  Correspondence Learning in Cross-Modal Retrieval","summary":"  In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.\n","authors":["Yue Duan","Zhangxuan Gu","Zhenzhe Ying","Lei Qi","Changhua Meng","Yinghuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.01349v1.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2403.13940v2","updated":"2024-08-02T15:54:21Z","published":"2024-03-20T19:25:11Z","title":"A multi-criteria approach for selecting an explanation from the set of\n  counterfactuals produced by an ensemble of explainers","summary":"  Counterfactuals are widely used to explain ML model predictions by providing\nalternative scenarios for obtaining the more desired predictions. They can be\ngenerated by a variety of methods that optimize different, sometimes\nconflicting, quality measures and produce quite different solutions. However,\nchoosing the most appropriate explanation method and one of the generated\ncounterfactuals is not an easy task. Instead of forcing the user to test many\ndifferent explanation methods and analysing conflicting solutions, in this\npaper, we propose to use a multi-stage ensemble approach that will select\nsingle counterfactual based on the multiple-criteria analysis. It offers a\ncompromise solution that scores well on several popular quality measures. This\napproach exploits the dominance relation and the ideal point decision aid\nmethod, which selects one counterfactual from the Pareto front. The conducted\nexperiments demonstrated that the proposed approach generates fully actionable\ncounterfactuals with attractive compromise values of the considered quality\nmeasures.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2403.13940v2.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.01343v1","updated":"2024-08-02T15:41:16Z","published":"2024-08-02T15:41:16Z","title":"StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal\n  Semantic Segmentation","summary":"  Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.\n","authors":["Bingyu Li","Da Zhang","Zhiyuan Zhao","Junyu Gao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.01343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11891v3","updated":"2024-08-02T15:38:38Z","published":"2023-10-18T11:20:59Z","title":"A Hyperparameter Study for Quantum Kernel Methods","summary":"  Quantum kernel methods are a promising method in quantum machine learning\nthanks to the guarantees connected to them. Their accessibility for analytic\nconsiderations also opens up the possibility of prescreening datasets based on\ntheir potential for a quantum advantage. To do so, earlier works developed the\ngeometric difference, which can be understood as a closeness measure between\ntwo kernel-based machine learning approaches, most importantly between a\nquantum kernel and a classical kernel. This metric links the quantum and\nclassical model complexities, and it was developed to bound generalization\nerror. Therefore, it raises the question of how this metric behaves in an\nempirical setting. In this work, we investigate the effects of hyperparameter\nchoice on the model performance and the generalization gap between classical\nand quantum kernels. The importance of hyperparameters is well known also for\nclassical machine learning. Of special interest are hyperparameters associated\nwith the quantum Hamiltonian evolution feature map, as well as the number of\nqubits to trace out before computing a projected quantum kernel. We conduct a\nthorough investigation of the hyperparameters across 11 datasets and we\nidentify certain aspects that can be exploited. Analyzing the effects of\ncertain hyperparameter settings on the empirical performance, as measured by\ncross validation accuracy, and generalization ability, as measured by geometric\ndifference described above, brings us one step closer to understanding the\npotential of quantum kernel methods on classical datasets.\n","authors":["Sebastian Egginger","Alona Sakhnenko","Jeanette Miriam Lorenz"],"pdf_url":"https://arxiv.org/pdf/2310.11891v3.pdf","comment":"Expanded implications of the paper"},{"id":"http://arxiv.org/abs/2408.01337v1","updated":"2024-08-02T15:34:05Z","published":"2024-08-02T15:34:05Z","title":"MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language\n  Models","summary":"  Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.\n","authors":["Benno Weck","Ilaria Manco","Emmanouil Benetos","Elio Quinton","George Fazekas","Dmitry Bogdanov"],"pdf_url":"https://arxiv.org/pdf/2408.01337v1.pdf","comment":"Accepted at ISMIR 2024. Data: https://doi.org/10.5281/zenodo.12709974\n  Code: https://github.com/mulab-mir/muchomusic Supplementary material:\n  https://mulab-mir.github.io/muchomusic"},{"id":"http://arxiv.org/abs/2408.01336v1","updated":"2024-08-02T15:33:04Z","published":"2024-08-02T15:33:04Z","title":"Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and\n  Contaminated by Outliers","summary":"  We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.\n","authors":["Takeyuki Sasai","Hironori Fujisawa"],"pdf_url":"https://arxiv.org/pdf/2408.01336v1.pdf","comment":"This research builds on and improves the results of arxiv:2206.07594.\n  There will be no further update for the earlier manuscript"},{"id":"http://arxiv.org/abs/2404.02476v3","updated":"2024-08-02T15:30:14Z","published":"2024-04-03T05:32:10Z","title":"Deep Reinforcement Learning for Traveling Purchaser Problems","summary":"  The traveling purchaser problem (TPP) is an important combinatorial\noptimization problem with broad applications. Due to the coupling between\nrouting and purchasing, existing works on TPPs commonly address route\nconstruction and purchase planning simultaneously, which, however, leads to\nexact methods with high computational cost and heuristics with sophisticated\ndesign but limited performance. In sharp contrast, we propose a novel approach\nbased on deep reinforcement learning (DRL), which addresses route construction\nand purchase planning separately, while evaluating and optimizing the solution\nfrom a global perspective. The key components of our approach include a\nbipartite graph representation for TPPs to capture the market-product\nrelations, and a policy network that extracts information from the bipartite\ngraph and uses it to sequentially construct the route. One significant benefit\nof our framework is that we can efficiently construct the route using the\npolicy network, and once the route is determined, the associated purchasing\nplan can be easily derived through linear programming, while, leveraging DRL,\nwe can train the policy network to optimize the global solution objective.\nFurthermore, by introducing a meta-learning strategy, the policy network can be\ntrained stably on large-sized TPP instances, and generalize well across\ninstances of varying sizes and distributions, even to much larger instances\nthat are never seen during training. Experiments on various synthetic TPP\ninstances and the TPPLIB benchmark demonstrate that our DRL-based approach can\nsignificantly outperform well-established TPP heuristics, reducing the\noptimality gap by 40%-90%, and also showing an advantage in runtime, especially\non large-sized instances.\n","authors":["Haofeng Yuan","Rongping Zhu","Wanlu Yang","Shiji Song","Keyou You","Yuli Zhang","C. L. Philip Chen"],"pdf_url":"https://arxiv.org/pdf/2404.02476v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01332v1","updated":"2024-08-02T15:29:59Z","published":"2024-08-02T15:29:59Z","title":"HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate\n  Prediction","summary":"  As the recommendation service needs to address increasingly diverse\ndistributions, such as multi-population, multi-scenario, multitarget, and\nmulti-interest, more and more recent works have focused on multi-distribution\nmodeling and achieved great progress. However, most of them only consider\nmodeling in a single multi-distribution manner, ignoring that mixed\nmulti-distributions often coexist and form hierarchical relationships. To\naddress these challenges, we propose a flexible modeling paradigm, named\nHierarchical Multi-Distribution Network (HMDN), which efficiently models these\nhierarchical relationships and can seamlessly integrate with existing\nmulti-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight\n(DW) models. Specifically, we first design a hierarchical multi-distribution\nrepresentation refinement module, employing a multi-level residual quantization\nto obtain fine-grained hierarchical representation. Then, the refined\nhierarchical representation is integrated into the existing single\nmulti-distribution models, seamlessly expanding them into mixed\nmulti-distribution models. Experimental results on both public and industrial\ndatasets validate the effectiveness and flexibility of HMDN.\n","authors":["Xingyu Lou","Yu Yang","Kuiyao Dong","Heyuan Huang","Wenyi Yu","Ping Wang","Xiu Li","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01331v1","updated":"2024-08-02T15:29:39Z","published":"2024-08-02T15:29:39Z","title":"UnifiedNN: Efficient Neural Network Training on the Cloud","summary":"  Nowadays, cloud-based services are widely favored over the traditional\napproach of locally training a Neural Network (NN) model. Oftentimes, a cloud\nservice processes multiple requests from users--thus training multiple NN\nmodels concurrently. However, training NN models concurrently is a challenging\nprocess, which typically requires significant amounts of available computing\nresources and takes a long time to complete. In this paper, we present\nUnifiedNN to effectively train multiple NN models concurrently on the cloud.\nUnifiedNN effectively \"combines\" multiple NN models and features several memory\nand time conservation mechanisms to train multiple NN models simultaneously\nwithout impacting the accuracy of the training process. Specifically, UnifiedNN\nmerges multiple NN models and creates a large singular unified model in order\nto efficiently train all models at once. We have implemented a prototype of\nUnifiedNN in PyTorch and we have compared its performance with relevant\nstate-of-the-art frameworks. Our experimental results demonstrate that\nUnifiedNN can reduce memory consumption by up to 53% and training time by up to\n81% when compared with vanilla PyTorch without impacting the model training and\ntesting accuracy. Finally, our results indicate that UnifiedNN can reduce\nmemory consumption by up to 52% and training time by up to 41% when compared to\nstate-of-the-art frameworks when training multiple models concurrently.\n","authors":["Sifat Ut Taki","Spyridon Mastorakis","Arthi Padmanabhan"],"pdf_url":"https://arxiv.org/pdf/2408.01331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00736v4","updated":"2024-08-02T15:26:37Z","published":"2023-01-02T16:11:05Z","title":"Mixed moving average field guided learning for spatio-temporal data","summary":"  Influenced mixed moving average fields are a versatile modeling class for\nspatio-temporal data. However, their predictive distribution is not generally\nknown. Under this modeling assumption, we define a novel spatio-temporal\nembedding and a theory-guided machine learning approach that employs a\ngeneralized Bayesian algorithm to make ensemble forecasts. We use Lipschitz\npredictors and determine fixed-time and any-time PAC Bayesian bounds in the\nbatch learning setting. Performing causal forecast is a highlight of our\nmethodology as its potential application to data with spatial and temporal\nshort and long-range dependence. We then test the performance of our learning\nmethodology by using linear predictors and data sets simulated from a\nspatio-temporal Ornstein-Uhlenbeck process.\n","authors":["Imma Valentina Curato","Orkun Furat","Lorenzo Proietti","Bennet Stroeh"],"pdf_url":"https://arxiv.org/pdf/2301.00736v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02659v2","updated":"2024-08-02T15:13:26Z","published":"2024-07-02T20:49:21Z","title":"LLMs Plagiarize: Ensuring Responsible Sourcing of Large Language Model\n  Training Data Through Knowledge Graph Comparison","summary":"  In light of recent legal allegations brought by publishers, newspapers, and\nother creators of copyrighted corpora against large language model developers\nwho use their copyrighted materials for training or fine-tuning purposes, we\npropose a novel system, a variant of a plagiarism detection system, that\nassesses whether a knowledge source has been used in the training or\nfine-tuning of a large language model. Unlike current methods, we utilize an\napproach that uses Resource Description Framework (RDF) triples to create\nknowledge graphs from both a source document and an LLM continuation of that\ndocument. These graphs are then analyzed with respect to content using cosine\nsimilarity and with respect to structure using a normalized version of graph\nedit distance that shows the degree of isomorphism. Unlike traditional\nplagiarism systems that focus on content matching and keyword identification\nbetween a source and a target corpus, our approach enables a broader and more\naccurate evaluation of similarity between a source document and LLM\ncontinuation by focusing on relationships between ideas and their organization\nwith regards to others. Additionally, our approach does not require access to\nLLM metrics like perplexity that may be unavailable in closed large language\nmodel \"black-box\" systems, as well as the training corpus. We thus assess\nwhether an LLM has \"plagiarized\" a corpus in its continuation through\nsimilarity measures. A prototype of our system will be found on a hyperlinked\nGitHub repository.\n","authors":["Devam Mondal","Carlo Lipizzi"],"pdf_url":"https://arxiv.org/pdf/2407.02659v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01318v1","updated":"2024-08-02T15:12:52Z","published":"2024-08-02T15:12:52Z","title":"Point Prediction for Streaming Data","summary":"  We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.\n","authors":["Aleena Chanda","N. V. Vinodchandran","Bertrand Clarke"],"pdf_url":"https://arxiv.org/pdf/2408.01318v1.pdf","comment":"42 pages, two figures"},{"id":"http://arxiv.org/abs/2408.01307v1","updated":"2024-08-02T15:00:04Z","published":"2024-08-02T15:00:04Z","title":"Decentralized Smoothing ADMM for Quantile Regression with Non-Convex\n  Sparse Penalties","summary":"  In the rapidly evolving internet-of-things (IoT) ecosystem, effective data\nanalysis techniques are crucial for handling distributed data generated by\nsensors. Addressing the limitations of existing methods, such as the\nsub-gradient approach, which fails to distinguish between active and non-active\ncoefficients effectively, this paper introduces the decentralized smoothing\nalternating direction method of multipliers (DSAD) for penalized quantile\nregression. Our method leverages non-convex sparse penalties like the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), improving\nthe identification and retention of significant predictors. DSAD incorporates a\ntotal variation norm within a smoothing ADMM framework, achieving consensus\namong distributed nodes and ensuring uniform model performance across disparate\ndata sources. This approach overcomes traditional convergence challenges\nassociated with non-convex penalties in decentralized settings. We present\ntheoretical proofs and extensive simulation results to validate the\neffectiveness of the DSAD, demonstrating its superiority in achieving reliable\nconvergence and enhancing estimation accuracy compared with prior methods.\n","authors":["Reza Mirzaeifard","Diyako Ghaderyan","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2408.01307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13586v2","updated":"2024-08-02T14:59:48Z","published":"2024-05-22T12:30:25Z","title":"Bond Graphs for multi-physics informed Neural Networks for multi-variate\n  time series","summary":"  In the trend of hybrid Artificial Intelligence techniques, Physical-Informed\nMachine Learning has seen a growing interest. It operates mainly by imposing\ndata, learning, or architecture bias with simulation data, Partial Differential\nEquations, or equivariance and invariance properties. While it has shown great\nsuccess on tasks involving one physical domain, such as fluid dynamics,\nexisting methods are not adapted to tasks with complex multi-physical and\nmulti-domain phenomena. In addition, it is mainly formulated as an end-to-end\nlearning scheme. To address these challenges, we propose to leverage Bond\nGraphs, a multi-physics modeling approach, together with Message Passing Graph\nNeural Networks. We propose a Neural Bond graph Encoder (NBgE) producing\nmulti-physics-informed representations that can be fed into any task-specific\nmodel. It provides a unified way to integrate both data and architecture biases\nin deep learning. Our experiments on two challenging multi-domain physical\nsystems - a Direct Current Motor and the Respiratory System - demonstrate the\neffectiveness of our approach on a multivariate time-series forecasting task.\n","authors":["Alexis-Raja Brachet","Pierre-Yves Richard","Céline Hudelot"],"pdf_url":"https://arxiv.org/pdf/2405.13586v2.pdf","comment":"9 pages, 3 figures, paper under review"},{"id":"http://arxiv.org/abs/2407.21043v2","updated":"2024-08-02T14:58:54Z","published":"2024-07-22T04:07:12Z","title":"CP-Prompt: Composition-Based Cross-modal Prompting for\n  Domain-Incremental Continual Learning","summary":"  The key challenge of cross-modal domain-incremental learning (DIL) is to\nenable the learning model to continuously learn from novel data with different\nfeature distributions under the same task without forgetting old ones. However,\nexisting top-performing methods still cause high forgetting rates, by lacking\nintra-domain knowledge extraction and inter-domain common prompting strategy.\nIn this paper, we propose a simple yet effective framework, CP-Prompt, by\ntraining limited parameters to instruct a pre-trained model to learn new\ndomains and avoid forgetting existing feature distributions. CP-Prompt captures\nintra-domain knowledge by compositionally inserting personalized prompts on\nmulti-head self-attention layers and then learns the inter-domain knowledge\nwith a common prompting strategy. CP-Prompt shows superiority compared with\nstate-of-the-art baselines among three widely evaluated DIL tasks. The source\ncode is available at https://github.com/dannis97500/CP_Prompt.\n","authors":["Yu Feng","Zhen Tian","Yifan Zhu","Zongfu Han","Haoran Luo","Guangwei Zhang","Meina Song"],"pdf_url":"https://arxiv.org/pdf/2407.21043v2.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2401.13979v2","updated":"2024-08-02T14:50:05Z","published":"2024-01-25T06:45:32Z","title":"Routoo: Learning to Route to Large Language Models Effectively","summary":"  Developing foundational large language models (LLMs) is becoming increasingly\ncostly and inefficient. Also, closed-source and larger open-source models\ngenerally offer better response quality but come with higher inference costs\nthan smaller models. In this paper, we introduce Routoo, an architecture\ndesigned to optimize the selection of LLMs for specific prompts based on\nperformance, cost, and efficiency. Routoo consists of two key components: a\nperformance predictor and a cost-aware decoding. The performance predictor is a\nlightweight LLM that estimates the performance of various underlying LLMs\nwithout needing to execute and evaluate them. The cost-aware decoding then\nselects the most suitable model based on these predictions and other\nconstraints like cost and latency. We evaluated Routoo using the MMLU benchmark\nacross 57 domains employing open-source models. Our results show that Routoo\nmatches the performance of the Mixtral 8x7b model while reducing inference\ncosts by one-third. Additionally, by allowing increased costs, Routoo surpasses\nMixtral's accuracy by over 5% at equivalent costs, achieving an accuracy of\n75.9%. When integrating GPT4 into our model pool, Routoo nearly matches GPT4's\nperformance at half the cost and exceeds it with a 25% cost reduction. These\noutcomes highlight Routoo's potential to create new SOTA in a cost-effective\nmanner by leveraging the collective knowledge of multiple LLMs.\n","authors":["Alireza Mohammadshahi","Arshad Rafiq Shaikh","Majid Yazdani"],"pdf_url":"https://arxiv.org/pdf/2401.13979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01301v1","updated":"2024-08-02T14:43:45Z","published":"2024-08-02T14:43:45Z","title":"A Decision-driven Methodology for Designing Uncertainty-aware AI\n  Self-Assessment","summary":"  Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.\n","authors":["Gregory Canal","Vladimir Leung","Philip Sage","Eric Heim","I-Jeng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01300v1","updated":"2024-08-02T14:41:36Z","published":"2024-08-02T14:41:36Z","title":"Assessing Robustness of Machine Learning Models using Covariate\n  Perturbations","summary":"  As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.\n","authors":["Arun Prakash R","Anwesha Bhattacharyya","Joel Vaughan","Vijayan N. Nair"],"pdf_url":"https://arxiv.org/pdf/2408.01300v1.pdf","comment":"31 pages, 11 figures, 14 tables"},{"id":"http://arxiv.org/abs/2408.00713v2","updated":"2024-08-02T14:40:19Z","published":"2024-08-01T16:58:54Z","title":"Reinforcement Learning applied to Insurance Portfolio Pursuit","summary":"  When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. We term\nthe problem of modulating offers to achieve a desired target portfolio the\nportfolio pursuit problem. Having formulated the portfolio pursuit problem as a\nsequential decision making problem, we devise a novel reinforcement learning\nalgorithm for its solution. We test our method on a complex synthetic market\nenvironment, and demonstrate that it outperforms a baseline method which mimics\ncurrent industry approaches to portfolio pursuit.\n","authors":["Edward James Young","Alistair Rogers","Elliott Tong","James Jordon"],"pdf_url":"https://arxiv.org/pdf/2408.00713v2.pdf","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.01297v1","updated":"2024-08-02T14:37:28Z","published":"2024-08-02T14:37:28Z","title":"Optimal Mixed Integer Linear Optimization Trained Multivariate\n  Classification Trees","summary":"  Multivariate decision trees are powerful machine learning tools for\nclassification and regression that attract many researchers and industry\nprofessionals. An optimal binary tree has two types of vertices, (i) branching\nvertices which have exactly two children and where datapoints are assessed on a\nset of discrete features and (ii) leaf vertices at which datapoints are given a\nprediction, and can be obtained by solving a biobjective optimization problem\nthat seeks to (i) maximize the number of correctly classified datapoints and\n(ii) minimize the number of branching vertices. Branching vertices are linear\ncombinations of training features and therefore can be thought of as\nhyperplanes. In this paper, we propose two cut-based mixed integer linear\noptimization (MILO) formulations for designing optimal binary classification\ntrees (leaf vertices assign discrete classes). Our models leverage on-the-fly\nidentification of minimal infeasible subsystems (MISs) from which we derive\ncutting planes that hold the form of packing constraints. We show theoretical\nimprovements on the strongest flow-based MILO formulation currently in the\nliterature and conduct experiments on publicly available datasets to show our\nmodels' ability to scale, strength against traditional branch and bound\napproaches, and robustness in out-of-sample test performance. Our code and data\nare available on GitHub.\n","authors":["Brandon Alston","Illya V. Hicks"],"pdf_url":"https://arxiv.org/pdf/2408.01297v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2206.04857"},{"id":"http://arxiv.org/abs/2405.03389v2","updated":"2024-08-02T14:33:32Z","published":"2024-05-06T11:51:09Z","title":"Don't Waste Your Time: Early Stopping Cross-Validation","summary":"  State-of-the-art automated machine learning systems for tabular data often\nemploy cross-validation; ensuring that measured performances generalize to\nunseen data, or that subsequent ensembling does not overfit. However, using\nk-fold cross-validation instead of holdout validation drastically increases the\ncomputational cost of validating a single configuration. While ensuring better\ngeneralization and, by extension, better performance, the additional cost is\noften prohibitive for effective model selection within a time budget. We aim to\nmake model selection with cross-validation more effective. Therefore, we study\nearly stopping the process of cross-validation during model selection. We\ninvestigate the impact of early stopping on random search for two algorithms,\nMLP and random forest, across 36 classification datasets. We further analyze\nthe impact of the number of folds by considering 3-, 5-, and 10-folds. In\naddition, we investigate the impact of early stopping with Bayesian\noptimization instead of random search and also repeated cross-validation. Our\nexploratory study shows that even a simple-to-understand and easy-to-implement\nmethod consistently allows model selection to converge faster; in ~94% of all\ndatasets, on average by ~214%. Moreover, stopping cross-validation enables\nmodel selection to explore the search space more exhaustively by considering\n+167% configurations on average within one hour, while also obtaining better\noverall performance.\n","authors":["Edward Bergman","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2405.03389v2.pdf","comment":"Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024); for code, see\n  https://github.com/automl/DontWasteYourTime-early-stopping"},{"id":"http://arxiv.org/abs/2408.01294v1","updated":"2024-08-02T14:31:37Z","published":"2024-08-02T14:31:37Z","title":"Feature Clock: High-Dimensional Effects in Two-Dimensional Plots","summary":"  Humans struggle to perceive and interpret high-dimensional data. Therefore,\nhigh-dimensional data are often projected into two dimensions for\nvisualization. Many applications benefit from complex nonlinear dimensionality\nreduction techniques, but the effects of individual high-dimensional features\nare hard to explain in the two-dimensional space. Most visualization solutions\nuse multiple two-dimensional plots, each showing the effect of one\nhigh-dimensional feature in two dimensions; this approach creates a need for a\nvisual inspection of k plots for a k-dimensional input space. Our solution,\nFeature Clock, provides a novel approach that eliminates the need to inspect\nthese k plots to grasp the influence of original features on the data structure\ndepicted in two dimensions. Feature Clock enhances the explainability and\ncompactness of visualizations of embedded data and is available in an\nopen-source Python library.\n","authors":["Olga Ovcharenko","Rita Sevastjanova","Valentina Boeva"],"pdf_url":"https://arxiv.org/pdf/2408.01294v1.pdf","comment":"To be published in IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2407.14962v3","updated":"2024-08-02T14:26:55Z","published":"2024-07-20T18:48:35Z","title":"Recent Advances in Generative AI and Large Language Models: Current\n  Status, Challenges, and Perspectives","summary":"  The emergence of Generative Artificial Intelligence (AI) and Large Language\nModels (LLMs) has marked a new era of Natural Language Processing (NLP),\nintroducing unprecedented capabilities that are revolutionizing various\ndomains. This paper explores the current state of these cutting-edge\ntechnologies, demonstrating their remarkable advancements and wide-ranging\napplications. Our paper contributes to providing a holistic perspective on the\ntechnical foundations, practical applications, and emerging challenges within\nthe evolving landscape of Generative AI and LLMs. We believe that understanding\nthe generative capabilities of AI systems and the specific context of LLMs is\ncrucial for researchers, practitioners, and policymakers to collaboratively\nshape the responsible and ethical integration of these technologies into\nvarious domains. Furthermore, we identify and address main research gaps,\nproviding valuable insights to guide future research endeavors within the AI\nresearch community.\n","authors":["Desta Haileselassie Hagos","Rick Battle","Danda B. Rawat"],"pdf_url":"https://arxiv.org/pdf/2407.14962v3.pdf","comment":"This version is accepted for publication in the journal of IEEE\n  Transactions on Artificial Intelligence (TAI)"},{"id":"http://arxiv.org/abs/2308.11635v2","updated":"2024-08-02T14:25:40Z","published":"2023-08-13T23:54:40Z","title":"Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive\n  Learning for Cross-Subject EEG-based Emotion Recognition","summary":"  Electroencephalography (EEG) is an objective tool for emotion recognition\nwith promising applications. However, the scarcity of labeled data remains a\nmajor challenge in this field, limiting the widespread use of EEG-based emotion\nrecognition. In this paper, a semi-supervised Dual-stream Self-Attentive\nAdversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed\nto tackle the challenge of limited labeled data in cross-subject EEG-based\nemotion recognition. The DS-AGC framework includes two parallel streams for\nextracting non-structural and structural EEG features. The non-structural\nstream incorporates a semi-supervised multi-domain adaptation method to\nalleviate distribution discrepancy among labeled source domain, unlabeled\nsource domain, and unknown target domain. The structural stream develops a\ngraph contrastive learning method to extract effective graph-based feature\nrepresentation from multiple EEG channels in a semi-supervised manner. Further,\na self-attentive fusion module is developed for feature fusion, sample\nselection, and emotion recognition, which highlights EEG features more relevant\nto emotions and data samples in the labeled source domain that are closer to\nthe target domain. Extensive experiments conducted on two benchmark databases\n(SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out\ncross-validation evaluation scheme show that the proposed model outperforms\nexisting methods under different incomplete label conditions (with an average\nimprovement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its\neffectiveness in addressing the label scarcity problem in cross-subject\nEEG-based emotion recognition.\n","authors":["Weishan Ye","Zhiguo Zhang","Fei Teng","Min Zhang","Jianhong Wang","Dong Ni","Fali Li","Peng Xu","Zhen Liang"],"pdf_url":"https://arxiv.org/pdf/2308.11635v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2304.06496"},{"id":"http://arxiv.org/abs/2408.01283v1","updated":"2024-08-02T14:09:39Z","published":"2024-08-02T14:09:39Z","title":"A Tiny Supervised ODL Core with Auto Data Pruning for Human Activity\n  Recognition","summary":"  In this paper, we introduce a low-cost and low-power tiny supervised\non-device learning (ODL) core that can address the distributional shift of\ninput data for human activity recognition. Although ODL for resource-limited\nedge devices has been studied recently, how exactly to provide the training\nlabels to these devices at runtime remains an open-issue. To address this\nproblem, we propose to combine an automatic data pruning with supervised ODL to\nreduce the number queries needed to acquire predicted labels from a nearby\nteacher device and thus save power consumption during model retraining. The\ndata pruning threshold is automatically tuned, eliminating a manual threshold\ntuning. As a tinyML solution at a few mW for the human activity recognition, we\ndesign a supervised ODL core that supports our automatic data pruning using a\n45nm CMOS process technology. We show that the required memory size for the\ncore is smaller than the same-shaped multilayer perceptron (MLP) and the power\nconsumption is only 3.39mW. Experiments using a human activity recognition\ndataset show that the proposed automatic data pruning reduces the communication\nvolume by 55.7% and power consumption accordingly with only 0.9% accuracy loss.\n","authors":["Hiroki Matsutani","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2408.01283v1.pdf","comment":"IEEE BSN 2024 (accepted)"},{"id":"http://arxiv.org/abs/2310.04561v2","updated":"2024-08-02T14:08:59Z","published":"2023-10-06T19:55:40Z","title":"DragD3D: Realistic Mesh Editing with Rigidity Control Driven by 2D\n  Diffusion Priors","summary":"  Direct mesh editing and deformation are key components in the geometric\nmodeling and animation pipeline. Mesh editing methods are typically framed as\noptimization problems combining user-specified vertex constraints with a\nregularizer that determines the position of the rest of the vertices. The\nchoice of the regularizer is key to the realism and authenticity of the final\nresult. Physics and geometry-based regularizers are not aware of the global\ncontext and semantics of the object, and the more recent deep learning priors\nare limited to a specific class of 3D object deformations. Our main\ncontribution is a vertex-based mesh editing method called DragD3D based on (1)\na novel optimization formulation that decouples the rotation and stretch\ncomponents of the deformation and combines a 3D geometric regularizer with (2)\nthe recently introduced DDS loss which scores the faithfulness of the rendered\n2D image to one from a diffusion model. Thus, our deformation method achieves\nglobally realistic shape deformation which is not restricted to any class of\nobjects. Our new formulation optimizes directly the transformation of the\nneural Jacobian field explicitly separating the rotational and stretching\ncomponents. The objective function of the optimization combines the approximate\ngradients of DDS and the gradients from the geometric loss to satisfy the\nvertex constraints. Additional user control over desired global shape\ndeformation is made possible by allowing explicit per-triangle deformation\ncontrol as well as explicit separation of rotational and stretching components\nof the deformation. We show that our deformations can be controlled to yield\nrealistic shape deformations that are aware of the global context of the\nobjects, and provide better results than just using geometric regularizers.\n","authors":["Tianhao Xie","Eugene Belilovsky","Sudhir Mudur","Tiberiu Popa"],"pdf_url":"https://arxiv.org/pdf/2310.04561v2.pdf","comment":"11 pages, 8 figures, project page:\n  https://tianhaoxie.github.io/project/DragD3D/"},{"id":"http://arxiv.org/abs/2404.09916v2","updated":"2024-08-02T13:59:12Z","published":"2024-04-15T16:43:13Z","title":"Comprehensive Library of Variational LSE Solvers","summary":"  Linear systems of equations can be found in various mathematical domains, as\nwell as in the field of machine learning. By employing noisy intermediate-scale\nquantum devices, variational solvers promise to accelerate finding solutions\nfor large systems. Although there is a wealth of theoretical research on these\nalgorithms, only fragmentary implementations exist. To fill this gap, we have\ndeveloped the variational-lse-solver framework, which realizes existing\napproaches in literature, and introduces several enhancements. The\nuser-friendly interface is designed for researchers that work at the\nabstraction level of identifying and developing end-to-end applications.\n","authors":["Nico Meyer","Martin Röhn","Jakob Murauer","Axel Plinge","Christopher Mutschler","Daniel D. Scherer"],"pdf_url":"https://arxiv.org/pdf/2404.09916v2.pdf","comment":"Accepted to the 2nd International Workshop on Quantum Machine\n  Learning: From Research to Practice (QML@QCE 2024), Montr\\'eal, Qu\\'ebec,\n  Canada. 4 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2408.01273v1","updated":"2024-08-02T13:55:26Z","published":"2024-08-02T13:55:26Z","title":"Certified Robust Invariant Polytope Training in Neural Controlled ODEs","summary":"  We consider a nonlinear control system modeled as an ordinary differential\nequation subject to disturbance, with a state feedback controller parameterized\nas a feedforward neural network. We propose a framework for training\ncontrollers with certified robust forward invariant polytopes, where any\ntrajectory initialized inside the polytope remains within the polytope,\nregardless of the disturbance. First, we parameterize a family of lifted\ncontrol systems in a higher dimensional space, where the original neural\ncontrolled system evolves on an invariant subspace of each lifted system. We\nuse interval analysis and neural network verifiers to further construct a\nfamily of lifted embedding systems, carefully capturing the knowledge of this\ninvariant subspace. If the vector field of any lifted embedding system\nsatisfies a sign constraint at a single point, then a certain convex polytope\nof the original system is robustly forward invariant. Treating the neural\nnetwork controller and the lifted system parameters as variables, we propose an\nalgorithm to train controllers with certified forward invariant polytopes in\nthe closed-loop control system. Through two examples, we demonstrate how the\nsimplicity of the sign constraint allows our approach to scale with system\ndimension to over $50$ states, and outperform state-of-the-art Lyapunov-based\nsampling approaches in runtime.\n","authors":["Akash Harapanahalli","Samuel Coogan"],"pdf_url":"https://arxiv.org/pdf/2408.01273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02604v2","updated":"2024-08-02T13:45:53Z","published":"2024-07-02T18:43:10Z","title":"D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data\n  and eXpert model predictions","summary":"  Large vision language models (VLMs) have progressed incredibly from research\nto applicability for general-purpose use cases. LLaVA-Med, a pioneering large\nlanguage and vision assistant for biomedicine, can perform multi-modal\nbiomedical image and data analysis to provide a natural language interface for\nradiologists. While it is highly generalizable and works with multi-modal data,\nit is currently limited by well-known challenges that exist in the large\nlanguage model space. Hallucinations and imprecision in responses can lead to\nmisdiagnosis which currently hinder the clinical adaptability of VLMs. To\ncreate precise, user-friendly models in healthcare, we propose D-Rax -- a\ndomain-specific, conversational, radiologic assistance tool that can be used to\ngain insights about a particular radiologic image. In this study, we enhance\nthe conversational analysis of chest X-ray (CXR) images to support radiological\nreporting, offering comprehensive insights from medical imaging and aiding in\nthe formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the\nLLaVA-Med architecture on our curated enhanced instruction-following data,\ncomprising of images, instructions, as well as disease diagnosis and\ndemographic predictions derived from MIMIC-CXR imaging data, CXR-related visual\nquestion answer (VQA) pairs, and predictive outcomes from multiple expert AI\nmodels. We observe statistically significant improvement in responses when\nevaluated for both open and close-ended conversations. Leveraging the power of\nstate-of-the-art diagnostic models combined with VLMs, D-Rax empowers\nclinicians to interact with medical images using natural language, which could\npotentially streamline their decision-making process, enhance diagnostic\naccuracy, and conserve their time.\n","authors":["Hareem Nisar","Syed Muhammad Anwar","Zhifan Jiang","Abhijeet Parida","Ramon Sanchez-Jacob","Vishwesh Nath","Holger R. Roth","Marius George Linguraru"],"pdf_url":"https://arxiv.org/pdf/2407.02604v2.pdf","comment":"accepted to the MICCAI 2024 Second International Workshop on\n  Foundation Models for General Medical AI"},{"id":"http://arxiv.org/abs/2408.01257v1","updated":"2024-08-02T13:27:56Z","published":"2024-08-02T13:27:56Z","title":"Detection and Characterization of Coordinated Online Behavior: A Survey","summary":"  Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.\n","authors":["Lorenzo Mannocci","Michele Mazza","Anna Monreale","Maurizio Tesconi","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2408.01257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15327v2","updated":"2024-08-02T13:25:16Z","published":"2024-06-21T17:40:46Z","title":"Fine-grained Attention in Hierarchical Transformers for Tabular\n  Time-series","summary":"  Tabular data is ubiquitous in many real-life systems. In particular,\ntime-dependent tabular data, where rows are chronologically related, is\ntypically used for recording historical events, e.g., financial transactions,\nhealthcare records, or stock history. Recently, hierarchical variants of the\nattention mechanism of transformer architectures have been used to model\ntabular time-series data. At first, rows (or columns) are encoded separately by\ncomputing attention between their fields. Subsequently, encoded rows (or\ncolumns) are attended to one another to model the entire tabular time-series.\nWhile efficient, this approach constrains the attention granularity and limits\nits ability to learn patterns at the field-level across separate rows, or\ncolumns. We take a first step to address this gap by proposing Fieldy, a\nfine-grained hierarchical model that contextualizes fields at both the row and\ncolumn levels. We compare our proposal against state of the art models on\nregression and classification tasks using public tabular time-series datasets.\nOur results show that combining row-wise and column-wise attention improves\nperformance without increasing model size. Code and data are available at\nhttps://github.com/raphaaal/fieldy.\n","authors":["Raphael Azorin","Zied Ben Houidi","Massimo Gallo","Alessandro Finamore","Pietro Michiardi"],"pdf_url":"https://arxiv.org/pdf/2406.15327v2.pdf","comment":"9 pages; Camera Ready version"},{"id":"http://arxiv.org/abs/2305.18493v3","updated":"2024-08-02T13:16:48Z","published":"2023-05-29T13:47:51Z","title":"Insights from the Design Space Exploration of Flow-Guided Nanoscale\n  Localization","summary":"  Nanodevices with Terahertz (THz)-based wireless communication capabilities\nare providing a primer for flow-guided localization within the human\nbloodstreams. Such localization is allowing for assigning the locations of\nsensed events with the events themselves, providing benefits along the lines of\nearly and precise diagnostics, and reduced costs and invasiveness. Flow-guided\nlocalization is still in a rudimentary phase, with only a handful of works\ntargeting the problem. Nonetheless, the performance assessments of the proposed\nsolutions are already carried out in a non-standardized way, usually along a\nsingle performance metric, and ignoring various aspects that are relevant at\nsuch a scale (e.g., nanodevices' limited energy) and for such a challenging\nenvironment (e.g., extreme attenuation of in-body THz propagation). As such,\nthese assessments feature low levels of realism and cannot be compared in an\nobjective way. Toward addressing this issue, we account for the environmental\nand scale-related peculiarities of the scenario and assess the performance of\ntwo state-of-the-art flow-guided localization approaches along a set of\nheterogeneous performance metrics such as the accuracy and reliability of\nlocalization.\n","authors":["Filip Lemic","Gerard Calvo Bartra","Arnau Brosa López","Jorge Torres Gómez","Jakob Struye","Falko Dressler","Sergi Abadal","Xavier Costa Perez"],"pdf_url":"https://arxiv.org/pdf/2305.18493v3.pdf","comment":"6 pages, 4 figures, 2 tables, 14 references, accepted at ACM\n  NanoCom'24"},{"id":"http://arxiv.org/abs/2408.01248v1","updated":"2024-08-02T13:10:33Z","published":"2024-08-02T13:10:33Z","title":"Deep progressive reinforcement learning-based flexible resource\n  scheduling framework for IRS and UAV-assisted MEC system","summary":"  The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.\n","authors":["Li Dong","Feibo Jiang","Minjie Wang","Yubo Peng","Xiaolong Li"],"pdf_url":"https://arxiv.org/pdf/2408.01248v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2408.01244v1","updated":"2024-08-02T13:05:33Z","published":"2024-08-02T13:05:33Z","title":"Automated Classification of Dry Bean Varieties Using XGBoost and SVM\n  Models","summary":"  This paper presents a comparative study on the automated classification of\nseven different varieties of dry beans using machine learning models.\nLeveraging a dataset of 12,909 dry bean samples, reduced from an initial 13,611\nthrough outlier removal and feature extraction, we applied Principal Component\nAnalysis (PCA) for dimensionality reduction and trained two multiclass\nclassifiers: XGBoost and Support Vector Machine (SVM). The models were\nevaluated using nested cross-validation to ensure robust performance assessment\nand hyperparameter tuning. The XGBoost and SVM models achieved overall correct\nclassification rates of 94.00% and 94.39%, respectively. The results underscore\nthe efficacy of these machine learning approaches in agricultural applications,\nparticularly in enhancing the uniformity and efficiency of seed classification.\nThis study contributes to the growing body of work on precision agriculture,\ndemonstrating that automated systems can significantly support seed quality\ncontrol and crop yield optimization. Future work will explore incorporating\nmore diverse datasets and advanced algorithms to further improve classification\naccuracy.\n","authors":["Ramtin Ardeshirifar"],"pdf_url":"https://arxiv.org/pdf/2408.01244v1.pdf","comment":"8 pages, 4 figurs"},{"id":"http://arxiv.org/abs/2407.21310v2","updated":"2024-08-02T13:03:00Z","published":"2024-07-31T03:26:14Z","title":"MSMA: Multi-agent Trajectory Prediction in Connected and Autonomous\n  Vehicle Environment with Multi-source Data Integration","summary":"  The prediction of surrounding vehicle trajectories is crucial for\ncollision-free path planning. In this study, we focus on a scenario where a\nconnected and autonomous vehicle (CAV) serves as the central agent, utilizing\nboth sensors and communication technologies to perceive its surrounding\ntraffics consisting of autonomous vehicles (AVs), connected vehicles (CVs), and\nhuman-driven vehicles (HDVs). Our trajectory prediction task is aimed at all\nthe detected surrounding vehicles. To effectively integrate the multi-source\ndata from both sensor and communication technologies, we propose a deep\nlearning framework called MSMA utilizing a cross-attention module for\nmulti-source data fusion. Vector map data is utilized to provide contextual\ninformation. The trajectory dataset is collected in CARLA simulator with\nsynthesized data errors introduced. Numerical experiments demonstrate that in a\nmixed traffic flow scenario, the integration of data from different sources\nenhances our understanding of the environment. This notably improves trajectory\nprediction accuracy, particularly in situations with a high CV market\npenetration rate. The code is available at: https://github.com/xichennn/MSMA.\n","authors":["Xi Chen","Rahul Bhadani","Zhanbo Sun","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2407.21310v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09602v2","updated":"2024-08-02T13:00:54Z","published":"2024-07-12T18:00:02Z","title":"Real-time gravitational-wave inference for binary neutron stars using\n  machine learning","summary":"  Mergers of binary neutron stars (BNSs) emit signals in both the\ngravitational-wave (GW) and electromagnetic (EM) spectra. Famously, the 2017\nmulti-messenger observation of GW170817 led to scientific discoveries across\ncosmology, nuclear physics, and gravity. Central to these results were the sky\nlocalization and distance obtained from GW data, which, in the case of\nGW170817, helped to identify the associated EM transient, AT 2017gfo, 11 hours\nafter the GW signal. Fast analysis of GW data is critical for directing\ntime-sensitive EM observations; however, due to challenges arising from the\nlength and complexity of signals, it is often necessary to make approximations\nthat sacrifice accuracy. Here, we present a machine learning framework that\nperforms complete BNS inference in just one second without making any such\napproximations. Our approach enhances multi-messenger observations by providing\n(i) accurate localization even before the merger; (ii) improved localization\nprecision by $\\sim30\\%$ compared to approximate low-latency methods; and (iii)\ndetailed information on luminosity distance, inclination, and masses, which can\nbe used to prioritize expensive telescope time. Additionally, the flexibility\nand reduced cost of our method open new opportunities for equation-of-state\nstudies. Finally, we demonstrate that our method scales to extremely long\nsignals, up to an hour in length, thus serving as a blueprint for data analysis\nfor next-generation ground- and space-based detectors.\n","authors":["Maximilian Dax","Stephen R. Green","Jonathan Gair","Nihar Gupte","Michael Pürrer","Vivien Raymond","Jonas Wildberger","Jakob H. Macke","Alessandra Buonanno","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2407.09602v2.pdf","comment":"8+8 pages, 3+7 figures"},{"id":"http://arxiv.org/abs/2408.00374v2","updated":"2024-08-02T13:00:46Z","published":"2024-08-01T08:32:03Z","title":"Conformal Trajectory Prediction with Multi-View Data Integration in\n  Cooperative Driving","summary":"  Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\n\\url{https://github.com/xichennn/V2I_trajectory_prediction}.\n","authors":["Xi Chen","Rahul Bhadani","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2408.00374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01239v1","updated":"2024-08-02T12:58:08Z","published":"2024-08-02T12:58:08Z","title":"Tailoring Graph Neural Network-based Flow-guided Localization to\n  Individual Bloodstreams and Activities","summary":"  Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.\n","authors":["Pablo Galván","Filip Lemic","Gerard Calvo Bartra","Sergi Abadal","Xavier Costa Pérez"],"pdf_url":"https://arxiv.org/pdf/2408.01239v1.pdf","comment":"7 pages, 9 figures, 2 tables, 16 references, accepted at ACM\n  NanoCom'25"},{"id":"http://arxiv.org/abs/2408.01230v1","updated":"2024-08-02T12:40:01Z","published":"2024-08-02T12:40:01Z","title":"HeteroMorpheus: Universal Control Based on Morphological Heterogeneity\n  Modeling","summary":"  In the field of robotic control, designing individual controllers for each\nrobot leads to high computational costs. Universal control policies, applicable\nacross diverse robot morphologies, promise to mitigate this challenge.\nPredominantly, models based on Graph Neural Networks (GNN) and Transformers are\nemployed, owing to their effectiveness in capturing relational dynamics across\na robot's limbs. However, these models typically employ homogeneous graph\nstructures that overlook the functional diversity of different limbs. To bridge\nthis gap, we introduce HeteroMorpheus, a novel method based on heterogeneous\ngraph Transformer. This method uniquely addresses limb heterogeneity, fostering\nbetter representation of robot dynamics of various morphologies. Through\nextensive experiments we demonstrate the superiority of HeteroMorpheus against\nstate-of-the-art methods in the capability of policy generalization, including\nzero-shot generalization and sample-efficient transfer to unfamiliar robot\nmorphologies.\n","authors":["YiFan Hao","Yang Yang","Junru Song","Wei Peng","Weien Zhou","Tingsong Jiang","Wen Yao"],"pdf_url":"https://arxiv.org/pdf/2408.01230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01215v1","updated":"2024-08-02T12:04:19Z","published":"2024-08-02T12:04:19Z","title":"ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network\n  Training","summary":"  The rapid advancements in deep learning necessitate efficient training\nmethods for deep neural networks (DNNs). As models grow in complexity,\nvanishing and exploding gradients impede convergence and performance. We\npropose Z-Score Normalization for Gradient Descent (ZNorm), an innovative\ntechnique that adjusts only the gradients to enhance training efficiency and\nimprove model performance. ZNorm normalizes the overall gradients, providing\nconsistent gradient scaling across layers, thereby reducing the risks of\nvanishing and exploding gradients. Our extensive experiments on CIFAR-10 and\nmedical datasets demonstrate that ZNorm not only accelerates convergence but\nalso enhances performance metrics. ZNorm consistently outperforms existing\nmethods, achieving superior results using the same computational settings. In\nmedical imaging applications, ZNorm improves tumor prediction and segmentation\nperformances, underscoring its practical utility. These findings highlight\nZNorm's potential as a robust and versatile tool for improving the efficiency\nand effectiveness of deep neural network training across a wide range of\narchitectures and applications.\n","authors":["Juyoung Yun","Hoyoung Kim","Suin Cho","Hangil Kang"],"pdf_url":"https://arxiv.org/pdf/2408.01215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00950v2","updated":"2024-08-02T11:54:57Z","published":"2023-12-13T12:57:55Z","title":"Unsupervised Graph-based Learning Method for Sub-band Allocation in 6G\n  Subnetworks","summary":"  In this paper, we present an unsupervised approach for frequency sub-band\nallocation in wireless networks using graph-based learning. We consider a dense\ndeployment of subnetworks in the factory environment with a limited number of\nsub-bands which must be optimally allocated to coordinate inter-subnetwork\ninterference. We model the subnetwork deployment as a conflict graph and\npropose an unsupervised learning approach inspired by the graph colouring\nheuristic and the Potts model to optimize the sub-band allocation using graph\nneural networks. The numerical evaluation shows that the proposed method\nachieves close performance to the centralized greedy colouring sub-band\nallocation heuristic with lower computational time complexity. In addition, it\nincurs reduced signalling overhead compared to iterative optimization\nheuristics that require all the mutual interfering channel information. We\nfurther demonstrate that the method is robust to different network settings.\n","authors":["Daniel Abode","Ramoni Adeogun","Lou Salaün","Renato Abreu","Thomas Jacobsen","Gilberto Berardinelli"],"pdf_url":"https://arxiv.org/pdf/2401.00950v2.pdf","comment":"Accepted in VTC Fall 2024"},{"id":"http://arxiv.org/abs/2408.01200v1","updated":"2024-08-02T11:29:21Z","published":"2024-08-02T11:29:21Z","title":"Certifiably Robust Encoding Schemes","summary":"  Quantum machine learning uses principles from quantum mechanics to process\ndata, offering potential advances in speed and performance. However, previous\nwork has shown that these models are susceptible to attacks that manipulate\ninput data or exploit noise in quantum circuits. Following this, various\nstudies have explored the robustness of these models. These works focus on the\nrobustness certification of manipulations of the quantum states. We extend this\nline of research by investigating the robustness against perturbations in the\nclassical data for a general class of data encoding schemes. We show that for\nsuch schemes, the addition of suitable noise channels is equivalent to\nevaluating the mean value of the noiseless classifier at the smoothed data,\nakin to Randomized Smoothing from classical machine learning. Using our general\nframework, we show that suitable additions of phase-damping noise channels\nimprove empirical and provable robustness for the considered class of encoding\nschemes.\n","authors":["Aman Saxena","Tom Wollschläger","Nicola Franco","Jeanette Miriam Lorenz","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2408.01200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01187v1","updated":"2024-08-02T11:14:41Z","published":"2024-08-02T11:14:41Z","title":"Optimizing Variational Quantum Circuits Using Metaheuristic Strategies\n  in Reinforcement Learning","summary":"  Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.\n","authors":["Michael Kölle","Daniel Seidl","Maximilian Zorn","Philipp Altmann","Jonas Stein","Thomas Gabor"],"pdf_url":"https://arxiv.org/pdf/2408.01187v1.pdf","comment":"Accepted at QCE24 - QCRL24 Workshop"},{"id":"http://arxiv.org/abs/2408.01180v1","updated":"2024-08-02T11:02:38Z","published":"2024-08-02T11:02:38Z","title":"Nested Music Transformer: Sequentially Decoding Compound Tokens in\n  Symbolic Music and Audio Generation","summary":"  Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.\n","authors":["Jiwoo Ryu","Hao-Wen Dong","Jongmin Jung","Dasaem Jeong"],"pdf_url":"https://arxiv.org/pdf/2408.01180v1.pdf","comment":"Accepted at 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024)"},{"id":"http://arxiv.org/abs/2408.01173v1","updated":"2024-08-02T10:47:10Z","published":"2024-08-02T10:47:10Z","title":"Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven\n  Digital Twins in Industrial Cyber-Physical Systems","summary":"  Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\nmanufacturing and industries. By digitizing data throughout the product life\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\nconstruction and update of DTs to improve predictive accuracy and prepare for\ndiverse smart manufacturing. However, mechanisms that leverage sensing\nIndustrial Internet of Things (IIoT) devices to share data for the construction\nof DTs are susceptible to adverse selection problems. In this paper, we first\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\nselection problem caused by information asymmetry, we propose a contract theory\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\nto identify the optimal feasible contract. Specifically, we leverage the\ndynamic structured pruning technique to reduce parameter numbers of actor\nnetworks, allowing sustainability and efficient implementation of the proposed\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\nproposed scheme.\n","authors":["Jinbo Wen","Jiawen Kang","Dusit Niyato","Yang Zhang","Shiwen Mao"],"pdf_url":"https://arxiv.org/pdf/2408.01173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01163v1","updated":"2024-08-02T10:25:19Z","published":"2024-08-02T10:25:19Z","title":"Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from\n  visual perception to mental imagery","summary":"  In cognitive neuroscience and brain-computer interface research, accurately\npredicting imagined stimuli is crucial. This study investigates the\neffectiveness of Domain Adaptation (DA) in enhancing imagery prediction using\nprimarily visual data from fMRI scans of 18 subjects. Initially, we train a\nbaseline model on visual stimuli to predict imagined stimuli, utilizing data\nfrom 14 brain regions. We then develop several models to improve imagery\nprediction, comparing different DA methods. Our results demonstrate that DA\nsignificantly enhances imagery prediction, especially with the Regular Transfer\napproach. We then conduct a DA-enhanced searchlight analysis using Regular\nTransfer, followed by permutation-based statistical tests to identify brain\nregions where imagery decoding is consistently above chance across subjects.\nOur DA-enhanced searchlight predicts imagery contents in a highly distributed\nset of brain regions, including the visual cortex and the frontoparietal\ncortex, thereby outperforming standard cross-domain classification methods. The\ncomplete code and data for this paper have been made openly available for the\nuse of the scientific community.\n","authors":["Alexander Olza","David Soto","Roberto Santana"],"pdf_url":"https://arxiv.org/pdf/2408.01163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01156v1","updated":"2024-08-02T10:16:28Z","published":"2024-08-02T10:16:28Z","title":"TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for\n  T-Cell Receptor Repertoires Generation","summary":"  T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.\n","authors":["Yicheng Lin","Dandan Zhang","Yun Liu"],"pdf_url":"https://arxiv.org/pdf/2408.01156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01144v1","updated":"2024-08-02T09:44:18Z","published":"2024-08-02T09:44:18Z","title":"Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with\n  Traumatic Brain Injury Using Advanced Machine Learning Techniques","summary":"  Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury\n(TBI) patients poses a significant mortality risk and imposes a considerable\nfinancial burden on patients and healthcare systems. Timely detection and\nprognostication of VAP in TBI patients are crucial to improve patient outcomes\nand alleviate the strain on healthcare resources.\n  Methods: We implemented six machine learning models using the MIMIC-III\ndatabase. Our methodology included preprocessing steps, such as feature\nselection with CatBoost and expert opinion, addressing class imbalance with the\nSynthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning\nthrough 5-fold cross-validation to optimize hyperparameters. Key models\nevaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and\nAdaBoost. Additionally, we conducted SHAP analysis to determine feature\nimportance and performed an ablation study to assess feature impacts on model\nperformance.\n  Results: XGBoost outperformed the baseline models and the best existing\nliterature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity,\nF1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an\nAUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than\nthe best results in the existing literature, with an AUC of 0.706 and an\nAccuracy of 0.640, respectively. This enhanced performance underscores the\nmodels' effectiveness in clinical settings.\n  Conclusions: This study enhances the predictive modeling of VAP in TBI\npatients, improving early detection and intervention potential. Refined feature\nselection and advanced ensemble techniques significantly boosted model accuracy\nand reliability, offering promising directions for future clinical applications\nand medical diagnostics research.\n","authors":["Negin Ashrafi","Armin Abdollahi","Maryam Pishgar"],"pdf_url":"https://arxiv.org/pdf/2408.01144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01141v1","updated":"2024-08-02T09:37:55Z","published":"2024-08-02T09:37:55Z","title":"Machine learning topological energy braiding of non-Bloch bands","summary":"  Machine learning has been used to identify phase transitions in a variety of\nphysical systems. However, there is still a lack of relevant research on\nnon-Bloch energy braiding in non-Hermitian systems. In this work, we study\nnon-Bloch energy braiding in one-dimensional non-Hermitian systems using\nunsupervised and supervised methods. In unsupervised learning, we use diffusion\nmaps to successfully identify non-Bloch energy braiding without any prior\nknowledge and combine it with k-means to cluster different topological elements\ninto clusters, such as Unlink and Hopf link. In supervised learning, we train a\nConvolutional Neural Network (CNN) based on Bloch energy data to predict not\nonly Bloch energy braiding but also non-Bloch energy braiding with an accuracy\napproaching 100%. By analysing the CNN, we can ascertain that the network has\nsuccessfully acquired the ability to recognise the braiding topology of the\nenergy bands. The present study demonstrates the considerable potential of\nmachine learning in the identification of non-Hermitian topological phases and\nenergy braiding.\n","authors":["Shuwei Shi","Shibing Chu","Yuee Xie","Yuanping Chen"],"pdf_url":"https://arxiv.org/pdf/2408.01141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01129v1","updated":"2024-08-02T09:18:41Z","published":"2024-08-02T09:18:41Z","title":"A Survey of Mamba","summary":"  Deep learning, as a vital technique, has sparked a notable revolution in\nartificial intelligence. As the most representative architecture, Transformers\nhave empowered numerous advanced models, especially the large language models\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space\nmodels, has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering from three main\naspects: the advancements of Mamba-based models, the techniques of adapting\nMamba to diverse data, and the applications where Mamba can excel.\nSpecifically, we first recall the foundational knowledge of various\nrepresentative deep learning models and the details of Mamba as preliminaries.\nThen, to showcase the significance of Mamba, we comprehensively review the\nrelated studies focusing on Mamba models' architecture design, data\nadaptability, and applications. Finally, we present an discussion of current\nlimitations and explore various promising research directions to provide deeper\ninsights for future investigations.\n","authors":["Haohao Qu","Liangbo Ning","Rui An","Wenqi Fan","Tyler Derr","Xin Xu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.01129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17900v3","updated":"2024-08-02T08:55:52Z","published":"2024-07-25T09:42:24Z","title":"The Power of Combining Data and Knowledge: GPT-4o is an Effective\n  Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of\n  Lung Cancer","summary":"  Lymph node metastasis (LNM) is a crucial factor in determining the initial\ntreatment for patients with lung cancer, yet accurate preoperative diagnosis of\nLNM remains challenging. Recently, large language models (LLMs) have garnered\nsignificant attention due to their remarkable text generation capabilities.\nLeveraging the extensive medical knowledge learned from vast corpora, LLMs can\nestimate probabilities for clinical problems, though their performance has\nhistorically been inferior to data-driven machine learning models. In this\npaper, we propose a novel ensemble method that combines the medical knowledge\nacquired by LLMs with the latent patterns identified by machine learning models\nto enhance LNM prediction performance. Initially, we developed machine learning\nmodels using patient data. We then designed a prompt template to integrate the\npatient data with the predicted probability from the machine learning model.\nSubsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,\nto estimate the likelihood of LNM based on patient data and then adjust the\nestimate using the machine learning output. Finally, we collected three outputs\nfrom the GPT-4o using the same prompt and ensembled these results as the final\nprediction. Using the proposed method, our models achieved an AUC value of\n0.765 and an AP value of 0.415 for LNM prediction, significantly improving\npredictive performance compared to baseline machine learning models. The\nexperimental results indicate that GPT-4o can effectively leverage its medical\nknowledge and the probabilities predicted by machine learning models to achieve\nmore accurate LNM predictions. These findings demonstrate that LLMs can perform\nwell in clinical risk prediction tasks, offering a new paradigm for integrating\nmedical knowledge and patient data in clinical predictions.\n","authors":["Danqing Hu","Bing Liu","Xiaofeng Zhu","Nan Wu"],"pdf_url":"https://arxiv.org/pdf/2407.17900v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15132v2","updated":"2024-08-02T08:49:14Z","published":"2024-02-23T06:33:51Z","title":"Improving Sentence Embeddings with Automatic Generation of Training Data\n  Using Few-shot Examples","summary":"  Decoder-based large language models (LLMs) have shown high performance on\nmany tasks in natural language processing. This is also true for sentence\nembedding learning, where a decoder-based model, PromptEOL, has achieved the\nbest performance on semantic textual similarity (STS) tasks. However, PromptEOL\nrequires a manually annotated natural language inference (NLI) dataset for\nfine-tuning. We aim to improve sentence embeddings without using large manually\nannotated datasets by automatically generating an NLI dataset with an LLM and\nusing it for fine-tuning of PromptEOL. To achieve this, we explore methods of\ndata generation suitable for sentence embedding learning in this study.\nSpecifically, we will focus on automatic dataset generation through few-shot\nlearning and explore the appropriate methods to leverage few-shot examples.\nExperimental results on the STS tasks demonstrate that our approach outperforms\nexisting models in settings without large manually annotated datasets.\n","authors":["Soma Sato","Hayato Tsukagoshi","Ryohei Sasano","Koichi Takeda"],"pdf_url":"https://arxiv.org/pdf/2402.15132v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18819v2","updated":"2024-08-02T08:22:57Z","published":"2024-02-29T03:06:10Z","title":"Dual Operating Modes of In-Context Learning","summary":"  In-context learning (ICL) exhibits dual operating modes: task learning, i.e.,\nacquiring a new skill from in-context samples, and task retrieval, i.e.,\nlocating and activating a relevant pretrained skill. Recent theoretical work\ninvestigates various mathematical models to analyze ICL, but existing models\nexplain only one operating mode at a time. We introduce a probabilistic model,\nwith which one can explain the dual operating modes of ICL simultaneously.\nFocusing on in-context learning of linear functions, we extend existing models\nfor pretraining data by introducing multiple task groups and task-dependent\ninput distributions. We then analyze the behavior of the optimally pretrained\nmodel under the squared loss, i.e., the MMSE estimator of the label given\nin-context examples. Regarding pretraining task distribution as prior and\nin-context examples as the observation, we derive the closed-form expression of\nthe task posterior distribution. With the closed-form expression, we obtain a\nquantitative understanding of the two operating modes of ICL. Furthermore, we\nshed light on an unexplained phenomenon observed in practice: under certain\nsettings, the ICL risk initially increases and then decreases with more\nin-context examples. Our model offers a plausible explanation for this \"early\nascent\" phenomenon: a limited number of in-context samples may lead to the\nretrieval of an incorrect skill, thereby increasing the risk, which will\neventually diminish as task learning takes effect with more in-context samples.\nWe also theoretically analyze ICL with biased labels, e.g., zero-shot ICL,\nwhere in-context examples are assigned random labels. Lastly, we validate our\nfindings and predictions via experiments involving Transformers and large\nlanguage models.\n","authors":["Ziqian Lin","Kangwook Lee"],"pdf_url":"https://arxiv.org/pdf/2402.18819v2.pdf","comment":"54 pages, 23 figures"},{"id":"http://arxiv.org/abs/2408.01094v1","updated":"2024-08-02T08:13:18Z","published":"2024-08-02T08:13:18Z","title":"An Encoding--Searching Separation Perspective on Bi-Encoder Neural\n  Search","summary":"  This paper reviews, analyzes, and proposes a new perspective on the\nbi-encoder architecture for neural search. While the bi-encoder architecture is\nwidely used due to its simplicity and scalability at test time, it has some\nnotable issues such as low performance on seen datasets and weak zero-shot\nperformance on new datasets. In this paper, we analyze these issues and\nsummarize two main critiques: the encoding information bottleneck problem and\nlimitations of the basic assumption of embedding search. We then construct a\nthought experiment to logically analyze the encoding and searching operations\nand challenge the basic assumption of embedding search. Building on these\nobservations, we propose a new perspective on the bi-encoder architecture\ncalled the \\textit{encoding--searching separation} perspective, which\nconceptually and practically separates the encoding and searching operations.\nThis new perspective is applied to explain the root cause of the identified\nissues and discuss ways to mitigate the problems. Finally, we discuss the\nimplications of the ideas underlying the new perspective, the design surface\nthat it exposes and the potential research directions arising from it.\n","authors":["Hung-Nghiep Tran","Akiko Aizawa","Atsuhiro Takasu"],"pdf_url":"https://arxiv.org/pdf/2408.01094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11660v2","updated":"2024-08-02T07:42:37Z","published":"2024-01-22T02:33:38Z","title":"Differentiable Tree Search Network","summary":"  In decision-making problems with limited training data, policy functions\napproximated using deep neural networks often exhibit suboptimal performance.\nAn alternative approach involves learning a world model from the limited data\nand determining actions through online search. However, the performance is\nadversely affected by compounding errors arising from inaccuracies in the\nlearned world model. While methods like TreeQN have attempted to address these\ninaccuracies by incorporating algorithmic inductive biases into the neural\nnetwork architectures, the biases they introduce are often weak and\ninsufficient for complex decision-making tasks. In this work, we introduce\nDifferentiable Tree Search Network (D-TSN), a novel neural network architecture\nthat significantly strengthens the inductive bias by embedding the algorithmic\nstructure of a best-first online search algorithm. D-TSN employs a learned\nworld model to conduct a fully differentiable online search. The world model is\njointly optimized with the search algorithm, enabling the learning of a robust\nworld model and mitigating the effect of prediction inaccuracies. Further, we\nnote that a naive incorporation of best-first search could lead to a\ndiscontinuous loss function in the parameter space. We address this issue by\nadopting a stochastic tree expansion policy, formulating search tree expansion\nas another decision-making task, and introducing an effective variance\nreduction technique for the gradient computation. We evaluate D-TSN in an\noffline-RL setting with a limited training data scenario on Procgen games and\ngrid navigation task, and demonstrate that D-TSN outperforms popular model-free\nand model-based baselines.\n","authors":["Dixant Mittal","Wee Sun Lee"],"pdf_url":"https://arxiv.org/pdf/2401.11660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01062v1","updated":"2024-08-02T07:29:49Z","published":"2024-08-02T07:29:49Z","title":"Universality of kernel random matrices and kernel regression in the\n  quadratic regime","summary":"  Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.\n","authors":["Parthe Pandit","Zhichao Wang","Yizhe Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.01062v1.pdf","comment":"75 pages"},{"id":"http://arxiv.org/abs/2408.01050v1","updated":"2024-08-02T06:56:59Z","published":"2024-08-02T06:56:59Z","title":"The Impact of Hyperparameters on Large Language Model Inference\n  Performance: An Evaluation of vLLM and HuggingFace Pipelines","summary":"  The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.\n","authors":["Matias Martinez"],"pdf_url":"https://arxiv.org/pdf/2408.01050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01040v1","updated":"2024-08-02T06:24:39Z","published":"2024-08-02T06:24:39Z","title":"Privacy-Preserving Split Learning with Vision Transformers using\n  Patch-Wise Random and Noisy CutMix","summary":"  In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.\n","authors":["Seungeun Oh","Sihun Baek","Jihong Park","Hyelin Nam","Praneeth Vepakomma","Ramesh Raskar","Mehdi Bennis","Seong-Lyun Kim"],"pdf_url":"https://arxiv.org/pdf/2408.01040v1.pdf","comment":"23 pages, 11 figures, 8 tables, to be published in Transactions on\n  Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2408.00023v2","updated":"2024-08-02T06:05:19Z","published":"2024-07-31T05:31:28Z","title":"On the Perturbed States for Transformed Input-robust Reinforcement\n  Learning","summary":"  Reinforcement Learning (RL) agents demonstrating proficiency in a training\nenvironment exhibit vulnerability to adversarial perturbations in input\nobservations during deployment. This underscores the importance of building a\nrobust agent before its real-world deployment. To alleviate the challenging\npoint, prior works focus on developing robust training-based procedures,\nencompassing efforts to fortify the deep neural network component's robustness\nor subject the agent to adversarial training against potent attacks. In this\nwork, we propose a novel method referred to as Transformed Input-robust RL\n(TIRL), which explores another avenue to mitigate the impact of adversaries by\nemploying input transformation-based defenses. Specifically, we introduce two\nprinciples for applying transformation-based defenses in learning robust RL\nagents: (1) autoencoder-styled denoising to reconstruct the original state and\n(2) bounded transformations (bit-depth reduction and vector quantization (VQ))\nto achieve close transformed inputs. The transformations are applied to the\nstate before feeding it into the policy network. Extensive experiments on\nmultiple MuJoCo environments demonstrate that input transformation-based\ndefenses, i.e., VQ, defend against several adversaries in the state\nobservations. The official code is available at\nhttps://github.com/tunglm2203/tirl\n","authors":["Tung M. Luu","Haeyong Kang","Tri Ton","Thanh Nguyen","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2408.00023v2.pdf","comment":"12 pages (Code: https://github.com/tunglm2203/tirl)"},{"id":"http://arxiv.org/abs/2407.16944v3","updated":"2024-08-02T06:05:10Z","published":"2024-07-24T02:23:18Z","title":"An Adaptive Gradient Regularization Method","summary":"  Optimizer plays an important role in neural network training with high\nefficiency and performance. Weight update based on its gradient is the central\npart of the optimizer. It has been shown that normalization and standardization\noperation on weight and gradient can accelerate the training process and\nimprove performance such as Weight Standardization (WS), weight normalization\n(WN) and gradient normalization (GN); there is also gradient centralization\n(GC). In this work, we introduce a new optimization technique based on the\ngradient magnitude in a gradient vector named adaptive gradient regularization\n(AGR), which normalizes the gradient vector in all dimensions as a coefficient\nvector and subtracts the product of the gradient and its coefficient vector by\nthe vanilla gradient. It can be viewed as an adaptive gradient clipping method.\nWe show that the AGR can improve the loss function Lipschitzness with a more\nstable training process and better generalization performance. AGR is very\nsimple to be embedded into vanilla optimizers such as Adan and AdamW with only\nthree lines of code. Our experiments are conducted in image generation, image\nclassification and language representation, which shows that our AGR improves\nthe training result.\n","authors":["Huixiu Jiang","Ling Yang","Yu Bao","Rutong Si"],"pdf_url":"https://arxiv.org/pdf/2407.16944v3.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2408.01023v1","updated":"2024-08-02T05:48:15Z","published":"2024-08-02T05:48:15Z","title":"Distilling interpretable causal trees from causal forests","summary":"  Machine learning methods for estimating treatment effect heterogeneity\npromise greater flexibility than existing methods that test a few pre-specified\nhypotheses. However, one problem these methods can have is that it can be\nchallenging to extract insights from complicated machine learning models. A\nhigh-dimensional distribution of conditional average treatment effects may give\naccurate, individual-level estimates, but it can be hard to understand the\nunderlying patterns; hard to know what the implications of the analysis are.\nThis paper proposes the Distilled Causal Tree, a method for distilling a\nsingle, interpretable causal tree from a causal forest. This compares well to\nexisting methods of extracting a single tree, particularly in noisy data or\nhigh-dimensional data where there are many correlated features. Here it even\noutperforms the base causal forest in most simulations. Its estimates are\ndoubly robust and asymptotically normal just as those of the causal forest are.\n","authors":["Patrick Rehill"],"pdf_url":"https://arxiv.org/pdf/2408.01023v1.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.01022v1","updated":"2024-08-02T05:46:17Z","published":"2024-08-02T05:46:17Z","title":"A Family of Distributions of Random Subsets for Controlling Positive and\n  Negative Dependence","summary":"  Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.\n","authors":["Takahiro Kawashima","Hideitsu Hino"],"pdf_url":"https://arxiv.org/pdf/2408.01022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01018v1","updated":"2024-08-02T05:36:14Z","published":"2024-08-02T05:36:14Z","title":"GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular\n  Representation Learning with GNNs","summary":"  Effective molecular representation learning is crucial for molecular property\nprediction and drug design. However, existing approaches struggle with\nlimitations in insufficient annotations and suboptimal architecture design. For\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\nloss of important structural details in molecules, thus impairing molecular\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\nNetworks (KAN) architecture from AI + Science into GNNs to address these\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\nadvanced KAN that offers increased stability and speed, further enhancing the\nperformance of standard GNNs. Notably, our approach holds three key benefits:\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\nprediction ability, robust generalization to unseen scaffolds, and versatile\ntransferability across different GNN architectures. 2) Efficiency: These models\nrequire less computational time and fewer parameters while matching or\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\nscenarios, achieving an average improvement of 6.97% across few-shot\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\nhighly competitive results across all of them.\n","authors":["Ruifeng Li"],"pdf_url":"https://arxiv.org/pdf/2408.01018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01016v1","updated":"2024-08-02T05:23:19Z","published":"2024-08-02T05:23:19Z","title":"IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model","summary":"  Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.\n","authors":["Eren Olug","Kiymet Kaya","Resul Tugay","Sule Gunduz Oguducu"],"pdf_url":"https://arxiv.org/pdf/2408.01016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.13894v2","updated":"2024-08-02T05:05:48Z","published":"2021-04-28T17:26:29Z","title":"Weighed l1 on the simplex: Compressive sensing meets locality","summary":"  Sparse manifold learning algorithms combine techniques in manifold learning\nand sparse optimization to learn features that could be utilized for downstream\ntasks. The standard setting of compressive sensing can not be immediately\napplied to this setup. Due to the intrinsic geometric structure of data,\ndictionary atoms might be redundant and do not satisfy the restricted isometry\nproperty or coherence condition. In addition, manifold learning emphasizes\nlearning local geometry which is not reflected in a standard $\\ell_1$\nminimization problem. We propose weighted $\\ell_0$ and weighted $\\ell_1$\nmetrics that encourage representation via neighborhood atoms suited for\ndictionary based manifold learning. Assuming that the data is generated from\nDelaunay triangulation, we show the equivalence of weighted $\\ell_0$ and\nweighted $\\ell_1$. We discuss an optimization program that learns the\ndictionaries and sparse coefficients and demonstrate the utility of our\nregularization on synthetic and real datasets.\n","authors":["Abiy Tasissa","Pranay Tankala","Demba Ba"],"pdf_url":"https://arxiv.org/pdf/2104.13894v2.pdf","comment":"7 pages, 2 figures. The proof of theorem 1 in v1 does not hold true\n  in general without additional assumptions. This version fixes this problem.\n  For more details, we refer the interested reader to arXiv:2012.02134 which is\n  the journal version of the workshop paper v1"},{"id":"http://arxiv.org/abs/2408.01008v1","updated":"2024-08-02T04:45:58Z","published":"2024-08-02T04:45:58Z","title":"Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with\n  Accelerated LLMs","summary":"  In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.\n","authors":["Afia Anjum","Maksim E. Eren","Ismael Boureima","Boian Alexandrov","Manish Bhattarai"],"pdf_url":"https://arxiv.org/pdf/2408.01008v1.pdf","comment":"LA-UR-24-28177"},{"id":"http://arxiv.org/abs/2408.01005v1","updated":"2024-08-02T04:40:15Z","published":"2024-08-02T04:40:15Z","title":"Enhancing Financial Market Predictions: Causality-Driven Feature\n  Selection","summary":"  This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).\n","authors":["Wenhao Liang","Zhengyang Li","Weitong Chen"],"pdf_url":"https://arxiv.org/pdf/2408.01005v1.pdf","comment":"Accepted by The 20th International Conference Advanced Data Mining\n  and Applications 2024 (ADMA 2024)"},{"id":"http://arxiv.org/abs/2408.01000v1","updated":"2024-08-02T04:19:25Z","published":"2024-08-02T04:19:25Z","title":"Adaptive Two-Stage Cloud Resource Scaling via Hierarchical\n  Multi-Indicator Forecasting and Bayesian Decision-Making","summary":"  The surging demand for cloud computing resources, driven by the rapid growth\nof sophisticated large-scale models and data centers, underscores the critical\nimportance of efficient and adaptive resource allocation. As major tech\nenterprises deploy massive infrastructures with thousands of GPUs, existing\ncloud platforms still struggle with low resource utilization due to key\nchallenges: capturing hierarchical indicator structures, modeling non-Gaussian\ndistributions, and decision-making under uncertainty. To address these\nchallenges, we propose HRAMONY, an adaptive Hierarchical Attention-based\nResource Modeling and Decision-Making System. HARMONY combines hierarchical\nmulti-indicator distribution forecasting and uncertainty-aware Bayesian\ndecision-making. It introduces a novel hierarchical attention mechanism that\ncomprehensively models complex inter-indicator dependencies, enabling accurate\npredictions that can adapt to evolving environment states. By transforming\nGaussian projections into adaptive non-Gaussian distributions via Normalizing\nFlows. Crucially, HARMONY leverages the full predictive distributions in an\nadaptive Bayesian process, proactively incorporating uncertainties to optimize\nresource allocation while robustly meeting SLA constraints under varying\nconditions. Extensive evaluations across four large-scale cloud datasets\ndemonstrate HARMONY's state-of-the-art performance, significantly outperforming\nnine established methods. A month-long real-world deployment validated\nHARMONY's substantial practical impact, realizing over 35,000 GPU hours in\nsavings and translating to $100K+ in cost reduction, showcasing its remarkable\neconomic value through adaptive, uncertainty-aware scaling. Our code is\navailable at https://github.com/Floating-LY/HARMONY1.\n","authors":["Yang Luo","Shiyu Wang","Zhemeng Yu","Wei Lu","Xiaofeng Gao","Lintao Ma","Guihai Chen"],"pdf_url":"https://arxiv.org/pdf/2408.01000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00996v1","updated":"2024-08-02T04:09:15Z","published":"2024-08-02T04:09:15Z","title":"IncidentNet: Traffic Incident Detection, Localization and Severity\n  Estimation with Sparse Sensing","summary":"  Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.\n","authors":["Sai Shashank Peddiraju","Kaustubh Harapanahalli","Edward Andert","Aviral Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2408.00996v1.pdf","comment":"6 pages, 6 figures, 2024 IEEE 27th International Conference on\n  Intelligent Transportation Systems (ITSC)"},{"id":"http://arxiv.org/abs/2303.12653v3","updated":"2024-08-02T04:02:26Z","published":"2023-03-09T05:30:53Z","title":"Robust Millimeter Beamforming via Self-Supervised Hybrid Deep Learning","summary":"  Beamforming with large-scale antenna arrays has been widely used in recent\nyears, which is acknowledged as an important part in 5G and incoming 6G. Thus,\nvarious techniques are leveraged to improve its performance, e.g., deep\nlearning, advanced optimization algorithms, etc. Although its performance in\nmany previous research scenarios with deep learning is quite attractive,\nusually it drops rapidly when the environment or dataset is changed. Therefore,\ndesigning effective beamforming network with strong robustness is an open issue\nfor the intelligent wireless communications. In this paper, we propose a robust\nbeamforming self-supervised network, and verify it in two kinds of different\ndatasets with various scenarios. Simulation results show that the proposed\nself-supervised network with hybrid learning performs well in both classic\nDeepMIMO and new WAIR-D dataset with the strong robustness under the various\nenvironments. Also, we present the principle to explain the rationality of this\nkind of hybrid learning, which is instructive to apply with more kinds of\ndatasets.\n","authors":["Fenghao Zhu","Bohao Wang","Zhaohui Yang","Chongwen Huang","Zhaoyang Zhang","George C. Alexandropoulos","Chau Yuen","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2303.12653v3.pdf","comment":"Accept by EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2408.00465v2","updated":"2024-08-02T03:56:14Z","published":"2024-08-01T11:09:01Z","title":"Infrequent Resolving Algorithm for Online Linear Programming","summary":"  Online linear programming (OLP) has gained significant attention from both\nresearchers and practitioners due to its extensive applications, such as online\nauction, network revenue management and advertising. Existing OLP algorithms\nfall into two categories: LP-based algorithms and LP-free algorithms. The\nformer one typically guarantees better performance, even offering a constant\nregret, but requires solving a large number of LPs, which could be\ncomputationally expensive. In contrast, LP-free algorithm only requires\nfirst-order computations but induces a worse performance, lacking a constant\nregret bound. In this work, we bridge the gap between these two extremes by\nproposing an algorithm that achieves a constant regret while solving LPs only\n$O(\\log\\log T)$ times over the time horizon $T$. Moreover, when we are allowed\nto solve LPs only $M$ times, we propose an algorithm that can guarantee an\n$O\\left(T^{(1/2+\\epsilon)^{M-1}}\\right)$ regret. Furthermore, when the arrival\nprobabilities are known at the beginning, our algorithm can guarantee a\nconstant regret by solving LPs $O(\\log\\log T)$ times, and an\n$O\\left(T^{(1/2+\\epsilon)^{M}}\\right)$ regret by solving LPs only $M$ times.\nNumerical experiments are conducted to demonstrate the efficiency of the\nproposed algorithms.\n","authors":["Guokai Li","Zizhuo Wang","Jingwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00465v2.pdf","comment":"35 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.00992v1","updated":"2024-08-02T03:44:14Z","published":"2024-08-02T03:44:14Z","title":"Fairness in Large Language Models in Three Hour","summary":"  Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.\n","authors":["Thang Doan Viet","Zichong Wang","Minh Nhat Nguyen","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.01258v2","updated":"2024-08-02T03:39:18Z","published":"2024-01-02T15:59:00Z","title":"Towards Model-Free LQR Control over Rate-Limited Channels","summary":"  Given the success of model-free methods for control design in many problem\nsettings, it is natural to ask how things will change if realistic\ncommunication channels are utilized for the transmission of gradients or\npolicies. While the resulting problem has analogies with the formulations\nstudied under the rubric of networked control systems, the rich literature in\nthat area has typically assumed that the model of the system is known. As a\nstep towards bridging the fields of model-free control design and networked\ncontrol systems, we ask: \\textit{Is it possible to solve basic control problems\n- such as the linear quadratic regulator (LQR) problem - in a model-free manner\nover a rate-limited channel?} Toward answering this question, we study a\nsetting where a worker agent transmits quantized policy gradients (of the LQR\ncost) to a server over a noiseless channel with a finite bit-rate. We propose a\nnew algorithm titled Adaptively Quantized Gradient Descent (\\texttt{AQGD}), and\nprove that above a certain finite threshold bit-rate, \\texttt{AQGD} guarantees\nexponentially fast convergence to the globally optimal policy, with \\textit{no\ndeterioration of the exponent relative to the unquantized setting}. More\ngenerally, our approach reveals the benefits of adaptive quantization in\npreserving fast linear convergence rates, and, as such, may be of independent\ninterest to the literature on compressed optimization.\n","authors":["Aritra Mitra","Lintao Ye","Vijay Gupta"],"pdf_url":"https://arxiv.org/pdf/2401.01258v2.pdf","comment":"Accepted for an Oral Presentation at the 6th Annual Learning for\n  Dynamics & Control Conference"},{"id":"http://arxiv.org/abs/2407.11046v2","updated":"2024-08-02T03:22:22Z","published":"2024-07-08T12:32:10Z","title":"A Survey on LoRA of Large Language Models","summary":"  Low-Rank Adaptation~(LoRA), which updates the dense neural network layers\nwith pluggable low-rank matrices, is one of the best performed parameter\nefficient fine-tuning paradigms. Furthermore, it has significant advantages in\ncross-task generalization and privacy-preserving. Hence, LoRA has gained much\nattention recently, and the number of related literature demonstrates\nexponential growth. It is necessary to conduct a comprehensive overview of the\ncurrent progress on LoRA. This survey categorizes and reviews the progress from\nthe perspectives of (1) downstream adaptation improving variants that improve\nLoRA's performance on downstream tasks; (2) cross-task generalization methods\nthat mix multiple LoRA plugins to achieve cross-task generalization; (3)\nefficiency-improving methods that boost the computation-efficiency of LoRA; (4)\ndata privacy-preserving methods that use LoRA in federated learning; (5)\napplication. Besides, this survey also discusses the future directions in this\nfield. At last, we provide a Github page\n(https://github.com/ZJU-LLMs/Awesome-LoRAs.git) for readers to check the\nupdates and initiate discussions on this survey paper.\n","authors":["Yuren Mao","Yuhang Ge","Yijiang Fan","Wenyi Xu","Yu Mi","Zhonghao Hu","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2407.11046v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.15870v5","updated":"2024-08-02T03:16:07Z","published":"2023-07-29T02:35:37Z","title":"SemiSFL: Split Federated Learning on Unlabeled and Non-IID Data","summary":"  Federated Learning (FL) has emerged to allow multiple clients to\ncollaboratively train machine learning models on their private data at the\nnetwork edge. However, training and deploying large-scale models on\nresource-constrained devices is challenging. Fortunately, Split Federated\nLearning (SFL) offers a feasible solution by alleviating the computation and/or\ncommunication burden on clients. However, existing SFL works often assume\nsufficient labeled data on clients, which is usually impractical. Besides, data\nnon-IIDness poses another challenge to ensure efficient model training. To our\nbest knowledge, the above two issues have not been simultaneously addressed in\nSFL. Herein, we propose a novel Semi-supervised SFL system, termed SemiSFL,\nwhich incorporates clustering regularization to perform SFL with unlabeled and\nnon-IID client data. Moreover, our theoretical and experimental investigations\ninto model convergence reveal that the inconsistent training processes on\nlabeled and unlabeled data have an influence on the effectiveness of clustering\nregularization. To mitigate the training inconsistency, we develop an algorithm\nfor dynamically adjusting the global updating frequency, so as to improve\ntraining performance. Extensive experiments on benchmark models and datasets\nshow that our system provides a 3.8x speed-up in training time, reduces the\ncommunication cost by about 70.3% while reaching the target accuracy, and\nachieves up to 5.8% improvement in accuracy under non-IID scenarios compared to\nthe state-of-the-art baselines.\n","authors":["Yang Xu","Yunming Liao","Hongli Xu","Zhipeng Sun","Liusheng Huang","Chunming Qiao"],"pdf_url":"https://arxiv.org/pdf/2307.15870v5.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2408.00985v1","updated":"2024-08-02T03:02:39Z","published":"2024-08-02T03:02:39Z","title":"Reconstructing Richtmyer-Meshkov instabilities from noisy radiographs\n  using low dimensional features and attention-based neural networks","summary":"  A trained attention-based transformer network can robustly recover the\ncomplex topologies given by the Richtmyer-Meshkoff instability from a sequence\nof hydrodynamic features derived from radiographic images corrupted with blur,\nscatter, and noise. This approach is demonstrated on ICF-like double shell\nhydrodynamic simulations. The key component of this network is a transformer\nencoder that acts on a sequence of features extracted from noisy radiographs.\nThis encoder includes numerous self-attention layers that act to learn temporal\ndependencies in the input sequences and increase the expressiveness of the\nmodel. This approach is demonstrated to exhibit an excellent ability to\naccurately recover the Richtmyer-Meshkov instability growth rates, even despite\nthe gas-metal interface being greatly obscured by radiographic noise.\n","authors":["Daniel A. Serino","Marc L. Klasky","Balasubramanya T. Nadiga","Xiaojian Xu","Trevor Wilcox"],"pdf_url":"https://arxiv.org/pdf/2408.00985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00973v1","updated":"2024-08-02T01:49:29Z","published":"2024-08-02T01:49:29Z","title":"META-ANOVA: Screening interactions for interpretable machine learning","summary":"  There are two things to be considered when we evaluate predictive models. One\nis prediction accuracy,and the other is interpretability. Over the recent\ndecades, many prediction models of high performance, such as ensemble-based\nmodels and deep neural networks, have been developed. However, these models are\noften too complex, making it difficult to intuitively interpret their\npredictions. This complexity in interpretation limits their use in many\nreal-world fields that require accountability, such as medicine, finance, and\ncollege admissions. In this study, we develop a novel method called Meta-ANOVA\nto provide an interpretable model for any given prediction model. The basic\nidea of Meta-ANOVA is to transform a given black-box prediction model to the\nfunctional ANOVA model. A novel technical contribution of Meta-ANOVA is a\nprocedure of screening out unnecessary interaction before transforming a given\nblack-box model to the functional ANOVA model. This screening procedure allows\nthe inclusion of higher order interactions in the transformed functional ANOVA\nmodel without computational difficulties. We prove that the screening procedure\nis asymptotically consistent. Through various experiments with synthetic and\nreal-world datasets, we empirically demonstrate the superiority of Meta-ANOVA\n","authors":["Yongchan Choi","Seokhun Park","Chanmoo Park","Dongha Kim","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2408.00973v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2308.14250v3","updated":"2024-08-02T01:38:16Z","published":"2023-08-28T01:57:38Z","title":"Rule-Based Error Detection and Correction to Operationalize Movement\n  Trajectory Classification","summary":"  Classification of movement trajectories has many applications in\ntransportation and is a key component for large-scale movement trajectory\ngeneration and anomaly detection which has key safety applications in the\naftermath of a disaster or other external shock. However, the current\nstate-of-the-art (SOTA) are based on supervised deep learning - which leads to\nchallenges when the distribution of trajectories changes due to such a shock.\nWe provide a neuro-symbolic rule-based framework to conduct error correction\nand detection of these models to integrate into our movement trajectory\nplatform. We provide a suite of experiments on several recent SOTA models where\nwe show highly accurate error detection, the ability to improve accuracy with a\nchanging test distribution, and accuracy improvement for the base use case in\naddition to a suite of theoretical properties that informed algorithm\ndevelopment. Specifically, we show an F1 scores for predicting errors of up to\n0.984, significant performance increase for out-of distribution accuracy (8.51%\nimprovement over SOTA for zero-shot accuracy), and accuracy improvement over\nthe SOTA model.\n","authors":["Bowen Xi","Kevin Scaria","Divyagna Bavikadi","Paulo Shakarian"],"pdf_url":"https://arxiv.org/pdf/2308.14250v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.03452v2","updated":"2024-08-02T01:33:25Z","published":"2023-09-07T02:26:55Z","title":"Multimodal Guidance Network for Missing-Modality Inference in Content\n  Moderation","summary":"  Multimodal deep learning, especially vision-language models, have gained\nsignificant traction in recent years, greatly improving performance on many\ndownstream tasks, including content moderation and violence detection. However,\nstandard multimodal approaches often assume consistent modalities between\ntraining and inference, limiting applications in many real-world use cases, as\nsome modalities may not be available during inference. While existing research\nmitigates this problem through reconstructing the missing modalities, they\nunavoidably increase unnecessary computational cost, which could be just as\ncritical, especially for large, deployed infrastructures in industry. To this\nend, we propose a novel guidance network that promotes knowledge sharing during\ntraining, taking advantage of the multimodal representations to train better\nsingle-modality models to be used for inference. Real-world experiments in\nviolence detection shows that our proposed framework trains single-modality\nmodels that significantly outperform traditionally trained counterparts, while\navoiding increases in computational cost for inference.\n","authors":["Zhuokai Zhao","Harish Palani","Tianyi Liu","Lena Evans","Ruth Toner"],"pdf_url":"https://arxiv.org/pdf/2309.03452v2.pdf","comment":"ICME 2024 Camera Ready. Code is available at\n  https://github.com/zhuokaizhao/multimodal-guidance-network"},{"id":"http://arxiv.org/abs/2408.00963v1","updated":"2024-08-02T00:35:18Z","published":"2024-08-02T00:35:18Z","title":"MIS-ME: A Multi-modal Framework for Soil Moisture Estimation","summary":"  Soil moisture estimation is an important task to enable precision agriculture\nin creating optimal plans for irrigation, fertilization, and harvest. It is\ncommon to utilize statistical and machine learning models to estimate soil\nmoisture from traditional data sources such as weather forecasts, soil\nproperties, and crop properties. However, there is a growing interest in\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\nthese images capture high-resolution crop details, they are expensive to curate\nand challenging to interpret. Imagine, an AI-enhanced software tool that\npredicts soil moisture using visual cues captured by smartphones and\nstatistical data given by weather forecasts. This work is a first step towards\nthat goal of developing a multi-modal approach for soil moisture estimation. In\nparticular, we curate a dataset consisting of real-world images taken from\nground stations and their corresponding weather data. We also propose MIS-ME -\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\ndata, highlighting the effectiveness of tailored multi-modal approaches.\n","authors":["Mohammed Rakib","Adil Aman Mohammed","Cole Diggins","Sumit Sharma","Jeff Michael Sadler","Tyson Ochsner","Arun Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2408.00963v1.pdf","comment":"Accepted by DSAA2024"},{"id":"http://arxiv.org/abs/2405.16522v4","updated":"2024-08-02T00:21:41Z","published":"2024-05-26T11:17:49Z","title":"Multi-State TD Target for Model-Free Reinforcement Learning","summary":"  Temporal difference (TD) learning is a fundamental technique in reinforcement\nlearning that updates value estimates for states or state-action pairs using a\nTD target. This target represents an improved estimate of the true value by\nincorporating both immediate rewards and the estimated value of subsequent\nstates. Traditionally, TD learning relies on the value of a single subsequent\nstate. We propose an enhanced multi-state TD (MSTD) target that utilizes the\nestimated values of multiple subsequent states. Building on this new MSTD\nconcept, we develop complete actor-critic algorithms that include management of\nreplay buffers in two modes, and integrate with deep deterministic policy\noptimization (DDPG) and soft actor-critic (SAC). Experimental results\ndemonstrate that algorithms employing the MSTD target significantly improve\nlearning performance compared to traditional methods.The code is provided on\nGitHub.\n","authors":["Wuhao Wang","Zhiyong Chen","Lepeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.16522v4.pdf","comment":"8 pages, 16 figures"}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2110.15501v4","updated":"2024-08-02T17:31:24Z","published":"2021-10-29T02:38:54Z","title":"Doubly Robust Interval Estimation for Optimal Policy Evaluation in\n  Online Learning","summary":"  Evaluating the performance of an ongoing policy plays a vital role in many\nareas such as medicine and economics, to provide crucial instructions on the\nearly-stop of the online experiment and timely feedback from the environment.\nPolicy evaluation in online learning thus attracts increasing attention by\ninferring the mean outcome of the optimal policy (i.e., the value) in\nreal-time. Yet, such a problem is particularly challenging due to the dependent\ndata generated in the online environment, the unknown optimal policy, and the\ncomplex exploration and exploitation trade-off in the adaptive experiment. In\nthis paper, we aim to overcome these difficulties in policy evaluation for\nonline learning. We explicitly derive the probability of exploration that\nquantifies the probability of exploring non-optimal actions under commonly used\nbandit algorithms. We use this probability to conduct valid inference on the\nonline conditional mean estimator under each action and develop the doubly\nrobust interval estimation (DREAM) method to infer the value under the\nestimated optimal policy in online learning. The proposed value estimator\nprovides double protection for consistency and is asymptotically normal with a\nWald-type confidence interval provided. Extensive simulation studies and real\ndata applications are conducted to demonstrate the empirical validity of the\nproposed DREAM method.\n","authors":["Ye Shen","Hengrui Cai","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2110.15501v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01379v1","updated":"2024-08-02T16:37:33Z","published":"2024-08-02T16:37:33Z","title":"Resampling and averaging coordinates on data","summary":"  We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.\n","authors":["Andrew J. Blumberg","Mathieu Carriere","Jun Hou Fung","Michael A. Mandell"],"pdf_url":"https://arxiv.org/pdf/2408.01379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01367v1","updated":"2024-08-02T16:21:48Z","published":"2024-08-02T16:21:48Z","title":"Transformers are Universal In-context Learners","summary":"  Transformers are deep architectures that define \"in-context mappings\" which\nenable predicting new tokens based on a given set of tokens (such as a prompt\nin NLP applications or a set of patches for vision transformers). This work\nstudies in particular the ability of these architectures to handle an\narbitrarily large number of context tokens. To mathematically and uniformly\naddress the expressivity of these architectures, we consider the case that the\nmappings are conditioned on a context represented by a probability distribution\nof tokens (discrete for a finite number of tokens). The related notion of\nsmoothness corresponds to continuity in terms of the Wasserstein distance\nbetween these contexts. We demonstrate that deep transformers are universal and\ncan approximate continuous in-context mappings to arbitrary precision,\nuniformly over compact token domains. A key aspect of our results, compared to\nexisting findings, is that for a fixed precision, a single transformer can\noperate on an arbitrary (even infinite) number of tokens. Additionally, it\noperates with a fixed embedding dimension of tokens (this dimension does not\nincrease with precision) and a fixed number of heads (proportional to the\ndimension). The use of MLP layers between multi-head attention layers is also\nexplicitly controlled.\n","authors":["Takashi Furuya","Maarten V. de Hoop","Gabriel Peyré"],"pdf_url":"https://arxiv.org/pdf/2408.01367v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2408.01362v1","updated":"2024-08-02T16:13:51Z","published":"2024-08-02T16:13:51Z","title":"Autoencoders in Function Space","summary":"  Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.\n","authors":["Justin Bunker","Mark Girolami","Hefin Lambley","Andrew M. Stuart","T. J. Sullivan"],"pdf_url":"https://arxiv.org/pdf/2408.01362v1.pdf","comment":"56 pages, 25 figures"},{"id":"http://arxiv.org/abs/2408.01336v1","updated":"2024-08-02T15:33:04Z","published":"2024-08-02T15:33:04Z","title":"Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and\n  Contaminated by Outliers","summary":"  We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.\n","authors":["Takeyuki Sasai","Hironori Fujisawa"],"pdf_url":"https://arxiv.org/pdf/2408.01336v1.pdf","comment":"This research builds on and improves the results of arxiv:2206.07594.\n  There will be no further update for the earlier manuscript"},{"id":"http://arxiv.org/abs/2301.00736v4","updated":"2024-08-02T15:26:37Z","published":"2023-01-02T16:11:05Z","title":"Mixed moving average field guided learning for spatio-temporal data","summary":"  Influenced mixed moving average fields are a versatile modeling class for\nspatio-temporal data. However, their predictive distribution is not generally\nknown. Under this modeling assumption, we define a novel spatio-temporal\nembedding and a theory-guided machine learning approach that employs a\ngeneralized Bayesian algorithm to make ensemble forecasts. We use Lipschitz\npredictors and determine fixed-time and any-time PAC Bayesian bounds in the\nbatch learning setting. Performing causal forecast is a highlight of our\nmethodology as its potential application to data with spatial and temporal\nshort and long-range dependence. We then test the performance of our learning\nmethodology by using linear predictors and data sets simulated from a\nspatio-temporal Ornstein-Uhlenbeck process.\n","authors":["Imma Valentina Curato","Orkun Furat","Lorenzo Proietti","Bennet Stroeh"],"pdf_url":"https://arxiv.org/pdf/2301.00736v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01318v1","updated":"2024-08-02T15:12:52Z","published":"2024-08-02T15:12:52Z","title":"Point Prediction for Streaming Data","summary":"  We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.\n","authors":["Aleena Chanda","N. V. Vinodchandran","Bertrand Clarke"],"pdf_url":"https://arxiv.org/pdf/2408.01318v1.pdf","comment":"42 pages, two figures"},{"id":"http://arxiv.org/abs/2408.01301v1","updated":"2024-08-02T14:43:45Z","published":"2024-08-02T14:43:45Z","title":"A Decision-driven Methodology for Designing Uncertainty-aware AI\n  Self-Assessment","summary":"  Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.\n","authors":["Gregory Canal","Vladimir Leung","Philip Sage","Eric Heim","I-Jeng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01300v1","updated":"2024-08-02T14:41:36Z","published":"2024-08-02T14:41:36Z","title":"Assessing Robustness of Machine Learning Models using Covariate\n  Perturbations","summary":"  As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.\n","authors":["Arun Prakash R","Anwesha Bhattacharyya","Joel Vaughan","Vijayan N. Nair"],"pdf_url":"https://arxiv.org/pdf/2408.01300v1.pdf","comment":"31 pages, 11 figures, 14 tables"},{"id":"http://arxiv.org/abs/2408.00713v2","updated":"2024-08-02T14:40:19Z","published":"2024-08-01T16:58:54Z","title":"Reinforcement Learning applied to Insurance Portfolio Pursuit","summary":"  When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. We term\nthe problem of modulating offers to achieve a desired target portfolio the\nportfolio pursuit problem. Having formulated the portfolio pursuit problem as a\nsequential decision making problem, we devise a novel reinforcement learning\nalgorithm for its solution. We test our method on a complex synthetic market\nenvironment, and demonstrate that it outperforms a baseline method which mimics\ncurrent industry approaches to portfolio pursuit.\n","authors":["Edward James Young","Alistair Rogers","Elliott Tong","James Jordon"],"pdf_url":"https://arxiv.org/pdf/2408.00713v2.pdf","comment":"16 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.17247v3","updated":"2024-08-02T09:03:09Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tau_{mix}$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolò Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01062v1","updated":"2024-08-02T07:29:49Z","published":"2024-08-02T07:29:49Z","title":"Universality of kernel random matrices and kernel regression in the\n  quadratic regime","summary":"  Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.\n","authors":["Parthe Pandit","Zhichao Wang","Yizhe Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.01062v1.pdf","comment":"75 pages"},{"id":"http://arxiv.org/abs/2408.01022v1","updated":"2024-08-02T05:46:17Z","published":"2024-08-02T05:46:17Z","title":"A Family of Distributions of Random Subsets for Controlling Positive and\n  Negative Dependence","summary":"  Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.\n","authors":["Takahiro Kawashima","Hideitsu Hino"],"pdf_url":"https://arxiv.org/pdf/2408.01022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00973v1","updated":"2024-08-02T01:49:29Z","published":"2024-08-02T01:49:29Z","title":"META-ANOVA: Screening interactions for interpretable machine learning","summary":"  There are two things to be considered when we evaluate predictive models. One\nis prediction accuracy,and the other is interpretability. Over the recent\ndecades, many prediction models of high performance, such as ensemble-based\nmodels and deep neural networks, have been developed. However, these models are\noften too complex, making it difficult to intuitively interpret their\npredictions. This complexity in interpretation limits their use in many\nreal-world fields that require accountability, such as medicine, finance, and\ncollege admissions. In this study, we develop a novel method called Meta-ANOVA\nto provide an interpretable model for any given prediction model. The basic\nidea of Meta-ANOVA is to transform a given black-box prediction model to the\nfunctional ANOVA model. A novel technical contribution of Meta-ANOVA is a\nprocedure of screening out unnecessary interaction before transforming a given\nblack-box model to the functional ANOVA model. This screening procedure allows\nthe inclusion of higher order interactions in the transformed functional ANOVA\nmodel without computational difficulties. We prove that the screening procedure\nis asymptotically consistent. Through various experiments with synthetic and\nreal-world datasets, we empirically demonstrate the superiority of Meta-ANOVA\n","authors":["Yongchan Choi","Seokhun Park","Chanmoo Park","Dongha Kim","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2408.00973v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2209.15224v4","updated":"2024-08-02T22:59:18Z","published":"2022-09-30T04:35:12Z","title":"Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture\n  Models","summary":"  Unsupervised learning has been widely used in many real-world applications.\nOne of the simplest and most important unsupervised learning models is the\nGaussian mixture model (GMM). In this work, we study the multi-task learning\nproblem on GMMs, which aims to leverage potentially similar GMM parameter\nstructures among tasks to obtain improved learning performance compared to\nsingle-task learning. We propose a multi-task GMM learning procedure based on\nthe EM algorithm that effectively utilizes unknown similarities between related\ntasks and is robust against a fraction of outlier tasks from arbitrary\ndistributions. The proposed procedure is shown to achieve the minimax optimal\nrate of convergence for both parameter estimation error and the excess\nmis-clustering error, in a wide range of regimes. Moreover, we generalize our\napproach to tackle the problem of transfer learning for GMMs, where similar\ntheoretical results are derived. Additionally, iterative unsupervised\nmulti-task and transfer learning methods may suffer from an initialization\nalignment problem, and two alignment algorithms are proposed to resolve the\nissue. Finally, we demonstrate the effectiveness of our methods through\nsimulations and real data examples. To the best of our knowledge, this is the\nfirst work studying multi-task and transfer learning on GMMs with theoretical\nguarantees.\n","authors":["Ye Tian","Haolei Weng","Lucy Xia","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2209.15224v4.pdf","comment":"162 pages, 15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2408.01582v1","updated":"2024-08-02T21:35:08Z","published":"2024-08-02T21:35:08Z","title":"Conformal Diffusion Models for Individual Treatment Effect Estimation\n  and Inference","summary":"  Estimating treatment effects from observational data is of central interest\nacross numerous application domains. Individual treatment effect offers the\nmost granular measure of treatment effect on an individual level, and is the\nmost useful to facilitate personalized care. However, its estimation and\ninference remain underdeveloped due to several challenges. In this article, we\npropose a novel conformal diffusion model-based approach that addresses those\nintricate challenges. We integrate the highly flexible diffusion modeling, the\nmodel-free statistical inference paradigm of conformal inference, along with\npropensity score and covariate local approximation that tackle distributional\nshifts. We unbiasedly estimate the distributions of potential outcomes for\nindividual treatment effect, construct an informative confidence interval, and\nestablish rigorous theoretical guarantees. We demonstrate the competitive\nperformance of the proposed method over existing solutions through extensive\nnumerical studies.\n","authors":["Hengrui Cai","Huaqing Jin","Lexin Li"],"pdf_url":"https://arxiv.org/pdf/2408.01582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01575v1","updated":"2024-08-02T21:14:13Z","published":"2024-08-02T21:14:13Z","title":"Deep Learning Framework for History Matching CO2 Storage with 4D Seismic\n  and Monitoring Well Data","summary":"  Geological carbon storage entails the injection of megatonnes of\nsupercritical CO2 into subsurface formations. The properties of these\nformations are usually highly uncertain, which makes design and optimization of\nlarge-scale storage operations challenging. In this paper we introduce a\nhistory matching strategy that enables the calibration of formation properties\nbased on early-time observations. Early-time assessments are essential to\nassure the operation is performing as planned. Our framework involves two\nfit-for-purpose deep learning surrogate models that provide predictions for\nin-situ monitoring well data and interpreted time-lapse (4D) seismic saturation\ndata. These two types of data are at very different scales of resolution, so it\nis appropriate to construct separate, specialized deep learning networks for\ntheir prediction. This approach results in a workflow that is more\nstraightforward to design and more efficient to train than a single surrogate\nthat provides global high-fidelity predictions. The deep learning models are\nintegrated into a hierarchical Markov chain Monte Carlo (MCMC) history matching\nprocedure. History matching is performed on a synthetic case with and without\n4D seismic data, which allows us to quantify the impact of 4D seismic on\nuncertainty reduction. The use of both data types is shown to provide\nsubstantial uncertainty reduction in key geomodel parameters and to enable\naccurate predictions of CO2 plume dynamics. The overall history matching\nframework developed in this study represents an efficient way to integrate\nmultiple data types and to assess the impact of each on uncertainty reduction\nand performance predictions.\n","authors":["Nanzhe Wang","Louis J. Durlofsky"],"pdf_url":"https://arxiv.org/pdf/2408.01575v1.pdf","comment":"43 pages, 18 figures"},{"id":"http://arxiv.org/abs/2408.01517v1","updated":"2024-08-02T18:23:17Z","published":"2024-08-02T18:23:17Z","title":"Gradient flow in parameter space is equivalent to linear interpolation\n  in output space","summary":"  We prove that the usual gradient flow in parameter space that underlies many\ntraining algorithms for neural networks in deep learning can be continuously\ndeformed into an adapted gradient flow which yields (constrained) Euclidean\ngradient flow in output space. Moreover, if the Jacobian of the outputs with\nrespect to the parameters is full rank (for fixed training data), then the time\nvariable can be reparametrized so that the resulting flow is simply linear\ninterpolation, and a global minimum can be achieved.\n","authors":["Thomas Chen","Patrícia Muñoz Ewald"],"pdf_url":"https://arxiv.org/pdf/2408.01517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.15727v4","updated":"2024-08-02T14:44:47Z","published":"2020-10-29T16:18:48Z","title":"Amortized Probabilistic Detection of Communities in Graphs","summary":"  Learning community structures in graphs has broad applications across\nscientific domains. While graph neural networks (GNNs) have been successful in\nencoding graph structures, existing GNN-based methods for community detection\nare limited by requiring knowledge of the number of communities in advance, in\naddition to lacking a proper probabilistic formulation to handle uncertainty.\nWe propose a simple framework for amortized community detection, which\naddresses both of these issues by combining the expressive power of GNNs with\nrecent methods for amortized clustering. Our models consist of a graph\nrepresentation backbone that extracts structural information and an amortized\nclustering network that naturally handles variable numbers of clusters. Both\ncomponents combine into well-defined models of the posterior distribution of\ngraph communities and are jointly optimized given labeled graphs. At inference\ntime, the models yield parallel samples from the posterior of community labels,\nquantifying uncertainty in a principled way. We evaluate several models from\nour framework on synthetic and real datasets, and demonstrate improved\nperformance compared to previous methods. As a separate contribution, we extend\nrecent amortized probabilistic clustering architectures by adding attention\nmodules, which yield further improvements on community detection tasks.\n","authors":["Yueqi Wang","Yoonho Lee","Pallab Basu","Juho Lee","Yee Whye Teh","Liam Paninski","Ari Pakman"],"pdf_url":"https://arxiv.org/pdf/2010.15727v4.pdf","comment":"Accepted by the Structured Probabilistic Inference & Generative\n  Modeling workshop of ICML 2024, Vienna, Austria"},{"id":"http://arxiv.org/abs/2109.08215v6","updated":"2024-08-02T20:13:29Z","published":"2021-09-16T20:46:26Z","title":"Pre-trained Gaussian Processes for Bayesian Optimization","summary":"  Bayesian optimization (BO) has become a popular strategy for global\noptimization of expensive real-world functions. Contrary to a common\nexpectation that BO is suited to optimizing black-box functions, it actually\nrequires domain knowledge about those functions to deploy BO successfully. Such\ndomain knowledge often manifests in Gaussian process (GP) priors that specify\ninitial beliefs on functions. However, even with expert knowledge, it is\nnon-trivial to quantitatively define a prior. This is especially true for\nhyperparameter tuning problems on complex machine learning models, where\nlandscapes of tuning objectives are often difficult to comprehend. We seek an\nalternative practice for setting these functional priors. In particular, we\nconsider the scenario where we have data from similar functions that allow us\nto pre-train a tighter distribution a priori. We detail what pre-training\nentails for GPs using a KL divergence based loss function, and propose a new\npre-training based BO framework named HyperBO. Theoretically, we show bounded\nposterior predictions and near-zero regrets for HyperBO without assuming the\n\"ground truth\" GP prior is known. To verify our approach in realistic setups,\nwe collect a large multi-task hyperparameter tuning dataset by training tens of\nthousands of configurations of near-state-of-the-art deep learning models on\npopular image and text datasets, as well as a protein sequence dataset. Our\nresults show that on average, HyperBO is able to locate good hyperparameters at\nleast 3 times more efficiently than the best competing methods on both our new\ntuning dataset and existing multi-task BO benchmarks.\n","authors":["Zi Wang","George E. Dahl","Kevin Swersky","Chansoo Lee","Zachary Nado","Justin Gilmer","Jasper Snoek","Zoubin Ghahramani"],"pdf_url":"https://arxiv.org/pdf/2109.08215v6.pdf","comment":null}]},"2024-08-05T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.02672v1","updated":"2024-08-05T17:59:51Z","published":"2024-08-05T17:59:51Z","title":"Latent-INR: A Flexible Framework for Implicit Representations of Videos\n  with Discriminative Semantics","summary":"  Implicit Neural Networks (INRs) have emerged as powerful representations to\nencode all forms of data, including images, videos, audios, and scenes. With\nvideo, many INRs for video have been proposed for the compression task, and\nrecent methods feature significant improvements with respect to encoding time,\nstorage, and reconstruction quality. However, these encoded representations\nlack semantic meaning, so they cannot be used for any downstream tasks that\nrequire such properties, such as retrieval. This can act as a barrier for\nadoption of video INRs over traditional codecs as they do not offer any\nsignificant edge apart from compression. To alleviate this, we propose a\nflexible framework that decouples the spatial and temporal aspects of the video\nINR. We accomplish this with a dictionary of per-frame latents that are learned\njointly with a set of video specific hypernetworks, such that given a latent,\nthese hypernetworks can predict the INR weights to reconstruct the given frame.\nThis framework not only retains the compression efficiency, but the learned\nlatents can be aligned with features from large vision models, which grants\nthem discriminative properties. We align these latents with CLIP and show good\nperformance for both compression and video retrieval tasks. By aligning with\nVideoLlama, we are able to perform open-ended chat with our learned latents as\nthe visual inputs. Additionally, the learned latents serve as a proxy for the\nunderlying weights, allowing us perform tasks like video interpolation. These\nsemantic properties and applications, existing simultaneously with ability to\nperform compression, interpolation, and superresolution properties, are a first\nin this field of work.\n","authors":["Shishira R Maiya","Anubhav Gupta","Matthew Gwilliam","Max Ehrlich","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2408.02672v1.pdf","comment":"equal contribution for first two authors; accepted to ECCV2024; 14\n  pages, 4 tables, 10 figures in main paper, supplementary after bibliography"},{"id":"http://arxiv.org/abs/2405.04634v3","updated":"2024-08-05T17:53:28Z","published":"2024-05-07T19:37:22Z","title":"FRACTAL: An Ultra-Large-Scale Aerial Lidar Dataset for 3D Semantic\n  Segmentation of Diverse Landscapes","summary":"  Mapping agencies are increasingly adopting Aerial Lidar Scanning (ALS) as a\nnew tool to monitor territory and support public policies. Processing ALS data\nat scale requires efficient point classification methods that perform well over\nhighly diverse territories. To evaluate them, researchers need large annotated\nLidar datasets, however, current Lidar benchmark datasets have restricted scope\nand often cover a single urban area. To bridge this data gap, we present the\nFRench ALS Clouds from TArgeted Landscapes (FRACTAL) dataset: an\nultra-large-scale aerial Lidar dataset made of 100,000 dense point clouds with\nhigh-quality labels for 7 semantic classes and spanning 250 km$^2$. FRACTAL is\nbuilt upon France's nationwide open Lidar data. It achieves spatial and\nsemantic diversity via a sampling scheme that explicitly concentrates rare\nclasses and challenging landscapes from five French regions. It should support\nthe development of 3D deep learning approaches for large-scale land monitoring.\nWe describe the nature of the source data, the sampling workflow, the content\nof the resulting dataset, and provide an initial evaluation of segmentation\nperformance using a performant 3D neural architecture.\n","authors":["Charles Gaydon","Michel Daab","Floryne Roche"],"pdf_url":"https://arxiv.org/pdf/2405.04634v3.pdf","comment":"15 pages | 9 figures | 8 tables | Dataset is available at\n  https://huggingface.co/datasets/IGNF/FRACTAL | Trained model is available at\n  https://huggingface.co/IGNF/FRACTAL-LidarHD_7cl_randlanet | Deep learning\n  code repository is on Gihtub at https://github.com/IGNF/myria3d | Data\n  engineering code repository is on Github at https://github.com/IGNF/pacasam"},{"id":"http://arxiv.org/abs/2407.11913v2","updated":"2024-08-05T17:50:03Z","published":"2024-07-16T17:05:20Z","title":"Quantised Global Autoencoder: A Holistic Approach to Representing Visual\n  Data","summary":"  In quantised autoencoders, images are usually split into local patches, each\nencoded by one token. This representation is redundant in the sense that the\nsame number of tokens is spend per region, regardless of the visual information\ncontent in that region. Adaptive discretisation schemes like quadtrees are\napplied to allocate tokens for patches with varying sizes, but this just varies\nthe region of influence for a token which nevertheless remains a local\ndescriptor. Modern architectures add an attention mechanism to the autoencoder\nwhich infuses some degree of global information into the local tokens. Despite\nthe global context, tokens are still associated with a local image region. In\ncontrast, our method is inspired by spectral decompositions which transform an\ninput signal into a superposition of global frequencies. Taking the data-driven\nperspective, we learn custom basis functions corresponding to the codebook\nentries in our VQ-VAE setup. Furthermore, a decoder combines these basis\nfunctions in a non-linear fashion, going beyond the simple linear superposition\nof spectral decompositions. We can achieve this global description with an\nefficient transpose operation between features and channels and demonstrate our\nperformance on compression.\n","authors":["Tim Elsner","Paula Usinger","Victor Czech","Gregor Kobsik","Yanjiang He","Isaak Lim","Leif Kobbelt"],"pdf_url":"https://arxiv.org/pdf/2407.11913v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02657v1","updated":"2024-08-05T17:46:53Z","published":"2024-08-05T17:46:53Z","title":"Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation\n  with Multimodal Generative Pretraining","summary":"  We present Lumina-mGPT, a family of multimodal autoregressive models capable\nof various vision and language tasks, particularly excelling in generating\nflexible photorealistic images from text descriptions. Unlike existing\nautoregressive image generation approaches, Lumina-mGPT employs a pretrained\ndecoder-only transformer as a unified framework for modeling multimodal token\nsequences. Our key insight is that a simple decoder-only transformer with\nmultimodal Generative PreTraining (mGPT), utilizing the next-token prediction\nobjective on massive interleaved text-image sequences, can learn broad and\ngeneral multimodal capabilities, thereby illuminating photorealistic\ntext-to-image generation. Building on these pretrained models, we propose\nFlexible Progressive Supervised Finetuning (FP-SFT) on high-quality image-text\npairs to fully unlock their potential for high-aesthetic image synthesis at any\nresolution while maintaining their general multimodal capabilities.\nFurthermore, we introduce Ominiponent Supervised Finetuning (Omni-SFT),\ntransforming Lumina-mGPT into a foundation model that seamlessly achieves\nomnipotent task unification. The resulting model demonstrates versatile\nmultimodal capabilities, including visual generation tasks like flexible\ntext-to-image generation and controllable generation, visual recognition tasks\nlike segmentation and depth estimation, and vision-language tasks like\nmultiturn visual question answering. Additionally, we analyze the differences\nand similarities between diffusion-based and autoregressive methods in a direct\ncomparison.\n","authors":["Dongyang Liu","Shitian Zhao","Le Zhuo","Weifeng Lin","Yu Qiao","Hongsheng Li","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2408.02657v1.pdf","comment":"Code available at: https://github.com/Alpha-VLLM/Lumina-mGPT"},{"id":"http://arxiv.org/abs/2408.02654v1","updated":"2024-08-05T17:33:09Z","published":"2024-08-05T17:33:09Z","title":"On Using Quasirandom Sequences in Machine Learning for Model Weight\n  Initialization","summary":"  The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.\n","authors":["Andriy Miranskyy","Adam Sorrenti","Viral Thakar"],"pdf_url":"https://arxiv.org/pdf/2408.02654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02635v1","updated":"2024-08-05T16:58:56Z","published":"2024-08-05T16:58:56Z","title":"Interactive 3D Medical Image Segmentation with SAM 2","summary":"  Interactive medical image segmentation (IMIS) has shown significant potential\nin enhancing segmentation accuracy by integrating iterative feedback from\nmedical professionals. However, the limited availability of enough 3D medical\ndata restricts the generalization and robustness of most IMIS methods. The\nSegment Anything Model (SAM), though effective for 2D images, requires\nexpensive semi-auto slice-by-slice annotations for 3D medical images. In this\npaper, we explore the zero-shot capabilities of SAM 2, the next-generation Meta\nSAM model trained on videos, for 3D medical image segmentation. By treating\nsequential 2D slices of 3D images as video frames, SAM 2 can fully\nautomatically propagate annotations from a single frame to the entire 3D\nvolume. We propose a practical pipeline for using SAM 2 in 3D medical image\nsegmentation and present key findings highlighting its efficiency and potential\nfor further optimization. Concretely, numerical experiments on the BraTS2020\nand the medical segmentation decathlon datasets demonstrate that SAM 2 still\nhas a gap with supervised methods but can narrow the gap in specific settings\nand organ types, significantly reducing the annotation burden on medical\nprofessionals. Our code will be open-sourced and available at\nhttps://github.com/Chuyun-Shen/SAM_2_Medical_3D.\n","authors":["Chuyun Shen","Wenhao Li","Yuhang Shi","Xiangfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02629v1","updated":"2024-08-05T16:53:23Z","published":"2024-08-05T16:53:23Z","title":"VidGen-1M: A Large-Scale Dataset for Text-to-video Generation","summary":"  The quality of video-text pairs fundamentally determines the upper bound of\ntext-to-video models. Currently, the datasets used for training these models\nsuffer from significant shortcomings, including low temporal consistency,\npoor-quality captions, substandard video quality, and imbalanced data\ndistribution. The prevailing video curation process, which depends on image\nmodels for tagging and manual rule-based curation, leads to a high\ncomputational load and leaves behind unclean data. As a result, there is a lack\nof appropriate training datasets for text-to-video models. To address this\nproblem, we present VidGen-1M, a superior training dataset for text-to-video\nmodels. Produced through a coarse-to-fine curation strategy, this dataset\nguarantees high-quality videos and detailed captions with excellent temporal\nconsistency. When used to train the video generation model, this dataset has\nled to experimental results that surpass those obtained with other models.\n","authors":["Zhiyu Tan","Xiaomeng Yang","Luozheng Qin","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2408.02629v1.pdf","comment":"project page: https://sais-fuxi.github.io/projects/vidgen-1m"},{"id":"http://arxiv.org/abs/2312.02396v3","updated":"2024-08-05T16:49:51Z","published":"2023-12-04T23:26:12Z","title":"Unsupervised Change Detection for Space Habitats Using 3D Point Clouds","summary":"  This work presents an algorithm for scene change detection from point clouds\nto enable autonomous robotic caretaking in future space habitats. Autonomous\nrobotic systems will help maintain future deep-space habitats, such as the\nGateway space station, which will be uncrewed for extended periods. Existing\nscene analysis software used on the International Space Station (ISS) relies on\nmanually-labeled images for detecting changes. In contrast, the algorithm\npresented in this work uses raw, unlabeled point clouds as inputs. The\nalgorithm first applies modified Expectation-Maximization Gaussian Mixture\nModel (GMM) clustering to two input point clouds. It then performs change\ndetection by comparing the GMMs using the Earth Mover's Distance. The algorithm\nis validated quantitatively and qualitatively using a test dataset collected by\nan Astrobee robot in the NASA Ames Granite Lab comprising single frame depth\nimages taken directly by Astrobee and full-scene reconstructed maps built with\nRGB-D and pose data from Astrobee. The runtimes of the approach are also\nanalyzed in depth. The source code is publicly released to promote further\ndevelopment.\n","authors":["Jamie Santos","Holly Dinkel","Julia Di","Paulo V. K. Borges","Marina Moreira","Oleg Alexandrov","Brian Coltin","Trey Smith"],"pdf_url":"https://arxiv.org/pdf/2312.02396v3.pdf","comment":"15 pages, 7 figures, Manuscript was presented at the AIAA SciTech\n  Forum in Orlando, FL, USA, 8 - 12 January 2024. Video presentation:\n  [https://www.youtube.com/watch?v=7WHp0dQYG4Y]. Code:\n  [https://github.com/nasa/isaac/tree/master/anomaly/gmm-change-detection]"},{"id":"http://arxiv.org/abs/2408.02623v1","updated":"2024-08-05T16:48:03Z","published":"2024-08-05T16:48:03Z","title":"YOWOv3: An Efficient and Generalized Framework for Human Action\n  Detection and Recognition","summary":"  In this paper, we propose a new framework called YOWOv3, which is an improved\nversion of YOWOv2, designed specifically for the task of Human Action Detection\nand Recognition. This framework is designed to facilitate extensive\nexperimentation with different configurations and supports easy customization\nof various components within the model, reducing efforts required for\nunderstanding and modifying the code. YOWOv3 demonstrates its superior\nperformance compared to YOWOv2 on two widely used datasets for Human Action\nDetection and Recognition: UCF101-24 and AVAv2.2. Specifically, the predecessor\nmodel YOWOv2 achieves an mAP of 85.2% and 20.3% on UCF101-24 and AVAv2.2,\nrespectively, with 109.7M parameters and 53.6 GFLOPs. In contrast, our model -\nYOWOv3, with only 59.8M parameters and 39.8 GFLOPs, achieves an mAP of 88.33%\nand 20.31% on UCF101-24 and AVAv2.2, respectively. The results demonstrate that\nYOWOv3 significantly reduces the number of parameters and GFLOPs while still\nachieving comparable performance.\n","authors":["Duc Manh Nguyen Dang","Viet Hang Duong","Jia Ching Wang","Nhan Bui Duc"],"pdf_url":"https://arxiv.org/pdf/2408.02623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02615v1","updated":"2024-08-05T16:39:39Z","published":"2024-08-05T16:39:39Z","title":"LaMamba-Diff: Linear-Time High-Fidelity Diffusion Models Based on Local\n  Attention and Mamba","summary":"  Recent Transformer-based diffusion models have shown remarkable performance,\nlargely attributed to the ability of the self-attention mechanism to accurately\ncapture both global and local contexts by computing all-pair interactions among\ninput tokens. However, their quadratic complexity poses significant\ncomputational challenges for long-sequence inputs. Conversely, a recent state\nspace model called Mamba offers linear complexity by compressing a filtered\nglobal context into a hidden state. Despite its efficiency, compression\ninevitably leads to information loss of fine-grained local dependencies among\ntokens, which are crucial for effective visual generative modeling. Motivated\nby these observations, we introduce Local Attentional Mamba (LaMamba) blocks\nthat combine the strengths of self-attention and Mamba, capturing both global\ncontexts and local details with linear complexity. Leveraging the efficient\nU-Net architecture, our model exhibits exceptional scalability and surpasses\nthe performance of DiT across various model scales on ImageNet at 256x256\nresolution, all while utilizing substantially fewer GFLOPs and a comparable\nnumber of parameters. Compared to state-of-the-art diffusion models on ImageNet\n256x256 and 512x512, our largest model presents notable advantages, such as a\nreduction of up to 62\\% GFLOPs compared to DiT-XL/2, while achieving superior\nperformance with comparable or fewer parameters.\n","authors":["Yunxiang Fu","Chaoqi Chen","Yizhou Yu"],"pdf_url":"https://arxiv.org/pdf/2408.02615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11515v2","updated":"2024-08-05T16:39:15Z","published":"2024-03-18T07:01:21Z","title":"SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption\n  of Monocular Depth Estimation in Autonomous Navigation Applications","summary":"  Monocular depth estimation (MDE) has advanced significantly, primarily\nthrough the integration of convolutional neural networks (CNNs) and more\nrecently, Transformers. However, concerns about their susceptibility to\nadversarial attacks have emerged, especially in safety-critical domains like\nautonomous driving and robotic navigation. Existing approaches for assessing\nCNN-based depth prediction methods have fallen short in inducing comprehensive\ndisruptions to the vision system, often limited to specific local areas. In\nthis paper, we introduce SSAP (Shape-Sensitive Adversarial Patch), a novel\napproach designed to comprehensively disrupt monocular depth estimation (MDE)\nin autonomous navigation applications. Our patch is crafted to selectively\nundermine MDE in two distinct ways: by distorting estimated distances or by\ncreating the illusion of an object disappearing from the system's perspective.\nNotably, our patch is shape-sensitive, meaning it considers the specific shape\nand scale of the target object, thereby extending its influence beyond\nimmediate proximity. Furthermore, our patch is trained to effectively address\ndifferent scales and distances from the camera. Experimental results\ndemonstrate that our approach induces a mean depth estimation error surpassing\n0.5, impacting up to 99% of the targeted region for CNN-based MDE models.\nAdditionally, we investigate the vulnerability of Transformer-based MDE models\nto patch-based attacks, revealing that SSAP yields a significant error of 0.59\nand exerts substantial influence over 99% of the target region on these models.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Bassem Ouni","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2403.11515v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2303.01351"},{"id":"http://arxiv.org/abs/2303.01351v3","updated":"2024-08-05T16:37:37Z","published":"2023-03-02T15:31:53Z","title":"APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth\n  Estimation for Autonomous Navigation","summary":"  In recent times, monocular depth estimation (MDE) has experienced significant\nadvancements in performance, largely attributed to the integration of\ninnovative architectures, i.e., convolutional neural networks (CNNs) and\nTransformers. Nevertheless, the susceptibility of these models to adversarial\nattacks has emerged as a noteworthy concern, especially in domains where safety\nand security are paramount. This concern holds particular weight for MDE due to\nits critical role in applications like autonomous driving and robotic\nnavigation, where accurate scene understanding is pivotal. To assess the\nvulnerability of CNN-based depth prediction methods, recent work tries to\ndesign adversarial patches against MDE. However, the existing approaches fall\nshort of inducing a comprehensive and substantially disruptive impact on the\nvision system. Instead, their influence is partial and confined to specific\nlocal areas. These methods lead to erroneous depth predictions only within the\noverlapping region with the input image, without considering the\ncharacteristics of the target object, such as its size, shape, and position. In\nthis paper, we introduce a novel adversarial patch named APARATE. This patch\npossesses the ability to selectively undermine MDE in two distinct ways: by\ndistorting the estimated distances or by creating the illusion of an object\ndisappearing from the perspective of the autonomous system. Notably, APARATE is\ndesigned to be sensitive to the shape and scale of the target object, and its\ninfluence extends beyond immediate proximity. APARATE, results in a mean depth\nestimation error surpassing $0.5$, significantly impacting as much as $99\\%$ of\nthe targeted region when applied to CNN-based MDE models. Furthermore, it\nyields a significant error of $0.34$ and exerts substantial influence over\n$94\\%$ of the target region in the context of Transformer-based MDE.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01351v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.07338v2","updated":"2024-08-05T16:34:43Z","published":"2023-03-13T17:59:02Z","title":"Revisiting Class-Incremental Learning with Pre-Trained Models:\n  Generalizability and Adaptivity are All You Need","summary":"  Class-incremental learning (CIL) aims to adapt to emerging new classes\nwithout forgetting old ones. Traditional CIL models are trained from scratch to\ncontinually acquire knowledge as data evolves. Recently, pre-training has\nachieved substantial progress, making vast pre-trained models (PTMs) accessible\nfor CIL. Contrary to traditional methods, PTMs possess generalizable\nembeddings, which can be easily transferred for CIL. In this work, we revisit\nCIL with PTMs and argue that the core factors in CIL are adaptivity for model\nupdating and generalizability for knowledge transferring. 1) We first reveal\nthat frozen PTM can already provide generalizable embeddings for CIL.\nSurprisingly, a simple baseline (SimpleCIL) which continually sets the\nclassifiers of PTM to prototype features can beat state-of-the-art even without\ntraining on the downstream task. 2) Due to the distribution gap between\npre-trained and downstream datasets, PTM can be further cultivated with\nadaptivity via model adaptation. We propose AdaPt and mERge (APER), which\naggregates the embeddings of PTM and adapted models for classifier\nconstruction. APER is a general framework that can be orthogonally combined\nwith any parameter-efficient tuning method, which holds the advantages of PTM's\ngeneralizability and adapted model's adaptivity. 3) Additionally, considering\nprevious ImageNet-based benchmarks are unsuitable in the era of PTM due to data\noverlapping, we propose four new benchmarks for assessment, namely ImageNet-A,\nObjectNet, OmniBenchmark, and VTAB. Extensive experiments validate the\neffectiveness of APER with a unified and concise framework. Code is available\nat https://github.com/zhoudw-zdw/RevisitingCIL\n","authors":["Da-Wei Zhou","Zi-Wen Cai","Han-Jia Ye","De-Chuan Zhan","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.07338v2.pdf","comment":"Accepted to IJCV. Code is available at:\n  https://github.com/zhoudw-zdw/RevisitingCIL"},{"id":"http://arxiv.org/abs/2408.02595v1","updated":"2024-08-05T16:07:31Z","published":"2024-08-05T16:07:31Z","title":"Modelling Visual Semantics via Image Captioning to extract Enhanced\n  Multi-Level Cross-Modal Semantic Incongruity Representation with Attention\n  for Multimodal Sarcasm Detection","summary":"  Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets.\n","authors":["Sajal Aggarwal","Ananya Pandey","Dinesh Kumar Vishwakarma"],"pdf_url":"https://arxiv.org/pdf/2408.02595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02571v1","updated":"2024-08-05T15:45:59Z","published":"2024-08-05T15:45:59Z","title":"Contrastive Learning-based Multi Modal Architecture for Emoticon\n  Prediction by Employing Image-Text Pairs","summary":"  The emoticons are symbolic representations that generally accompany the\ntextual content to visually enhance or summarize the true intention of a\nwritten message. Although widely utilized in the realm of social media, the\ncore semantics of these emoticons have not been extensively explored based on\nmultiple modalities. Incorporating textual and visual information within a\nsingle message develops an advanced way of conveying information. Hence, this\nresearch aims to analyze the relationship among sentences, visuals, and\nemoticons. For an orderly exposition, this paper initially provides a detailed\nexamination of the various techniques for extracting multimodal features,\nemphasizing the pros and cons of each method. Through conducting a\ncomprehensive examination of several multimodal algorithms, with specific\nemphasis on the fusion approaches, we have proposed a novel contrastive\nlearning based multimodal architecture. The proposed model employs the joint\ntraining of dual-branch encoder along with the contrastive learning to\naccurately map text and images into a common latent space. Our key finding is\nthat by integrating the principle of contrastive learning with that of the\nother two branches yields superior results. The experimental results\ndemonstrate that our suggested methodology surpasses existing multimodal\napproaches in terms of accuracy and robustness. The proposed model attained an\naccuracy of 91% and an MCC-score of 90% while assessing emoticons using the\nMultimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence\nthat deep features acquired by contrastive learning are more efficient,\nsuggesting that the proposed fusion technique also possesses strong\ngeneralisation capabilities for recognising emoticons across several modes.\n","authors":["Ananya Pandey","Dinesh Kumar Vishwakarma"],"pdf_url":"https://arxiv.org/pdf/2408.02571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02568v1","updated":"2024-08-05T15:43:56Z","published":"2024-08-05T15:43:56Z","title":"Cross-Modality Clustering-based Self-Labeling for Multimodal Data\n  Classification","summary":"  Technological advances facilitate the ability to acquire multimodal data,\nposing a challenge for recognition systems while also providing an opportunity\nto use the heterogeneous nature of the information to increase the\ngeneralization capability of models. An often overlooked issue is the cost of\nthe labeling process, which is typically high due to the need for a significant\ninvestment in time and money associated with human experts. Existing\nsemi-supervised learning methods often focus on operating in the feature space\ncreated by the fusion of available modalities, neglecting the potential for\ncross-utilizing complementary information available in each modality. To\naddress this problem, we propose Cross-Modality Clustering-based Self-Labeling\n(CMCSL). Based on a small set of pre-labeled data, CMCSL groups instances\nbelonging to each modality in the deep feature space and then propagates known\nlabels within the resulting clusters. Next, information about the instances'\nclass membership in each modality is exchanged based on the Euclidean distance\nto ensure more accurate labeling. Experimental evaluation conducted on 20\ndatasets derived from the MM-IMDb dataset indicates that cross-propagation of\nlabels between modalities -- especially when the number of pre-labeled\ninstances is small -- can allow for more reliable labeling and thus increase\nthe classification performance in each modality.\n","authors":["Paweł Zyblewski","Leandro L. Minku"],"pdf_url":"https://arxiv.org/pdf/2408.02568v1.pdf","comment":"10 pages, 5 figures, 9 tables"},{"id":"http://arxiv.org/abs/2301.07088v3","updated":"2024-08-05T15:38:05Z","published":"2023-01-17T18:53:24Z","title":"Vision Learners Meet Web Image-Text Pairs","summary":"  Many self-supervised learning methods are pre-trained on the well-curated\nImageNet-1K dataset. In this work, given the excellent scalability of web data,\nwe consider self-supervised pre-training on noisy web sourced image-text paired\ndata. First, we conduct a benchmark study of representative self-supervised\npre-training methods on large-scale web data in a like-for-like setting. We\ncompare a range of methods, including single-modal ones that use masked\ntraining objectives and multi-modal ones that use image-text constrastive\ntraining. We observe that existing multi-modal methods do not outperform their\nsingle-modal counterparts on vision transfer learning tasks. We derive an\ninformation-theoretical view to explain these benchmark results, which provides\ninsight into how to design a novel vision learner. Inspired by this insight, we\npresent a new visual representation pre-training method, MUlti-modal\nGenerator~(MUG), that learns from scalable web sourced image-text data. MUG\nachieves state-of-the-art transfer performance on a variety of tasks and\ndemonstrates promising scaling properties. Pre-trained models and code will be\nmade public upon acceptance.\n","authors":["Bingchen Zhao","Quan Cui","Hao Wu","Osamu Yoshie","Cheng Yang","Oisin Mac Aodha"],"pdf_url":"https://arxiv.org/pdf/2301.07088v3.pdf","comment":"Project page: https://bzhao.me/MUG/"},{"id":"http://arxiv.org/abs/2408.02561v1","updated":"2024-08-05T15:37:18Z","published":"2024-08-05T15:37:18Z","title":"HQOD: Harmonious Quantization for Object Detection","summary":"  Task inharmony problem commonly occurs in modern object detectors, leading to\ninconsistent qualities between classification and regression tasks. The\npredicted boxes with high classification scores but poor localization positions\nor low classification scores but accurate localization positions will worsen\nthe performance of detectors after Non-Maximum Suppression. Furthermore, when\nobject detectors collaborate with Quantization-Aware Training (QAT), we observe\nthat the task inharmony problem will be further exacerbated, which is\nconsidered one of the main causes of the performance degradation of quantized\ndetectors. To tackle this issue, we propose the Harmonious Quantization for\nObject Detection (HQOD) framework, which consists of two components. Firstly,\nwe propose a task-correlated loss to encourage detectors to focus on improving\nsamples with lower task harmony quality during QAT. Secondly, a harmonious\nIntersection over Union (IoU) loss is incorporated to balance the optimization\nof the regression branch across different IoU levels. The proposed HQOD can be\neasily integrated into different QAT algorithms and detectors. Remarkably, on\nthe MS COCO dataset, our 4-bit ATSS with ResNet-50 backbone achieves a\nstate-of-the-art mAP of 39.6%, even surpassing the full-precision one.\n","authors":["Long Huang","Zhiwei Dong","Song-Lu Chen","Ruiyao Zhang","Shutong Ti","Feng Chen","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2408.02561v1.pdf","comment":"2024 IEEE International Conference on Multimedia and Expo (ICME),\n  July 15 - July 19, 2024, Niagra Falls, Ontario, Canada"},{"id":"http://arxiv.org/abs/2408.02555v1","updated":"2024-08-05T15:33:45Z","published":"2024-08-05T15:33:45Z","title":"MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh\n  Tokenization","summary":"  We introduce MeshAnything V2, an autoregressive transformer that generates\nArtist-Created Meshes (AM) aligned to given shapes. It can be integrated with\nvarious 3D asset production pipelines to achieve high-quality, highly\ncontrollable AM generation. MeshAnything V2 surpasses previous methods in both\nefficiency and performance using models of the same size. These improvements\nare due to our newly proposed mesh tokenization method: Adjacent Mesh\nTokenization (AMT). Different from previous methods that represent each face\nwith three vertices, AMT uses a single vertex whenever possible. Compared to\nprevious methods, AMT requires about half the token sequence length to\nrepresent the same mesh in average. Furthermore, the token sequences from AMT\nare more compact and well-structured, fundamentally benefiting AM generation.\nOur extensive experiments show that AMT significantly improves the efficiency\nand performance of AM generation. Project Page:\nhttps://buaacyw.github.io/meshanything-v2/\n","authors":["Yiwen Chen","Yikai Wang","Yihao Luo","Zhengyi Wang","Zilong Chen","Jun Zhu","Chi Zhang","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2408.02555v1.pdf","comment":"Project Page: https://buaacyw.github.io/meshanything-v2/ Github:\n  https://github.com/buaacyw/MeshAnythingV2"},{"id":"http://arxiv.org/abs/2408.02507v1","updated":"2024-08-05T14:31:09Z","published":"2024-08-05T14:31:09Z","title":"Estimating Pore Location of PBF-LB/M Processes with Segmentation Models","summary":"  Reliably manufacturing defect free products is still an open challenge for\nLaser Powder Bed Fusion processes. Particularly, pores that occur frequently\nhave a negative impact on mechanical properties like fatigue performance.\nTherefore, an accurate localisation of pores is mandatory for quality\nassurance, but requires time-consuming post-processing steps like computer\ntomography scans. Although existing solutions using in-situ monitoring data can\ndetect pore occurrence within a layer, they are limited in their localisation\nprecision. Therefore, we propose a pore localisation approach that estimates\ntheir position within a single layer using a Gaussian kernel density\nestimation. This allows segmentation models to learn the correlation between\nin-situ monitoring data and the derived probability distribution of pore\noccurrence. Within our experiments, we compare the prediction performance of\ndifferent segmentation models depending on machine parameter configuration and\ngeometry features. From our results, we conclude that our approach allows a\nprecise localisation of pores that requires minimal data preprocessing. Our\nresearch extends the literature by providing a foundation for more precise pore\ndetection systems.\n","authors":["Hans Aoyang Zhou","Jan Theunissen","Marco Kemmerling","Anas Abdelrazeq","Johannes Henrich Schleifenbaum","Robert H. Schmitt"],"pdf_url":"https://arxiv.org/pdf/2408.02507v1.pdf","comment":"20 pages, 7 figures, This work has been submitted to the Journal\n  Progress in Additive Manufacturing"},{"id":"http://arxiv.org/abs/2408.02496v1","updated":"2024-08-05T14:19:03Z","published":"2024-08-05T14:19:03Z","title":"Automatic rating of incomplete hippocampal inversions evaluated across\n  multiple cohorts","summary":"  Incomplete Hippocampal Inversion (IHI), sometimes called hippocampal\nmalrotation, is an atypical anatomical pattern of the hippocampus found in\nabout 20% of the general population. IHI can be visually assessed on coronal\nslices of T1 weighted MR images, using a composite score that combines four\nanatomical criteria. IHI has been associated with several brain disorders\n(epilepsy, schizophrenia). However, these studies were based on small samples.\nFurthermore, the factors (genetic or environmental) that contribute to the\ngenesis of IHI are largely unknown. Large-scale studies are thus needed to\nfurther understand IHI and their potential relationships to neurological and\npsychiatric disorders. However, visual evaluation is long and tedious,\njustifying the need for an automatic method. In this paper, we propose, for the\nfirst time, to automatically rate IHI. We proceed by predicting four anatomical\ncriteria, which are then summed up to form the IHI score, providing the\nadvantage of an interpretable score. We provided an extensive experimental\ninvestigation of different machine learning methods and training strategies. We\nperformed automatic rating using a variety of deep learning models (conv5-FC3,\nResNet and SECNN) as well as a ridge regression. We studied the generalization\nof our models using different cohorts and performed multi-cohort learning. We\nrelied on a large population of 2,008 participants from the IMAGEN study, 993\nand 403 participants from the QTIM/QTAB studies as well as 985 subjects from\nthe UKBiobank. We showed that deep learning models outperformed a ridge\nregression. We demonstrated that the performances of the conv5-FC3 network were\nat least as good as more complex networks while maintaining a low complexity\nand computation time. We showed that training on a single cohort may lack in\nvariability while training on several cohorts improves generalization.\n","authors":["Lisa Hemforth","Baptiste Couvy-Duchesne","Kevin De Matos","Camille Brianceau","Matthieu Joulot","Tobias Banaschewski","Arun L. W. Bokde","Sylvane Desrivières","Herta Flor","Antoine Grigis","Hugh Garavan","Penny Gowland","Andreas Heinz","Rüdiger Brühl","Jean-Luc Martinot","Marie-Laure Paillère Martinot","Eric Artiges","Dimitri Papadopoulos","Herve Lemaitre","Tomas Paus","Luise Poustka","Sarah Hohmann","Nathalie Holz","Juliane H. Fröhner","Michael N. Smolka","Nilakshi Vaidya","Henrik Walter","Robert Whelan","Gunter Schumann","Christian Büchel","JB Poline","Bernd Itterman","Vincent Frouin","Alexandre Martin","IMAGEN study group","Claire Cury","Olivier Colliot"],"pdf_url":"https://arxiv.org/pdf/2408.02496v1.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:016"},{"id":"http://arxiv.org/abs/2408.02494v1","updated":"2024-08-05T14:18:29Z","published":"2024-08-05T14:18:29Z","title":"HyperSpaceX: Radial and Angular Exploration of HyperSpherical Dimensions","summary":"  Traditional deep learning models rely on methods such as softmax\ncross-entropy and ArcFace loss for tasks like classification and face\nrecognition. These methods mainly explore angular features in a hyperspherical\nspace, often resulting in entangled inter-class features due to dense angular\ndata across many classes. In this paper, a new field of feature exploration is\nproposed known as HyperSpaceX which enhances class discrimination by exploring\nboth angular and radial dimensions in multi-hyperspherical spaces, facilitated\nby a novel DistArc loss. The proposed DistArc loss encompasses three feature\narrangement components: two angular and one radial, enforcing intra-class\nbinding and inter-class separation in multi-radial arrangement, improving\nfeature discriminability. Evaluation of HyperSpaceX framework for the novel\nrepresentation utilizes a proposed predictive measure that accounts for both\nangular and radial elements, providing a more comprehensive assessment of model\naccuracy beyond standard metrics. Experiments across seven object\nclassification and six face recognition datasets demonstrate state-of-the-art\n(SoTA) results obtained from HyperSpaceX, achieving up to a 20% performance\nimprovement on large-scale object datasets in lower dimensions and up to 6%\ngain in higher dimensions.\n","authors":["Chiranjeev Chiranjeev","Muskan Dosi","Kartik Thakral","Mayank Vatsa","Richa Singh"],"pdf_url":"https://arxiv.org/pdf/2408.02494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10107v2","updated":"2024-08-05T14:06:35Z","published":"2024-06-14T15:08:04Z","title":"Annotation Cost-Efficient Active Learning for Deep Metric Learning\n  Driven Remote Sensing Image Retrieval","summary":"  Deep metric learning (DML) has shown to be effective for content-based image\nretrieval (CBIR) in remote sensing (RS). Most of DML methods for CBIR rely on a\nhigh number of annotated images to accurately learn model parameters of deep\nneural networks (DNNs). However, gathering such data is time-consuming and\ncostly. To address this, we propose an annotation cost-efficient active\nlearning (ANNEAL) method tailored to DML-driven CBIR in RS. ANNEAL aims to\ncreate a small but informative training set made up of similar and dissimilar\nimage pairs to be utilized for accurately learning a metric space. The\ninformativeness of image pairs is evaluated by combining uncertainty and\ndiversity criteria. To assess the uncertainty of image pairs, we introduce two\nalgorithms: 1) metric-guided uncertainty estimation (MGUE); and 2) binary\nclassifier guided uncertainty estimation (BCGUE). MGUE algorithm automatically\nestimates a threshold value that acts as a boundary between similar and\ndissimilar image pairs based on the distances in the metric space. The closer\nthe similarity between image pairs is to the estimated threshold value the\nhigher their uncertainty. BCGUE algorithm estimates the uncertainty of the\nimage pairs based on the confidence of the classifier in assigning correct\nsimilarity labels. The diversity criterion is assessed through a\nclustering-based strategy. ANNEAL combines either MGUE or BCGUE algorithm with\nthe clustering-based strategy to select the most informative image pairs, which\nare then labelled by expert annotators as similar or dissimilar. This way of\nannotating images significantly reduces the annotation cost compared to\nannotating images with land-use land-cover class labels. Experimental results\non two RS benchmark datasets demonstrate the effectiveness of our method. The\ncode of this work is publicly available at\n\\url{https://git.tu-berlin.de/rsim/anneal_tgrs}.\n","authors":["Genc Hoxha","Gencer Sumbul","Julia Henkel","Lars Möllenbrok","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2406.10107v2.pdf","comment":"Accepted for publication in the IEEE Transactions on Geoscience and\n  Remote Sensing (TGRS)"},{"id":"http://arxiv.org/abs/2408.02484v1","updated":"2024-08-05T14:05:25Z","published":"2024-08-05T14:05:25Z","title":"Exploring Conditional Multi-Modal Prompts for Zero-shot HOI Detection","summary":"  Zero-shot Human-Object Interaction (HOI) detection has emerged as a frontier\ntopic due to its capability to detect HOIs beyond a predefined set of\ncategories. This task entails not only identifying the interactiveness of\nhuman-object pairs and localizing them but also recognizing both seen and\nunseen interaction categories. In this paper, we introduce a novel framework\nfor zero-shot HOI detection using Conditional Multi-Modal Prompts, namely CMMP.\nThis approach enhances the generalization of large foundation models, such as\nCLIP, when fine-tuned for HOI detection. Unlike traditional prompt-learning\nmethods, we propose learning decoupled vision and language prompts for\ninteractiveness-aware visual feature extraction and generalizable interaction\nclassification, respectively. Specifically, we integrate prior knowledge of\ndifferent granularity into conditional vision prompts, including an\ninput-conditioned instance prior and a global spatial pattern prior. The former\nencourages the image encoder to treat instances belonging to seen or\npotentially unseen HOI concepts equally while the latter provides\nrepresentative plausible spatial configuration of the human and object under\ninteraction. Besides, we employ language-aware prompt learning with a\nconsistency constraint to preserve the knowledge of the large foundation model\nto enable better generalization in the text branch. Extensive experiments\ndemonstrate the efficacy of our detector with conditional multi-modal prompts,\noutperforming previous state-of-the-art on unseen classes of various zero-shot\nsettings. The code and models are available at\n\\url{https://github.com/ltttpku/CMMP}.\n","authors":["Ting Lei","Shaofeng Yin","Yuxin Peng","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02875v2","updated":"2024-08-05T14:01:26Z","published":"2024-03-05T11:38:48Z","title":"Enhancing Conceptual Understanding in Multimodal Contrastive Learning\n  through Hard Negative Samples","summary":"  Current multimodal models leveraging contrastive learning often face\nlimitations in developing fine-grained conceptual understanding. This is due to\nrandom negative samples during pretraining, causing almost exclusively very\ndissimilar concepts to be compared in the loss function. Consequently, the\nmodels struggle with fine-grained semantic differences. To address this\nproblem, we introduce a novel pretraining method incorporating synthetic hard\nnegative text examples. The hard negatives permute terms corresponding to\nvisual concepts, leading to a more fine-grained visual and textual concept\nalignment. Further, we introduce InpaintCOCO, a new challenging dataset for\nassessing the fine-grained alignment of colors, objects, and sizes in\nvision-language models. We created the dataset using generative inpainting from\nCOCO images by changing the visual concepts so that the images no longer match\ntheir original captions. Our results show significant improvements in\nfine-grained concept understanding across a wide range of vision-language\ndatasets, including our InpaintCOCO dataset.\n","authors":["Philipp J. Rösch","Norbert Oswald","Michaela Geierhos","Jindřich Libovický"],"pdf_url":"https://arxiv.org/pdf/2403.02875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02464v1","updated":"2024-08-05T13:44:22Z","published":"2024-08-05T13:44:22Z","title":"Fairness and Bias Mitigation in Computer Vision: A Survey","summary":"  Computer vision systems have witnessed rapid progress over the past two\ndecades due to multiple advances in the field. As these systems are\nincreasingly being deployed in high-stakes real-world applications, there is a\ndire need to ensure that they do not propagate or amplify any discriminatory\ntendencies in historical or human-curated data or inadvertently learn biases\nfrom spurious correlations. This paper presents a comprehensive survey on\nfairness that summarizes and sheds light on ongoing trends and successes in the\ncontext of computer vision. The topics we discuss include 1) The origin and\ntechnical definitions of fairness drawn from the wider fair machine learning\nliterature and adjacent disciplines. 2) Work that sought to discover and\nanalyze biases in computer vision systems. 3) A summary of methods proposed to\nmitigate bias in computer vision systems in recent years. 4) A comprehensive\nsummary of resources and datasets produced by researchers to measure, analyze,\nand mitigate bias and enhance fairness. 5) Discussion of the field's success,\ncontinuing trends in the context of multimodal foundation and generative\nmodels, and gaps that still need to be addressed. The presented\ncharacterization should help researchers understand the importance of\nidentifying and mitigating bias in computer vision and the state of the field\nand identify potential directions for future research.\n","authors":["Sepehr Dehdashtian","Ruozhen He","Yi Li","Guha Balakrishnan","Nuno Vasconcelos","Vicente Ordonez","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2408.02464v1.pdf","comment":"20 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.02462v1","updated":"2024-08-05T13:40:33Z","published":"2024-08-05T13:40:33Z","title":"An investigation into the causes of race bias in AI-based cine CMR\n  segmentation","summary":"  Artificial intelligence (AI) methods are being used increasingly for the\nautomated segmentation of cine cardiac magnetic resonance (CMR) imaging.\nHowever, these methods have been shown to be subject to race bias, i.e. they\nexhibit different levels of performance for different races depending on the\n(im)balance of the data used to train the AI model. In this paper we\ninvestigate the source of this bias, seeking to understand its root cause(s) so\nthat it can be effectively mitigated. We perform a series of classification and\nsegmentation experiments on short-axis cine CMR images acquired from Black and\nWhite subjects from the UK Biobank and apply AI interpretability methods to\nunderstand the results. In the classification experiments, we found that race\ncan be predicted with high accuracy from the images alone, but less accurately\nfrom ground truth segmentations, suggesting that the distributional shift\nbetween races, which is often the cause of AI bias, is mostly image-based\nrather than segmentation-based. The interpretability methods showed that most\nattention in the classification models was focused on non-heart regions, such\nas subcutaneous fat. Cropping the images tightly around the heart reduced\nclassification accuracy to around chance level. Similarly, race can be\npredicted from the latent representations of a biased segmentation model,\nsuggesting that race information is encoded in the model. Cropping images\ntightly around the heart reduced but did not eliminate segmentation bias. We\nalso investigate the influence of possible confounders on the bias observed.\n","authors":["Tiarna Lee","Esther Puyol-Anton","Bram Ruijsink","Sebastien Roujol","Theodore Barfoot","Shaheim Ogbomo-Harmitt","Miaojing Shi","Andrew P. King"],"pdf_url":"https://arxiv.org/pdf/2408.02462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15269v2","updated":"2024-08-05T13:23:17Z","published":"2024-06-21T16:04:14Z","title":"You Only Acquire Sparse-channel (YOAS): A Unified Framework for\n  Dense-channel EEG Generation","summary":"  High-precision acquisition of dense-channel electroencephalogram (EEG)\nsignals is often impeded by the costliness and lack of portability of\nequipment. In contrast, generating dense-channel EEG signals effectively from\nsparse channels shows promise and economic viability. However, sparse-channel\nEEG poses challenges such as reduced spatial resolution, information loss,\nsignal mixing, and heightened susceptibility to noise and interference. To\naddress these challenges, we first theoretically formulate the dense-channel\nEEG generation problem as by optimizing a set of cross-channel EEG signal\ngeneration problems. Then, we propose the YOAS framework for generating\ndense-channel data from sparse-channel EEG signals. The YOAS totally consists\nof four sequential stages: Data Preparation, Data Preprocessing, Biased-EEG\nGeneration, and Synthetic EEG Generation. Data Preparation and Preprocessing\ncarefully consider the distribution of EEG electrodes and low signal-to-noise\nratio problem of EEG signals. Biased-EEG Generation includes sub-modules of\nBiasEEGGanFormer and BiasEEGDiffFormer, which facilitate long-term feature\nextraction with attention and generate signals by combining electrode position\nalignment with diffusion model, respectively. Synthetic EEG Generation\nsynthesizes the final signals, employing a deduction paradigm for multi-channel\nEEG generation. Extensive experiments confirmed YOAS's feasibility, efficiency,\nand theoretical validity, even remarkably enhancing data discernibility. This\nbreakthrough in dense-channel EEG signal generation from sparse-channel data\nopens new avenues for exploration in EEG signal processing and application.\n","authors":["Hongyu Chen","Weiming Zeng","Luhui Cai","Lei Wang","Jia Lu","Yueyang Li","Hongjie Yan","Wai Ting Siok","Nizhuan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.15269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12890v3","updated":"2024-08-05T13:10:02Z","published":"2023-11-21T06:24:09Z","title":"De-fine: Decomposing and Refining Visual Programs with Auto-Feedback","summary":"  Visual programming, a modular and generalizable paradigm, integrates\ndifferent modules and Python operators to solve various vision-language tasks.\nUnlike end-to-end models that need task-specific data, it advances in\nperforming visual processing and reasoning in an unsupervised manner. Current\nvisual programming methods generate programs in a single pass for each task\nwhere the ability to evaluate and optimize based on feedback, unfortunately, is\nlacking, which consequentially limits their effectiveness for complex,\nmulti-step problems. Drawing inspiration from benders decomposition, we\nintroduce De-fine, a training-free framework that automatically decomposes\ncomplex tasks into simpler subtasks and refines programs through auto-feedback.\nThis model-agnostic approach can improve logical reasoning performance by\nintegrating the strengths of multiple models. Our experiments across various\nvisual tasks show that De-fine creates more robust programs. Moreover, viewing\neach feedback module as an independent agent will yield fresh prospects for the\nfield of agent research.\n","authors":["Minghe Gao","Juncheng Li","Hao Fei","Liang Pang","Wei Ji","Guoming Wang","Zheqi Lv","Wenqiao Zhang","Siliang Tang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2311.12890v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07990v2","updated":"2024-08-05T12:55:47Z","published":"2024-04-11T17:59:56Z","title":"OpenBias: Open-set Bias Detection in Text-to-Image Generative Models","summary":"  Text-to-image generative models are becoming increasingly popular and\naccessible to the general public. As these models see large-scale deployments,\nit is necessary to deeply investigate their safety and fairness to not\ndisseminate and perpetuate any kind of biases. However, existing works focus on\ndetecting closed sets of biases defined a priori, limiting the studies to\nwell-known concepts. In this paper, we tackle the challenge of open-set bias\ndetection in text-to-image generative models presenting OpenBias, a new\npipeline that identifies and quantifies the severity of biases agnostically,\nwithout access to any precompiled set. OpenBias has three stages. In the first\nphase, we leverage a Large Language Model (LLM) to propose biases given a set\nof captions. Secondly, the target generative model produces images using the\nsame set of captions. Lastly, a Vision Question Answering model recognizes the\npresence and extent of the previously proposed biases. We study the behavior of\nStable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated\nbefore. Via quantitative experiments, we demonstrate that OpenBias agrees with\ncurrent closed-set bias detection methods and human judgement.\n","authors":["Moreno D'Incà","Elia Peruzzo","Massimiliano Mancini","Dejia Xu","Vidit Goel","Xingqian Xu","Zhangyang Wang","Humphrey Shi","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2404.07990v2.pdf","comment":"CVPR 2024 Highlight - Code:\n  https://github.com/Picsart-AI-Research/OpenBias"},{"id":"http://arxiv.org/abs/2303.10571v2","updated":"2024-08-05T12:44:04Z","published":"2023-03-19T05:20:52Z","title":"Reinforcement Learning Friendly Vision-Language Model for Minecraft","summary":"  One of the essential missions in the AI research community is to build an\nautonomous embodied agent that can achieve high-level performance across a wide\nspectrum of tasks. However, acquiring or manually designing rewards for all\nopen-ended tasks is unrealistic. In this paper, we propose a novel cross-modal\ncontrastive learning framework architecture, CLIP4MC, aiming to learn a\nreinforcement learning (RL) friendly vision-language model (VLM) that serves as\nan intrinsic reward function for open-ended tasks. Simply utilizing the\nsimilarity between the video snippet and the language prompt is not RL-friendly\nsince standard VLMs may only capture the similarity at a coarse level. To\nachieve RL-friendliness, we incorporate the task completion degree into the VLM\ntraining objective, as this information can assist agents in distinguishing the\nimportance between different states. Moreover, we provide neat YouTube datasets\nbased on the large-scale YouTube database provided by MineDojo. Specifically,\ntwo rounds of filtering operations guarantee that the dataset covers enough\nessential information and that the video-text pair is highly correlated.\nEmpirically, we demonstrate that the proposed method achieves better\nperformance on RL tasks compared with baselines. The code and datasets are\navailable at https://github.com/PKU-RL/CLIP4MC.\n","authors":["Haobin Jiang","Junpeng Yue","Hao Luo","Ziluo Ding","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2303.10571v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2404.11129v2","updated":"2024-08-05T12:39:06Z","published":"2024-04-17T07:20:56Z","title":"Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales","summary":"  The remarkable performance of Multimodal Large Language Models (MLLMs) has\nunequivocally demonstrated their proficient understanding capabilities in\nhandling a wide array of visual tasks. Nevertheless, the opaque nature of their\nblack-box reasoning processes persists as an enigma, rendering them\nuninterpretable and struggling with hallucination. Their ability to execute\nintricate compositional reasoning tasks is also constrained, culminating in a\nstagnation of learning progression for these models. In this work, we introduce\nFact, a novel paradigm designed to generate multimodal rationales that are\nfaithful, concise, and transferable for teaching MLLMs. This paradigm utilizes\nverifiable visual programming to generate executable code guaranteeing\nfaithfulness and precision. Subsequently, through a series of operations\nincluding pruning, merging, and bridging, the rationale enhances its\nconciseness. Furthermore, we filter rationales that can be transferred to\nend-to-end paradigms from programming paradigms to guarantee transferability.\nEmpirical evidence from experiments demonstrates the superiority of our method\nacross models of varying parameter sizes, significantly enhancing their\ncompositional reasoning and generalization ability. Our approach also reduces\nhallucinations owing to its high correlation between images and text.\n","authors":["Minghe Gao","Shuang Chen","Liang Pang","Yuan Yao","Jisheng Dang","Wenqiao Zhang","Juncheng Li","Siliang Tang","Yueting Zhuang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2404.11129v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02427v1","updated":"2024-08-05T12:34:49Z","published":"2024-08-05T12:34:49Z","title":"Attenuation-adjusted deep learning of pore defects in 2D radiographs of\n  additive manufacturing powders","summary":"  The presence of gas pores in metal feedstock powder for additive\nmanufacturing greatly affects the final AM product. Since current porosity\nanalysis often involves lengthy X-ray computed tomography (XCT) scans with a\nfull rotation around the sample, motivation exists to explore methods that\nallow for high throughput -- possibly enabling in-line porosity analysis during\nmanufacturing. Through labelling pore pixels on single 2D radiographs of\npowders, this work seeks to simulate such future efficient setups. High\nsegmentation accuracy is achieved by combining a model of X-ray attenuation\nthrough particles with a variant of the widely applied UNet architecture;\nnotably, F1-score increases by $11.4\\%$ compared to the baseline UNet. The\nproposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2)\nmaking tight particle cutouts, and 3) subtracting an ideal particle without\npores generated from a distance map inspired by Lambert-Beers law. This paper\nexplores four image processing methods, where the fastest (yet still\nunoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$,\nand the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable\nnature, these strategies can be involved in making high throughput porosity\nanalysis of metal feedstock powder for additive manufacturing.\n","authors":["Andreas Bjerregaard","David Schumacher","Jon Sporring"],"pdf_url":"https://arxiv.org/pdf/2408.02427v1.pdf","comment":"Implementation on https://github.com/yhsure/porosity"},{"id":"http://arxiv.org/abs/2408.02426v1","updated":"2024-08-05T12:33:07Z","published":"2024-08-05T12:33:07Z","title":"FPT+: A Parameter and Memory Efficient Transfer Learning Method for\n  High-resolution Medical Image Classification","summary":"  The success of large-scale pre-trained models has established fine-tuning as\na standard method for achieving significant improvements in downstream tasks.\nHowever, fine-tuning the entire parameter set of a pre-trained model is costly.\nParameter-efficient transfer learning (PETL) has recently emerged as a\ncost-effective alternative for adapting pre-trained models to downstream tasks.\nDespite its advantages, the increasing model size and input resolution present\nchallenges for PETL, as the training memory consumption is not reduced as\neffectively as the parameter usage. In this paper, we introduce Fine-grained\nPrompt Tuning plus (FPT+), a PETL method designed for high-resolution medical\nimage classification, which significantly reduces memory consumption compared\nto other PETL methods. FPT+ performs transfer learning by training a\nlightweight side network and accessing pre-trained knowledge from a large\npre-trained model (LPM) through fine-grained prompts and fusion modules.\nSpecifically, we freeze the LPM and construct a learnable lightweight side\nnetwork. The frozen LPM processes high-resolution images to extract\nfine-grained features, while the side network employs the corresponding\ndown-sampled low-resolution images to minimize the memory usage. To enable the\nside network to leverage pre-trained knowledge, we propose fine-grained prompts\nand fusion modules, which collaborate to summarize information through the\nLPM's intermediate activations. We evaluate FPT+ on eight medical image\ndatasets of varying sizes, modalities, and complexities. Experimental results\ndemonstrate that FPT+ outperforms other PETL methods, using only 1.03% of the\nlearnable parameters and 3.18% of the memory required for fine-tuning an entire\nViT-B model. Our code is available at https://github.com/YijinHuang/FPT.\n","authors":["Yijin Huang","Pujin Cheng","Roger Tam","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2408.02426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19719v2","updated":"2024-08-05T12:29:47Z","published":"2024-07-29T06:03:13Z","title":"Revolutionizing Urban Safety Perception Assessments: Integrating\n  Multimodal Large Language Models with Street View Images","summary":"  Measuring urban safety perception is an important and complex task that\ntraditionally relies heavily on human resources. This process often involves\nextensive field surveys, manual data collection, and subjective assessments,\nwhich can be time-consuming, costly, and sometimes inconsistent. Street View\nImages (SVIs), along with deep learning methods, provide a way to realize\nlarge-scale urban safety detection. However, achieving this goal often requires\nextensive human annotation to train safety ranking models, and the\narchitectural differences between cities hinder the transferability of these\nmodels. Thus, a fully automated method for conducting safety evaluations is\nessential. Recent advances in multimodal large language models (MLLMs) have\ndemonstrated powerful reasoning and analytical capabilities. Cutting-edge\nmodels, e.g., GPT-4 have shown surprising performance in many tasks. We\nemployed these models for urban safety ranking on a human-annotated anchor set\nand validated that the results from MLLMs align closely with human perceptions.\nAdditionally, we proposed a method based on the pre-trained Contrastive\nLanguage-Image Pre-training (CLIP) feature and K-Nearest Neighbors (K-NN)\nretrieval to quickly assess the safety index of the entire city. Experimental\nresults show that our method outperforms existing training needed deep learning\napproaches, achieving efficient and accurate urban safety evaluations. The\nproposed automation for urban safety perception assessment is a valuable tool\nfor city planners, policymakers, and researchers aiming to improve urban\nenvironments.\n","authors":["Jiaxin Zhang","Yunqin Li","Tomohiro Fukuda","Bowen Wang"],"pdf_url":"https://arxiv.org/pdf/2407.19719v2.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.02421v1","updated":"2024-08-05T12:27:28Z","published":"2024-08-05T12:27:28Z","title":"FE-Adapter: Adapting Image-based Emotion Classifiers to Videos","summary":"  Utilizing large pre-trained models for specific tasks has yielded impressive\nresults. However, fully fine-tuning these increasingly large models is becoming\nprohibitively resource-intensive. This has led to a focus on more\nparameter-efficient transfer learning, primarily within the same modality. But\nthis approach has limitations, particularly in video understanding where\nsuitable pre-trained models are less common. Addressing this, our study\nintroduces a novel cross-modality transfer learning approach from images to\nvideos, which we call parameter-efficient image-to-video transfer learning. We\npresent the Facial-Emotion Adapter (FE-Adapter), designed for efficient\nfine-tuning in video tasks. This adapter allows pre-trained image models, which\ntraditionally lack temporal processing capabilities, to analyze dynamic video\ncontent efficiently. Notably, it uses about 15 times fewer parameters than\nprevious methods, while improving accuracy. Our experiments in video emotion\nrecognition demonstrate that the FE-Adapter can match or even surpass existing\nfine-tuning and video emotion models in both performance and efficiency. This\nbreakthrough highlights the potential for cross-modality approaches in\nenhancing the capabilities of AI models, particularly in fields like video\nemotion analysis where the demand for efficiency and accuracy is constantly\nrising.\n","authors":["Shreyank N Gowda","Boyan Gao","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2408.02421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12198v2","updated":"2024-08-05T12:20:49Z","published":"2024-02-19T15:03:04Z","title":"Zero shot VLMs for hate meme detection: Are we there yet?","summary":"  Multimedia content on social media is rapidly evolving, with memes gaining\nprominence as a distinctive form. Unfortunately, some malicious users exploit\nmemes to target individuals or vulnerable communities, making it imperative to\nidentify and address such instances of hateful memes. Extensive research has\nbeen conducted to address this issue by developing hate meme detection models.\nHowever, a notable limitation of traditional machine/deep learning models is\nthe requirement for labeled datasets for accurate classification. Recently, the\nresearch community has witnessed the emergence of several visual language\nmodels that have exhibited outstanding performance across various tasks. In\nthis study, we aim to investigate the efficacy of these visual language models\nin handling intricate tasks such as hate meme detection. We use various prompt\nsettings to focus on zero-shot classification of hateful/harmful memes. Through\nour analysis, we observe that large VLMs are still vulnerable for zero-shot\nhate meme detection.\n","authors":["Naquee Rizwan","Paramananda Bhaskar","Mithun Das","Swadhin Satyaprakash Majhi","Punyajoy Saha","Animesh Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2402.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19905v2","updated":"2024-08-05T12:12:48Z","published":"2024-06-28T13:20:17Z","title":"Solving Token Gradient Conflict in Mixture-of-Experts for Large\n  Vision-Language Model","summary":"  The Mixture-of-Experts (MoE) has gained increasing attention in studying\nLarge Vision-Language Models (LVLMs). It uses a sparse model to replace the\ndense model, achieving comparable performance while activating fewer parameters\nduring inference, thus significantly reducing the inference cost. Existing MoE\nmethods in LVLMs encourage different experts to handle different tokens, and\nthey usually employ a router to predict the routing of each token. However, the\npredictions are based solely on sample features and do not truly reveal the\noptimization directions of tokens. This may lead to severe optimization\ninterference between different tokens assigned to an expert. To address this\nproblem, this paper proposes a novel method based on token-level gradient\nanalysis, i.e., Solving Token Gradient Conflict (STGC). Specifically, we first\nuse token-level gradients to identify conflicting tokens in experts. After\nthat, we add a specialized loss tailored to eliminate conflicts among tokens\nwithin each expert. Our method can serve as a plug-in for diverse Large\nVision-Language Models, and extensive experimental results demonstrate its\neffectiveness. The code will be publicly available at\nhttps://github.com/longrongyang/STGC.\n","authors":["Longrong Yang","Dong Shen","Chaoxiang Cai","Fan Yang","Size Li","Di Zhang","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2406.19905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02408v1","updated":"2024-08-05T12:09:38Z","published":"2024-08-05T12:09:38Z","title":"Multi-weather Cross-view Geo-localization Using Denoising Diffusion\n  Models","summary":"  Cross-view geo-localization in GNSS-denied environments aims to determine an\nunknown location by matching drone-view images with the correct geo-tagged\nsatellite-view images from a large gallery. Recent research shows that learning\ndiscriminative image representations under specific weather conditions can\nsignificantly enhance performance. However, the frequent occurrence of unseen\nextreme weather conditions hinders progress. This paper introduces MCGF, a\nMulti-weather Cross-view Geo-localization Framework designed to dynamically\nadapt to unseen weather conditions. MCGF establishes a joint optimization\nbetween image restoration and geo-localization using denoising diffusion\nmodels. For image restoration, MCGF incorporates a shared encoder and a\nlightweight restoration module to help the backbone eliminate weather-specific\ninformation. For geo-localization, MCGF uses EVA-02 as a backbone for feature\nextraction, with cross-entropy loss for training and cosine distance for\ntesting. Extensive experiments on University160k-WX demonstrate that MCGF\nachieves competitive results for geo-localization in varying weather\nconditions.\n","authors":["Tongtong Feng","Qing Li","Xin Wang","Mingzi Wang","Guangyao Li","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.02408v1.pdf","comment":"Accepted by ACM MM24 workshop"},{"id":"http://arxiv.org/abs/2408.02398v1","updated":"2024-08-05T11:42:41Z","published":"2024-08-05T11:42:41Z","title":"Tensorial template matching for fast cross-correlation with rotations\n  and its application for tomography","summary":"  Object detection is a main task in computer vision. Template matching is the\nreference method for detecting objects with arbitrary templates. However,\ntemplate matching computational complexity depends on the rotation accuracy,\nbeing a limiting factor for large 3D images (tomograms). Here, we implement a\nnew algorithm called tensorial template matching, based on a mathematical\nframework that represents all rotations of a template with a tensor field.\nContrary to standard template matching, the computational complexity of the\npresented algorithm is independent of the rotation accuracy. Using both,\nsynthetic and real data from tomography, we demonstrate that tensorial template\nmatching is much faster than template matching and has the potential to improve\nits accuracy\n","authors":["Antonio Martinez-Sanchez","Ulrike Homberg","José María Almira","Harold Phelippeau"],"pdf_url":"https://arxiv.org/pdf/2408.02398v1.pdf","comment":"Accepted in The 18th European Conference on Computer Vision ECCV 2024"},{"id":"http://arxiv.org/abs/2408.02394v1","updated":"2024-08-05T11:40:59Z","published":"2024-08-05T11:40:59Z","title":"CMR-Agent: Learning a Cross-Modal Agent for Iterative Image-to-Point\n  Cloud Registration","summary":"  Image-to-point cloud registration aims to determine the relative camera pose\nof an RGB image with respect to a point cloud. It plays an important role in\ncamera localization within pre-built LiDAR maps. Despite the modality gaps,\nmost learning-based methods establish 2D-3D point correspondences in feature\nspace without any feedback mechanism for iterative optimization, resulting in\npoor accuracy and interpretability. In this paper, we propose to reformulate\nthe registration procedure as an iterative Markov decision process, allowing\nfor incremental adjustments to the camera pose based on each intermediate\nstate. To achieve this, we employ reinforcement learning to develop a\ncross-modal registration agent (CMR-Agent), and use imitation learning to\ninitialize its registration policy for stability and quick-start of the\ntraining. According to the cross-modal observations, we propose a 2D-3D hybrid\nstate representation that fully exploits the fine-grained features of RGB\nimages while reducing the useless neutral states caused by the spatial\ntruncation of camera frustum. Additionally, the overall framework is\nwell-designed to efficiently reuse one-shot cross-modal embeddings, avoiding\nrepetitive and time-consuming feature extraction. Extensive experiments on the\nKITTI-Odometry and NuScenes datasets demonstrate that CMR-Agent achieves\ncompetitive accuracy and efficiency in registration. Once the one-shot\nembeddings are completed, each iteration only takes a few milliseconds.\n","authors":["Gongxin Yao","Yixin Xuan","Xinyang Li","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2408.02394v1.pdf","comment":"Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2024"},{"id":"http://arxiv.org/abs/2408.02392v1","updated":"2024-08-05T11:39:22Z","published":"2024-08-05T11:39:22Z","title":"MaFreeI2P: A Matching-Free Image-to-Point Cloud Registration Paradigm\n  with Active Camera Pose Retrieval","summary":"  Image-to-point cloud registration seeks to estimate their relative camera\npose, which remains an open question due to the data modality gaps. The recent\nmatching-based methods tend to tackle this by building 2D-3D correspondences.\nIn this paper, we reveal the information loss inherent in these methods and\npropose a matching-free paradigm, named MaFreeI2P. Our key insight is to\nactively retrieve the camera pose in SE(3) space by contrasting the geometric\nfeatures between the point cloud and the query image. To achieve this, we first\nsample a set of candidate camera poses and construct their cost volume using\nthe cross-modal features. Superior to matching, cost volume can preserve more\ninformation and its feature similarity implicitly reflects the confidence level\nof the sampled poses. Afterwards, we employ a convolutional network to\nadaptively formulate a similarity assessment function, where the input cost\nvolume is further improved by filtering and pose-based weighting. Finally, we\nupdate the camera pose based on the similarity scores, and adopt a heuristic\nstrategy to iteratively shrink the pose sampling space for convergence. Our\nMaFreeI2P achieves a very competitive registration accuracy and recall on the\nKITTI-Odometry and Apollo-DaoxiangLake datasets.\n","authors":["Gongxin Yao","Xinyang Li","Yixin Xuan","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2408.02392v1.pdf","comment":"Accepted to IEEE Conference on Multimedia Expo 2024"},{"id":"http://arxiv.org/abs/2309.01446v4","updated":"2024-08-05T11:34:10Z","published":"2023-09-04T08:54:20Z","title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models","summary":"  Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n","authors":["Raz Lapid","Ron Langberg","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2309.01446v4.pdf","comment":"Accepted at SeT-LLM @ ICLR 2024"},{"id":"http://arxiv.org/abs/2408.02382v1","updated":"2024-08-05T11:14:23Z","published":"2024-08-05T11:14:23Z","title":"Cross Psuedo Supervision Framework for Sparsely Labelled Geo-spatial\n  Images","summary":"  Land Use Land Cover (LULC) mapping is essential for urban and resource\nplanning and is one of the key elements in developing smart and sustainable\ncities. This study introduces a semi-supervised segmentation model for LULC\nprediction using high-resolution satellite images with a huge diversity in data\ndistributions in different areas from the country of India. Our approach\nensures a robust generalization across different types of buildings, roads,\ntrees, and water bodies within these distinct areas. We propose a modified\nCross Pseudo Supervision framework to train image segmentation models on\nsparsely labelled data. The proposed framework addresses the limitations of the\npopular \"Cross Pseudo Supervision\" technique for semi-supervised learning.\nSpecifically, it tackles the challenges of training segmentation models on\nnoisy satellite image data with sparse and inaccurate labels. This\ncomprehensive approach enhances the accuracy and utility of LULC mapping for\nvarious urban planning applications.\n","authors":["Yash Dixit","Naman Srivastava","Joel D Joy","Rohan Olikara","Swarup E","Rakshit Ramesh"],"pdf_url":"https://arxiv.org/pdf/2408.02382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02369v1","updated":"2024-08-05T10:38:50Z","published":"2024-08-05T10:38:50Z","title":"The NPU-ASLP System Description for Visual Speech Recognition in CNVSRC\n  2024","summary":"  This paper delineates the visual speech recognition (VSR) system introduced\nby the NPU-ASLP (Team 237) in the second Chinese Continuous Visual Speech\nRecognition Challenge (CNVSRC 2024), engaging in all four tracks, including the\nfixed and open tracks of Single-Speaker VSR Task and Multi-Speaker VSR Task. In\nterms of data processing, we leverage the lip motion extractor from the\nbaseline1 to produce multiscale video data. Besides, various augmentation\ntechniques are applied during training, encompassing speed perturbation, random\nrotation, horizontal flipping, and color transformation. The VSR model adopts\nan end-to-end architecture with joint CTC/attention loss, introducing Enhanced\nResNet3D visual frontend, E-Branchformer encoder, and Bi-directional\nTransformer decoder. Our approach yields a 30.47% CER for the Single-Speaker\nTask and 34.30% CER for the Multi-Speaker Task, securing second place in the\nopen track of the Single-Speaker Task and first place in the other three\ntracks.\n","authors":["He Wang","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2408.02369v1.pdf","comment":"2 pages, 2 figures, CNVSRC 2024 System Report"},{"id":"http://arxiv.org/abs/2408.02367v1","updated":"2024-08-05T10:32:06Z","published":"2024-08-05T10:32:06Z","title":"StoDIP: Efficient 3D MRF image reconstruction with deep image priors and\n  stochastic iterations","summary":"  Magnetic Resonance Fingerprinting (MRF) is a time-efficient approach to\nquantitative MRI for multiparametric tissue mapping. The reconstruction of\nquantitative maps requires tailored algorithms for removing aliasing artefacts\nfrom the compressed sampled MRF acquisitions. Within approaches found in the\nliterature, many focus solely on two-dimensional (2D) image reconstruction,\nneglecting the extension to volumetric (3D) scans despite their higher\nrelevance and clinical value. A reason for this is that transitioning to 3D\nimaging without appropriate mitigations presents significant challenges,\nincluding increased computational cost and storage requirements, and the need\nfor large amount of ground-truth (artefact-free) data for training. To address\nthese issues, we introduce StoDIP, a new algorithm that extends the\nground-truth-free Deep Image Prior (DIP) reconstruction to 3D MRF imaging.\nStoDIP employs memory-efficient stochastic updates across the multicoil MRF\ndata, a carefully selected neural network architecture, as well as faster\nnonuniform FFT (NUFFT) transformations. This enables a faster convergence\ncompared against a conventional DIP implementation without these features.\nTested on a dataset of whole-brain scans from healthy volunteers, StoDIP\ndemonstrated superior performance over the ground-truth-free reconstruction\nbaselines, both quantitatively and qualitatively.\n","authors":["Perla Mayo","Matteo Cencini","Carolin M. Pirkl","Marion I. Menzel","Michela Tosetti","Bjoern H. Menze","Mohammad Golbabaee"],"pdf_url":"https://arxiv.org/pdf/2408.02367v1.pdf","comment":"10 pages, 2 figures, 1 table, 1 algorithm"},{"id":"http://arxiv.org/abs/2407.08583v2","updated":"2024-08-05T10:31:24Z","published":"2024-07-11T15:08:11Z","title":"The Synergy between Data and Multi-Modal Large Language Models: A Survey\n  from Co-Development Perspective","summary":"  The rapid development of large language models (LLMs) has been witnessed in\nrecent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the\nmodality from text to a broader spectrum of domains, attracting widespread\nattention due to the broader range of application scenarios. As LLMs and MLLMs\nrely on vast amounts of model parameters and data to achieve emergent\ncapabilities, the importance of data is receiving increasingly widespread\nattention and recognition. Tracing and analyzing recent data-oriented works for\nMLLMs, we find that the development of models and data is not two separate\npaths but rather interconnected. On the one hand, vaster and higher-quality\ndata contribute to better performance of MLLMs; on the other hand, MLLMs can\nfacilitate the development of data. The co-development of multi-modal data and\nMLLMs requires a clear view of 1) at which development stages of MLLMs specific\ndata-centric approaches can be employed to enhance certain MLLM capabilities,\nand 2) how MLLMs, utilizing those capabilities, can contribute to multi-modal\ndata in specific roles. To promote the data-model co-development for MLLM\ncommunity, we systematically review existing works related to MLLMs from the\ndata-model co-development perspective. A regularly maintained project\nassociated with this survey is accessible at\nhttps://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.\n","authors":["Zhen Qin","Daoyuan Chen","Wenhao Zhang","Liuyi Yao","Yilun Huang","Bolin Ding","Yaliang Li","Shuiguang Deng"],"pdf_url":"https://arxiv.org/pdf/2407.08583v2.pdf","comment":"Ongoing work. 21 pages. Related materials are continually maintained\n  and available at\n  https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md"},{"id":"http://arxiv.org/abs/2405.10802v2","updated":"2024-08-05T10:20:11Z","published":"2024-05-17T14:16:40Z","title":"Reduced storage direct tensor ring decomposition for convolutional\n  neural networks compression","summary":"  Convolutional neural networks (CNNs) are among the most widely used machine\nlearning models for computer vision tasks, such as image classification. To\nimprove the efficiency of CNNs, many CNNs compressing approaches have been\ndeveloped. Low-rank methods approximate the original convolutional kernel with\na sequence of smaller convolutional kernels, which leads to reduced storage and\ntime complexities. In this study, we propose a novel low-rank CNNs compression\nmethod that is based on reduced storage direct tensor ring decomposition\n(RSDTR). The proposed method offers a higher circular mode permutation\nflexibility, and it is characterized by large parameter and FLOPS compression\nrates, while preserving a good classification accuracy of the compressed\nnetwork. The experiments, performed on the CIFAR-10 and ImageNet datasets,\nclearly demonstrate the efficiency of RSDTR in comparison to other\nstate-of-the-art CNNs compression approaches.\n","authors":["Mateusz Gabor","Rafał Zdunek"],"pdf_url":"https://arxiv.org/pdf/2405.10802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02348v1","updated":"2024-08-05T09:50:16Z","published":"2024-08-05T09:50:16Z","title":"Earth System Data Cubes: Avenues for advancing Earth system research","summary":"  Recent advancements in Earth system science have been marked by the\nexponential increase in the availability of diverse, multivariate datasets\ncharacterised by moderate to high spatio-temporal resolutions. Earth System\nData Cubes (ESDCs) have emerged as one suitable solution for transforming this\nflood of data into a simple yet robust data structure. ESDCs achieve this by\norganising data into an analysis-ready format aligned with a spatio-temporal\ngrid, facilitating user-friendly analysis and diminishing the need for\nextensive technical data processing knowledge. Despite these significant\nbenefits, the completion of the entire ESDC life cycle remains a challenging\ntask. Obstacles are not only of a technical nature but also relate to\ndomain-specific problems in Earth system research. There exist barriers to\nrealising the full potential of data collections in light of novel cloud-based\ntechnologies, particularly in curating data tailored for specific application\ndomains. These include transforming data to conform to a spatio-temporal grid\nwith minimum distortions and managing complexities such as spatio-temporal\nautocorrelation issues. Addressing these challenges is pivotal for the\neffective application of Artificial Intelligence (AI) approaches. Furthermore,\nadhering to open science principles for data dissemination, reproducibility,\nvisualisation, and reuse is crucial for fostering sustainable research.\nOvercoming these challenges offers a substantial opportunity to advance\ndata-driven Earth system research, unlocking the full potential of an\nintegrated, multidimensional view of Earth system processes. This is\nparticularly true when such research is coupled with innovative research\nparadigms and technological progress.\n","authors":["David Montero","Guido Kraemer","Anca Anghelea","César Aybar","Gunnar Brandt","Gustau Camps-Valls","Felix Cremer","Ida Flik","Fabian Gans","Sarah Habershon","Chaonan Ji","Teja Kattenborn","Laura Martínez-Ferrer","Francesco Martinuzzi","Martin Reinhardt","Maximilian Söchting","Khalil Teber","Miguel D. Mahecha"],"pdf_url":"https://arxiv.org/pdf/2408.02348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00938v2","updated":"2024-08-05T09:32:30Z","published":"2024-08-01T22:01:42Z","title":"CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting\n  Idiopathic Pulmonary Fibrosis Progression","summary":"  The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly\ncorrelates with higher patient mortality rates. Early detection of IPF\nprogression is critical for initiating timely treatment, which can effectively\nslow down the advancement of the disease. However, the current clinical\ncriteria define disease progression requiring two CT scans with a one-year\ninterval, presenting a dilemma: a disease progression is identified only after\nthe disease has already progressed. To this end, in this paper, we develop a\nnovel diffusion model to accurately predict the progression of IPF by\ngenerating patient's follow-up CT scan from the initial CT scan. Specifically,\nfrom the clinical prior knowledge, we tailor improvements to the traditional\ndiffusion model and propose a Clinically-Informed Residual Diffusion model,\ncalled CIResDiff. The key innovations of CIResDiff include 1) performing the\ntarget region pre-registration to align the lung regions of two CT scans at\ndifferent time points for reducing the generation difficulty, 2) adopting the\nresidual diffusion instead of traditional diffusion to enable the model focus\nmore on differences (i.e., lesions) between the two CT scans rather than the\nlargely identical anatomical content, and 3) designing the clinically-informed\nprocess based on CLIP technology to integrate lung function information which\nis highly relevant to diagnosis into the reverse process for assisting\ngeneration. Extensive experiments on clinical data demonstrate that our\napproach can outperform state-of-the-art methods and effectively predict the\nprogression of IPF.\n","authors":["Caiwen Jiang","Xiaodan Xing","Zaixin Ou","Mianxin Liu","Walsh Simon","Guang Yang","Dinggang Shen"],"pdf_url":"https://arxiv.org/pdf/2408.00938v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02336v1","updated":"2024-08-05T09:19:52Z","published":"2024-08-05T09:19:52Z","title":"Infusing Environmental Captions for Long-Form Video Language Grounding","summary":"  In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.\n","authors":["Hyogun Lee","Soyeon Hong","Mujeen Sung","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2408.02336v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.16248v3","updated":"2024-08-05T09:05:59Z","published":"2024-07-23T07:36:54Z","title":"Spatiotemporal Graph Guided Multi-modal Network for Livestreaming\n  Product Retrieval","summary":"  With the rapid expansion of e-commerce, more consumers have become accustomed\nto making purchases via livestreaming. Accurately identifying the products\nbeing sold by salespeople, i.e., livestreaming product retrieval (LPR), poses a\nfundamental and daunting challenge. The LPR task encompasses three primary\ndilemmas in real-world scenarios: 1) the recognition of intended products from\ndistractor products present in the background; 2) the video-image heterogeneity\nthat the appearance of products showcased in live streams often deviates\nsubstantially from standardized product images in stores; 3) there are numerous\nconfusing products with subtle visual nuances in the shop. To tackle these\nchallenges, we propose the Spatiotemporal Graphing Multi-modal Network (SGMN).\nFirst, we employ a text-guided attention mechanism that leverages the spoken\ncontent of salespeople to guide the model to focus toward intended products,\nemphasizing their salience over cluttered background products. Second, a\nlong-range spatiotemporal graph network is further designed to achieve both\ninstance-level interaction and frame-level matching, solving the misalignment\ncaused by video-image heterogeneity. Third, we propose a multi-modal hard\nexample mining, assisting the model in distinguishing highly similar products\nwith fine-grained features across the video-image-text domain. Through\nextensive quantitative and qualitative experiments, we demonstrate the superior\nperformance of our proposed SGMN model, surpassing the state-of-the-art methods\nby a substantial margin. The code is available at\nhttps://github.com/Huxiaowan/SGMN.\n","authors":["Xiaowan Hu","Yiyi Chen","Yan Li","Minquan Wang","Haoqian Wang","Quan Chen","Han Li","Peng Jiang"],"pdf_url":"https://arxiv.org/pdf/2407.16248v3.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.01090v2","updated":"2024-08-05T08:47:19Z","published":"2023-11-02T08:55:11Z","title":"Infusion: internal diffusion for inpainting of dynamic textures and\n  complex motion","summary":"  Video inpainting is the task of filling a region in a video in a visually\nconvincing manner. It is very challenging due to the high dimensionality of the\ndata and the temporal consistency required for obtaining convincing results.\nRecently, diffusion models have shown impressive results in modeling complex\ndata distributions, including images and videos. Such models remain nonetheless\nvery expensive to train and to perform inference with, which strongly reduce\ntheir applicability to videos, and yields unreasonable computational loads. We\nshow that in the case of video inpainting, thanks to the highly auto-similar\nnature of videos, the training data of a diffusion model can be restricted to\nthe input video and still produce very satisfying results. This leads us to\nadopt an internal learning approach, which also allows us to greatly reduce the\nneural network size by about three orders of magnitude less than current\ndiffusion models used for image inpainting. We also introduce a new method for\nefficient training and inference of diffusion models in the context of internal\nlearning, by splitting the diffusion process into different learning intervals\ncorresponding to different noise levels of the diffusion process. To the best\nof our knowledge, this is the first video inpainting method based purely on\ndiffusion. Other methods require additional components such as optical flow\nestimation, which limits their performance in the case of dynamic textures and\ncomplex motions. We show qualitative and quantitative results, demonstrating\nthat our method reaches state of the art performance in the case of dynamic\ntextures and complex dynamic backgrounds.\n","authors":["Nicolas Cherel","Andrés Almansa","Yann Gousseau","Alasdair Newson"],"pdf_url":"https://arxiv.org/pdf/2311.01090v2.pdf","comment":"11 pages, 10 figures"},{"id":"http://arxiv.org/abs/2408.02307v1","updated":"2024-08-05T08:36:13Z","published":"2024-08-05T08:36:13Z","title":"Low-Cost Self-Ensembles Based on Multi-Branch Transformation and Grouped\n  Convolution","summary":"  Recent advancements in low-cost ensemble learning have demonstrated improved\nefficiency for image classification. However, the existing low-cost ensemble\nmethods show relatively lower accuracy compared to conventional ensemble\nlearning. In this paper, we propose a new low-cost ensemble learning, which can\nsimultaneously achieve high efficiency and classification performance. A CNN is\ntransformed into a multi-branch structure without introduction of additional\ncomponents, which maintains the computational complexity as that of the\noriginal single model and also enhances diversity among the branches' outputs\nvia sufficient separation between different pathways of the branches. In\naddition, we propose a new strategy that applies grouped convolution in the\nbranches with different numbers of groups in different branches, which boosts\nthe diversity of the branches' outputs. For training, we employ knowledge\ndistillation using the ensemble of the outputs as the teacher signal. The high\ndiversity among the outputs enables to form a powerful teacher, enhancing the\nindividual branch's classification performance and consequently the overall\nensemble performance. Experimental results show that our method achieves\nstate-of-the-art classification accuracy and higher uncertainty estimation\nperformance compared to previous low-cost ensemble methods. The code is\navailable at https://github.com/hjdw2/SEMBG.\n","authors":["Hojung Lee","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2408.02307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02306v1","updated":"2024-08-05T08:35:59Z","published":"2024-08-05T08:35:59Z","title":"Mixture-of-Noises Enhanced Forgery-Aware Predictor for Multi-Face\n  Manipulation Detection and Localization","summary":"  With the advancement of face manipulation technology, forgery images in\nmulti-face scenarios are gradually becoming a more complex and realistic\nchallenge. Despite this, detection and localization methods for such multi-face\nmanipulations remain underdeveloped. Traditional manipulation localization\nmethods either indirectly derive detection results from localization masks,\nresulting in limited detection performance, or employ a naive two-branch\nstructure to simultaneously obtain detection and localization results, which\ncannot effectively benefit the localization capability due to limited\ninteraction between two tasks. This paper proposes a new framework, namely\nMoNFAP, specifically tailored for multi-face manipulation detection and\nlocalization. The MoNFAP primarily introduces two novel modules: the\nForgery-aware Unified Predictor (FUP) Module and the Mixture-of-Noises Module\n(MNM). The FUP integrates detection and localization tasks using a token\nlearning strategy and multiple forgery-aware transformers, which facilitates\nthe use of classification information to enhance localization capability.\nBesides, motivated by the crucial role of noise information in forgery\ndetection, the MNM leverages multiple noise extractors based on the concept of\nthe mixture of experts to enhance the general RGB features, further boosting\nthe performance of our framework. Finally, we establish a comprehensive\nbenchmark for multi-face detection and localization and the proposed\n\\textit{MoNFAP} achieves significant performance. The codes will be made\navailable.\n","authors":["Changtao Miao","Qi Chu","Tao Gong","Zhentao Tan","Zhenchao Jin","Wanyi Zhuang","Man Luo","Honggang Hu","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2408.02306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15362v2","updated":"2024-08-05T08:26:24Z","published":"2024-07-22T04:09:27Z","title":"A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model","summary":"  Remarkable strides in computational pathology have been made in the\ntask-agnostic foundation model that advances the performance of a wide array of\ndownstream clinical tasks. Despite the promising performance, there are still\nseveral challenges. First, prior works have resorted to either vision-only or\nvision-captions data, disregarding invaluable pathology reports and gene\nexpression profiles which respectively offer distinct knowledge for versatile\nclinical applications. Second, the current progress in pathology FMs\npredominantly concentrates on the patch level, where the restricted context of\npatch-level pretraining fails to capture whole-slide patterns. Here we curated\nthe largest multimodal dataset consisting of H\\&E diagnostic whole slide images\nand their associated pathology reports and RNA-Seq data, resulting in 26,169\nslide-level modality pairs from 10,275 patients across 32 cancer types. To\nleverage these data for CPath, we propose a novel whole-slide pretraining\nparadigm which injects multimodal knowledge at the whole-slide context into the\npathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed\nparadigm revolutionizes the workflow of pretraining for CPath, which enables\nthe pathology FM to acquire the whole-slide context. To our knowledge, this is\nthe first attempt to incorporate multimodal knowledge at the slide level for\nenhancing pathology FMs, expanding the modelling context from unimodal to\nmultimodal knowledge and from patch-level to slide-level. To systematically\nevaluate the capabilities of mSTAR, extensive experiments including slide-level\nunimodal and multimodal applications, are conducted across 7 diverse types of\ntasks on 43 subtasks, resulting in the largest spectrum of downstream tasks.\nThe average performance in various slide-level applications consistently\ndemonstrates significant performance enhancements for mSTAR compared to SOTA\nFMs.\n","authors":["Yingxue Xu","Yihui Wang","Fengtao Zhou","Jiabo Ma","Shu Yang","Huangjing Lin","Xin Wang","Jiguang Wang","Li Liang","Anjia Han","Ronald Cheong Kin Chan","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2407.15362v2.pdf","comment":"45 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.02301v1","updated":"2024-08-05T08:23:59Z","published":"2024-08-05T08:23:59Z","title":"Network Fission Ensembles for Low-Cost Self-Ensembles","summary":"  Recent ensemble learning methods for image classification have been shown to\nimprove classification accuracy with low extra cost. However, they still\nrequire multiple trained models for ensemble inference, which eventually\nbecomes a significant burden when the model size increases. In this paper, we\npropose a low-cost ensemble learning and inference, called Network Fission\nEnsembles (NFE), by converting a conventional network itself into a multi-exit\nstructure. Starting from a given initial network, we first prune some of the\nweights to reduce the training burden. We then group the remaining weights into\nseveral sets and create multiple auxiliary paths using each set to construct\nmulti-exits. We call this process Network Fission. Through this, multiple\noutputs can be obtained from a single network, which enables ensemble learning.\nSince this process simply changes the existing network structure to multi-exits\nwithout using additional networks, there is no extra computational burden for\nensemble learning and inference. Moreover, by learning from multiple losses of\nall exits, the multi-exits improve performance via regularization, and high\nperformance can be achieved even with increased network sparsity. With our\nsimple yet effective method, we achieve significant improvement compared to\nexisting ensemble methods. The code is available at\nhttps://github.com/hjdw2/NFE.\n","authors":["Hojung Lee","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2408.02301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02297v1","updated":"2024-08-05T08:14:28Z","published":"2024-08-05T08:14:28Z","title":"Perception Matters: Enhancing Embodied AI with Uncertainty-Aware\n  Semantic Segmentation","summary":"  Embodied AI has made significant progress acting in unexplored environments.\nHowever, tasks such as object search have largely focused on efficient policy\nlearning. In this work, we identify several gaps in current search methods:\nThey largely focus on dated perception models, neglect temporal aggregation,\nand transfer from ground truth directly to noisy perception at test time,\nwithout accounting for the resulting overconfidence in the perceived state. We\naddress the identified problems through calibrated perception probabilities and\nuncertainty across aggregation and found decisions, thereby adapting the models\nfor sequential tasks. The resulting methods can be directly integrated with\npretrained models across a wide family of existing search approaches at no\nadditional training cost. We perform extensive evaluations of aggregation\nmethods across both different semantic perception models and policies,\nconfirming the importance of calibrated uncertainties in both the aggregation\nand found decisions. We make the code and trained models available at\nhttp://semantic-search.cs.uni-freiburg.de.\n","authors":["Sai Prasanna","Daniel Honerkamp","Kshitij Sirohi","Tim Welschehold","Wolfram Burgard","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2408.02297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02291v1","updated":"2024-08-05T08:00:30Z","published":"2024-08-05T08:00:30Z","title":"SelfGeo: Self-supervised and Geodesic-consistent Estimation of Keypoints\n  on Deformable Shapes","summary":"  Unsupervised 3D keypoints estimation from Point Cloud Data (PCD) is a complex\ntask, even more challenging when an object shape is deforming. As keypoints\nshould be semantically and geometrically consistent across all the 3D frames -\neach keypoint should be anchored to a specific part of the deforming shape\nirrespective of intrinsic and extrinsic motion. This paper presents, \"SelfGeo\",\na self-supervised method that computes persistent 3D keypoints of non-rigid\nobjects from arbitrary PCDs without the need of human annotations. The gist of\nSelfGeo is to estimate keypoints between frames that respect invariant\nproperties of deforming bodies. Our main contribution is to enforce that\nkeypoints deform along with the shape while keeping constant geodesic distances\namong them. This principle is then propagated to the design of a set of losses\nwhich minimization let emerge repeatable keypoints in specific semantic\nlocations of the non-rigid shape. We show experimentally that the use of\ngeodesic has a clear advantage in challenging dynamic scenes and with different\nclasses of deforming shapes (humans and animals). Code and data are available\nat: https://github.com/IIT-PAVIS/SelfGeo\n","authors":["Mohammad Zohaib","Luca Cosmo","Alessio Del Bue"],"pdf_url":"https://arxiv.org/pdf/2408.02291v1.pdf","comment":"This paper has been accepted in ECCV 2024"},{"id":"http://arxiv.org/abs/2407.07720v4","updated":"2024-08-05T07:56:29Z","published":"2024-07-10T14:53:37Z","title":"Exploiting Scale-Variant Attention for Segmenting Small Medical Objects","summary":"  Early detection and accurate diagnosis can predict the risk of malignant\ndisease transformation, thereby increasing the probability of effective\ntreatment. Identifying mild syndrome with small pathological regions serves as\nan ominous warning and is fundamental in the early diagnosis of diseases. While\ndeep learning algorithms, particularly convolutional neural networks (CNNs),\nhave shown promise in segmenting medical objects, analyzing small areas in\nmedical images remains challenging. This difficulty arises due to information\nlosses and compression defects from convolution and pooling operations in CNNs,\nwhich become more pronounced as the network deepens, especially for small\nmedical objects. To address these challenges, we propose a novel scale-variant\nattention-based network (SvANet) for accurately segmenting small-scale objects\nin medical images. The SvANet consists of scale-variant attention, cross-scale\nguidance, Monte Carlo attention, and vision transformer, which incorporates\ncross-scale features and alleviates compression artifacts for enhancing the\ndiscrimination of small medical objects. Quantitative experimental results\ndemonstrate the superior performance of SvANet, achieving 96.12%, 96.11%,\n89.79%, 84.15%, 80.25%, 73.05%, and 72.58% in mean Dice coefficient for\nsegmenting kidney tumors, skin lesions, hepatic tumors, polyps, surgical\nexcision cells, retinal vasculatures, and sperms, which occupy less than 1% of\nthe image areas in KiTS23, ISIC 2018, ATLAS, PolypGen, TissueNet, FIVES, and\nSpermHealth datasets, respectively.\n","authors":["Wei Dai","Rui Liu","Zixuan Wu","Tianyi Wu","Min Wang","Junxian Zhou","Yixuan Yuan","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2407.07720v4.pdf","comment":"14 pages, 9 figures, under review"},{"id":"http://arxiv.org/abs/2408.02285v1","updated":"2024-08-05T07:37:55Z","published":"2024-08-05T07:37:55Z","title":"Joint-Motion Mutual Learning for Pose Estimation in Videos","summary":"  Human pose estimation in videos has long been a compelling yet challenging\ntask within the realm of computer vision. Nevertheless, this task remains\ndifficult because of the complex video scenes, such as video defocus and\nself-occlusion. Recent methods strive to integrate multi-frame visual features\ngenerated by a backbone network for pose estimation. However, they often ignore\nthe useful joint information encoded in the initial heatmap, which is a\nby-product of the backbone generation. Comparatively, methods that attempt to\nrefine the initial heatmap fail to consider any spatio-temporal motion\nfeatures. As a result, the performance of existing methods for pose estimation\nfalls short due to the lack of ability to leverage both local joint (heatmap)\ninformation and global motion (feature) dynamics.\n  To address this problem, we propose a novel joint-motion mutual learning\nframework for pose estimation, which effectively concentrates on both local\njoint dependency and global pixel-level motion dynamics. Specifically, we\nintroduce a context-aware joint learner that adaptively leverages initial\nheatmaps and motion flow to retrieve robust local joint feature. Given that\nlocal joint feature and global motion flow are complementary, we further\npropose a progressive joint-motion mutual learning that synergistically\nexchanges information and interactively learns between joint feature and motion\nflow to improve the capability of the model. More importantly, to capture more\ndiverse joint and motion cues, we theoretically analyze and propose an\ninformation orthogonality objective to avoid learning redundant information\nfrom multi-cues. Empirical experiments show our method outperforms prior arts\non three challenging benchmarks.\n","authors":["Sifan Wu","Haipeng Chen","Yifang Yin","Sihao Hu","Runyang Feng","Yingying Jiao","Ziqi Yang","Zhenguang Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02285v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.18534v2","updated":"2024-08-05T07:37:06Z","published":"2024-07-26T06:29:09Z","title":"Boosting Cross-Domain Point Classification via Distilling Relational\n  Priors from 2D Transformers","summary":"  Semantic pattern of an object point cloud is determined by its topological\nconfiguration of local geometries. Learning discriminative representations can\nbe challenging due to large shape variations of point sets in local regions and\nincomplete surface in a global perspective, which can be made even more severe\nin the context of unsupervised domain adaptation (UDA). In specific,\ntraditional 3D networks mainly focus on local geometric details and ignore the\ntopological structure between local geometries, which greatly limits their\ncross-domain generalization. Recently, the transformer-based models have\nachieved impressive performance gain in a range of image-based tasks,\nbenefiting from its strong generalization capability and scalability stemming\nfrom capturing long range correlation across local patches. Inspired by such\nsuccesses of visual transformers, we propose a novel Relational Priors\nDistillation (RPD) method to extract relational priors from the well-trained\ntransformers on massive images, which can significantly empower cross-domain\nrepresentations with consistent topological priors of objects. To this end, we\nestablish a parameter-frozen pre-trained transformer module shared between 2D\nteacher and 3D student models, complemented by an online knowledge distillation\nstrategy for semantically regularizing the 3D student model. Furthermore, we\nintroduce a novel self-supervised task centered on reconstructing masked point\ncloud patches using corresponding masked multi-view image features, thereby\nempowering the model with incorporating 3D geometric information. Experiments\non the PointDA-10 and the Sim-to-Real datasets verify that the proposed method\nconsistently achieves the state-of-the-art performance of UDA for point cloud\nclassification. The source code of this work is available at\nhttps://github.com/zou-longkun/RPD.git.\n","authors":["Longkun Zou","Wanru Zhu","Ke Chen","Lihua Guo","Kailing Guo","Kui Jia","Yaowei Wang"],"pdf_url":"https://arxiv.org/pdf/2407.18534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02284v1","updated":"2024-08-05T07:34:44Z","published":"2024-08-05T07:34:44Z","title":"Cascading Refinement Video Denoising with Uncertainty Adaptivity","summary":"  Accurate alignment is crucial for video denoising. However, estimating\nalignment in noisy environments is challenging. This paper introduces a\ncascading refinement video denoising method that can refine alignment and\nrestore images simultaneously. Better alignment enables restoration of more\ndetailed information in each frame. Furthermore, better image quality leads to\nbetter alignment. This method has achieved SOTA performance by a large margin\non the CRVD dataset. Simultaneously, aiming to deal with multi-level noise, an\nuncertainty map was created after each iteration. Because of this, redundant\ncomputation on the easily restored videos was avoided. By applying this method,\nthe entire computation was reduced by 25% on average.\n","authors":["Xinyuan Yu"],"pdf_url":"https://arxiv.org/pdf/2408.02284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04485v2","updated":"2024-08-05T07:18:25Z","published":"2024-06-06T20:15:42Z","title":"GenAI Arena: An Open Evaluation Platform for Generative Models","summary":"  Generative AI has made remarkable strides to revolutionize fields such as\nimage and video generation. These advancements are driven by innovative\nalgorithms, architecture, and data. However, the rapid proliferation of\ngenerative models has highlighted a critical gap: the absence of trustworthy\nevaluation metrics. Current automatic assessments such as FID, CLIP, FVD, etc\noften fail to capture the nuanced quality and user satisfaction associated with\ngenerative outputs. This paper proposes an open platform GenAI-Arena to\nevaluate different image and video generative models, where users can actively\nparticipate in evaluating these models. By leveraging collective user feedback\nand votes, GenAI-Arena aims to provide a more democratic and accurate measure\nof model performance. It covers three arenas for text-to-image generation,\ntext-to-video generation, and image editing respectively. Currently, we cover a\ntotal of 27 open-source generative models. GenAI-Arena has been operating for\nfour months, amassing over 6000 votes from the community. We describe our\nplatform, analyze the data, and explain the statistical methods for ranking the\nmodels. To further promote the research in building model-based evaluation\nmetrics, we release a cleaned version of our preference data for the three\ntasks, namely GenAI-Bench. We prompt the existing multi-modal models like\nGemini, GPT-4o to mimic human voting. We compute the correlation between model\nvoting with human voting to understand their judging abilities. Our results\nshow existing multimodal models are still lagging in assessing the generated\nvisual content, even the best model GPT-4o only achieves a Pearson correlation\nof 0.22 in the quality subscore, and behaves like random guessing in others.\n","authors":["Dongfu Jiang","Max Ku","Tianle Li","Yuansheng Ni","Shizhuo Sun","Rongqi Fan","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.04485v2.pdf","comment":"9 pages,7 figures"},{"id":"http://arxiv.org/abs/2408.02275v1","updated":"2024-08-05T07:10:40Z","published":"2024-08-05T07:10:40Z","title":"Geometric Algebra Meets Large Language Models: Instruction-Based\n  Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes","summary":"  This paper introduces a novel integration of Large Language Models (LLMs)\nwith Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene\nediting, particularly for object repositioning tasks, which traditionally\nrequires intricate manual processes and specialized expertise. These\nconventional methods typically suffer from reliance on large training datasets\nor lack a formalized language for precise edits. Utilizing CGA as a robust\nformal language, our system, shenlong, precisely models spatial transformations\nnecessary for accurate object repositioning. Leveraging the zero-shot learning\ncapabilities of pre-trained LLMs, shenlong translates natural language\ninstructions into CGA operations which are then applied to the scene,\nfacilitating exact spatial transformations within 3D scenes without the need\nfor specialized pre-training. Implemented in a realistic simulation\nenvironment, shenlong ensures compatibility with existing graphics pipelines.\nTo accurately assess the impact of CGA, we benchmark against robust Euclidean\nSpace baselines, evaluating both latency and accuracy. Comparative performance\nevaluations indicate that shenlong significantly reduces LLM response times by\n16% and boosts success rates by 9.6% on average compared to the traditional\nmethods. Notably, shenlong achieves a 100% perfect success rate in common\npractical queries, a benchmark where other systems fall short. These\nadvancements underscore shenlong's potential to democratize 3D scene editing,\nenhancing accessibility and fostering innovation across sectors such as\neducation, digital entertainment, and virtual reality.\n","authors":["Dimitris Angelis","Prodromos Kolyvakis","Manos Kamarianakis","George Papagiannakis"],"pdf_url":"https://arxiv.org/pdf/2408.02275v1.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.02272v1","updated":"2024-08-05T07:00:10Z","published":"2024-08-05T07:00:10Z","title":"COM Kitchens: An Unedited Overhead-view Video Dataset as a\n  Vision-Language Benchmark","summary":"  Procedural video understanding is gaining attention in the vision and\nlanguage community. Deep learning-based video analysis requires extensive data.\nConsequently, existing works often use web videos as training resources, making\nit challenging to query instructional contents from raw video observations. To\naddress this issue, we propose a new dataset, COM Kitchens. The dataset\nconsists of unedited overhead-view videos captured by smartphones, in which\nparticipants performed food preparation based on given recipes. Fixed-viewpoint\nvideo datasets often lack environmental diversity due to high camera setup\ncosts. We used modern wide-angle smartphone lenses to cover cooking counters\nfrom sink to cooktop in an overhead view, capturing activity without in-person\nassistance. With this setup, we collected a diverse dataset by distributing\nsmartphones to participants. With this dataset, we propose the novel\nvideo-to-text retrieval task Online Recipe Retrieval (OnRR) and new video\ncaptioning domain Dense Video Captioning on unedited Overhead-View videos\n(DVC-OV). Our experiments verified the capabilities and limitations of current\nweb-video-based SOTA methods in handling these tasks.\n","authors":["Koki Maeda","Tosho Hirasawa","Atsushi Hashimoto","Jun Harashima","Leszek Rybicki","Yusuke Fukasawa","Yoshitaka Ushiku"],"pdf_url":"https://arxiv.org/pdf/2408.02272v1.pdf","comment":"ECCV2024 accepted"},{"id":"http://arxiv.org/abs/2407.18289v2","updated":"2024-08-05T06:53:43Z","published":"2024-07-25T15:18:28Z","title":"MARINE: A Computer Vision Model for Detecting Rare Predator-Prey\n  Interactions in Animal Videos","summary":"  Encounters between predator and prey play an essential role in ecosystems,\nbut their rarity makes them difficult to detect in video recordings. Although\nadvances in action recognition (AR) and temporal action detection (AD),\nespecially transformer-based models and vision foundation models, have achieved\nhigh performance on human action datasets, animal videos remain relatively\nunder-researched. This thesis addresses this gap by proposing the model MARINE,\nwhich utilizes motion-based frame selection designed for fast animal actions\nand DINOv2 feature extraction with a trainable classification head for action\nrecognition. MARINE outperforms VideoMAE in identifying predator attacks in\nvideos of fish, both on a small and specific coral reef dataset (81.53\\%\nagainst 52.64\\% accuracy), and on a subset of the more extensive Animal Kingdom\ndataset (94.86\\% against 83.14\\% accuracy). In a multi-label setting on a\nrepresentative sample of Animal Kingdom, MARINE achieves 23.79\\% mAP,\npositioning it mid-field among existing benchmarks. Furthermore, in an AD task\non the coral reef dataset, MARINE achieves 80.78\\% AP (against VideoMAE's\n34.89\\%) although at a lowered t-IoU threshold of 25\\%. Therefore, despite room\nfor improvement, MARINE offers an effective starter framework to apply to AR\nand AD tasks on animal recordings and thus contribute to the study of natural\necosystems.\n","authors":["Zsófia Katona","Seyed Sahand Mohammadi Ziabari","Fatemeh Karimi Nejadasl"],"pdf_url":"https://arxiv.org/pdf/2407.18289v2.pdf","comment":"This is an MSc thesis by Zsofia Katona, supervised by the two other\n  authors"},{"id":"http://arxiv.org/abs/2407.18288v2","updated":"2024-08-05T06:50:44Z","published":"2024-07-25T14:21:35Z","title":"Leveraging Foundation Models via Knowledge Distillation in Multi-Object\n  Tracking: Distilling DINOv2 Features to FairMOT","summary":"  Multiple Object Tracking (MOT) is a computer vision task that has been\nemployed in a variety of sectors. Some common limitations in MOT are varying\nobject appearances, occlusions, or crowded scenes. To address these challenges,\nmachine learning methods have been extensively deployed, leveraging large\ndatasets, sophisticated models, and substantial computational resources. Due to\npractical limitations, access to the above is not always an option. However,\nwith the recent release of foundation models by prominent AI companies,\npretrained models have been trained on vast datasets and resources using\nstate-of-the-art methods. This work tries to leverage one such foundation\nmodel, called DINOv2, through using knowledge distillation. The proposed method\nuses a teacher-student architecture, where DINOv2 is the teacher and the\nFairMOT backbone HRNetv2 W18 is the student. The results imply that although\nthe proposed method shows improvements in certain scenarios, it does not\nconsistently outperform the original FairMOT model. These findings highlight\nthe potential and limitations of applying foundation models in knowledge\n","authors":["Niels G. Faber","Seyed Sahand Mohammadi Ziabari","Fatemeh Karimi Nejadasl"],"pdf_url":"https://arxiv.org/pdf/2407.18288v2.pdf","comment":"This is an MSc thesis by Niels Faber, supervised by the two other\n  authors"},{"id":"http://arxiv.org/abs/2408.02265v1","updated":"2024-08-05T06:42:00Z","published":"2024-08-05T06:42:00Z","title":"Explain via Any Concept: Concept Bottleneck Model with Open Vocabulary\n  Concepts","summary":"  The concept bottleneck model (CBM) is an interpretable-by-design framework\nthat makes decisions by first predicting a set of interpretable concepts, and\nthen predicting the class label based on the given concepts. Existing CBMs are\ntrained with a fixed set of concepts (concepts are either annotated by the\ndataset or queried from language models). However, this closed-world assumption\nis unrealistic in practice, as users may wonder about the role of any desired\nconcept in decision-making after the model is deployed. Inspired by the large\nsuccess of recent vision-language pre-trained models such as CLIP in zero-shot\nclassification, we propose \"OpenCBM\" to equip the CBM with open vocabulary\nconcepts via: (1) Aligning the feature space of a trainable image feature\nextractor with that of a CLIP's image encoder via a prototype based feature\nalignment; (2) Simultaneously training an image classifier on the downstream\ndataset; (3) Reconstructing the trained classification head via any set of\nuser-desired textual concepts encoded by CLIP's text encoder. To reveal\npotentially missing concepts from users, we further propose to iteratively find\nthe closest concept embedding to the residual parameters during the\nreconstruction until the residual is small enough. To the best of our\nknowledge, our \"OpenCBM\" is the first CBM with concepts of open vocabularies,\nproviding users the unique benefit such as removing, adding, or replacing any\ndesired concept to explain the model's prediction even after a model is\ntrained. Moreover, our model significantly outperforms the previous\nstate-of-the-art CBM by 9% in the classification accuracy on the benchmark\ndataset CUB-200-2011.\n","authors":["Andong Tan","Fengtao Zhou","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2408.02265v1.pdf","comment":"ECCV2024"},{"id":"http://arxiv.org/abs/2305.15213v3","updated":"2024-08-05T06:40:52Z","published":"2023-05-24T14:51:18Z","title":"GTNet: Graph Transformer Network for 3D Point Cloud Classification and\n  Semantic Segmentation","summary":"  Recently, graph-based and Transformer-based deep learning networks have\ndemonstrated excellent performances on various point cloud tasks. Most of the\nexisting graph methods are based on static graph, which take a fixed input to\nestablish graph relations. Moreover, many graph methods apply maximization and\naveraging to aggregate neighboring features, so that only a single neighboring\npoint affects the feature of centroid or different neighboring points have the\nsame influence on the centroid's feature, which ignoring the correlation and\ndifference between points. Most Transformer-based methods extract point cloud\nfeatures based on global attention and lack the feature learning on local\nneighbors. To solve the problems of these two types of models, we propose a new\nfeature extraction block named Graph Transformer and construct a 3D point point\ncloud learning network called GTNet to learn features of point clouds on local\nand global patterns. Graph Transformer integrates the advantages of graph-based\nand Transformer-based methods, and consists of Local Transformer and Global\nTransformer modules. Local Transformer uses a dynamic graph to calculate all\nneighboring point weights by intra-domain cross-attention with dynamically\nupdated graph relations, so that every neighboring point could affect the\nfeatures of centroid with different weights; Global Transformer enlarges the\nreceptive field of Local Transformer by a global self-attention. In addition,\nto avoid the disappearance of the gradient caused by the increasing depth of\nnetwork, we conduct residual connection for centroid features in GTNet; we also\nadopt the features of centroid and neighbors to generate the local geometric\ndescriptors in Local Transformer to strengthen the local information learning\ncapability of the model. Finally, we use GTNet for shape classification, part\nsegmentation and semantic segmentation tasks in this paper.\n","authors":["Wei Zhou","Qian Wang","Weiwei Jin","Xinzhe Shi","Ying He"],"pdf_url":"https://arxiv.org/pdf/2305.15213v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02263v1","updated":"2024-08-05T06:38:43Z","published":"2024-08-05T06:38:43Z","title":"VoxelTrack: Exploring Voxel Representation for 3D Point Cloud Object\n  Tracking","summary":"  Current LiDAR point cloud-based 3D single object tracking (SOT) methods\ntypically rely on point-based representation network. Despite demonstrated\nsuccess, such networks suffer from some fundamental problems: 1) It contains\npooling operation to cope with inherently disordered point clouds, hindering\nthe capture of 3D spatial information that is useful for tracking, a regression\ntask. 2) The adopted set abstraction operation hardly handles\ndensity-inconsistent point clouds, also preventing 3D spatial information from\nbeing modeled. To solve these problems, we introduce a novel tracking\nframework, termed VoxelTrack. By voxelizing inherently disordered point clouds\ninto 3D voxels and extracting their features via sparse convolution blocks,\nVoxelTrack effectively models precise and robust 3D spatial information,\nthereby guiding accurate position prediction for tracked objects. Moreover,\nVoxelTrack incorporates a dual-stream encoder with cross-iterative feature\nfusion module to further explore fine-grained 3D spatial information for\ntracking. Benefiting from accurate 3D spatial information being modeled, our\nVoxelTrack simplifies tracking pipeline with a single regression loss.\nExtensive experiments are conducted on three widely-adopted datasets including\nKITTI, NuScenes and Waymo Open Dataset. The experimental results confirm that\nVoxelTrack achieves state-of-the-art performance (88.3%, 71.4% and 63.6% mean\nprecision on the three datasets, respectively), and outperforms the existing\ntrackers with a real-time speed of 36 Fps on a single TITAN RTX GPU. The source\ncode and model will be released.\n","authors":["Yuxuan Lu","Jiahao Nie","Zhiwei He","Hongjie Gu","Xudong Lv"],"pdf_url":"https://arxiv.org/pdf/2408.02263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08651v4","updated":"2024-08-05T06:37:48Z","published":"2024-03-13T16:06:07Z","title":"HAIFIT: Fashion Image Translation for Human-to-AI Style Learning and\n  Generation","summary":"  In the realm of fashion design, sketches serve as the canvas for expressing\nan artist's distinctive drawing style and creative vision, capturing intricate\ndetails like stroke variations and texture nuances. The advent of\nsketch-to-image cross-modal translation technology has notably aided designers.\nHowever, existing methods often compromise these sketch details during image\ngeneration, resulting in images that deviate from the designer's intended\nconcept. This limitation hampers the ability to offer designers a precise\npreview of the final output. To overcome this challenge, we introduce HAIFIT, a\nnovel approach that transforms sketches into high-fidelity, lifelike clothing\nimages by integrating multi-scale features and capturing extensive feature map\ndependencies from diverse perspectives. Through extensive qualitative and\nquantitative evaluations conducted on our self-collected dataset, our method\ndemonstrates superior performance compared to existing methods in generating\nphotorealistic clothing images. Our method excels in preserving the distinctive\nstyle and intricate details essential for fashion design applications. In\naddition, our method also has obvious advantages in model training and\ninference speed, contributing to reducing designers' time costs and improving\ndesign efficiency.\n","authors":["Jianan Jiang","Xinglin Li","Weiren Yu","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2403.08651v4.pdf","comment":"10 pages,8 figures"},{"id":"http://arxiv.org/abs/2408.02261v1","updated":"2024-08-05T06:32:20Z","published":"2024-08-05T06:32:20Z","title":"Cross-Domain Semantic Segmentation on Inconsistent Taxonomy using VLMs","summary":"  The challenge of semantic segmentation in Unsupervised Domain Adaptation\n(UDA) emerges not only from domain shifts between source and target images but\nalso from discrepancies in class taxonomies across domains. Traditional UDA\nresearch assumes consistent taxonomy between the source and target domains,\nthereby limiting their ability to recognize and adapt to the taxonomy of the\ntarget domain. This paper introduces a novel approach, Cross-Domain Semantic\nSegmentation on Inconsistent Taxonomy using Vision Language Models (CSI), which\neffectively performs domain-adaptive semantic segmentation even in situations\nof source-target class mismatches. CSI leverages the semantic generalization\npotential of Visual Language Models (VLMs) to create synergy with previous UDA\nmethods. It leverages segment reasoning obtained through traditional UDA\nmethods, combined with the rich semantic knowledge embedded in VLMs, to relabel\nnew classes in the target domain. This approach allows for effective adaptation\nto extended taxonomies without requiring any ground truth label for the target\ndomain. Our method has shown to be effective across various benchmarks in\nsituations of inconsistent taxonomy settings (coarse-to-fine taxonomy and open\ntaxonomy) and demonstrates consistent synergy effects when integrated with\nprevious state-of-the-art UDA methods. The implementation is available at\nhttp://github.com/jkee58/CSI.\n","authors":["Jeongkee Lim","Yusung Kim"],"pdf_url":"https://arxiv.org/pdf/2408.02261v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2312.16477v3","updated":"2024-08-05T05:51:21Z","published":"2023-12-27T08:52:41Z","title":"Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding","summary":"  In recent years, the results of view-based 3D shape recognition methods have\nsaturated, and models with excellent performance cannot be deployed on\nmemory-limited devices due to their huge size of parameters. To address this\nproblem, we introduce a compression method based on knowledge distillation for\nthis field, which largely reduces the number of parameters while preserving\nmodel performance as much as possible. Specifically, to enhance the\ncapabilities of smaller models, we design a high-performing large model called\nGroup Multi-view Vision Transformer (GMViT). In GMViT, the view-level ViT first\nestablishes relationships between view-level features. Additionally, to capture\ndeeper features, we employ the grouping module to enhance view-level features\ninto group-level features. Finally, the group-level ViT aggregates group-level\nfeatures into complete, well-formed 3D shape descriptors. Notably, in both\nViTs, we introduce spatial encoding of camera coordinates as innovative\nposition embeddings. Furthermore, we propose two compressed versions based on\nGMViT, namely GMViT-simple and GMViT-mini. To enhance the training\neffectiveness of the small models, we introduce a knowledge distillation method\nthroughout the GMViT process, where the key outputs of each GMViT component\nserve as distillation targets. Extensive experiments demonstrate the efficacy\nof the proposed method. The large model GMViT achieves excellent 3D\nclassification and retrieval results on the benchmark datasets ModelNet,\nShapeNetCore55, and MCB. The smaller models, GMViT-simple and GMViT-mini,\nreduce the parameter size by 8 and 17.6 times, respectively, and improve shape\nrecognition speed by 1.5 times on average, while preserving at least 90% of the\nclassification and retrieval performance. The code is available at\nhttps://github.com/bigdata-graph/GMViT.\n","authors":["Lixiang Xu","Qingzhe Cui","Richang Hong","Wei Xu","Enhong Chen","Xin Yuan","Chenglong Li","Yuanyan Tang"],"pdf_url":"https://arxiv.org/pdf/2312.16477v3.pdf","comment":"13pages, 8 figuers"},{"id":"http://arxiv.org/abs/2408.02250v1","updated":"2024-08-05T05:48:45Z","published":"2024-08-05T05:48:45Z","title":"Hierarchical Clustering using Reversible Binary Cellular Automata for\n  High-Dimensional Data","summary":"  This work proposes a hierarchical clustering algorithm for high-dimensional\ndatasets using the cyclic space of reversible finite cellular automata. In\ncellular automaton (CA) based clustering, if two objects belong to the same\ncycle, they are closely related and considered as part of the same cluster.\nHowever, if a high-dimensional dataset is clustered using the cycles of one CA,\nclosely related objects may belong to different cycles. This paper identifies\nthe relationship between objects in two different cycles based on the median of\nall elements in each cycle so that they can be grouped in the next stage.\nFurther, to minimize the number of intermediate clusters which in turn reduces\nthe computational cost, a rule selection strategy is taken to find the best\nrules based on information propagation and cycle structure. After encoding the\ndataset using frequency-based encoding such that the consecutive data elements\nmaintain a minimum hamming distance in encoded form, our proposed clustering\nalgorithm iterates over three stages to finally cluster the data elements into\nthe desired number of clusters given by user. This algorithm can be applied to\nvarious fields, including healthcare, sports, chemical research, agriculture,\netc. When verified over standard benchmark datasets with various performance\nmetrics, our algorithm is at par with the existing algorithms with quadratic\ntime complexity.\n","authors":["Baby C. J.","Kamalika Bhattacharjee"],"pdf_url":"https://arxiv.org/pdf/2408.02250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02245v1","updated":"2024-08-05T05:33:59Z","published":"2024-08-05T05:33:59Z","title":"Curriculum learning based pre-training using Multi-Modal Contrastive\n  Masked Autoencoders","summary":"  In this paper, we propose a new pre-training method for image understanding\ntasks under Curriculum Learning (CL) paradigm which leverages RGB-D. The method\nutilizes Multi-Modal Contrastive Masked Autoencoder and Denoising techniques.\nRecent approaches either use masked autoencoding (e.g., MultiMAE) or\ncontrastive learning(e.g., Pri3D, or combine them in a single contrastive\nmasked autoencoder architecture such as CMAE and CAV-MAE. However, none of the\nsingle contrastive masked autoencoder is applicable to RGB-D datasets. To\nimprove the performance and efficacy of such methods, we propose a new\npre-training strategy based on CL. Specifically, in the first stage, we\npre-train the model using contrastive learning to learn cross-modal\nrepresentations. In the second stage, we initialize the modality-specific\nencoders using the weights from the first stage and then pre-train the model\nusing masked autoencoding and denoising/noise prediction used in diffusion\nmodels. Masked autoencoding focuses on reconstructing the missing patches in\nthe input modality using local spatial correlations, while denoising learns\nhigh frequency components of the input data. Our approach is scalable, robust\nand suitable for pre-training with limited RGB-D datasets. Extensive\nexperiments on multiple datasets such as ScanNet, NYUv2 and SUN RGB-D show the\nefficacy and superior performance of our approach. Specifically, we show an\nimprovement of +1.0% mIoU against Mask3D on ScanNet semantic segmentation. We\nfurther demonstrate the effectiveness of our approach in low-data regime by\nevaluating it for semantic segmentation task against the state-of-the-art\nmethods.\n","authors":["Muhammad Abdullah Jamal","Omid Mohareri"],"pdf_url":"https://arxiv.org/pdf/2408.02245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02244v1","updated":"2024-08-05T05:30:36Z","published":"2024-08-05T05:30:36Z","title":"Evaluating Vision-Language Models for Zero-Shot Detection,\n  Classification, and Association of Motorcycles, Passengers, and Helmets","summary":"  Motorcycle accidents pose significant risks, particularly when riders and\npassengers do not wear helmets. This study evaluates the efficacy of an\nadvanced vision-language foundation model, OWLv2, in detecting and classifying\nvarious helmet-wearing statuses of motorcycle occupants using video data. We\nextend the dataset provided by the CVPR AI City Challenge and employ a cascaded\nmodel approach for detection and classification tasks, integrating OWLv2 and\nCNN models. The results highlight the potential of zero-shot learning to\naddress challenges arising from incomplete and biased training datasets,\ndemonstrating the usage of such models in detecting motorcycles, helmet usage,\nand occupant positions under varied conditions. We have achieved an average\nprecision of 0.5324 for helmet detection and provided precision-recall curves\ndetailing the detection and classification performance. Despite limitations\nsuch as low-resolution data and poor visibility, our research shows promising\nadvancements in automated vehicle safety and traffic safety enforcement\nsystems.\n","authors":["Lucas Choi","Ross Greer"],"pdf_url":"https://arxiv.org/pdf/2408.02244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11070v2","updated":"2024-08-05T05:13:06Z","published":"2024-04-17T04:59:36Z","title":"Sky-GVIO: an enhanced GNSS/INS/Vision navigation with FCN-based\n  sky-segmentation in urban canyon","summary":"  Accurate, continuous, and reliable positioning is a critical component of\nachieving autonomous driving. However, in complex urban canyon environments,\nthe vulnerability of a stand-alone sensor and non-line-of-sight (NLOS) caused\nby high buildings, trees, and elevated structures seriously affect positioning\nresults. To address these challenges, a sky-view images segmentation algorithm\nbased on Fully Convolutional Network (FCN) is proposed for GNSS NLOS detection.\nBuilding upon this, a novel NLOS detection and mitigation algorithm (named\nS-NDM) is extended to the tightly coupled Global Navigation Satellite Systems\n(GNSS), Inertial Measurement Units (IMU), and visual feature system which is\ncalled Sky-GVIO, with the aim of achieving continuous and accurate positioning\nin urban canyon environments. Furthermore, the system harmonizes Single Point\nPositioning (SPP) with Real-Time Kinematic (RTK) methodologies to bolster its\noperational versatility and resilience. In urban canyon environments, the\npositioning performance of S-NDM algorithm proposed in this paper is evaluated\nunder different tightly coupled SPP-related and RTK-related models. The results\nexhibit that Sky-GVIO system achieves meter-level accuracy under SPP mode and\nsub-decimeter precision with RTK, surpassing the performance of GNSS/INS/Vision\nframeworks devoid of S-NDM. Additionally, the sky-view image dataset, inclusive\nof training and evaluation subsets, has been made publicly accessible for\nscholarly exploration at https://github.com/whuwangjr/sky-view-images .\n","authors":["Jingrong Wang","Bo Xu","Ronghe Jin","Shoujian Zhang","Kefu Gao","Jingnan Liu"],"pdf_url":"https://arxiv.org/pdf/2404.11070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02231v1","updated":"2024-08-05T04:51:46Z","published":"2024-08-05T04:51:46Z","title":"REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language\n  Models","summary":"  Text-to-Image (T2I) and multimodal large language models (MLLMs) have been\nadopted in solutions for several computer vision and multimodal learning tasks.\nHowever, it has been found that such vision-language models lack the ability to\ncorrectly reason over spatial relationships. To tackle this shortcoming, we\ndevelop the REVISION framework which improves spatial fidelity in\nvision-language models. REVISION is a 3D rendering based pipeline that\ngenerates spatially accurate synthetic images, given a textual prompt. REVISION\nis an extendable framework, which currently supports 100+ 3D assets, 11 spatial\nrelationships, all with diverse camera perspectives and backgrounds. Leveraging\nimages from REVISION as additional guidance in a training-free manner\nconsistently improves the spatial consistency of T2I models across all spatial\nrelationships, achieving competitive performance on the VISOR and T2I-CompBench\nbenchmarks. We also design RevQA, a question-answering benchmark to evaluate\nthe spatial reasoning abilities of MLLMs, and find that state-of-the-art models\nare not robust to complex spatial reasoning under adversarial settings. Our\nresults and findings indicate that utilizing rendering-based frameworks is an\neffective approach for developing spatially-aware generative models.\n","authors":["Agneet Chatterjee","Yiran Luo","Tejas Gokhale","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2408.02231v1.pdf","comment":"Accepted to ECCV 2024. Project Page :\n  https://agneetchatterjee.com/revision/"},{"id":"http://arxiv.org/abs/2408.02226v1","updated":"2024-08-05T04:10:52Z","published":"2024-08-05T04:10:52Z","title":"ProCreate, Dont Reproduce! Propulsive Energy Diffusion for Creative\n  Generation","summary":"  In this paper, we propose ProCreate, a simple and easy-to-implement method to\nimprove sample diversity and creativity of diffusion-based image generative\nmodels and to prevent training data reproduction. ProCreate operates on a set\nof reference images and actively propels the generated image embedding away\nfrom the reference embeddings during the generation process. We propose FSCG-8\n(Few-Shot Creative Generation 8), a few-shot creative generation dataset on\neight different categories -- encompassing different concepts, styles, and\nsettings -- in which ProCreate achieves the highest sample diversity and\nfidelity. Furthermore, we show that ProCreate is effective at preventing\nreplicating training data in a large-scale evaluation using training text\nprompts. Code and FSCG-8 are available at\nhttps://github.com/Agentic-Learning-AI-Lab/procreate-diffusion-public. The\nproject page is available at https://procreate-diffusion.github.io.\n","authors":["Jack Lu","Ryan Teehan","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2408.02226v1.pdf","comment":"Accepted for ECCV 2024. Project page:\n  https://procreate-diffusion.github.io"},{"id":"http://arxiv.org/abs/2408.02222v1","updated":"2024-08-05T03:54:40Z","published":"2024-08-05T03:54:40Z","title":"Cross-modulated Attention Transformer for RGBT Tracking","summary":"  Existing Transformer-based RGBT trackers achieve remarkable performance\nbenefits by leveraging self-attention to extract uni-modal features and\ncross-attention to enhance multi-modal feature interaction and template-search\ncorrelation computation. Nevertheless, the independent search-template\ncorrelation calculations ignore the consistency between branches, which can\nresult in ambiguous and inappropriate correlation weights. It not only limits\nthe intra-modal feature representation, but also harms the robustness of\ncross-attention for multi-modal feature interaction and search-template\ncorrelation computation. To address these issues, we propose a novel approach\ncalled Cross-modulated Attention Transformer (CAFormer), which performs\nintra-modality self-correlation, inter-modality feature interaction, and\nsearch-template correlation computation in a unified attention model, for RGBT\ntracking. In particular, we first independently generate correlation maps for\neach modality and feed them into the designed Correlation Modulated Enhancement\nmodule, modulating inaccurate correlation weights by seeking the consensus\nbetween modalities. Such kind of design unifies self-attention and\ncross-attention schemes, which not only alleviates inaccurate attention weight\ncomputation in self-attention but also eliminates redundant computation\nintroduced by extra cross-attention scheme. In addition, we propose a\ncollaborative token elimination strategy to further improve tracking inference\nefficiency and accuracy. Extensive experiments on five public RGBT tracking\nbenchmarks show the outstanding performance of the proposed CAFormer against\nstate-of-the-art methods.\n","authors":["Yun Xiao","Jiacong Zhao","Andong Lu","Chenglong Li","Yin Lin","Bing Yin","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02222v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.02214v1","updated":"2024-08-05T03:33:00Z","published":"2024-08-05T03:33:00Z","title":"More Than Positive and Negative: Communicating Fine Granularity in\n  Medical Diagnosis","summary":"  With the advance of deep learning, much progress has been made in building\npowerful artificial intelligence (AI) systems for automatic Chest X-ray (CXR)\nanalysis. Most existing AI models are trained to be a binary classifier with\nthe aim of distinguishing positive and negative cases. However, a large gap\nexists between the simple binary setting and complicated real-world medical\nscenarios. In this work, we reinvestigate the problem of automatic radiology\ndiagnosis. We first observe that there is considerable diversity among cases\nwithin the positive class, which means simply classifying them as positive\nloses many important details. This motivates us to build AI models that can\ncommunicate fine-grained knowledge from medical images like human experts. To\nthis end, we first propose a new benchmark on fine granularity learning from\nmedical images. Specifically, we devise a division rule based on medical\nknowledge to divide positive cases into two subcategories, namely atypical\npositive and typical positive. Then, we propose a new metric termed\nAUC$^\\text{FG}$ on the two subcategories for evaluation of the ability to\nseparate them apart. With the proposed benchmark, we encourage the community to\ndevelop AI diagnosis systems that could better learn fine granularity from\nmedical images. Last, we propose a simple risk modulation approach to this\nproblem by only using coarse labels in training. Empirical results show that\ndespite its simplicity, the proposed method achieves superior performance and\nthus serves as a strong baseline.\n","authors":["Xiangyu Peng","Kai Wang","Jianfei Yang","Yingying Zhu","Yang You"],"pdf_url":"https://arxiv.org/pdf/2408.02214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02210v1","updated":"2024-08-05T03:22:10Z","published":"2024-08-05T03:22:10Z","title":"ExoViP: Step-by-step Verification and Exploration with Exoskeleton\n  Modules for Compositional Visual Reasoning","summary":"  Compositional visual reasoning methods, which translate a complex query into\na structured composition of feasible visual tasks, have exhibited a strong\npotential in complicated multi-modal tasks. Empowered by recent advances in\nlarge language models (LLMs), this multi-modal challenge has been brought to a\nnew stage by treating LLMs as few-shot/zero-shot planners, i.e.,\nvision-language (VL) programming. Such methods, despite their numerous merits,\nsuffer from challenges due to LLM planning mistakes or inaccuracy of visual\nexecution modules, lagging behind the non-compositional models. In this work,\nwe devise a \"plug-and-play\" method, ExoViP, to correct errors in both the\nplanning and execution stages through introspective verification. We employ\nverification modules as \"exoskeletons\" to enhance current VL programming\nschemes. Specifically, our proposed verification module utilizes a mixture of\nthree sub-verifiers to validate predictions after each reasoning step,\nsubsequently calibrating the visual module predictions and refining the\nreasoning trace planned by LLMs. Experimental results on two representative VL\nprogramming methods showcase consistent improvements on five compositional\nreasoning tasks on standard benchmarks. In light of this, we believe that\nExoViP can foster better performance and generalization on open-domain\nmulti-modal challenges.\n","authors":["Yuxuan Wang","Alan Yuille","Zhuowan Li","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2408.02210v1.pdf","comment":"To Appear at COLM 2024"},{"id":"http://arxiv.org/abs/2408.02209v1","updated":"2024-08-05T03:18:58Z","published":"2024-08-05T03:18:58Z","title":"Source-Free Domain-Invariant Performance Prediction","summary":"  Accurately estimating model performance poses a significant challenge,\nparticularly in scenarios where the source and target domains follow different\ndata distributions. Most existing performance prediction methods heavily rely\non the source data in their estimation process, limiting their applicability in\na more realistic setting where only the trained model is accessible. The few\nmethods that do not require source data exhibit considerably inferior\nperformance. In this work, we propose a source-free approach centred on\nuncertainty-based estimation, using a generative model for calibration in the\nabsence of source data. We establish connections between our approach for\nunsupervised calibration and temperature scaling. We then employ a\ngradient-based strategy to evaluate the correctness of the calibrated\npredictions. Our experiments on benchmark object recognition datasets reveal\nthat existing source-based methods fall short with limited source sample\navailability. Furthermore, our approach significantly outperforms the current\nstate-of-the-art source-free and source-based methods, affirming its\neffectiveness in domain-invariant performance estimation.\n","authors":["Ekaterina Khramtsova","Mahsa Baktashmotlagh","Guido Zuccon","Xi Wang","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2408.02209v1.pdf","comment":"Accepted in ECCV 2024"},{"id":"http://arxiv.org/abs/2402.17521v3","updated":"2024-08-05T03:16:03Z","published":"2024-02-27T14:05:05Z","title":"AVS-Net: Point Sampling with Adaptive Voxel Size for 3D Scene\n  Understanding","summary":"  The recent advancements in point cloud learning have enabled intelligent\nvehicles and robots to comprehend 3D environments better. However, processing\nlarge-scale 3D scenes remains a challenging problem, such that efficient\ndownsampling methods play a crucial role in point cloud learning. Existing\ndownsampling methods either require a huge computational burden or sacrifice\nfine-grained geometric information. For such purpose, this paper presents an\nadvanced sampler that achieves both high accuracy and efficiency. The proposed\nmethod utilizes voxel centroid sampling as a foundation but effectively\naddresses the challenges regarding voxel size determination and the\npreservation of critical geometric cues. Specifically, we propose a Voxel\nAdaptation Module that adaptively adjusts voxel sizes with the reference of\npoint-based downsampling ratio. This ensures that the sampling results exhibit\na favorable distribution for comprehending various 3D objects or scenes.\nMeanwhile, we introduce a network compatible with arbitrary voxel sizes for\nsampling and feature extraction while maintaining high efficiency. The proposed\napproach is demonstrated with 3D object detection and 3D semantic segmentation.\nCompared to existing state-of-the-art methods, our approach achieves better\naccuracy on outdoor and indoor large-scale datasets, e.g. Waymo and ScanNet,\nwith promising efficiency.\n","authors":["Hongcheng Yang","Dingkang Liang","Dingyuan Zhang","Zhe Liu","Zhikang Zou","Xingyu Jiang","Yingying Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.17521v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.00380v2","updated":"2024-08-05T02:45:50Z","published":"2024-08-01T08:41:13Z","title":"Enhancing Whole Slide Pathology Foundation Models through Stain\n  Normalization","summary":"  Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nStain Normalized Pathology Foundational Model, a novel foundational model\ntrained on patches that have undergone stain normalization. Stain normalization\nhelps reduce color variability arising from different laboratories and\nscanners, enabling the model to learn more consistent features. Stain\nNormalized Pathology Foundational Model is trained using 285,153,903 patches\nextracted from a total of 34,795 WSIs, combining data from The Cancer Genome\nAtlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments\ndemonstrate that Stain Normalized Pathology Foundational Model significantly\nmitigates the feature collapse problem, indicating that the model has learned\nmore generalized features rather than overfitting to individual WSI\ncharacteristics. We compared Stain Normalized Pathology Foundational Model with\nstate-of-the-art models across six downstream task datasets, and our results\nshow that Stain Normalized Pathology Foundational Model achieves excellent\nperformance relative to the number of WSIs used and the model's parameter\ncount. This suggests that the application of stain normalization has\nsubstantially improved the model's efficiency and generalization capabilities.\n","authors":["Juseung Yun","Yi Hu","Jinhyung Kim","Jongseong Jang","Soonyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00380v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2404.07950v2","updated":"2024-08-05T02:45:42Z","published":"2024-03-18T16:50:23Z","title":"Reinforcement Learning with Generalizable Gaussian Splatting","summary":"  An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL.\n","authors":["Jiaxu Wang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Gang Han","Wen Zhao","Weining Zhang","Yecheng Shao","Yijie Guo","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2404.07950v2.pdf","comment":"7 pages,2 figures"},{"id":"http://arxiv.org/abs/2305.03713v3","updated":"2024-08-05T02:38:33Z","published":"2023-05-05T17:54:34Z","title":"Avatar Fingerprinting for Authorized Use of Synthetic Talking-Head\n  Videos","summary":"  Modern avatar generators allow anyone to synthesize photorealistic real-time\ntalking avatars, ushering in a new era of avatar-based human communication,\nsuch as with immersive AR/VR interactions or videoconferencing with limited\nbandwidths. Their safe adoption, however, requires a mechanism to verify if the\nrendered avatar is trustworthy: does it use the appearance of an individual\nwithout their consent? We term this task avatar fingerprinting. To tackle it,\nwe first introduce a large-scale dataset of real and synthetic videos of people\ninteracting on a video call, where the synthetic videos are generated using the\nfacial appearance of one person and the expressions of another. We verify the\nidentity driving the expressions in a synthetic video, by learning motion\nsignatures that are independent of the facial appearance shown. Our solution,\nthe first in this space, achieves an average AUC of 0.85. Critical to its\npractical use, it also generalizes to new generators never seen in training\n(average AUC of 0.83). The proposed dataset and other resources can be found\nat: https://research.nvidia.com/labs/nxp/avatar-fingerprinting/.\n","authors":["Ekta Prashnani","Koki Nagano","Shalini De Mello","David Luebke","Orazio Gallo"],"pdf_url":"https://arxiv.org/pdf/2305.03713v3.pdf","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.02192v1","updated":"2024-08-05T02:37:59Z","published":"2024-08-05T02:37:59Z","title":"Unsupervised Domain Adaption Harnessing Vision-Language Pre-training","summary":"  This paper addresses two vital challenges in Unsupervised Domain Adaptation\n(UDA) with a focus on harnessing the power of Vision-Language Pre-training\n(VLP) models. Firstly, UDA has primarily relied on ImageNet pre-trained models.\nHowever, the potential of VLP models in UDA remains largely unexplored. The\nrich representation of VLP models holds significant promise for enhancing UDA\ntasks. To address this, we propose a novel method called Cross-Modal Knowledge\nDistillation (CMKD), leveraging VLP models as teacher models to guide the\nlearning process in the target domain, resulting in state-of-the-art\nperformance. Secondly, current UDA paradigms involve training separate models\nfor each task, leading to significant storage overhead and impractical model\ndeployment as the number of transfer tasks grows. To overcome this challenge,\nwe introduce Residual Sparse Training (RST) exploiting the benefits conferred\nby VLP's extensive pre-training, a technique that requires minimal adjustment\n(approximately 0.1\\%$\\sim$0.5\\%) of VLP model parameters to achieve performance\ncomparable to fine-tuning. Combining CMKD and RST, we present a comprehensive\nsolution that effectively leverages VLP models for UDA tasks while reducing\nstorage overhead for model deployment. Furthermore, CMKD can serve as a\nbaseline in conjunction with other methods like FixMatch, enhancing the\nperformance of UDA. Our proposed method outperforms existing techniques on\nstandard benchmarks. Our code will be available at:\nhttps://github.com/Wenlve-Zhou/VLP-UDA.\n","authors":["Wenlve Zhou","Zhiheng Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02191v1","updated":"2024-08-05T02:35:13Z","published":"2024-08-05T02:35:13Z","title":"Dense Feature Interaction Network for Image Inpainting Localization","summary":"  Image inpainting, which is the task of filling in missing areas in an image,\nis a common image editing technique. Inpainting can be used to conceal or alter\nimage contents in malicious manipulation of images, driving the need for\nresearch in image inpainting detection. Existing methods mostly rely on a basic\nencoder-decoder structure, which often results in a high number of false\npositives or misses the inpainted regions, especially when dealing with targets\nof varying semantics and scales. Additionally, the absence of an effective\napproach to capture boundary artifacts leads to less accurate edge\nlocalization. In this paper, we describe a new method for inpainting detection\nbased on a Dense Feature Interaction Network (DeFI-Net). DeFI-Net uses a novel\nfeature pyramid architecture to capture and amplify multi-scale representations\nacross various stages, thereby improving the detection of image inpainting by\nbetter revealing feature-level interactions. Additionally, the network can\nadaptively direct the lower-level features, which carry edge and shape\ninformation, to refine the localization of manipulated regions while\nintegrating the higher-level semantic features. Using DeFI-Net, we develop a\nmethod combining complementary representations to accurately identify inpainted\nareas. Evaluation on five image inpainting datasets demonstrate the\neffectiveness of our approach, which achieves state-of-the-art performance in\ndetecting inpainting across diverse models.\n","authors":["Ye Yao","Tingfeng Han","Shan Jia","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2408.02191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01355v2","updated":"2024-08-05T02:14:54Z","published":"2024-08-02T16:07:15Z","title":"Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models\n  within Perturbed Inputs","summary":"  Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on various visual-language understanding and generation tasks.\nHowever, MLLMs occasionally generate content inconsistent with the given\nimages, which is known as \"hallucination\". Prior works primarily center on\nevaluating hallucination using standard, unperturbed benchmarks, which overlook\nthe prevalent occurrence of perturbed inputs in real-world scenarios-such as\nimage cropping or blurring-that are critical for a comprehensive assessment of\nMLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI,\nthe first benchmark designed to evaluate Hallucination in MLLMs within\nPerturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios,\ncontaining 1,260 perturbed images from 11 object types. Each image is\naccompanied by detailed annotations, which include fine-grained hallucination\ntypes, such as existence, attribute, and relation. We equip these annotations\nwith a rich set of questions, making Hallu-PI suitable for both discriminative\nand generative tasks. Extensive experiments on 12 mainstream MLLMs, such as\nGPT-4V and Gemini-Pro Vision, demonstrate that these models exhibit significant\nhallucinations on Hallu-PI, which is not observed in unperturbed scenarios.\nFurthermore, our research reveals a severe bias in MLLMs' ability to handle\ndifferent types of hallucinations. We also design two baselines specifically\nfor perturbed scenarios, namely Perturbed-Reminder and Perturbed-ICL. We hope\nthat our study will bring researchers' attention to the limitations of MLLMs\nwhen dealing with perturbed inputs, and spur further investigations to address\nthis issue. Our code and datasets are publicly available at\nhttps://github.com/NJUNLP/Hallu-PI.\n","authors":["Peng Ding","Jingyu Wu","Jun Kuang","Dan Ma","Xuezhi Cao","Xunliang Cai","Shi Chen","Jiajun Chen","Shujian Huang"],"pdf_url":"https://arxiv.org/pdf/2408.01355v2.pdf","comment":"Acccepted by ACM MM 2024, 14 pages, 11 figures, 9 tables"},{"id":"http://arxiv.org/abs/2312.10993v3","updated":"2024-08-05T01:58:58Z","published":"2023-12-18T07:44:40Z","title":"Realistic Human Motion Generation with Cross-Diffusion Models","summary":"  We introduce the Cross Human Motion Diffusion Model (CrossDiff), a novel\napproach for generating high-quality human motion based on textual\ndescriptions. Our method integrates 3D and 2D information using a shared\ntransformer network within the training of the diffusion model, unifying motion\nnoise into a single feature space. This enables cross-decoding of features into\nboth 3D and 2D motion representations, regardless of their original dimension.\nThe primary advantage of CrossDiff is its cross-diffusion mechanism, which\nallows the model to reverse either 2D or 3D noise into clean motion during\ntraining. This capability leverages the complementary information in both\nmotion representations, capturing intricate human movement details often missed\nby models relying solely on 3D information. Consequently, CrossDiff effectively\ncombines the strengths of both representations to generate more realistic\nmotion sequences. In our experiments, our model demonstrates competitive\nstate-of-the-art performance on text-to-motion benchmarks. Moreover, our method\nconsistently provides enhanced motion generation quality, capturing complex\nfull-body movement intricacies. Additionally, with a pretrained model,our\napproach accommodates using in the wild 2D motion data without 3D motion ground\ntruth during training to generate 3D motion, highlighting its potential for\nbroader applications and efficient use of available data resources. Project\npage: https://wonderno.github.io/CrossDiff-webpage/.\n","authors":["Zeping Ren","Shaoli Huang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2312.10993v3.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2408.02181v1","updated":"2024-08-05T01:50:09Z","published":"2024-08-05T01:50:09Z","title":"AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing\n  Pipelines","summary":"  Anomaly detection in manufacturing pipelines remains a critical challenge,\nintensified by the complexity and variability of industrial environments. This\npaper introduces AssemAI, an interpretable image-based anomaly detection system\ntailored for smart manufacturing pipelines. Our primary contributions include\nthe creation of a tailored image dataset and the development of a custom object\ndetection model, YOLO-FF, designed explicitly for anomaly detection in\nmanufacturing assembly environments. Utilizing the preprocessed image dataset\nderived from an industry-focused rocket assembly pipeline, we address the\nchallenge of imbalanced image data and demonstrate the importance of\nimage-based methods in anomaly detection. The proposed approach leverages\ndomain knowledge in data preparation, model development and reasoning. We\ncompare our method against several baselines, including simple CNN and custom\nVisual Transformer (ViT) models, showcasing the effectiveness of our custom\ndata preparation and pretrained CNN integration. Additionally, we incorporate\nexplainability techniques at both user and model levels, utilizing ontology for\nuser-friendly explanations and SCORE-CAM for in-depth feature and model\nanalysis. Finally, the model was also deployed in a real-time setting. Our\nresults include ablation studies on the baselines, providing a comprehensive\nevaluation of the proposed system. This work highlights the broader impact of\nadvanced image-based anomaly detection in enhancing the reliability and\nefficiency of smart manufacturing processes.\n","authors":["Renjith Prasad","Chathurangi Shyalika","Ramtin Zand","Fadi El Kalach","Revathy Venkataramanan","Ramy Harik","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2408.02181v1.pdf","comment":"8 Pages, 6 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2407.20937v2","updated":"2024-08-05T01:27:39Z","published":"2024-07-30T16:19:14Z","title":"EAR: Edge-Aware Reconstruction of 3-D vertebrae structures from\n  bi-planar X-ray images","summary":"  X-ray images ease the diagnosis and treatment process due to their rapid\nimaging speed and high resolution. However, due to the projection process of\nX-ray imaging, much spatial information has been lost. To accurately provide\nefficient spinal morphological and structural information, reconstructing the\n3-D structures of the spine from the 2-D X-ray images is essential. It is\nchallenging for current reconstruction methods to preserve the edge information\nand local shapes of the asymmetrical vertebrae structures. In this study, we\npropose a new Edge-Aware Reconstruction network (EAR) to focus on the\nperformance improvement of the edge information and vertebrae shapes. In our\nnetwork, by using the auto-encoder architecture as the backbone, the edge\nattention module and frequency enhancement module are proposed to strengthen\nthe perception of the edge reconstruction. Meanwhile, we also combine four loss\nterms, including reconstruction loss, edge loss, frequency loss and projection\nloss. The proposed method is evaluated using three publicly accessible datasets\nand compared with four state-of-the-art models. The proposed method is superior\nto other methods and achieves 25.32%, 15.32%, 86.44%, 80.13%, 23.7612 and\n0.3014 with regard to MSE, MAE, Dice, SSIM, PSNR and frequency distance. Due to\nthe end-to-end and accurate reconstruction process, EAR can provide sufficient\n3-D spatial information and precise preoperative surgical planning guidance.\n","authors":["Lixing Tan","Shuang Song","Yaofeng He","Kangneng Zhou","Tong Lu","Ruoxiu Xiao"],"pdf_url":"https://arxiv.org/pdf/2407.20937v2.pdf","comment":"13 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.03572v2","updated":"2024-08-05T01:05:54Z","published":"2023-11-06T22:17:18Z","title":"Unsupervised Region-Growing Network for Object Segmentation in\n  Atmospheric Turbulence","summary":"  Moving object segmentation in the presence of atmospheric turbulence is\nhighly challenging due to turbulence-induced irregular and time-varying\ndistortions. In this paper, we present an unsupervised approach for segmenting\nmoving objects in videos downgraded by atmospheric turbulence. Our key approach\nis a detect-then-grow scheme: we first identify a small set of moving object\npixels with high confidence, then gradually grow a foreground mask from those\nseeds to segment all moving objects. This method leverages rigid geometric\nconsistency among video frames to disentangle different types of motions, and\nthen uses the Sampson distance to initialize the seedling pixels. After growing\nper-frame foreground masks, we use spatial grouping loss and temporal\nconsistency loss to further refine the masks in order to ensure their\nspatio-temporal consistency. Our method is unsupervised and does not require\ntraining on labeled data. For validation, we collect and release the first\nreal-captured long-range turbulent video dataset with ground truth masks for\nmoving objects. Results show that our method achieves good accuracy in\nsegmenting moving objects and is robust for long-range videos with various\nturbulence strengths.\n","authors":["Dehao Qin","Ripon Saha","Suren Jayasuriya","Jinwei Ye","Nianyi Li"],"pdf_url":"https://arxiv.org/pdf/2311.03572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18302v2","updated":"2024-08-05T23:48:12Z","published":"2024-02-28T12:50:16Z","title":"EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous\n  Driving","summary":"  This paper introduces the task of Auditory Referring Multi-Object Tracking\n(AR-MOT), which dynamically tracks specific objects in a video sequence based\non audio expressions and appears as a challenging problem in autonomous\ndriving. Due to the lack of semantic modeling capacity in audio and video,\nexisting works have mainly focused on text-based multi-object tracking, which\noften comes at the cost of tracking quality, interaction efficiency, and even\nthe safety of assistance systems, limiting the application of such methods in\nautonomous driving. In this paper, we delve into the problem of AR-MOT from the\nperspective of audio-video fusion and audio-video tracking. We put forward\nEchoTrack, an end-to-end AR-MOT framework with dual-stream vision transformers.\nThe dual streams are intertwined with our Bidirectional Frequency-domain\nCross-attention Fusion Module (Bi-FCFM), which bidirectionally fuses audio and\nvideo features from both frequency- and spatiotemporal domains. Moreover, we\npropose the Audio-visual Contrastive Tracking Learning (ACTL) regime to extract\nhomogeneous semantic features between expressions and visual objects by\nlearning homogeneous features between different audio and video objects\neffectively. Aside from the architectural design, we establish the first set of\nlarge-scale AR-MOT benchmarks, including Echo-KITTI, Echo-KITTI+, and Echo-BDD.\nExtensive experiments on the established benchmarks demonstrate the\neffectiveness of the proposed EchoTrack and its components. The source code and\ndatasets are available at https://github.com/lab206/EchoTrack.\n","authors":["Jiacheng Lin","Jiajun Chen","Kunyu Peng","Xuan He","Zhiyong Li","Rainer Stiefelhagen","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2402.18302v2.pdf","comment":"Accepted to IEEE Transactions on Intelligent Transportation Systems\n  (T-ITS). The source code and datasets are available at\n  https://github.com/lab206/EchoTrack"},{"id":"http://arxiv.org/abs/2408.02865v1","updated":"2024-08-05T23:31:07Z","published":"2024-08-05T23:31:07Z","title":"VisionUnite: A Vision-Language Foundation Model for Ophthalmology\n  Enhanced with Clinical Knowledge","summary":"  The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.\n","authors":["Zihan Li","Diping Song","Zefeng Yang","Deming Wang","Fei Li","Xiulan Zhang","Paul E. Kinahan","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.02865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02859v1","updated":"2024-08-05T22:59:50Z","published":"2024-08-05T22:59:50Z","title":"Multistain Pretraining for Slide Representation Learning in Pathology","summary":"  Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.\n","authors":["Guillaume Jaume","Anurag Vaidya","Andrew Zhang","Andrew H. Song","Richard J. Chen","Sharifa Sahai","Dandan Mo","Emilio Madrigal","Long Phi Le","Faisal Mahmood"],"pdf_url":"https://arxiv.org/pdf/2408.02859v1.pdf","comment":"ECCV'24"},{"id":"http://arxiv.org/abs/2408.02855v1","updated":"2024-08-05T22:49:20Z","published":"2024-08-05T22:49:20Z","title":"Analyzing Data Efficiency and Performance of Machine Learning Algorithms\n  for Assessing Low Back Pain Physical Rehabilitation Exercises","summary":"  Analyzing human motion is an active research area, with various applications.\nIn this work, we focus on human motion analysis in the context of physical\nrehabilitation using a robot coach system. Computer-aided assessment of\nphysical rehabilitation entails evaluation of patient performance in completing\nprescribed rehabilitation exercises, based on processing movement data captured\nwith a sensory system, such as RGB and RGB-D cameras. As 2D and 3D human pose\nestimation from RGB images had made impressive improvements, we aim to compare\nthe assessment of physical rehabilitation exercises using movement data\nobtained from both RGB-D camera (Microsoft Kinect) and estimation from RGB\nvideos (OpenPose and BlazePose algorithms). A Gaussian Mixture Model (GMM) is\nemployed from position (and orientation) features, with performance metrics\ndefined based on the log-likelihood values from GMM. The evaluation is\nperformed on a medical database of clinical patients carrying out low back-pain\nrehabilitation exercises, previously coached by robot Poppy.\n","authors":["Aleksa Marusic","Louis Annabi","Sao Msi Nguyen","Adriana Tapus"],"pdf_url":"https://arxiv.org/pdf/2408.02855v1.pdf","comment":"European Conference on Mobile Robots (2023)"},{"id":"http://arxiv.org/abs/2408.02840v1","updated":"2024-08-05T21:29:33Z","published":"2024-08-05T21:29:33Z","title":"GAReT: Cross-view Video Geolocalization with Adapters and\n  Auto-Regressive Transformers","summary":"  Cross-view video geo-localization (CVGL) aims to derive GPS trajectories from\nstreet-view videos by aligning them with aerial-view images. Despite their\npromising performance, current CVGL methods face significant challenges. These\nmethods use camera and odometry data, typically absent in real-world scenarios.\nThey utilize multiple adjacent frames and various encoders for feature\nextraction, resulting in high computational costs. Moreover, these approaches\nindependently predict each street-view frame's location, resulting in\ntemporally inconsistent GPS trajectories. To address these challenges, in this\nwork, we propose GAReT, a fully transformer-based method for CVGL that does not\nrequire camera and odometry data. We introduce GeoAdapter, a\ntransformer-adapter module designed to efficiently aggregate image-level\nrepresentations and adapt them for video inputs. Specifically, we train a\ntransformer encoder on video frames and aerial images, then freeze the encoder\nto optimize the GeoAdapter module to obtain video-level representation. To\naddress temporally inconsistent trajectories, we introduce TransRetriever, an\nencoder-decoder transformer model that predicts GPS locations of street-view\nframes by encoding top-k nearest neighbor predictions per frame and\nauto-regressively decoding the best neighbor based on the previous frame's\npredictions. Our method's effectiveness is validated through extensive\nexperiments, demonstrating state-of-the-art performance on benchmark datasets.\nOur code is available at https://github.com/manupillai308/GAReT.\n","authors":["Manu S Pillai","Mamshad Nayeem Rizve","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2408.02840v1.pdf","comment":"Accepted at ECCV 2024"},{"id":"http://arxiv.org/abs/2408.02834v1","updated":"2024-08-05T21:11:34Z","published":"2024-08-05T21:11:34Z","title":"DaCapo: a modular deep learning framework for scalable 3D image\n  segmentation","summary":"  DaCapo is a specialized deep learning library tailored to expedite the\ntraining and application of existing machine learning approaches on large,\nnear-isotropic image data. In this correspondence, we introduce DaCapo's unique\nfeatures optimized for this specific domain, highlighting its modular\nstructure, efficient experiment management tools, and scalable deployment\ncapabilities. We discuss its potential to improve access to large-scale,\nisotropic image segmentation and invite the community to explore and contribute\nto this open-source initiative.\n","authors":["William Patton","Jeff L. Rhoades","Marwan Zouinkhi","David G. Ackerman","Caroline Malin-Mayor","Diane Adjavon","Larissa Heinrich","Davis Bennett","Yurii Zubov","CellMap Project Team","Aubrey V. Weigel","Jan Funke"],"pdf_url":"https://arxiv.org/pdf/2408.02834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19082v2","updated":"2024-08-05T21:09:50Z","published":"2024-07-26T21:02:11Z","title":"Regularized Multi-Decoder Ensemble for an Error-Aware Scene\n  Representation Network","summary":"  Feature grid Scene Representation Networks (SRNs) have been applied to\nscientific data as compact functional surrogates for analysis and\nvisualization. As SRNs are black-box lossy data representations, assessing the\nprediction quality is critical for scientific visualization applications to\nensure that scientists can trust the information being visualized. Currently,\nexisting architectures do not support inference time reconstruction quality\nassessment, as coordinate-level errors cannot be evaluated in the absence of\nground truth data. We propose a parameter-efficient multi-decoder SRN (MDSRN)\nensemble architecture consisting of a shared feature grid with multiple\nlightweight multi-layer perceptron decoders. MDSRN can generate a set of\nplausible predictions for a given input coordinate to compute the mean as the\nprediction of the multi-decoder ensemble and the variance as a confidence\nscore. The coordinate-level variance can be rendered along with the data to\ninform the reconstruction quality, or be integrated into uncertainty-aware\nvolume visualization algorithms. To prevent the misalignment between the\nquantified variance and the prediction quality, we propose a novel variance\nregularization loss for ensemble learning that promotes the Regularized\nmulti-decoder SRN (RMDSRN) to obtain a more reliable variance that correlates\nclosely to the true model error. We comprehensively evaluate the quality of\nvariance quantification and data reconstruction of Monte Carlo Dropout, Mean\nField Variational Inference, Deep Ensemble, and Predicting Variance compared to\nthe proposed MDSRN and RMDSRN across diverse scalar field datasets. We\ndemonstrate that RMDSRN attains the most accurate data reconstruction and\ncompetitive variance-error correlation among uncertain SRNs under the same\nneural network parameter budgets.\n","authors":["Tianyu Xiong","Skylar W. Wurster","Hanqi Guo","Tom Peterka","Han-Wei Shen"],"pdf_url":"https://arxiv.org/pdf/2407.19082v2.pdf","comment":"To be published in Proc. IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2408.02813v1","updated":"2024-08-05T20:27:45Z","published":"2024-08-05T20:27:45Z","title":"Mitigating Malicious Attacks in Federated Learning via Confidence-aware\n  Defense","summary":"  Federated Learning (FL) is an emerging distributed machine learning paradigm\nthat allows multiple clients to collaboratively train a global model without\nsharing private local data. However, FL systems are vulnerable to attacks from\nmalicious clients, who can degrade the global model performance through data\npoisoning and model poisoning. Existing defense methods typically focus on a\nsingle type of attack, such as Byzantine attacks or backdoor attacks, and are\noften ineffective against potential data poisoning attacks like label flipping\nand label shuffling. Additionally, these methods often lack accuracy and\nrobustness in detecting and handling malicious updates. To address these\nissues, we propose a novel method based on model confidence scores, which\nevaluates the uncertainty of client model updates to detect and defend against\nmalicious clients. Our approach is comprehensively effective for both model\npoisoning and data poisoning attacks and is capable of accurately identifying\nand mitigating potential malicious updates from being aggregated. Experimental\nresults demonstrate that our method significantly improves the robustness of FL\nsystems against various types of attacks, also achieving higher model accuracy\nand stability across various scenarios.\n","authors":["Qilei Li","Ahmed M. Abdelmoniem"],"pdf_url":"https://arxiv.org/pdf/2408.02813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02803v1","updated":"2024-08-05T19:46:59Z","published":"2024-08-05T19:46:59Z","title":"SiCo: A Size-Controllable Virtual Try-On Approach for Informed\n  Decision-Making","summary":"  Virtual try-on (VTO) applications aim to improve the online shopping\nexperience by allowing users to preview garments, before making purchase\ndecisions. However, many VTO tools fail to consider the crucial relationship\nbetween a garment's size and the user's body size, often employing a\none-size-fits-all approach when visualizing a clothing item. This results in\npoor size recommendations and purchase decisions leading to increased return\nrates. To address this limitation, we introduce SiCo, an online VTO system,\nwhere users can upload images of themselves and visualize how different sizes\nof clothing would look on their body to help make better-informed purchase\ndecisions. Our user study shows SiCo's superiority over baseline VTO. The\nresults indicate that our approach significantly enhances user ability to gauge\nthe appearance of outfits on their bodies and boosts their confidence in\nselecting clothing sizes that match desired goals. Based on our evaluation, we\nbelieve our VTO design has the potential to reduce return rates and enhance the\nonline clothes shopping experience. Our code is available at\nhttps://github.com/SherryXTChen/SiCo.\n","authors":["Sherry X. Chen","Alex Christopher Lim","Yimeng Liu","Pradeep Sen","Misha Sra"],"pdf_url":"https://arxiv.org/pdf/2408.02803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02796v1","updated":"2024-08-05T19:23:45Z","published":"2024-08-05T19:23:45Z","title":"Gaussian Mixture based Evidential Learning for Stereo Matching","summary":"  In this paper, we introduce a novel Gaussian mixture based evidential\nlearning solution for robust stereo matching. Diverging from previous\nevidential deep learning approaches that rely on a single Gaussian\ndistribution, our framework posits that individual image data adheres to a\nmixture-of-Gaussian distribution in stereo matching. This assumption yields\nmore precise pixel-level predictions and more accurately mirrors the real-world\nimage distribution. By further employing the inverse-Gamma distribution as an\nintermediary prior for each mixture component, our probabilistic model achieves\nimproved depth estimation compared to its counterpart with the single Gaussian\nand effectively captures the model uncertainty, which enables a strong\ncross-domain generation ability. We evaluated our method for stereo matching by\ntraining the model using the Scene Flow dataset and testing it on KITTI 2015\nand Middlebury 2014. The experiment results consistently show that our method\nbrings improvements over the baseline methods in a trustworthy manner. Notably,\nour approach achieved new state-of-the-art results on both the in-domain\nvalidated data and the cross-domain datasets, demonstrating its effectiveness\nand robustness in stereo matching tasks.\n","authors":["Weide Liu","Xingxing Wang","Lu Wang","Jun Cheng","Fayao Liu","Xulei Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11751v2","updated":"2024-08-05T19:22:13Z","published":"2024-03-18T12:59:35Z","title":"Relational Representation Learning Network for Cross-Spectral Image\n  Patch Matching","summary":"  Recently, feature relation learning has drawn widespread attention in\ncross-spectral image patch matching. However, existing related research focuses\non extracting diverse relations between image patch features and ignores\nsufficient intrinsic feature representations of individual image patches.\nTherefore, we propose an innovative relational representation learning idea\nthat simultaneously focuses on sufficiently mining the intrinsic features of\nindividual image patches and the relations between image patch features. Based\non this, we construct a Relational Representation Learning Network (RRL-Net).\nSpecifically, we innovatively construct an autoencoder to fully characterize\nthe individual intrinsic features, and introduce a feature interaction learning\n(FIL) module to extract deep-level feature relations. To further fully mine\nindividual intrinsic features, a lightweight multi-dimensional global-to-local\nattention (MGLA) module is constructed to enhance the global feature extraction\nof individual image patches and capture local dependencies within global\nfeatures. By combining the MGLA module, we further explore the feature\nextraction network and construct an attention-based lightweight feature\nextraction (ALFE) network. In addition, we propose a multi-loss post-pruning\n(MLPP) optimization strategy, which greatly promotes network optimization while\navoiding increases in parameters and inference time. Extensive experiments\ndemonstrate that our RRL-Net achieves state-of-the-art (SOTA) performance on\nmultiple public datasets. Our code will be made public later.\n","authors":["Chuang Yu","Yunpeng Liu","Jinmiao Zhao","Dou Quan","Zelin Shi"],"pdf_url":"https://arxiv.org/pdf/2403.11751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09894v2","updated":"2024-08-05T19:21:16Z","published":"2023-12-15T15:45:52Z","title":"PathoDuet: Foundation Models for Pathological Slide Analysis of H&E and\n  IHC Stains","summary":"  Large amounts of digitized histopathological data display a promising future\nfor developing pathological foundation models via self-supervised learning\nmethods. Foundation models pretrained with these methods serve as a good basis\nfor downstream tasks. However, the gap between natural and histopathological\nimages hinders the direct application of existing methods. In this work, we\npresent PathoDuet, a series of pretrained models on histopathological images,\nand a new self-supervised learning framework in histopathology. The framework\nis featured by a newly-introduced pretext token and later task raisers to\nexplicitly utilize certain relations between images, like multiple\nmagnifications and multiple stains. Based on this, two pretext tasks,\ncross-scale positioning and cross-stain transferring, are designed to pretrain\nthe model on Hematoxylin and Eosin (H&E) images and transfer the model to\nimmunohistochemistry (IHC) images, respectively. To validate the efficacy of\nour models, we evaluate the performance over a wide variety of downstream\ntasks, including patch-level colorectal cancer subtyping and whole slide image\n(WSI)-level classification in H&E field, together with expression level\nprediction of IHC marker, tumor identification and slide-level qualitative\nanalysis in IHC field. The experimental results show the superiority of our\nmodels over most tasks and the efficacy of proposed pretext tasks. The codes\nand models are available at https://github.com/openmedlab/PathoDuet.\n","authors":["Shengyi Hua","Fang Yan","Tianle Shen","Lei Ma","Xiaofan Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.09894v2.pdf","comment":"Accepted for Medical Image Analysis"},{"id":"http://arxiv.org/abs/2408.02792v1","updated":"2024-08-05T19:19:29Z","published":"2024-08-05T19:19:29Z","title":"Lesion Elevation Prediction from Skin Images Improves Diagnosis","summary":"  While deep learning-based computer-aided diagnosis for skin lesion image\nanalysis is approaching dermatologists' performance levels, there are several\nworks showing that incorporating additional features such as shape priors,\ntexture, color constancy, and illumination further improves the lesion\ndiagnosis performance. In this work, we look at another clinically useful\nfeature, skin lesion elevation, and investigate the feasibility of predicting\nand leveraging skin lesion elevation labels. Specifically, we use a deep\nlearning model to predict image-level lesion elevation labels from 2D skin\nlesion images. We test the elevation prediction accuracy on the derm7pt\ndataset, and use the elevation prediction model to estimate elevation labels\nfor images from five other datasets: ISIC 2016, 2017, and 2018 Challenge\ndatasets, MSK, and DermoFit. We evaluate cross-domain generalization by using\nthese estimated elevation labels as auxiliary inputs to diagnosis models, and\nshow that these improve the classification performance, with AUROC improvements\nof up to 6.29% and 2.69% for dermoscopic and clinical images, respectively. The\ncode is publicly available at https://github.com/sfu-mial/LesionElevation.\n","authors":["Kumar Abhishek","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2408.02792v1.pdf","comment":"Medical Image Computing and Computer-Assisted Intervention (MICCAI)\n  ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2024; 12 pages, 2 tables, 4\n  figures"},{"id":"http://arxiv.org/abs/2408.02788v1","updated":"2024-08-05T19:11:46Z","published":"2024-08-05T19:11:46Z","title":"GazeXplain: Learning to Predict Natural Language Explanations of Visual\n  Scanpaths","summary":"  While exploring visual scenes, humans' scanpaths are driven by their\nunderlying attention processes. Understanding visual scanpaths is essential for\nvarious applications. Traditional scanpath models predict the where and when of\ngaze shifts without providing explanations, creating a gap in understanding the\nrationale behind fixations. To bridge this gap, we introduce GazeXplain, a\nnovel study of visual scanpath prediction and explanation. This involves\nannotating natural-language explanations for fixations across eye-tracking\ndatasets and proposing a general model with an attention-language decoder that\njointly predicts scanpaths and generates explanations. It integrates a unique\nsemantic alignment mechanism to enhance the consistency between fixations and\nexplanations, alongside a cross-dataset co-training approach for\ngeneralization. These novelties present a comprehensive and adaptable solution\nfor explainable human visual scanpath prediction. Extensive experiments on\ndiverse eye-tracking datasets demonstrate the effectiveness of GazeXplain in\nboth scanpath prediction and explanation, offering valuable insights into human\nvisual attention and cognitive processes.\n","authors":["Xianyu Chen","Ming Jiang","Qi Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.02788v1.pdf","comment":"To appear in ECCV2024"},{"id":"http://arxiv.org/abs/2408.02787v1","updated":"2024-08-05T19:11:05Z","published":"2024-08-05T19:11:05Z","title":"Segmentation Style Discovery: Application to Skin Lesion Images","summary":"  Variability in medical image segmentation, arising from annotator\npreferences, expertise, and their choice of tools, has been well documented.\nWhile the majority of multi-annotator segmentation approaches focus on modeling\nannotator-specific preferences, they require annotator-segmentation\ncorrespondence. In this work, we introduce the problem of segmentation style\ndiscovery, and propose StyleSeg, a segmentation method that learns plausible,\ndiverse, and semantically consistent segmentation styles from a corpus of\nimage-mask pairs without any knowledge of annotator correspondence. StyleSeg\nconsistently outperforms competing methods on four publicly available skin\nlesion segmentation (SLS) datasets. We also curate ISIC-MultiAnnot, the largest\nmulti-annotator SLS dataset with annotator correspondence, and our results show\na strong alignment, using our newly proposed measure AS2, between the predicted\nstyles and annotator preferences. The code and the dataset are available at\nhttps://github.com/sfu-mial/StyleSeg.\n","authors":["Kumar Abhishek","Jeremy Kawahara","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2408.02787v1.pdf","comment":"Medical Image Computing and Computer-Assisted Intervention (MICCAI)\n  ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2024; 13 pages, 2 tables, 3\n  figures"},{"id":"http://arxiv.org/abs/2309.05490v2","updated":"2024-08-05T18:57:42Z","published":"2023-09-11T14:32:04Z","title":"Learning Semantic Segmentation with Query Points Supervision on Aerial\n  Images","summary":"  Semantic segmentation is crucial in remote sensing, where high-resolution\nsatellite images are segmented into meaningful regions. Recent advancements in\ndeep learning have significantly improved satellite image segmentation.\nHowever, most of these methods are typically trained in fully supervised\nsettings that require high-quality pixel-level annotations, which are expensive\nand time-consuming to obtain. In this work, we present a weakly supervised\nlearning algorithm to train semantic segmentation algorithms that only rely on\nquery point annotations instead of full mask labels. Our proposed approach\nperforms accurate semantic segmentation and improves efficiency by\nsignificantly reducing the cost and time required for manual annotation.\nSpecifically, we generate superpixels and extend the query point labels into\nthose superpixels that group similar meaningful semantics. Then, we train\nsemantic segmentation models supervised with images partially labeled with the\nsuperpixel pseudo-labels. We benchmark our weakly supervised training approach\non an aerial image dataset and different semantic segmentation architectures,\nshowing that we can reach competitive performance compared to fully supervised\ntraining while reducing the annotation effort. The code of our proposed\napproach is publicly available at: https://github.com/santiago2205/LSSQPS.\n","authors":["Santiago Rivier","Carlos Hinojosa","Silvio Giancola","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2309.05490v2.pdf","comment":"Paper Accepted at ICIP 2024 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2408.02780v1","updated":"2024-08-05T18:57:33Z","published":"2024-08-05T18:57:33Z","title":"LR-Net: A Lightweight and Robust Network for Infrared Small Target\n  Detection","summary":"  Limited by equipment limitations and the lack of target intrinsic features,\nexisting infrared small target detection methods have difficulty meeting actual\ncomprehensive performance requirements. Therefore, we propose an innovative\nlightweight and robust network (LR-Net), which abandons the complex structure\nand achieves an effective balance between detection accuracy and resource\nconsumption. Specifically, to ensure the lightweight and robustness, on the one\nhand, we construct a lightweight feature extraction attention (LFEA) module,\nwhich can fully extract target features and strengthen information interaction\nacross channels. On the other hand, we construct a simple refined feature\ntransfer (RFT) module. Compared with direct cross-layer connections, the RFT\nmodule can improve the network's feature refinement extraction capability with\nlittle resource consumption. Meanwhile, to solve the problem of small target\nloss in high-level feature maps, on the one hand, we propose a low-level\nfeature distribution (LFD) strategy to use low-level features to supplement the\ninformation of high-level features. On the other hand, we introduce an\nefficient simplified bilinear interpolation attention module (SBAM) to promote\nthe guidance constraints of low-level features on high-level features and the\nfusion of the two. In addition, We abandon the traditional resizing method and\nadopt a new training and inference cropping strategy, which is more robust to\ndatasets with multi-scale samples. Extensive experimental results show that our\nLR-Net achieves state-of-the-art (SOTA) performance. Notably, on the basis of\nthe proposed LR-Net, we achieve 3rd place in the \"ICPR 2024 Resource-Limited\nInfrared Small Target Detection Challenge Track 2: Lightweight Infrared Small\nTarget Detection\".\n","authors":["Chuang Yu","Yunpeng Liu","Jinmiao Zhao","Zelin Shi"],"pdf_url":"https://arxiv.org/pdf/2408.02780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02773v1","updated":"2024-08-05T18:49:58Z","published":"2024-08-05T18:49:58Z","title":"Refined Infrared Small Target Detection Scheme with Single-Point\n  Supervision","summary":"  Recently, infrared small target detection with single-point supervision has\nattracted extensive attention. However, the detection accuracy of existing\nmethods has difficulty meeting actual needs. Therefore, we propose an\ninnovative refined infrared small target detection scheme with single-point\nsupervision, which has excellent segmentation accuracy and detection rate.\nSpecifically, we introduce label evolution with single point supervision\n(LESPS) framework and explore the performance of various excellent infrared\nsmall target detection networks based on this framework. Meanwhile, to improve\nthe comprehensive performance, we construct a complete post-processing\nstrategy. On the one hand, to improve the segmentation accuracy, we use a\ncombination of test-time augmentation (TTA) and conditional random field (CRF)\nfor post-processing. On the other hand, to improve the detection rate, we\nintroduce an adjustable sensitivity (AS) strategy for post-processing, which\nfully considers the advantages of multiple detection results and reasonably\nadds some areas with low confidence to the fine segmentation image in the form\nof centroid points. In addition, to further improve the performance and explore\nthe characteristics of this task, on the one hand, we construct and find that a\nmulti-stage loss is helpful for fine-grained detection. On the other hand, we\nfind that a reasonable sliding window cropping strategy for test samples has\nbetter performance for actual multi-size samples. Extensive experimental\nresults show that the proposed scheme achieves state-of-the-art (SOTA)\nperformance. Notably, the proposed scheme won the third place in the \"ICPR 2024\nResource-Limited Infrared Small Target Detection Challenge Track 1: Weakly\nSupervised Infrared Small Target Detection\".\n","authors":["Jinmiao Zhao","Zelin Shi","Chuang Yu","Yunpeng Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00761v4","updated":"2024-08-05T18:40:07Z","published":"2023-12-01T18:29:08Z","title":"Deep Unlearning: Fast and Efficient Gradient-free Approach to Class\n  Forgetting","summary":"  Machine unlearning is a prominent and challenging field, driven by regulatory\ndemands for user data deletion and heightened privacy awareness. Existing\napproaches involve retraining model or multiple finetuning steps for each\ndeletion request, often constrained by computational limits and restricted data\naccess. In this work, we introduce a novel class unlearning algorithm designed\nto strategically eliminate specific classes from the learned model. Our\nalgorithm first estimates the Retain and the Forget Spaces using Singular Value\nDecomposition on the layerwise activations for a small subset of samples from\nthe retain and unlearn classes, respectively. We then compute the shared\ninformation between these spaces and remove it from the forget space to isolate\nclass-discriminatory feature space. Finally, we obtain the unlearned model by\nupdating the weights to suppress the class discriminatory features from the\nactivation spaces. We demonstrate our algorithm's efficacy on ImageNet using a\nVision Transformer with only $\\sim 1.5\\%$ drop in retain accuracy compared to\nthe original model while maintaining under $1\\%$ accuracy on the unlearned\nclass samples. Furthermore, our algorithm exhibits competitive unlearning\nperformance and resilience against Membership Inference Attacks (MIA). Compared\nto baselines, it achieves an average accuracy improvement of $1.38\\%$ on the\nImageNet dataset while requiring up to $10 \\times$ fewer samples for\nunlearning. Additionally, under stronger MIA attacks on the CIFAR-100 dataset\nusing a ResNet18 architecture, our approach outperforms the best baseline by\n$1.8\\%$. Our code is available at\nhttps://github.com/sangamesh-kodge/class_forgetting.\n","authors":["Sangamesh Kodge","Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2312.00761v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02769v1","updated":"2024-08-05T18:38:29Z","published":"2024-08-05T18:38:29Z","title":"From Recognition to Prediction: Leveraging Sequence Reasoning for Action\n  Anticipation","summary":"  The action anticipation task refers to predicting what action will happen\nbased on observed videos, which requires the model to have a strong ability to\nsummarize the present and then reason about the future. Experience and common\nsense suggest that there is a significant correlation between different\nactions, which provides valuable prior knowledge for the action anticipation\ntask. However, previous methods have not effectively modeled this underlying\nstatistical relationship. To address this issue, we propose a novel end-to-end\nvideo modeling architecture that utilizes attention mechanisms, named\nAnticipation via Recognition and Reasoning (ARR). ARR decomposes the action\nanticipation task into action recognition and sequence reasoning tasks, and\neffectively learns the statistical relationship between actions by next action\nprediction (NAP). In comparison to existing temporal aggregation strategies,\nARR is able to extract more effective features from observable videos to make\nmore reasonable predictions. In addition, to address the challenge of\nrelationship modeling that requires extensive training data, we propose an\ninnovative approach for the unsupervised pre-training of the decoder, which\nleverages the inherent temporal dynamics of video to enhance the reasoning\ncapabilities of the network. Extensive experiments on the Epic-kitchen-100,\nEGTEA Gaze+, and 50salads datasets demonstrate the efficacy of the proposed\nmethods. The code is available at https://github.com/linuxsino/ARR.\n","authors":["Xin Liu","Chao Hao","Zitong Yu","Huanjing Yue","Jingyu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02769v1.pdf","comment":"Accepted by ACM TOMM"},{"id":"http://arxiv.org/abs/2408.02766v1","updated":"2024-08-05T18:34:15Z","published":"2024-08-05T18:34:15Z","title":"ConDL: Detector-Free Dense Image Matching","summary":"  In this work, we introduce a deep-learning framework designed for estimating\ndense image correspondences. Our fully convolutional model generates dense\nfeature maps for images, where each pixel is associated with a descriptor that\ncan be matched across multiple images. Unlike previous methods, our model is\ntrained on synthetic data that includes significant distortions, such as\nperspective changes, illumination variations, shadows, and specular highlights.\nUtilizing contrastive learning, our feature maps achieve greater invariance to\nthese distortions, enabling robust matching. Notably, our method eliminates the\nneed for a keypoint detector, setting it apart from many existing\nimage-matching techniques.\n","authors":["Monika Kwiatkowski","Simon Matern","Olaf Hellwich"],"pdf_url":"https://arxiv.org/pdf/2408.02766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02761v1","updated":"2024-08-05T18:24:48Z","published":"2024-08-05T18:24:48Z","title":"Dimensionality Reduction and Nearest Neighbors for Improving\n  Out-of-Distribution Detection in Medical Image Segmentation","summary":"  Clinically deployed deep learning-based segmentation models are known to fail\non data outside of their training distributions. While clinicians review the\nsegmentations, these models tend to perform well in most instances, which could\nexacerbate automation bias. Therefore, detecting out-of-distribution images at\ninference is critical to warn the clinicians that the model likely failed. This\nwork applied the Mahalanobis distance (MD) post hoc to the bottleneck features\nof four Swin UNETR and nnU-net models that segmented the liver on T1-weighted\nmagnetic resonance imaging and computed tomography. By reducing the dimensions\nof the bottleneck features with either principal component analysis or uniform\nmanifold approximation and projection, images the models failed on were\ndetected with high performance and minimal computational load. In addition,\nthis work explored a non-parametric alternative to the MD, a k-th nearest\nneighbors distance (KNN). KNN drastically improved scalability and performance\nover MD when both were applied to raw and average-pooled bottleneck features.\n","authors":["McKell Woodland","Nihil Patel","Austin Castelo","Mais Al Taie","Mohamed Eltaher","Joshua P. Yung","Tucker J. Netherton","Tiffany L. Calderone","Jessica I. Sanchez","Darrel W. Cleere","Ahmed Elsaiey","Nakul Gupta","David Victor","Laura Beretta","Ankit B. Patel Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2408.02761v1.pdf","comment":"Expansion of \"Dimensionality Reduction for Improving\n  Out-of-Distribution Detection in Medical Image Segmentation\" arXiv:2308.03723\n  . Submitted to the Journal for Machine Learning in Biomedical Imaging. Code\n  available at https://github.com/mckellwoodland/dimen_reduce_mahal"},{"id":"http://arxiv.org/abs/2405.01531v2","updated":"2024-08-05T18:20:39Z","published":"2024-05-02T17:59:01Z","title":"Improving Intervention Efficacy via Concept Realignment in Concept\n  Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) ground image classification on\nhuman-understandable concepts to allow for interpretable model decisions.\nCrucially, the CBM design inherently allows for human interventions, in which\nexpert users are given the ability to modify potentially misaligned concept\nchoices to influence the decision behavior of the model in an interpretable\nfashion. However, existing approaches often require numerous human\ninterventions per image to achieve strong performances, posing practical\nchallenges in scenarios where obtaining human feedback is expensive. In this\npaper, we find that this is noticeably driven by an independent treatment of\nconcepts during intervention, wherein a change of one concept does not\ninfluence the use of other ones in the model's final decision. To address this\nissue, we introduce a trainable concept intervention realignment module, which\nleverages concept relations to realign concept assignments post-intervention.\nAcross standard, real-world benchmarks, we find that concept realignment can\nsignificantly improve intervention efficacy; significantly reducing the number\nof interventions needed to reach a target classification performance or concept\nprediction accuracy. In addition, it easily integrates into existing\nconcept-based architectures without requiring changes to the models themselves.\nThis reduced cost of human-model collaboration is crucial to enhancing the\nfeasibility of CBMs in resource-constrained environments. Our code is available\nat: https://github.com/ExplainableML/concept_realignment.\n","authors":["Nishad Singhi","Jae Myung Kim","Karsten Roth","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2405.01531v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.02750v1","updated":"2024-08-05T18:09:02Z","published":"2024-08-05T18:09:02Z","title":"Privacy-Safe Iris Presentation Attack Detection","summary":"  This paper proposes a framework for a privacy-safe iris presentation attack\ndetection (PAD) method, designed solely with synthetically-generated,\nidentity-leakage-free iris images. Once trained, the method is evaluated in a\nclassical way using state-of-the-art iris PAD benchmarks. We designed two\ngenerative models for the synthesis of ISO/IEC 19794-6-compliant iris images.\nThe first model synthesizes bona fide-looking samples. To avoid ``identity\nleakage,'' the generated samples that accidentally matched those used in the\nmodel's training were excluded. The second model synthesizes images of irises\nwith textured contact lenses and is conditioned by a given contact lens brand\nto have better control over textured contact lens appearance when forming the\ntraining set. Our experiments demonstrate that models trained solely on\nsynthetic data achieve a lower but still reasonable performance when compared\nto solutions trained with iris images collected from human subjects. This is\nthe first-of-its-kind attempt to use solely synthetic data to train a\nfully-functional iris PAD solution, and despite the performance gap between\nregular and the proposed methods, this study demonstrates that with the\nincreasing fidelity of generative models, creating such privacy-safe iris PAD\nmethods may be possible. The source codes and generative models trained for\nthis work are offered along with the paper.\n","authors":["Mahsa Mitcheff","Patrick Tinsley","Adam Czajka"],"pdf_url":"https://arxiv.org/pdf/2408.02750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02718v1","updated":"2024-08-05T17:56:41Z","published":"2024-08-05T17:56:41Z","title":"MMIU: Multimodal Multi-image Understanding for Evaluating Large\n  Vision-Language Models","summary":"  The capability to process multiple images is crucial for Large\nVision-Language Models (LVLMs) to develop a more thorough and nuanced\nunderstanding of a scene. Recent multi-image LVLMs have begun to address this\nneed. However, their evaluation has not kept pace with their development. To\nfill this gap, we introduce the Multimodal Multi-image Understanding (MMIU)\nbenchmark, a comprehensive evaluation suite designed to assess LVLMs across a\nwide range of multi-image tasks. MMIU encompasses 7 types of multi-image\nrelationships, 52 tasks, 77K images, and 11K meticulously curated\nmultiple-choice questions, making it the most extensive benchmark of its kind.\nOur evaluation of 24 popular LVLMs, including both open-source and proprietary\nmodels, reveals significant challenges in multi-image comprehension,\nparticularly in tasks involving spatial understanding. Even the most advanced\nmodels, such as GPT-4o, achieve only 55.7% accuracy on MMIU. Through\nmulti-faceted analytical experiments, we identify key performance gaps and\nlimitations, providing valuable insights for future model and data\nimprovements. We aim for MMIU to advance the frontier of LVLM research and\ndevelopment, moving us toward achieving sophisticated multimodal multi-image\nuser interactions.\n","authors":["Fanqing Meng","Jin Wang","Chuanhao Li","Quanfeng Lu","Hao Tian","Jiaqi Liao","Xizhou Zhu","Jifeng Dai","Yu Qiao","Ping Luo","Kaipeng Zhang","Wenqi Shao"],"pdf_url":"https://arxiv.org/pdf/2408.02718v1.pdf","comment":"Project Page: https://mmiu-bench.github.io/"},{"id":"http://arxiv.org/abs/2311.13297v2","updated":"2024-08-05T17:49:58Z","published":"2023-11-22T10:27:19Z","title":"Retargeting Visual Data with Deformation Fields","summary":"  Seam carving is an image editing method that enable content-aware resizing,\nincluding operations like removing objects. However, the seam-finding strategy\nbased on dynamic programming or graph-cut limits its applications to broader\nvisual data formats and degrees of freedom for editing. Our observation is that\ndescribing the editing and retargeting of images more generally by a\ndisplacement field yields a generalisation of content-aware deformations. We\npropose to learn a deformation with a neural network that keeps the output\nplausible while trying to deform it only in places with low information\ncontent. This technique applies to different kinds of visual data, including\nimages, 3D scenes given as neural radiance fields, or even polygon meshes.\nExperiments conducted on different visual data show that our method achieves\nbetter content-aware retargeting compared to previous methods.\n","authors":["Tim Elsner","Julia Berger","Tong Wu","Victor Czech","Lin Gao","Leif Kobbelt"],"pdf_url":"https://arxiv.org/pdf/2311.13297v2.pdf","comment":"ECCV 2024"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2405.04634v3","updated":"2024-08-05T17:53:28Z","published":"2024-05-07T19:37:22Z","title":"FRACTAL: An Ultra-Large-Scale Aerial Lidar Dataset for 3D Semantic\n  Segmentation of Diverse Landscapes","summary":"  Mapping agencies are increasingly adopting Aerial Lidar Scanning (ALS) as a\nnew tool to monitor territory and support public policies. Processing ALS data\nat scale requires efficient point classification methods that perform well over\nhighly diverse territories. To evaluate them, researchers need large annotated\nLidar datasets, however, current Lidar benchmark datasets have restricted scope\nand often cover a single urban area. To bridge this data gap, we present the\nFRench ALS Clouds from TArgeted Landscapes (FRACTAL) dataset: an\nultra-large-scale aerial Lidar dataset made of 100,000 dense point clouds with\nhigh-quality labels for 7 semantic classes and spanning 250 km$^2$. FRACTAL is\nbuilt upon France's nationwide open Lidar data. It achieves spatial and\nsemantic diversity via a sampling scheme that explicitly concentrates rare\nclasses and challenging landscapes from five French regions. It should support\nthe development of 3D deep learning approaches for large-scale land monitoring.\nWe describe the nature of the source data, the sampling workflow, the content\nof the resulting dataset, and provide an initial evaluation of segmentation\nperformance using a performant 3D neural architecture.\n","authors":["Charles Gaydon","Michel Daab","Floryne Roche"],"pdf_url":"https://arxiv.org/pdf/2405.04634v3.pdf","comment":"15 pages | 9 figures | 8 tables | Dataset is available at\n  https://huggingface.co/datasets/IGNF/FRACTAL | Trained model is available at\n  https://huggingface.co/IGNF/FRACTAL-LidarHD_7cl_randlanet | Deep learning\n  code repository is on Gihtub at https://github.com/IGNF/myria3d | Data\n  engineering code repository is on Github at https://github.com/IGNF/pacasam"},{"id":"http://arxiv.org/abs/2407.11913v2","updated":"2024-08-05T17:50:03Z","published":"2024-07-16T17:05:20Z","title":"Quantised Global Autoencoder: A Holistic Approach to Representing Visual\n  Data","summary":"  In quantised autoencoders, images are usually split into local patches, each\nencoded by one token. This representation is redundant in the sense that the\nsame number of tokens is spend per region, regardless of the visual information\ncontent in that region. Adaptive discretisation schemes like quadtrees are\napplied to allocate tokens for patches with varying sizes, but this just varies\nthe region of influence for a token which nevertheless remains a local\ndescriptor. Modern architectures add an attention mechanism to the autoencoder\nwhich infuses some degree of global information into the local tokens. Despite\nthe global context, tokens are still associated with a local image region. In\ncontrast, our method is inspired by spectral decompositions which transform an\ninput signal into a superposition of global frequencies. Taking the data-driven\nperspective, we learn custom basis functions corresponding to the codebook\nentries in our VQ-VAE setup. Furthermore, a decoder combines these basis\nfunctions in a non-linear fashion, going beyond the simple linear superposition\nof spectral decompositions. We can achieve this global description with an\nefficient transpose operation between features and channels and demonstrate our\nperformance on compression.\n","authors":["Tim Elsner","Paula Usinger","Victor Czech","Gregor Kobsik","Yanjiang He","Isaak Lim","Leif Kobbelt"],"pdf_url":"https://arxiv.org/pdf/2407.11913v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02654v1","updated":"2024-08-05T17:33:09Z","published":"2024-08-05T17:33:09Z","title":"On Using Quasirandom Sequences in Machine Learning for Model Weight\n  Initialization","summary":"  The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.\n","authors":["Andriy Miranskyy","Adam Sorrenti","Viral Thakar"],"pdf_url":"https://arxiv.org/pdf/2408.02654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02641v1","updated":"2024-08-05T17:14:35Z","published":"2024-08-05T17:14:35Z","title":"Detection of Compromised Functions in a Serverless Cloud Environment","summary":"  Serverless computing is an emerging cloud paradigm with serverless functions\nat its core. While serverless environments enable software developers to focus\non developing applications without the need to actively manage the underlying\nruntime infrastructure, they open the door to a wide variety of security\nthreats that can be challenging to mitigate with existing methods. Existing\nsecurity solutions do not apply to all serverless architectures, since they\nrequire significant modifications to the serverless infrastructure or rely on\nthird-party services for the collection of more detailed data. In this paper,\nwe present an extendable serverless security threat detection model that\nleverages cloud providers' native monitoring tools to detect anomalous behavior\nin serverless applications. Our model aims to detect compromised serverless\nfunctions by identifying post-exploitation abnormal behavior related to\ndifferent types of attacks on serverless functions, and therefore, it is a last\nline of defense. Our approach is not tied to any specific serverless\napplication, is agnostic to the type of threats, and is adaptable through model\nadjustments. To evaluate our model's performance, we developed a serverless\ncybersecurity testbed in an AWS cloud environment, which includes two different\nserverless applications and simulates a variety of attack scenarios that cover\nthe main security threats faced by serverless functions. Our evaluation\ndemonstrates our model's ability to detect all implemented attacks while\nmaintaining a negligible false alarm rate.\n","authors":["Danielle Lavi","Oleg Brodt","Dudu Mimran","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2408.02641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02637v1","updated":"2024-08-05T17:01:33Z","published":"2024-08-05T17:01:33Z","title":"Command-line Obfuscation Detection using Small Language Models","summary":"  To avoid detection, adversaries often use command-line obfuscation. There are\nnumerous techniques of the command-line obfuscation, all designed to alter the\ncommand-line syntax without affecting its original functionality. This\nvariability forces most security solutions to create an exhaustive enumeration\nof signatures for even a single pattern. In contrast to using signatures, we\nhave implemented a scalable NLP-based detection method that leverages a\ncustom-trained, small transformer language model that can be applied to any\nsource of execution logs. The evaluation on top of real-world telemetry\ndemonstrates that our approach yields high-precision detections even on\nhigh-volume telemetry from a diverse set of environments spanning from\nuniversities and businesses to healthcare or finance. The practical value is\ndemonstrated in a case study of real-world samples detected by our model. We\nshow the model's superiority to signatures on established malware known to\nemploy obfuscation and showcase previously unseen obfuscated samples detected\nby our model.\n","authors":["Vojtech Outrata","Michael Adam Polak","Martin Kopp"],"pdf_url":"https://arxiv.org/pdf/2408.02637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02396v3","updated":"2024-08-05T16:49:51Z","published":"2023-12-04T23:26:12Z","title":"Unsupervised Change Detection for Space Habitats Using 3D Point Clouds","summary":"  This work presents an algorithm for scene change detection from point clouds\nto enable autonomous robotic caretaking in future space habitats. Autonomous\nrobotic systems will help maintain future deep-space habitats, such as the\nGateway space station, which will be uncrewed for extended periods. Existing\nscene analysis software used on the International Space Station (ISS) relies on\nmanually-labeled images for detecting changes. In contrast, the algorithm\npresented in this work uses raw, unlabeled point clouds as inputs. The\nalgorithm first applies modified Expectation-Maximization Gaussian Mixture\nModel (GMM) clustering to two input point clouds. It then performs change\ndetection by comparing the GMMs using the Earth Mover's Distance. The algorithm\nis validated quantitatively and qualitatively using a test dataset collected by\nan Astrobee robot in the NASA Ames Granite Lab comprising single frame depth\nimages taken directly by Astrobee and full-scene reconstructed maps built with\nRGB-D and pose data from Astrobee. The runtimes of the approach are also\nanalyzed in depth. The source code is publicly released to promote further\ndevelopment.\n","authors":["Jamie Santos","Holly Dinkel","Julia Di","Paulo V. K. Borges","Marina Moreira","Oleg Alexandrov","Brian Coltin","Trey Smith"],"pdf_url":"https://arxiv.org/pdf/2312.02396v3.pdf","comment":"15 pages, 7 figures, Manuscript was presented at the AIAA SciTech\n  Forum in Orlando, FL, USA, 8 - 12 January 2024. Video presentation:\n  [https://www.youtube.com/watch?v=7WHp0dQYG4Y]. Code:\n  [https://github.com/nasa/isaac/tree/master/anomaly/gmm-change-detection]"},{"id":"http://arxiv.org/abs/2303.07338v2","updated":"2024-08-05T16:34:43Z","published":"2023-03-13T17:59:02Z","title":"Revisiting Class-Incremental Learning with Pre-Trained Models:\n  Generalizability and Adaptivity are All You Need","summary":"  Class-incremental learning (CIL) aims to adapt to emerging new classes\nwithout forgetting old ones. Traditional CIL models are trained from scratch to\ncontinually acquire knowledge as data evolves. Recently, pre-training has\nachieved substantial progress, making vast pre-trained models (PTMs) accessible\nfor CIL. Contrary to traditional methods, PTMs possess generalizable\nembeddings, which can be easily transferred for CIL. In this work, we revisit\nCIL with PTMs and argue that the core factors in CIL are adaptivity for model\nupdating and generalizability for knowledge transferring. 1) We first reveal\nthat frozen PTM can already provide generalizable embeddings for CIL.\nSurprisingly, a simple baseline (SimpleCIL) which continually sets the\nclassifiers of PTM to prototype features can beat state-of-the-art even without\ntraining on the downstream task. 2) Due to the distribution gap between\npre-trained and downstream datasets, PTM can be further cultivated with\nadaptivity via model adaptation. We propose AdaPt and mERge (APER), which\naggregates the embeddings of PTM and adapted models for classifier\nconstruction. APER is a general framework that can be orthogonally combined\nwith any parameter-efficient tuning method, which holds the advantages of PTM's\ngeneralizability and adapted model's adaptivity. 3) Additionally, considering\nprevious ImageNet-based benchmarks are unsuitable in the era of PTM due to data\noverlapping, we propose four new benchmarks for assessment, namely ImageNet-A,\nObjectNet, OmniBenchmark, and VTAB. Extensive experiments validate the\neffectiveness of APER with a unified and concise framework. Code is available\nat https://github.com/zhoudw-zdw/RevisitingCIL\n","authors":["Da-Wei Zhou","Zi-Wen Cai","Han-Jia Ye","De-Chuan Zhan","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.07338v2.pdf","comment":"Accepted to IJCV. Code is available at:\n  https://github.com/zhoudw-zdw/RevisitingCIL"},{"id":"http://arxiv.org/abs/2408.02604v1","updated":"2024-08-05T16:27:38Z","published":"2024-08-05T16:27:38Z","title":"Learning rheological parameters of non-Newtonian fluids from velocimetry\n  data","summary":"  We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates\nvelocimetry data in order to jointly reconstruct the flow field and learn the\nunknown N-S parameters. By incorporating a Carreau shear-thinning viscosity\nmodel into the N-S problem, we devise an algorithm that learns the most likely\nCarreau parameters of a shear-thinning fluid, and estimates their\nuncertainties, from velocimetry data alone. We then conduct a flow-MRI\nexperiment to obtain velocimetry data of an axisymmetric laminar jet through an\nidealised medical device (FDA nozzle) for a blood analogue fluid. We show that\nthe algorithm can successfully reconstruct the flow field by learning the most\nlikely Carreau parameters, and that the learned parameters are in very good\nagreement with rheometry measurements. The algorithm accepts any algebraic\neffective viscosity model, as long as the model is differentiable, and it can\nbe extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if\na viscoelastic model is incorporated into the N-S problem.\n","authors":["Alexandros Kontogiannis","Richard Hodgkinson","Emily L. Manchester"],"pdf_url":"https://arxiv.org/pdf/2408.02604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02598v1","updated":"2024-08-05T16:15:31Z","published":"2024-08-05T16:15:31Z","title":"AI-Driven Strategies for Reducing Student Withdrawal -- A Study of EMU\n  Student Stopout","summary":"  Not everyone who enrolls in college will leave with a certificate or degree,\nbut the number of people who drop out or take a break is much higher than\nexperts previously believed. In December 2013, there were 29 million people\nwith some college education but no degree. That number jumped to 36 million by\nDecember of 2018, according to a new report from the National Student\nClearinghouse Research Center[1]. It is imperative to understand the underlying\nfactors contributing to student withdrawal and to assist decision-makers to\nidentify effective strategies to prevent it. By analyzing the characteristics\nand educational pathways of the stopout student population, our aim is to\nprovide actionable insights that can benefit institutions facing similar\nchallenges. Eastern Michigan University (EMU) faces significant challenges in\nstudent retention, with approximately 55% of its undergraduate students not\ncompleting their degrees within six years. As an institution committed to\nstudent success, EMU conducted a comprehensive study of student withdrawals to\nunderstand the influencing factors. And the paper revealed a high correlation\nbetween certain factors and withdrawals, even in the early stages of university\nattendance. Based on these findings, we developed a predictive model that\nemploys artificial intelligence techniques to assess the potential risk that\nstudents abandon their studies. These models enable universities to implement\nearly intervention strategies, support at-risk students, and improve overall\nhigher education success.\n","authors":["Yan Zhao","Amy Otteson"],"pdf_url":"https://arxiv.org/pdf/2408.02598v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.16517v2","updated":"2024-08-05T16:02:51Z","published":"2024-02-26T11:58:02Z","title":"Discovering Artificial Viscosity Models for Discontinuous Galerkin\n  Approximation of Conservation Laws using Physics-Informed Machine Learning","summary":"  Finite element-based high-order solvers of conservation laws offer large\naccuracy but face challenges near discontinuities due to the Gibbs phenomenon.\nArtificial viscosity is a popular and effective solution to this problem based\non physical insight. In this work, we present a physics-informed machine\nlearning algorithm to automate the discovery of artificial viscosity models in\na non-supervised paradigm. The algorithm is inspired by reinforcement learning\nand trains a neural network acting cell-by-cell (the viscosity model) by\nminimizing a loss defined as the difference with respect to a reference\nsolution thanks to automatic differentiation. This enables a dataset-free\ntraining procedure. We prove that the algorithm is effective by integrating it\ninto a state-of-the-art Runge-Kutta discontinuous Galerkin solver. We showcase\nseveral numerical tests on scalar and vectorial problems, such as Burgers' and\nEuler's equations in one and two dimensions. Results demonstrate that the\nproposed approach trains a model that is able to outperform classical viscosity\nmodels. Moreover, we show that the learnt artificial viscosity model is able to\ngeneralize across different problems and parameters.\n","authors":["Matteo Caldana","Paola F. Antonietti","Luca Dede'"],"pdf_url":"https://arxiv.org/pdf/2402.16517v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02581v1","updated":"2024-08-05T15:59:36Z","published":"2024-08-05T15:59:36Z","title":"Operational range bounding of spectroscopy models with anomaly detection","summary":"  Safe operation of machine learning models requires architectures that\nexplicitly delimit their operational ranges. We evaluate the ability of anomaly\ndetection algorithms to provide indicators correlated with degraded model\nperformance. By placing acceptance thresholds over such indicators, hard\nboundaries are formed that define the model's coverage. As a use case, we\nconsider the extraction of exoplanetary spectra from transit light curves,\nspecifically within the context of ESA's upcoming Ariel mission. Isolation\nForests are shown to effectively identify contexts where prediction models are\nlikely to fail. Coverage/error trade-offs are evaluated under conditions of\ndata and concept drift. The best performance is seen when Isolation Forests\nmodel projections of the prediction model's explainability SHAP values.\n","authors":["Luís F. Simões","Pierluigi Casale","Marília Felismino","Kai Hou Yip","Ingo P. Waldmann","Giovanna Tinetti","Theresa Lueftinger"],"pdf_url":"https://arxiv.org/pdf/2408.02581v1.pdf","comment":"To appear in \"Proceedings of SPAICE 2024: 1st ESA/IAA conference on\n  AI in and for Space\". Conference page at https://spaice.esa.int/"},{"id":"http://arxiv.org/abs/2405.06093v2","updated":"2024-08-05T15:51:50Z","published":"2024-05-09T20:45:58Z","title":"Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human\n  Annotation: A Case Study Using Schedule-of-Event Table Detection","summary":"  Large Language Models (LLMs) have demonstrated their efficacy across a broad\nspectrum of tasks in healthcare applications. However, often LLMs need to be\nfine-tuned on task-specific expert annotated data to achieve optimal\nperformance, which can be expensive and time consuming. In this study, we\nfine-tune PaLM-2 with parameter efficient fine-tuning (PEFT) using noisy labels\nobtained from gemini-pro 1.0 for the detection of Schedule-of-Event (SoE)\ntables, which specify care plan in clinical trial protocols. We introduce a\nfiltering mechanism to select high-confidence labels for this table\nclassification task, thereby reducing the noise in the auto-generated labels.\nWe show that fine-tuned PaLM-2 with those labels achieves performance that\nexceeds the gemini-pro 1.0 and other LLMs. Furthermore, its performance is\nclose to a PaLM-2 fine-tuned on labels obtained from non-expert annotators. Our\nresults show that leveraging LLM-generated labels through powerful models like\ngemini-pro can potentially serve as a viable strategy for improving LLM\nperformance through fine-tuning in specialized tasks, particularly in domains\nwhere expert annotations are scarce, expensive, or time-consuming to obtain.\n","authors":["Bhawesh Kumar","Jonathan Amar","Eric Yang","Nan Li","Yugang Jia"],"pdf_url":"https://arxiv.org/pdf/2405.06093v2.pdf","comment":"23 pages. Published in MLHC 2024"},{"id":"http://arxiv.org/abs/2407.01281v2","updated":"2024-08-05T15:50:32Z","published":"2024-07-01T13:35:53Z","title":"Bridging Smoothness and Approximation: Theoretical Insights into\n  Over-Smoothing in Graph Neural Networks","summary":"  In this paper, we explore the approximation theory of functions defined on\ngraphs. Our study builds upon the approximation results derived from the\n$K$-functional. We establish a theoretical framework to assess the lower bounds\nof approximation for target functions using Graph Convolutional Networks (GCNs)\nand examine the over-smoothing phenomenon commonly observed in these networks.\nInitially, we introduce the concept of a $K$-functional on graphs, establishing\nits equivalence to the modulus of smoothness. We then analyze a typical type of\nGCN to demonstrate how the high-frequency energy of the output decays, an\nindicator of over-smoothing. This analysis provides theoretical insights into\nthe nature of over-smoothing within GCNs. Furthermore, we establish a lower\nbound for the approximation of target functions by GCNs, which is governed by\nthe modulus of smoothness of these functions. This finding offers a new\nperspective on the approximation capabilities of GCNs. In our numerical\nexperiments, we analyze several widely applied GCNs and observe the phenomenon\nof energy decay. These observations corroborate our theoretical results on\nexponential decay order.\n","authors":["Guangrui Yang","Jianfei Li","Ming Li","Han Feng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.01281v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02575v1","updated":"2024-08-05T15:48:51Z","published":"2024-08-05T15:48:51Z","title":"Artificial Intelligence for Public Health Surveillance in Africa:\n  Applications and Opportunities","summary":"  Artificial Intelligence (AI) is revolutionizing various fields, including\npublic health surveillance. In Africa, where health systems frequently\nencounter challenges such as limited resources, inadequate infrastructure,\nfailed health information systems and a shortage of skilled health\nprofessionals, AI offers a transformative opportunity. This paper investigates\nthe applications of AI in public health surveillance across the continent,\npresenting successful case studies and examining the benefits, opportunities,\nand challenges of implementing AI technologies in African healthcare settings.\nOur paper highlights AI's potential to enhance disease monitoring and health\noutcomes, and support effective public health interventions. The findings\npresented in the paper demonstrate that AI can significantly improve the\naccuracy and timeliness of disease detection and prediction, optimize resource\nallocation, and facilitate targeted public health strategies. Additionally, our\npaper identified key barriers to the widespread adoption of AI in African\npublic health systems and proposed actionable recommendations to overcome these\nchallenges.\n","authors":["Jean Marie Tshimula","Mitterrand Kalengayi","Dieumerci Makenga","Dorcas Lilonge","Marius Asumani","Déborah Madiya","Élie Nkuba Kalonji","Hugues Kanda","René Manassé Galekwa","Josias Kumbu","Hardy Mikese","Grace Tshimula","Jean Tshibangu Muabila","Christian N. Mayemba","D'Jeff K. Nkashama","Kalonji Kalala","Steve Ataky","Tighana Wenge Basele","Mbuyi Mukendi Didier","Selain K. Kasereka","Maximilien V. Dialufuma","Godwill Ilunga Wa Kumwita","Lionel Muyuku","Jean-Paul Kimpesa","Dominique Muteba","Aaron Aruna Abedi","Lambert Mukendi Ntobo","Gloria M. Bundutidi","Désiré Kulimba Mashinda","Emmanuel Kabengele Mpinga","Nathanaël M. Kasoro"],"pdf_url":"https://arxiv.org/pdf/2408.02575v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02568v1","updated":"2024-08-05T15:43:56Z","published":"2024-08-05T15:43:56Z","title":"Cross-Modality Clustering-based Self-Labeling for Multimodal Data\n  Classification","summary":"  Technological advances facilitate the ability to acquire multimodal data,\nposing a challenge for recognition systems while also providing an opportunity\nto use the heterogeneous nature of the information to increase the\ngeneralization capability of models. An often overlooked issue is the cost of\nthe labeling process, which is typically high due to the need for a significant\ninvestment in time and money associated with human experts. Existing\nsemi-supervised learning methods often focus on operating in the feature space\ncreated by the fusion of available modalities, neglecting the potential for\ncross-utilizing complementary information available in each modality. To\naddress this problem, we propose Cross-Modality Clustering-based Self-Labeling\n(CMCSL). Based on a small set of pre-labeled data, CMCSL groups instances\nbelonging to each modality in the deep feature space and then propagates known\nlabels within the resulting clusters. Next, information about the instances'\nclass membership in each modality is exchanged based on the Euclidean distance\nto ensure more accurate labeling. Experimental evaluation conducted on 20\ndatasets derived from the MM-IMDb dataset indicates that cross-propagation of\nlabels between modalities -- especially when the number of pre-labeled\ninstances is small -- can allow for more reliable labeling and thus increase\nthe classification performance in each modality.\n","authors":["Paweł Zyblewski","Leandro L. Minku"],"pdf_url":"https://arxiv.org/pdf/2408.02568v1.pdf","comment":"10 pages, 5 figures, 9 tables"},{"id":"http://arxiv.org/abs/2301.07088v3","updated":"2024-08-05T15:38:05Z","published":"2023-01-17T18:53:24Z","title":"Vision Learners Meet Web Image-Text Pairs","summary":"  Many self-supervised learning methods are pre-trained on the well-curated\nImageNet-1K dataset. In this work, given the excellent scalability of web data,\nwe consider self-supervised pre-training on noisy web sourced image-text paired\ndata. First, we conduct a benchmark study of representative self-supervised\npre-training methods on large-scale web data in a like-for-like setting. We\ncompare a range of methods, including single-modal ones that use masked\ntraining objectives and multi-modal ones that use image-text constrastive\ntraining. We observe that existing multi-modal methods do not outperform their\nsingle-modal counterparts on vision transfer learning tasks. We derive an\ninformation-theoretical view to explain these benchmark results, which provides\ninsight into how to design a novel vision learner. Inspired by this insight, we\npresent a new visual representation pre-training method, MUlti-modal\nGenerator~(MUG), that learns from scalable web sourced image-text data. MUG\nachieves state-of-the-art transfer performance on a variety of tasks and\ndemonstrates promising scaling properties. Pre-trained models and code will be\nmade public upon acceptance.\n","authors":["Bingchen Zhao","Quan Cui","Hao Wu","Osamu Yoshie","Cheng Yang","Oisin Mac Aodha"],"pdf_url":"https://arxiv.org/pdf/2301.07088v3.pdf","comment":"Project page: https://bzhao.me/MUG/"},{"id":"http://arxiv.org/abs/2408.02551v1","updated":"2024-08-05T15:26:39Z","published":"2024-08-05T15:26:39Z","title":"Process-constrained batch Bayesian approaches for yield optimization in\n  multi-reactor systems","summary":"  The optimization of yields in multi-reactor systems, which are advanced tools\nin heterogeneous catalysis research, presents a significant challenge due to\nhierarchical technical constraints. To this respect, this work introduces a\nnovel approach called process-constrained batch Bayesian optimization via\nThompson sampling (pc-BO-TS) and its generalized hierarchical extension\n(hpc-BO-TS). This method, tailored for the efficiency demands in multi-reactor\nsystems, integrates experimental constraints and balances between exploration\nand exploitation in a sequential batch optimization strategy. It offers an\nimprovement over other Bayesian optimization methods. The performance of\npc-BO-TS and hpc-BO-TS is validated in synthetic cases as well as in a\nrealistic scenario based on data obtained from high-throughput experiments done\non a multi-reactor system available in the REALCAT platform. The proposed\nmethods often outperform other sequential Bayesian optimizations and existing\nprocess-constrained batch Bayesian optimization methods. This work proposes a\nnovel approach to optimize the yield of a reaction in a multi-reactor system,\nmarking a significant step forward in digital catalysis and generally in\noptimization methods for chemical engineering.\n","authors":["Markus Grimm","Sébastien Paul","Pierre Chainais"],"pdf_url":"https://arxiv.org/pdf/2408.02551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02547v1","updated":"2024-08-05T15:17:34Z","published":"2024-08-05T15:17:34Z","title":"The Role of Functional Muscle Networks in Improving Hand Gesture\n  Perception for Human-Machine Interfaces","summary":"  Developing accurate hand gesture perception models is critical for various\nrobotic applications, enabling effective communication between humans and\nmachines and directly impacting neurorobotics and interactive robots. Recently,\nsurface electromyography (sEMG) has been explored for its rich informational\ncontext and accessibility when combined with advanced machine learning\napproaches and wearable systems. The literature presents numerous approaches to\nboost performance while ensuring robustness for neurorobots using sEMG, often\nresulting in models requiring high processing power, large datasets, and less\nscalable solutions. This paper addresses this challenge by proposing the\ndecoding of muscle synchronization rather than individual muscle activation. We\nstudy coherence-based functional muscle networks as the core of our perception\nmodel, proposing that functional synchronization between muscles and the\ngraph-based network of muscle connectivity encode contextual information about\nintended hand gestures. This can be decoded using shallow machine learning\napproaches without the need for deep temporal networks. Our technique could\nimpact myoelectric control of neurorobots by reducing computational burdens and\nenhancing efficiency. The approach is benchmarked on the Ninapro database,\nwhich contains 12 EMG signals from 40 subjects performing 17 hand gestures. It\nachieves an accuracy of 85.1%, demonstrating improved performance compared to\nexisting methods while requiring much less computational power. The results\nsupport the hypothesis that a coherence-based functional muscle network encodes\ncritical information related to gesture execution, significantly enhancing hand\ngesture perception with potential applications for neurorobotic systems and\ninteractive machines.\n","authors":["Costanza Armanini","Tuka Alhanai","Farah E. Shamout","S. Farokh Atashzar"],"pdf_url":"https://arxiv.org/pdf/2408.02547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02545v1","updated":"2024-08-05T15:16:24Z","published":"2024-08-05T15:16:24Z","title":"RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\n  Generation","summary":"  Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.\n","authors":["Daniel Fleischer","Moshe Berchansky","Moshe Wasserblat","Peter Izsak"],"pdf_url":"https://arxiv.org/pdf/2408.02545v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2406.04216v3","updated":"2024-08-05T15:08:02Z","published":"2024-06-06T16:15:34Z","title":"What Do Language Models Learn in Context? The Structured Task Hypothesis","summary":"  Large language models (LLMs) exhibit an intriguing ability to learn a novel\ntask from in-context examples presented in a demonstration, termed in-context\nlearning (ICL). Understandably, a swath of research has been dedicated to\nuncovering the theories underpinning ICL. One popular hypothesis explains ICL\nby task selection. LLMs identify the task based on the demonstration and\ngeneralize it to the prompt. Another popular hypothesis is that ICL is a form\nof meta-learning, i.e., the models learn a learning algorithm at pre-training\ntime and apply it to the demonstration. Finally, a third hypothesis argues that\nLLMs use the demonstration to select a composition of tasks learned during\npre-training to perform ICL. In this paper, we empirically explore these three\nhypotheses that explain LLMs' ability to learn in context with a suite of\nexperiments derived from common text classification tasks. We invalidate the\nfirst two hypotheses with counterexamples and provide evidence in support of\nthe last hypothesis. Our results suggest an LLM could learn a novel task in\ncontext via composing tasks learned during pre-training.\n","authors":["Jiaoda Li","Yifan Hou","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2406.04216v3.pdf","comment":"This work is published in ACL 2024"},{"id":"http://arxiv.org/abs/2310.02812v2","updated":"2024-08-05T15:06:24Z","published":"2023-10-04T13:37:34Z","title":"Time-Series Classification in Smart Manufacturing Systems: An\n  Experimental Evaluation of State-of-the-Art Machine Learning Algorithms","summary":"  Manufacturing is gathering extensive amounts of diverse data, thanks to the\ngrowing number of sensors and rapid advances in sensing technologies. Among the\nvarious data types available in SMS settings, time-series data plays a pivotal\nrole. Hence, TSC emerges is crucial in this domain. The objective of this study\nis to fill this gap by providing a rigorous experimental evaluation of the SoTA\nML and DL algorithms for TSC tasks in manufacturing and industrial settings. We\nfirst explored and compiled a comprehensive list of more than 92 SoTA\nalgorithms from both TSC and manufacturing literature. Following, we selected\nthe 36 most representative algorithms from this list. To evaluate their\nperformance across various manufacturing classification tasks, we curated a set\nof 22 manufacturing datasets, representative of different characteristics that\ncover diverse manufacturing problems. Subsequently, we implemented and\nevaluated the algorithms on the manufacturing benchmark datasets, and analyzed\nthe results for each dataset. Based on the results, ResNet, DrCIF,\nInceptionTime, and ARSENAL are the top-performing algorithms, boasting an\naverage accuracy of over 96.6% across all 22 manufacturing TSC datasets. These\nfindings underscore the robustness, efficiency, scalability, and effectiveness\nof convolutional kernels in capturing temporal features in time-series data, as\nthree out of the top four performing algorithms leverage these kernels for\nfeature extraction. Additionally, LSTM, BiLSTM, and TS-LSTM algorithms deserve\nrecognition for their effectiveness in capturing features within time-series\ndata using RNN-based structures.\n","authors":["Mojtaba A. Farahani","M. R. McCormick","Ramy Harik","Thorsten Wuest"],"pdf_url":"https://arxiv.org/pdf/2310.02812v2.pdf","comment":"Published in Robotics and Computer-Integrated Manufacturing journal"},{"id":"http://arxiv.org/abs/2408.02533v1","updated":"2024-08-05T15:03:19Z","published":"2024-08-05T15:03:19Z","title":"LMEMs for post-hoc analysis of HPO Benchmarking","summary":"  The importance of tuning hyperparameters in Machine Learning (ML) and Deep\nLearning (DL) is established through empirical research and applications,\nevident from the increase in new hyperparameter optimization (HPO) algorithms\nand benchmarks steadily added by the community. However, current benchmarking\npractices using averaged performance across many datasets may obscure key\ndifferences between HPO methods, especially for pairwise comparisons. In this\nwork, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing\nfor post-hoc analysis of HPO benchmarking runs. LMEMs allow flexible and\nexpressive modeling on the entire experiment data, including information such\nas benchmark meta-features, offering deeper insights than current analysis\npractices. We demonstrate this through a case study on the PriorBand paper's\nexperiment data to find insights not reported in the original work.\n","authors":["Anton Geburek","Neeratyoy Mallik","Danny Stoll","Xavier Bouthillier","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2408.02533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14294v2","updated":"2024-08-05T14:59:27Z","published":"2024-02-22T05:16:04Z","title":"High-arity PAC learning via exchangeability","summary":"  We develop a theory of high-arity PAC learning, which is statistical learning\nin the presence of \"structured correlation\". In this theory, hypotheses are\neither graphs, hypergraphs or, more generally, structures in finite relational\nlanguages, and i.i.d. sampling is replaced by sampling an induced substructure,\nproducing an exchangeable distribution. Our main theorems establish a\nhigh-arity (agnostic) version of the fundamental theorem of statistical\nlearning.\n","authors":["Leonardo N. Coregliano","Maryanthe Malliaris"],"pdf_url":"https://arxiv.org/pdf/2402.14294v2.pdf","comment":"150 pages, 1 figure. (This version makes expository changes to\n  Sections 1 and 2 and adds Appendix B on Bayes predictors.)"},{"id":"http://arxiv.org/abs/2408.02525v1","updated":"2024-08-05T14:46:04Z","published":"2024-08-05T14:46:04Z","title":"Single-tap Latency Reduction with Single- or Double- tap Prediction","summary":"  Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.\n","authors":["Naoto Nishida","Kaori Ikematsu","Junichi Sato","Shota Yamanaka","Kota Tsubouchi"],"pdf_url":"https://arxiv.org/pdf/2408.02525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02514v1","updated":"2024-08-05T14:34:40Z","published":"2024-08-05T14:34:40Z","title":"Stem-JEPA: A Joint-Embedding Predictive Architecture for Musical Stem\n  Compatibility Estimation","summary":"  This paper explores the automated process of determining stem compatibility\nby identifying audio recordings of single instruments that blend well with a\ngiven musical context. To tackle this challenge, we present Stem-JEPA, a novel\nJoint-Embedding Predictive Architecture (JEPA) trained on a multi-track dataset\nusing a self-supervised learning approach.\n  Our model comprises two networks: an encoder and a predictor, which are\njointly trained to predict the embeddings of compatible stems from the\nembeddings of a given context, typically a mix of several instruments. Training\na model in this manner allows its use in estimating stem compatibility -\nretrieving, aligning, or generating a stem to match a given mix - or for\ndownstream tasks such as genre or key estimation, as the training paradigm\nrequires the model to learn information related to timbre, harmony, and rhythm.\n  We evaluate our model's performance on a retrieval task on the MUSDB18\ndataset, testing its ability to find the missing stem from a mix and through a\nsubjective user study. We also show that the learned embeddings capture\ntemporal alignment information and, finally, evaluate the representations\nlearned by our model on several downstream tasks, highlighting that they\neffectively capture meaningful musical features.\n","authors":["Alain Riou","Stefan Lattner","Gaëtan Hadjeres","Michael Anslow","Geoffroy Peeters"],"pdf_url":"https://arxiv.org/pdf/2408.02514v1.pdf","comment":"Proceedings of the 25th International Society for Music Information\n  Retrieval Conference, ISMIR 2024"},{"id":"http://arxiv.org/abs/2408.02509v1","updated":"2024-08-05T14:31:26Z","published":"2024-08-05T14:31:26Z","title":"Practical Attacks against Black-box Code Completion Engines","summary":"  Modern code completion engines, powered by large language models, have\ndemonstrated impressive capabilities to generate functionally correct code\nbased on surrounding context. As these tools are extensively used by millions\nof developers, it is crucial to investigate their security implications. In\nthis work, we present INSEC, a novel attack that directs code completion\nengines towards generating vulnerable code. In line with most commercial\ncompletion engines, such as GitHub Copilot, INSEC assumes only black-box query\naccess to the targeted engine, without requiring any knowledge of the engine's\ninternals. Our attack works by inserting a malicious attack string as a short\ncomment in the completion input. To derive the attack string, we design a\nseries of specialized initialization schemes and an optimization procedure for\nfurther refinement. We demonstrate the strength of INSEC not only on\nstate-of-the-art open-source models but also on black-box commercial services\nsuch as the OpenAI API and GitHub Copilot. On a comprehensive set of\nsecurity-critical test cases covering 16 CWEs across 5 programming languages,\nINSEC significantly increases the likelihood of the considered completion\nengines in generating unsafe code by >50% in absolute, while maintaining the\nability in producing functionally correct code. At the same time, our attack\nhas low resource requirements, and can be developed for a cost of well under\nten USD on commodity hardware.\n","authors":["Slobodan Jenko","Jingxuan He","Niels Mündler","Mark Vero","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2408.02509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02496v1","updated":"2024-08-05T14:19:03Z","published":"2024-08-05T14:19:03Z","title":"Automatic rating of incomplete hippocampal inversions evaluated across\n  multiple cohorts","summary":"  Incomplete Hippocampal Inversion (IHI), sometimes called hippocampal\nmalrotation, is an atypical anatomical pattern of the hippocampus found in\nabout 20% of the general population. IHI can be visually assessed on coronal\nslices of T1 weighted MR images, using a composite score that combines four\nanatomical criteria. IHI has been associated with several brain disorders\n(epilepsy, schizophrenia). However, these studies were based on small samples.\nFurthermore, the factors (genetic or environmental) that contribute to the\ngenesis of IHI are largely unknown. Large-scale studies are thus needed to\nfurther understand IHI and their potential relationships to neurological and\npsychiatric disorders. However, visual evaluation is long and tedious,\njustifying the need for an automatic method. In this paper, we propose, for the\nfirst time, to automatically rate IHI. We proceed by predicting four anatomical\ncriteria, which are then summed up to form the IHI score, providing the\nadvantage of an interpretable score. We provided an extensive experimental\ninvestigation of different machine learning methods and training strategies. We\nperformed automatic rating using a variety of deep learning models (conv5-FC3,\nResNet and SECNN) as well as a ridge regression. We studied the generalization\nof our models using different cohorts and performed multi-cohort learning. We\nrelied on a large population of 2,008 participants from the IMAGEN study, 993\nand 403 participants from the QTIM/QTAB studies as well as 985 subjects from\nthe UKBiobank. We showed that deep learning models outperformed a ridge\nregression. We demonstrated that the performances of the conv5-FC3 network were\nat least as good as more complex networks while maintaining a low complexity\nand computation time. We showed that training on a single cohort may lack in\nvariability while training on several cohorts improves generalization.\n","authors":["Lisa Hemforth","Baptiste Couvy-Duchesne","Kevin De Matos","Camille Brianceau","Matthieu Joulot","Tobias Banaschewski","Arun L. W. Bokde","Sylvane Desrivières","Herta Flor","Antoine Grigis","Hugh Garavan","Penny Gowland","Andreas Heinz","Rüdiger Brühl","Jean-Luc Martinot","Marie-Laure Paillère Martinot","Eric Artiges","Dimitri Papadopoulos","Herve Lemaitre","Tomas Paus","Luise Poustka","Sarah Hohmann","Nathalie Holz","Juliane H. Fröhner","Michael N. Smolka","Nilakshi Vaidya","Henrik Walter","Robert Whelan","Gunter Schumann","Christian Büchel","JB Poline","Bernd Itterman","Vincent Frouin","Alexandre Martin","IMAGEN study group","Claire Cury","Olivier Colliot"],"pdf_url":"https://arxiv.org/pdf/2408.02496v1.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:016"},{"id":"http://arxiv.org/abs/2408.02487v1","updated":"2024-08-05T14:09:30Z","published":"2024-08-05T14:09:30Z","title":"A First Look at License Compliance Capability of LLMs in Code Generation","summary":"  Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose an evaluation benchmark LiCoEval, to evaluate the\nlicense compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular\nLLMs, finding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.\n","authors":["Weiwei Xu","Kai Gao","Hao He","Minghui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02473v1","updated":"2024-08-05T13:57:32Z","published":"2024-08-05T13:57:32Z","title":"Toward Attention-based TinyML: A Heterogeneous Accelerated Architecture\n  and Automated Deployment Flow","summary":"  One of the challenges for Tiny Machine Learning (tinyML) is keeping up with\nthe evolution of Machine Learning models from Convolutional Neural Networks to\nTransformers. We address this by leveraging a heterogeneous architectural\ntemplate coupling RISC-V processors with hardwired accelerators supported by an\nautomated deployment flow. We demonstrate an Attention-based model in a tinyML\npower envelope with an octa-core cluster coupled with an accelerator for\nquantized Attention. Our deployment flow enables an end-to-end 8-bit\nMobileBERT, achieving leading-edge energy efficiency and throughput of 2960\nGOp/J and 154 GOp/s at 32.5 Inf/s consuming 52.0 mW (0.65 V, 22 nm FD-SOI\ntechnology).\n","authors":["Philip Wiese","Gamze İslamoğlu","Moritz Scherer","Luka Macan","Victor J. B. Jung","Alessio Burrello","Francesco Conti","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2408.02473v1.pdf","comment":"Pre-print manuscript submitted for review to the IEEE Design and Test\n  Special Issue on tinyML"},{"id":"http://arxiv.org/abs/2408.02456v1","updated":"2024-08-05T13:28:51Z","published":"2024-08-05T13:28:51Z","title":"Enhancing Heterogeneous Knowledge Graph Completion with a Novel\n  GAT-based Approach","summary":"  Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.\n","authors":["Wanxu Wei","Yitong Song","Bin Yao"],"pdf_url":"https://arxiv.org/pdf/2408.02456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03453v2","updated":"2024-08-05T13:01:47Z","published":"2024-04-04T13:57:44Z","title":"Conditioning of Banach Space Valued Gaussian Random Variables: An\n  Approximation Approach Based on Martingales","summary":"  In this paper we investigate the conditional distributions of two Banach\nspace valued, jointly Gaussian random variables. We show that these conditional\ndistributions are again Gaussian and that their means and covariances are\ndetermined by a general finite dimensional approximation scheme based upon a\nmartingale approach. In particular, it turns out that the covariance operators\noccurring in this scheme converge with respect to the nuclear norm and that the\nconditional probabilities converge weakly. Moreover, we discuss in detail, how\nour approximation scheme can be implemented in several classes of important\nBanach spaces such as RKHSs and $C(T)$. As an example, we then apply our\ngeneral results to the case of Gaussian processes with continuous paths\nconditioned to partial but infinite observations of their paths. Here we show\nthat conditioning on sufficiently rich, increasing sets of finitely many\nobservations leads to consistent approximations, in the sense that both the\nmean and covariance functions converge uniformly. Moreover, we discuss how\nthese results improve our understanding of the popular Gaussian processes for\nmachine learning.\n","authors":["Ingo Steinwart"],"pdf_url":"https://arxiv.org/pdf/2404.03453v2.pdf","comment":"52 pages plus 22 pages of supplemental material"},{"id":"http://arxiv.org/abs/2405.14244v2","updated":"2024-08-05T12:59:32Z","published":"2024-05-23T07:23:33Z","title":"Tell me why: Training preferences-based RL with human preferences and\n  step-level explanations","summary":"  Human-in-the-loop reinforcement learning allows the training of agents\nthrough various interfaces, even for non-expert humans. Recently,\npreference-based methods (PbRL), where the human has to give his preference\nover two trajectories, increased in popularity since they allow training in\ndomains where more direct feedback is hard to formulate. However, the current\nPBRL methods have limitations and do not provide humans with an expressive\ninterface for giving feedback. With this work, we propose a new\npreference-based learning method that provides humans with a more expressive\ninterface to provide their preference over trajectories and a factual\nexplanation (or annotation of why they have this preference). These\nexplanations allow the human to explain what parts of the trajectory are most\nrelevant for the preference. We allow the expression of the explanations over\nindividual trajectory steps. We evaluate our method in various simulations\nusing a simulated human oracle (with realistic restrictions), and our results\nshow that our extended feedback can improve the speed of learning.\n","authors":["Jakob Karalus"],"pdf_url":"https://arxiv.org/pdf/2405.14244v2.pdf","comment":"Workshop on Reinforcement Learning Beyond Rewards @ Reinforcement\n  Learning Conference (2024)"},{"id":"http://arxiv.org/abs/2202.04309v2","updated":"2024-08-05T12:58:37Z","published":"2022-02-09T06:56:41Z","title":"Vertical Federated Learning: Challenges, Methodologies and Experiments","summary":"  Recently, federated learning (FL) has emerged as a promising distributed\nmachine learning (ML) technology, owing to the advancing computational and\nsensing capacities of end-user devices, however with the increasing concerns on\nusers' privacy. As a special architecture in FL, vertical FL (VFL) is capable\nof constructing a hyper ML model by embracing sub-models from different\nclients. These sub-models are trained locally by vertically partitioned data\nwith distinct attributes. Therefore, the design of VFL is fundamentally\ndifferent from that of conventional FL, raising new and unique research issues.\nIn this paper, we aim to discuss key challenges in VFL with effective\nsolutions, and conduct experiments on real-life datasets to shed light on these\nissues. Specifically, we first propose a general framework on VFL, and\nhighlight the key differences between VFL and conventional FL. Then, we discuss\nresearch challenges rooted in VFL systems under four aspects, i.e., security\nand privacy risks, expensive computation and communication costs, possible\nstructural damage caused by model splitting, and system heterogeneity.\nAfterwards, we develop solutions to addressing the aforementioned challenges,\nand conduct extensive experiments to showcase the effectiveness of our proposed\nsolutions.\n","authors":["Kang Wei","Jun Li","Chuan Ma","Ming Ding","Sha Wei","Fan Wu","Guihai Chen","Thilina Ranbaduge"],"pdf_url":"https://arxiv.org/pdf/2202.04309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02433v1","updated":"2024-08-05T12:46:21Z","published":"2024-08-05T12:46:21Z","title":"On Probabilistic Embeddings in Optimal Dimension Reduction","summary":"  Dimension reduction algorithms are a crucial part of many data science\npipelines, including data exploration, feature creation and selection, and\ndenoising. Despite their wide utilization, many non-linear dimension reduction\nalgorithms are poorly understood from a theoretical perspective. In this work\nwe consider a generalized version of multidimensional scaling, which is posed\nas an optimization problem in which a mapping from a high-dimensional feature\nspace to a lower-dimensional embedding space seeks to preserve either inner\nproducts or norms of the distribution in feature space, and which encompasses\nmany commonly used dimension reduction algorithms. We analytically investigate\nthe variational properties of this problem, leading to the following insights:\n1) Solutions found using standard particle descent methods may lead to\nnon-deterministic embeddings, 2) A relaxed or probabilistic formulation of the\nproblem admits solutions with easily interpretable necessary conditions, 3) The\nglobally optimal solutions to the relaxed problem actually must give a\ndeterministic embedding. This progression of results mirrors the classical\ndevelopment of optimal transportation, and in a case relating to the\nGromov-Wasserstein distance actually gives explicit insight into the structure\nof the optimal embeddings, which are parametrically determined and\ndiscontinuous. Finally, we illustrate that a standard computational\nimplementation of this task does not learn deterministic embeddings, which\nmeans that it learns sub-optimal mappings, and that the embeddings learned in\nthat context have highly misleading clustering structure, underscoring the\ndelicate nature of solving this problem computationally.\n","authors":["Ryan Murray","Adam Pickarski"],"pdf_url":"https://arxiv.org/pdf/2408.02433v1.pdf","comment":"26 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.10571v2","updated":"2024-08-05T12:44:04Z","published":"2023-03-19T05:20:52Z","title":"Reinforcement Learning Friendly Vision-Language Model for Minecraft","summary":"  One of the essential missions in the AI research community is to build an\nautonomous embodied agent that can achieve high-level performance across a wide\nspectrum of tasks. However, acquiring or manually designing rewards for all\nopen-ended tasks is unrealistic. In this paper, we propose a novel cross-modal\ncontrastive learning framework architecture, CLIP4MC, aiming to learn a\nreinforcement learning (RL) friendly vision-language model (VLM) that serves as\nan intrinsic reward function for open-ended tasks. Simply utilizing the\nsimilarity between the video snippet and the language prompt is not RL-friendly\nsince standard VLMs may only capture the similarity at a coarse level. To\nachieve RL-friendliness, we incorporate the task completion degree into the VLM\ntraining objective, as this information can assist agents in distinguishing the\nimportance between different states. Moreover, we provide neat YouTube datasets\nbased on the large-scale YouTube database provided by MineDojo. Specifically,\ntwo rounds of filtering operations guarantee that the dataset covers enough\nessential information and that the video-text pair is highly correlated.\nEmpirically, we demonstrate that the proposed method achieves better\nperformance on RL tasks compared with baselines. The code and datasets are\navailable at https://github.com/PKU-RL/CLIP4MC.\n","authors":["Haobin Jiang","Junpeng Yue","Hao Luo","Ziluo Ding","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2303.10571v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2407.19858v2","updated":"2024-08-05T12:42:38Z","published":"2024-07-29T10:26:52Z","title":"AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models\n  with Neural Networks","summary":"  In quantitative finance, machine learning methods are essential for alpha\ngeneration. This study introduces a new approach that combines Hidden Markov\nModels (HMM) and neural networks, integrated with Black-Litterman portfolio\noptimization. During the COVID period (2019-2022), this dual-model approach\nachieved a 97% return with a Sharpe ratio of 0.992. It incorporates two risk\nmodels to enhance risk management, showing efficiency during volatile periods.\nThe methodology was implemented on the QuantConnect platform, which was chosen\nfor its robust framework and experimental reproducibility. The system, which\npredicts future price movements, includes a three-year warm-up to ensure proper\nalgorithm function. It targets highly liquid, large-cap energy stocks to ensure\nstable and predictable performance while also considering broker payments. The\ndual-model alpha system utilizes log returns to select the optimal state based\non the historical performance. It combines state predictions with neural\nnetwork outputs, which are based on historical data, to generate trading\nsignals. This study examined the architecture of the trading system, data\npre-processing, training, and performance. The full code and backtesting data\nare available under the MIT license.\n","authors":["Tiago Monteiro"],"pdf_url":"https://arxiv.org/pdf/2407.19858v2.pdf","comment":"14 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2408.02427v1","updated":"2024-08-05T12:34:49Z","published":"2024-08-05T12:34:49Z","title":"Attenuation-adjusted deep learning of pore defects in 2D radiographs of\n  additive manufacturing powders","summary":"  The presence of gas pores in metal feedstock powder for additive\nmanufacturing greatly affects the final AM product. Since current porosity\nanalysis often involves lengthy X-ray computed tomography (XCT) scans with a\nfull rotation around the sample, motivation exists to explore methods that\nallow for high throughput -- possibly enabling in-line porosity analysis during\nmanufacturing. Through labelling pore pixels on single 2D radiographs of\npowders, this work seeks to simulate such future efficient setups. High\nsegmentation accuracy is achieved by combining a model of X-ray attenuation\nthrough particles with a variant of the widely applied UNet architecture;\nnotably, F1-score increases by $11.4\\%$ compared to the baseline UNet. The\nproposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2)\nmaking tight particle cutouts, and 3) subtracting an ideal particle without\npores generated from a distance map inspired by Lambert-Beers law. This paper\nexplores four image processing methods, where the fastest (yet still\nunoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$,\nand the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable\nnature, these strategies can be involved in making high throughput porosity\nanalysis of metal feedstock powder for additive manufacturing.\n","authors":["Andreas Bjerregaard","David Schumacher","Jon Sporring"],"pdf_url":"https://arxiv.org/pdf/2408.02427v1.pdf","comment":"Implementation on https://github.com/yhsure/porosity"},{"id":"http://arxiv.org/abs/2402.12198v2","updated":"2024-08-05T12:20:49Z","published":"2024-02-19T15:03:04Z","title":"Zero shot VLMs for hate meme detection: Are we there yet?","summary":"  Multimedia content on social media is rapidly evolving, with memes gaining\nprominence as a distinctive form. Unfortunately, some malicious users exploit\nmemes to target individuals or vulnerable communities, making it imperative to\nidentify and address such instances of hateful memes. Extensive research has\nbeen conducted to address this issue by developing hate meme detection models.\nHowever, a notable limitation of traditional machine/deep learning models is\nthe requirement for labeled datasets for accurate classification. Recently, the\nresearch community has witnessed the emergence of several visual language\nmodels that have exhibited outstanding performance across various tasks. In\nthis study, we aim to investigate the efficacy of these visual language models\nin handling intricate tasks such as hate meme detection. We use various prompt\nsettings to focus on zero-shot classification of hateful/harmful memes. Through\nour analysis, we observe that large VLMs are still vulnerable for zero-shot\nhate meme detection.\n","authors":["Naquee Rizwan","Paramananda Bhaskar","Mithun Das","Swadhin Satyaprakash Majhi","Punyajoy Saha","Animesh Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2402.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02412v1","updated":"2024-08-05T12:11:09Z","published":"2024-08-05T12:11:09Z","title":"PENDRAM: Enabling High-Performance and Energy-Efficient Processing of\n  Deep Neural Networks through a Generalized DRAM Data Mapping Policy","summary":"  Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.\n","authors":["Rachmad Vidya Wicaksana Putra","Muhammad Abdullah Hanif","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2408.02412v1.pdf","comment":"11 pages, 15 figures, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:2004.10341"},{"id":"http://arxiv.org/abs/2408.02407v1","updated":"2024-08-05T12:01:42Z","published":"2024-08-05T12:01:42Z","title":"Terracorder: Sense Long and Prosper","summary":"  In-situ sensing devices need to be deployed in remote environments for long\nperiods of time; minimizing their power consumption is vital for maximising\nboth their operational lifetime and coverage. We introduce Terracorder -- a\nversatile multi-sensor device -- and showcase its exceptionally low power\nconsumption using an on-device reinforcement learning scheduler. We prototype a\nunique device setup for biodiversity monitoring and compare its battery life\nusing our scheduler against a number of fixed schedules; the scheduler captures\nmore than 80% of events at less than 50% of the number of activations of the\nbest-performing fixed schedule. We then explore how a collaborative scheduler\ncan maximise the useful operation of a network of devices, improving overall\nnetwork power consumption and robustness.\n","authors":["Josh Millar","Sarab Sethi","Hamed Haddadi","Anil Madhavapeddy"],"pdf_url":"https://arxiv.org/pdf/2408.02407v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2403.05996v3","updated":"2024-08-05T11:55:19Z","published":"2024-03-09T19:56:40Z","title":"Dissecting Deep RL with High Update Ratios: Combatting Value Divergence","summary":"  We show that deep reinforcement learning algorithms can retain their ability\nto learn without resetting network parameters in settings where the number of\ngradient updates greatly exceeds the number of environment samples by\ncombatting value function divergence. Under large update-to-data ratios, a\nrecent study by Nikishin et al. (2022) suggested the emergence of a primacy\nbias, in which agents overfit early interactions and downplay later experience,\nimpairing their ability to learn. In this work, we investigate the phenomena\nleading to the primacy bias. We inspect the early stages of training that were\nconjectured to cause the failure to learn and find that one fundamental\nchallenge is a long-standing acquaintance: value function divergence.\nOverinflated Q-values are found not only on out-of-distribution but also\nin-distribution data and can be linked to overestimation on unseen action\nprediction propelled by optimizer momentum. We employ a simple unit-ball\nnormalization that enables learning under large update ratios, show its\nefficacy on the widely used dm_control suite, and obtain strong performance on\nthe challenging dog tasks, competitive with model-based approaches. Our results\nquestion, in parts, the prior explanation for sub-optimal learning due to\noverfitting early data.\n","authors":["Marcel Hussing","Claas Voelcker","Igor Gilitschenski","Amir-massoud Farahmand","Eric Eaton"],"pdf_url":"https://arxiv.org/pdf/2403.05996v3.pdf","comment":"Accepted as a conference paper at the First Reinforcement Learning\n  Conference (RLC)"},{"id":"http://arxiv.org/abs/2407.19707v3","updated":"2024-08-05T11:22:34Z","published":"2024-07-29T05:05:13Z","title":"Neural networks for bifurcation and linear stability analysis of steady\n  states in partial differential equations","summary":"  This research introduces an extended application of neural networks for\nsolving nonlinear partial differential equations (PDEs). A neural network,\ncombined with a pseudo-arclength continuation, is proposed to construct\nbifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural\nnetwork approach is also presented for solving eigenvalue problems to analyze\nsolution linear stability, focusing on identifying the largest eigenvalue. The\neffectiveness of the proposed neural network is examined through experiments on\nthe Bratu equation and the Burgers equation. Results from a finite difference\nmethod are also presented as comparison. Varying numbers of grid points are\nemployed in each case to assess the behavior and accuracy of both the neural\nnetwork and the finite difference method. The experimental results demonstrate\nthat the proposed neural network produces better solutions, generates more\naccurate bifurcation diagrams, has reasonable computational times, and proves\neffective for linear stability analysis.\n","authors":["Muhammad Luthfi Shahab","Hadi Susanto"],"pdf_url":"https://arxiv.org/pdf/2407.19707v3.pdf","comment":"Accepted for publication in Applied Mathematics and Computation"},{"id":"http://arxiv.org/abs/2309.14857v2","updated":"2024-08-05T11:20:33Z","published":"2023-09-26T11:35:25Z","title":"Cluster Exploration using Informative Manifold Projections","summary":"  Dimensionality reduction (DR) is one of the key tools for the visual\nexploration of high-dimensional data and uncovering its cluster structure in\ntwo- or three-dimensional spaces. The vast majority of DR methods in the\nliterature do not take into account any prior knowledge a practitioner may have\nregarding the dataset under consideration. We propose a novel method to\ngenerate informative embeddings which not only factor out the structure\nassociated with different kinds of prior knowledge but also aim to reveal any\nremaining underlying structure. To achieve this, we employ a linear combination\nof two objectives: firstly, contrastive PCA that discounts the structure\nassociated with the prior information, and secondly, kurtosis projection\npursuit which ensures meaningful data separation in the obtained embeddings. We\nformulate this task as a manifold optimization problem and validate it\nempirically across a variety of datasets considering three distinct types of\nprior knowledge. Lastly, we provide an automated framework to perform iterative\nvisual exploration of high-dimensional data.\n","authors":["Stavros Gerolymatos","Xenophon Evangelopoulos","Vladimir Gusev","John Y. Goulermas"],"pdf_url":"https://arxiv.org/pdf/2309.14857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02384v1","updated":"2024-08-05T11:16:26Z","published":"2024-08-05T11:16:26Z","title":"Strategic Federated Learning: Application to Smart Meter Data Clustering","summary":"  Federated learning (FL) involves several clients that share with a fusion\ncenter (FC), the model each client has trained with its own data. Conventional\nFL, which can be interpreted as an estimation or distortion-based approach,\nignores the final use of model information (MI) by the FC and the other\nclients. In this paper, we introduce a novel FL framework in which the FC uses\nan aggregate version of the MI to make decisions that affect the client's\nutility functions. Clients cannot choose the decisions and can only use the MI\nreported to the FC to maximize their utility. Depending on the alignment\nbetween the client and FC utilities, the client may have an individual interest\nin adding strategic noise to the model. This general framework is stated and\nspecialized to the case of clustering, in which noisy cluster representative\ninformation is reported. This is applied to the problem of power consumption\nscheduling. In this context, utility non-alignment occurs, for instance, when\nthe client wants to consume when the price of electricity is low, whereas the\nFC wants the consumption to occur when the total power is the lowest. This is\nillustrated with aggregated real data from Ausgrid \\cite{ausgrid}. Our\nnumerical analysis clearly shows that the client can increase his utility by\nadding noise to the model reported to the FC. Corresponding results and source\ncodes can be downloaded from \\cite{source-code}.\n","authors":["Hassan Mohamad","Chao Zhang","Samson Lasaulce","Vineeth S Varma","Mérouane Debbah","Mounir Ghogho"],"pdf_url":"https://arxiv.org/pdf/2408.02384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18103v2","updated":"2024-08-05T11:13:57Z","published":"2024-07-25T15:07:35Z","title":"Fine-Tuning Large Language Models for Stock Return Prediction Using\n  Newsflow","summary":"  Large language models (LLMs) and their fine-tuning techniques have\ndemonstrated superior performance in various language understanding and\ngeneration tasks. This paper explores fine-tuning LLMs for stock return\nforecasting with financial newsflow. In quantitative investing, return\nforecasting is fundamental for subsequent tasks like stock picking, portfolio\noptimization, etc. We formulate the model to include text representation and\nforecasting modules. We propose to compare the encoder-only and decoder-only\nLLMs, considering they generate text representations in distinct ways. The\nimpact of these different representations on forecasting performance remains an\nopen question. Meanwhile, we compare two simple methods of integrating LLMs'\ntoken-level representations into the forecasting module. The experiments on\nreal news and investment universes reveal that: (1) aggregated representations\nfrom LLMs' token-level embeddings generally produce return predictions that\nenhance the performance of long-only and long-short portfolios; (2) in the\nrelatively large investment universe, the decoder LLMs-based prediction model\nleads to stronger portfolios, whereas in the small universes, there are no\nconsistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),\nMistral performs more robustly across different universes; (3) return\npredictions derived from LLMs' text representations are a strong signal for\nportfolio construction, outperforming conventional sentiment scores.\n","authors":["Tian Guo","Emmanuel Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2407.18103v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02367v1","updated":"2024-08-05T10:32:06Z","published":"2024-08-05T10:32:06Z","title":"StoDIP: Efficient 3D MRF image reconstruction with deep image priors and\n  stochastic iterations","summary":"  Magnetic Resonance Fingerprinting (MRF) is a time-efficient approach to\nquantitative MRI for multiparametric tissue mapping. The reconstruction of\nquantitative maps requires tailored algorithms for removing aliasing artefacts\nfrom the compressed sampled MRF acquisitions. Within approaches found in the\nliterature, many focus solely on two-dimensional (2D) image reconstruction,\nneglecting the extension to volumetric (3D) scans despite their higher\nrelevance and clinical value. A reason for this is that transitioning to 3D\nimaging without appropriate mitigations presents significant challenges,\nincluding increased computational cost and storage requirements, and the need\nfor large amount of ground-truth (artefact-free) data for training. To address\nthese issues, we introduce StoDIP, a new algorithm that extends the\nground-truth-free Deep Image Prior (DIP) reconstruction to 3D MRF imaging.\nStoDIP employs memory-efficient stochastic updates across the multicoil MRF\ndata, a carefully selected neural network architecture, as well as faster\nnonuniform FFT (NUFFT) transformations. This enables a faster convergence\ncompared against a conventional DIP implementation without these features.\nTested on a dataset of whole-brain scans from healthy volunteers, StoDIP\ndemonstrated superior performance over the ground-truth-free reconstruction\nbaselines, both quantitatively and qualitatively.\n","authors":["Perla Mayo","Matteo Cencini","Carolin M. Pirkl","Marion I. Menzel","Michela Tosetti","Bjoern H. Menze","Mohammad Golbabaee"],"pdf_url":"https://arxiv.org/pdf/2408.02367v1.pdf","comment":"10 pages, 2 figures, 1 table, 1 algorithm"},{"id":"http://arxiv.org/abs/2407.08583v2","updated":"2024-08-05T10:31:24Z","published":"2024-07-11T15:08:11Z","title":"The Synergy between Data and Multi-Modal Large Language Models: A Survey\n  from Co-Development Perspective","summary":"  The rapid development of large language models (LLMs) has been witnessed in\nrecent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the\nmodality from text to a broader spectrum of domains, attracting widespread\nattention due to the broader range of application scenarios. As LLMs and MLLMs\nrely on vast amounts of model parameters and data to achieve emergent\ncapabilities, the importance of data is receiving increasingly widespread\nattention and recognition. Tracing and analyzing recent data-oriented works for\nMLLMs, we find that the development of models and data is not two separate\npaths but rather interconnected. On the one hand, vaster and higher-quality\ndata contribute to better performance of MLLMs; on the other hand, MLLMs can\nfacilitate the development of data. The co-development of multi-modal data and\nMLLMs requires a clear view of 1) at which development stages of MLLMs specific\ndata-centric approaches can be employed to enhance certain MLLM capabilities,\nand 2) how MLLMs, utilizing those capabilities, can contribute to multi-modal\ndata in specific roles. To promote the data-model co-development for MLLM\ncommunity, we systematically review existing works related to MLLMs from the\ndata-model co-development perspective. A regularly maintained project\nassociated with this survey is accessible at\nhttps://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.\n","authors":["Zhen Qin","Daoyuan Chen","Wenhao Zhang","Liuyi Yao","Yilun Huang","Bolin Ding","Yaliang Li","Shuiguang Deng"],"pdf_url":"https://arxiv.org/pdf/2407.08583v2.pdf","comment":"Ongoing work. 21 pages. Related materials are continually maintained\n  and available at\n  https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md"},{"id":"http://arxiv.org/abs/2305.09958v2","updated":"2024-08-05T10:24:09Z","published":"2023-05-17T05:35:49Z","title":"SIGMA: Similarity-based Efficient Global Aggregation for Heterophilous\n  Graph Neural Networks","summary":"  Graph neural networks (GNNs) realize great success in graph learning but\nsuffer from performance loss when meeting heterophily, i.e. neighboring nodes\nare dissimilar, due to their local and uniform aggregation. Existing attempts\nof heterophilous GNNs incorporate long-range or global aggregations to\ndistinguish nodes in the graph. However, these aggregations usually require\niteratively maintaining and updating full-graph information, which limits their\nefficiency when applying to large-scale graphs. In this paper, we propose\n\\aggname{}, an efficient global heterophilous GNN aggregation integrating the\nstructural similarity measurement SimRank. Our theoretical analysis illustrates\nthat \\aggname{} inherently captures distant global similarity even under\nheterophily, that conventional approaches can only achieve after iterative\naggregations. Furthermore, it enjoys efficient one-time computation with a\ncomplexity only linear to the node set size $\\mathcal{O}(n)$. Comprehensive\nevaluation demonstrates that \\aggname{} achieves state-of-the-art performance\nwith superior aggregation and overall efficiency. Notably, it obtains 5$\\times$\nacceleration on the large-scale heterophily dataset \\emph{pokec} with over 30\nmillion edges compared to the best baseline aggregation.\n","authors":["Haoyu Liu","Ningyi Liao","Siqiang Luo"],"pdf_url":"https://arxiv.org/pdf/2305.09958v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2405.10802v2","updated":"2024-08-05T10:20:11Z","published":"2024-05-17T14:16:40Z","title":"Reduced storage direct tensor ring decomposition for convolutional\n  neural networks compression","summary":"  Convolutional neural networks (CNNs) are among the most widely used machine\nlearning models for computer vision tasks, such as image classification. To\nimprove the efficiency of CNNs, many CNNs compressing approaches have been\ndeveloped. Low-rank methods approximate the original convolutional kernel with\na sequence of smaller convolutional kernels, which leads to reduced storage and\ntime complexities. In this study, we propose a novel low-rank CNNs compression\nmethod that is based on reduced storage direct tensor ring decomposition\n(RSDTR). The proposed method offers a higher circular mode permutation\nflexibility, and it is characterized by large parameter and FLOPS compression\nrates, while preserving a good classification accuracy of the compressed\nnetwork. The experiments, performed on the CIFAR-10 and ImageNet datasets,\nclearly demonstrate the efficiency of RSDTR in comparison to other\nstate-of-the-art CNNs compression approaches.\n","authors":["Mateusz Gabor","Rafał Zdunek"],"pdf_url":"https://arxiv.org/pdf/2405.10802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v1","updated":"2024-08-05T10:10:01Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2408.02361v1.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.02357v1","updated":"2024-08-05T10:06:53Z","published":"2024-08-05T10:06:53Z","title":"On the consistent reasoning paradox of intelligence and optimal trust in\n  AI: The power of 'I don't know'","summary":"  We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.\n","authors":["Alexander Bastounis","Paolo Campodonico","Mihaela van der Schaar","Ben Adcock","Anders C. Hansen"],"pdf_url":"https://arxiv.org/pdf/2408.02357v1.pdf","comment":"12 pages and 50 pages of supplementary material, 7 figures"},{"id":"http://arxiv.org/abs/2408.02355v1","updated":"2024-08-05T10:02:33Z","published":"2024-08-05T10:02:33Z","title":"Quantile Regression using Random Forest Proximities","summary":"  Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.\n","authors":["Mingshu Li","Bhaskarjit Sarmah","Dhruv Desai","Joshua Rosaler","Snigdha Bhagat","Philip Sommer","Dhagash Mehta"],"pdf_url":"https://arxiv.org/pdf/2408.02355v1.pdf","comment":"9 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2408.02354v1","updated":"2024-08-05T10:02:29Z","published":"2024-08-05T10:02:29Z","title":"RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential\n  Recommenders","summary":"  Scalability is a major challenge in modern recommender systems. In sequential\nrecommendations, full Cross-Entropy (CE) loss achieves state-of-the-art\nrecommendation quality but consumes excessive GPU memory with large item\ncatalogs, limiting its practicality. Using a GPU-efficient locality-sensitive\nhashing-like algorithm for approximating large tensor of logits, this paper\nintroduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly\nreduces memory consumption while allowing one to enjoy the state-of-the-art\nperformance of full CE loss. Experimental results on various datasets show that\nRECE cuts training peak memory usage by up to 12 times compared to existing\nmethods while retaining or exceeding performance metrics of CE loss. The\napproach also opens up new possibilities for large-scale applications in other\ndomains.\n","authors":["Danil Gusak","Gleb Mezentsev","Ivan Oseledets","Evgeny Frolov"],"pdf_url":"https://arxiv.org/pdf/2408.02354v1.pdf","comment":"5 pages, 4 figures, submitted to CIKM'24"},{"id":"http://arxiv.org/abs/2401.13185v2","updated":"2024-08-05T10:01:48Z","published":"2024-01-24T02:16:03Z","title":"Fast Partition-Based Cross-Validation With Centering and Scaling for\n  $\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$","summary":"  We present algorithms that substantially accelerate partition-based\ncross-validation for machine learning models that require matrix products\n$\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$. Our\nalgorithms have applications in model selection for, e.g., principal component\nanalysis (PCA), principal component regression (PCR), ridge regression (RR),\nordinary least squares (OLS), and partial least squares (PLS). Our algorithms\nsupport all combinations of column-wise centering and scaling of $\\mathbf{X}$\nand $\\mathbf{Y}$, and we demonstrate in our accompanying implementation that\nthis adds only a manageable, practical constant over efficient variants without\npreprocessing. We prove the correctness of our algorithms under a fold-based\npartitioning scheme and show that the running time is independent of the number\nof folds; that is, they have the same time complexity as that of computing\n$\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$ and\nspace complexity equivalent to storing $\\mathbf{X}$, $\\mathbf{Y}$,\n$\\mathbf{X}^\\mathbf{T}\\mathbf{X}$, and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$.\nImportantly, unlike alternatives found in the literature, we avoid data leakage\ndue to preprocessing. We achieve these results by eliminating redundant\ncomputations in the overlap between training partitions. Concretely, we show\nhow to manipulate $\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and\n$\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$ using only samples from the validation\npartition to obtain the preprocessed training partition-wise\n$\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$. To our\nknowledge, we are the first to derive correct and efficient cross-validation\nalgorithms for any of the $16$ combinations of column-wise centering and\nscaling, for which we also prove only $12$ give distinct matrix products.\n","authors":["Ole-Christian Galbo Engstrøm","Martin Holm Jensen"],"pdf_url":"https://arxiv.org/pdf/2401.13185v2.pdf","comment":"31 pages, 2 tables, 1 figure, 7 algorithms"},{"id":"http://arxiv.org/abs/2408.02349v1","updated":"2024-08-05T09:54:08Z","published":"2024-08-05T09:54:08Z","title":"Active Sensing of Knee Osteoarthritis Progression with Reinforcement\n  Learning","summary":"  Osteoarthritis (OA) is the most common musculoskeletal disease, which has no\ncure. Knee OA (KOA) is one of the highest causes of disability worldwide, and\nit costs billions of United States dollars to the global community. Prediction\nof KOA progression has been of high interest to the community for years, as it\ncan advance treatment development through more efficient clinical trials and\nimprove patient outcomes through more efficient healthcare utilization.\nExisting approaches for predicting KOA, however, are predominantly static, i.e.\nconsider data from a single time point to predict progression many years into\nthe future, and knee level, i.e. consider progression in a single joint only.\nDue to these and related reasons, these methods fail to deliver the level of\npredictive performance, which is sufficient to result in cost savings and\nbetter patient outcomes. Collecting extensive data from all patients on a\nregular basis could address the issue, but it is limited by the high cost at a\npopulation level. In this work, we propose to go beyond static prediction\nmodels in OA, and bring a novel Active Sensing (AS) approach, designed to\ndynamically follow up patients with the objective of maximizing the number of\ninformative data acquisitions, while minimizing their total cost over a period\nof time. Our approach is based on Reinforcement Learning (RL), and it leverages\na novel reward function designed specifically for AS of disease progression in\nmore than one part of a human body. Our method is end-to-end, relies on\nmulti-modal Deep Learning, and requires no human input at inference time.\nThroughout an exhaustive experimental evaluation, we show that using RL can\nprovide a higher monetary benefit when compared to state-of-the-art baselines.\n","authors":["Khanh Nguyen","Huy Hoang Nguyen","Egor Panfilov","Aleksei Tiulpin"],"pdf_url":"https://arxiv.org/pdf/2408.02349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02346v1","updated":"2024-08-05T09:45:31Z","published":"2024-08-05T09:45:31Z","title":"Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel\n  Precision Matrices","summary":"  The Hilbert-space Gaussian Process (HGP) approach offers a\nhyperparameter-independent basis function approximation for speeding up\nGaussian Process (GP) inference by projecting the GP onto M basis functions.\nThese properties result in a favorable data-independent $\\mathcal{O}(M^3)$\ncomputational complexity during hyperparameter optimization but require a\ndominating one-time precomputation of the precision matrix costing\n$\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating\ncomputational complexity to $\\mathcal{O}(NM)$ with no additional\napproximations. We can do this because we realize that the precision matrix can\nbe split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$\nunique entries. Based on this realization we propose computing only these\nunique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems\nthat prescribe sufficient conditions for the complexity reduction to hold\ngenerally for a wide range of other approximate GP models, such as the\nVariational Fourier Feature (VFF) approach. The two theorems do this with no\nassumptions on the data and no additional approximations of the GP models\nthemselves. Thus, our contribution provides a pure speed-up of several\nexisting, widely used, GP approximations, without further approximations.\n","authors":["Frida Viset","Anton Kullberg","Frederiek Wesel","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2408.02346v1.pdf","comment":"Published in Transactions on Machine Learning (TMLR) July 2024"},{"id":"http://arxiv.org/abs/2408.02344v1","updated":"2024-08-05T09:41:34Z","published":"2024-08-05T09:41:34Z","title":"Machine Learning Applications in Medical Prognostics: A Comprehensive\n  Review","summary":"  Machine learning (ML) has revolutionized medical prognostics by integrating\nadvanced algorithms with clinical data to enhance disease prediction, risk\nassessment, and patient outcome forecasting. This comprehensive review\ncritically examines the application of various ML techniques in medical\nprognostics, focusing on their efficacy, challenges, and future directions. The\nmethodologies discussed include Random Forest (RF) for sepsis prediction,\nlogistic regression for cardiovascular risk assessment, Convolutional Neural\nNetworks (CNNs) for cancer detection, and Long Short-Term Memory (LSTM)\nnetworks for predicting clinical deterioration. RF models demonstrate robust\nperformance in handling high-dimensional data and capturing non-linear\nrelationships, making them particularly effective for sepsis prediction.\nLogistic regression remains valuable for its interpretability and ease of use\nin cardiovascular risk assessment. CNNs have shown exceptional accuracy in\ncancer detection, leveraging their ability to learn complex visual patterns\nfrom medical imaging. LSTM networks excel in analyzing temporal data, providing\naccurate predictions of clinical deterioration. The review highlights the\nstrengths and limitations of each technique, the importance of model\ninterpretability, and the challenges of data quality and privacy. Future\nresearch directions include the integration of multi-modal data sources, the\napplication of transfer learning, and the development of continuous learning\nsystems. These advancements aim to enhance the predictive power and clinical\napplicability of ML models, ultimately improving patient outcomes in healthcare\nsettings.\n","authors":["Michael Fascia"],"pdf_url":"https://arxiv.org/pdf/2408.02344v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2408.02337v1","updated":"2024-08-05T09:23:49Z","published":"2024-08-05T09:23:49Z","title":"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR\n  Dataset Construction","summary":"  Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.\n","authors":["Albert Sawczyn","Katsiaryna Viarenich","Konrad Wojtasik","Aleksandra Domogała","Marcin Oleksy","Maciej Piasecki","Tomasz Kajdanowicz"],"pdf_url":"https://arxiv.org/pdf/2408.02337v1.pdf","comment":"Accepted for ACL 2024 (findings)"},{"id":"http://arxiv.org/abs/2408.02336v1","updated":"2024-08-05T09:19:52Z","published":"2024-08-05T09:19:52Z","title":"Infusing Environmental Captions for Long-Form Video Language Grounding","summary":"  In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.\n","authors":["Hyogun Lee","Soyeon Hong","Mujeen Sung","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2408.02336v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.02320v1","updated":"2024-08-05T09:02:24Z","published":"2024-08-05T09:02:24Z","title":"A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion\n  Models","summary":"  Diffusion models, which convert noise into new data instances by learning to\nreverse a diffusion process, have become a cornerstone in contemporary\ngenerative modeling. In this work, we develop non-asymptotic convergence theory\nfor a popular diffusion-based sampler (i.e., the probability flow ODE sampler)\nin discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein)\nscore functions. For distributions in $\\mathbb{R}^d$, we prove that\n$d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms --\nare sufficient to approximate the target distribution to within $\\varepsilon$\ntotal-variation distance. This is the first result establishing nearly linear\ndimension-dependency (in $d$) for the probability flow ODE sampler. Imposing\nonly minimal assumptions on the target data distribution (e.g., no smoothness\nassumption is imposed), our results also characterize how $\\ell_2$ score\nestimation errors affect the quality of the data generation processes. In\ncontrast to prior works, our theory is developed based on an elementary yet\nversatile non-asymptotic approach without the need of resorting to SDE and ODE\ntoolboxes.\n","authors":["Gen Li","Yuting Wei","Yuejie Chi","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2408.02320v1.pdf","comment":"This manuscript presents improved theory for probability flow ODEs\n  compared to its earlier version arXiv:2306.09251"},{"id":"http://arxiv.org/abs/2308.09605v2","updated":"2024-08-05T08:53:12Z","published":"2023-08-18T14:58:23Z","title":"Solving PDEs on Spheres with Physics-Informed Convolutional Neural\n  Networks","summary":"  Physics-informed neural networks (PINNs) have been demonstrated to be\nefficient in solving partial differential equations (PDEs) from a variety of\nexperimental perspectives. Some recent studies have also proposed PINN\nalgorithms for PDEs on surfaces, including spheres. However, theoretical\nunderstanding of the numerical performance of PINNs, especially PINNs on\nsurfaces or manifolds, is still lacking. In this paper, we establish rigorous\nanalysis of the physics-informed convolutional neural network (PICNN) for\nsolving PDEs on the sphere. By using and improving the latest approximation\nresults of deep convolutional neural networks and spherical harmonic analysis,\nwe prove an upper bound for the approximation error with respect to the Sobolev\nnorm. Subsequently, we integrate this with innovative localization complexity\nanalysis to establish fast convergence rates for PICNN. Our theoretical results\nare also confirmed and supplemented by our experiments. In light of these\nfindings, we explore potential strategies for circumventing the curse of\ndimensionality that arises when solving high-dimensional PDEs.\n","authors":["Guanhang Lei","Zhen Lei","Lei Shi","Chenyu Zeng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2308.09605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02313v1","updated":"2024-08-05T08:46:46Z","published":"2024-08-05T08:46:46Z","title":"A Lean Transformer Model for Dynamic Malware Analysis and Detection","summary":"  Malware is a fast-growing threat to the modern computing world and existing\nlines of defense are not efficient enough to address this issue. This is mainly\ndue to the fact that many prevention solutions rely on signature-based\ndetection methods that can easily be circumvented by hackers. Therefore, there\nis a recurrent need for behavior-based analysis where a suspicious file is ran\nin a secured environment and its traces are collected to reports for analysis.\nPrevious works have shown some success leveraging Neural Networks and API calls\nsequences extracted from these execution reports.\n  Recently, Large Language Models and Generative AI have demonstrated\nimpressive capabilities mainly in Natural Language Processing tasks and\npromising applications in the cybersecurity field for both attackers and\ndefenders.\n  In this paper, we design an Encoder-Only model, based on the Transformers\narchitecture, to detect malicious files, digesting their API call sequences\ncollected by an execution emulation solution. We are also limiting the size of\nthe model architecture and the number of its parameters since it is often\nconsidered that Large Language Models may be overkill for specific tasks such\nas the one we are dealing with hereafter. In addition to achieving decent\ndetection results, this approach has the advantage of reducing our carbon\nfootprint by limiting training and inference times and facilitating technical\noperations with less hardware requirements.\n  We also carry out some analysis of our results and highlight the limits and\npossible improvements when using Transformers to analyze malicious files.\n","authors":["Tony Quertier","Benjamin Marais","Grégoire Barrué","Stéphane Morucci","Sévan Azé","Sébastien Salladin"],"pdf_url":"https://arxiv.org/pdf/2408.02313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02312v1","updated":"2024-08-05T08:45:50Z","published":"2024-08-05T08:45:50Z","title":"Optimization of Iterative Blind Detection based on Expectation\n  Maximization and Belief Propagation","summary":"  We study iterative blind symbol detection for block-fading linear\ninter-symbol interference channels. Based on the factor graph framework, we\ndesign a joint channel estimation and detection scheme that combines the\nexpectation maximization (EM) algorithm and the ubiquitous belief propagation\n(BP) algorithm. Interweaving the iterations of both schemes significantly\nreduces the EM algorithm's computational burden while retaining its excellent\nperformance. To this end, we apply simple yet effective model-based learning\nmethods to find a suitable parameter update schedule by introducing momentum in\nboth the EM parameter updates as well as in the BP message passing. Numerical\nsimulations verify that the proposed method can learn efficient schedules that\ngeneralize well and even outperform coherent BP detection in high\nsignal-to-noise scenarios.\n","authors":["Luca Schmid","Tomer Raviv","Nir Shlezinger","Laurent Schmalen"],"pdf_url":"https://arxiv.org/pdf/2408.02312v1.pdf","comment":"Accepted for presentation at Asilomar Conference on Signals, Systems,\n  and Computers 2024"},{"id":"http://arxiv.org/abs/2408.02310v1","updated":"2024-08-05T08:41:07Z","published":"2024-08-05T08:41:07Z","title":"On the Robustness of Malware Detectors to Adversarial Samples","summary":"  Adversarial examples add imperceptible alterations to inputs with the\nobjective to induce misclassification in machine learning models. They have\nbeen demonstrated to pose significant challenges in domains like image\nclassification, with results showing that an adversarially perturbed image to\nevade detection against one classifier is most likely transferable to other\nclassifiers. Adversarial examples have also been studied in malware analysis.\nUnlike images, program binaries cannot be arbitrarily perturbed without\nrendering them non-functional. Due to the difficulty of crafting adversarial\nprogram binaries, there is no consensus on the transferability of adversarially\nperturbed programs to different detectors. In this work, we explore the\nrobustness of malware detectors against adversarially perturbed malware. We\ninvestigate the transferability of adversarial attacks developed against one\ndetector, against other machine learning-based malware detectors, and code\nsimilarity techniques, specifically, locality sensitive hashing-based\ndetectors. Our analysis reveals that adversarial program binaries crafted for\none detector are generally less effective against others. We also evaluate an\nensemble of detectors and show that they can potentially mitigate the impact of\nadversarial program binaries. Finally, we demonstrate that substantial program\nchanges made to evade detection may result in the transformation technique\nbeing identified, implying that the adversary must make minimal changes to the\nprogram binary.\n","authors":["Muhammad Salman","Benjamin Zi Hao Zhao","Hassan Jameel Asghar","Muhammad Ikram","Sidharth Kaushik","Mohamed Ali Kaafar"],"pdf_url":"https://arxiv.org/pdf/2408.02310v1.pdf","comment":"This is the full version of the paper with the same title to appear\n  in the proceedings of the 2024 Workshop on Security and Artificial\n  Intelligence (SECAI 2024)"},{"id":"http://arxiv.org/abs/2408.02301v1","updated":"2024-08-05T08:23:59Z","published":"2024-08-05T08:23:59Z","title":"Network Fission Ensembles for Low-Cost Self-Ensembles","summary":"  Recent ensemble learning methods for image classification have been shown to\nimprove classification accuracy with low extra cost. However, they still\nrequire multiple trained models for ensemble inference, which eventually\nbecomes a significant burden when the model size increases. In this paper, we\npropose a low-cost ensemble learning and inference, called Network Fission\nEnsembles (NFE), by converting a conventional network itself into a multi-exit\nstructure. Starting from a given initial network, we first prune some of the\nweights to reduce the training burden. We then group the remaining weights into\nseveral sets and create multiple auxiliary paths using each set to construct\nmulti-exits. We call this process Network Fission. Through this, multiple\noutputs can be obtained from a single network, which enables ensemble learning.\nSince this process simply changes the existing network structure to multi-exits\nwithout using additional networks, there is no extra computational burden for\nensemble learning and inference. Moreover, by learning from multiple losses of\nall exits, the multi-exits improve performance via regularization, and high\nperformance can be achieved even with increased network sparsity. With our\nsimple yet effective method, we achieve significant improvement compared to\nexisting ensemble methods. The code is available at\nhttps://github.com/hjdw2/NFE.\n","authors":["Hojung Lee","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2408.02301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10504v2","updated":"2024-08-05T08:22:56Z","published":"2024-02-16T08:27:55Z","title":"On the resilience of the quadratic Littlewood-Offord problem","summary":"  We study the statistical resilience of the anti-concentration properties of\nRademacher polynomials in face of adversarial deterministic noise taking the\nform of sign-flips. Given a multilinear polynomial $f:\\mathbb{R}^n \\to\n\\mathbb{R}$ and a Rademacher vector $\\boldsymbol{\\xi} \\in \\{\\pm 1\\}^n$ (with\nindependent entries), our results provide probabilistic lower bound estimations\non the number of sign-flips that $\\boldsymbol{\\xi}$ can sustain without\n``inflating\" the atom probability $\\sup_{x \\in \\mathbb{R} }\n\\mathbb{P}\\{f(\\boldsymbol{\\xi}) = x\\}$ otherwise resulting in an adversarially\nbiased distribution. Special emphasis is put on bilinear and quadratic forms,\nfor which strengthened estimates are attained. From a computational\nperspective, our results in this venue are instance-bound in such a way that\nallows for an efficient computation of the statistical resilience guarantees\nfrom the quadratic polynomial itself directly. All of our probabilistic lower\nbound resilience guarantees are asymptotically tight.\n  On route, we provide a short proof for a new small-ball probability estimate\nfitting Rademacher multilinear polynomials $f: \\mathbb{R}^n \\to \\mathbb{R}$\nremoveing a polylog-factor from the classical Meka-Nguyen-Vu bound provided the\ncoefficients are independent of $n$ (dimension-free, hereafter). This removal\nwas conjectured to be possible by Meka-Nguyen-Vu regardless of our assumption.\nBilinear Rademacher forms with dimension-free coefficients arise naturally in\nCombinatorics and specifically in the dense case of the edge-statistics\nconjecture posed by Alon, Hefetz, Krivelevich, and Tyomkyn. This case of the\nconjecture was resolved by Kwan and Sauermann. Replacing the appeal to the\nMeka-Nguyen-Vu classical bound in the work of Kwan, Sudakov, and Tran with our\nshortly proved result attains an additional proof of the dense case of the\nedge-statistics conjecture.\n","authors":["Elad Aigner-Horev","Daniel Rosenberg","Roi Weiss"],"pdf_url":"https://arxiv.org/pdf/2402.10504v2.pdf","comment":"Numerous changes from the last version: 1. An oversight in the proof\n  fixed. 2. Added treatment of high degree polynomials 3. New results added"},{"id":"http://arxiv.org/abs/2408.02298v1","updated":"2024-08-05T08:14:32Z","published":"2024-08-05T08:14:32Z","title":"Backward Compatibility in Attributive Explanation and Enhanced Model\n  Training Method","summary":"  Model update is a crucial process in the operation of ML/AI systems. While\nupdating a model generally enhances the average prediction performance, it also\nsignificantly impacts the explanations of predictions. In real-world\napplications, even minor changes in explanations can have detrimental\nconsequences. To tackle this issue, this paper introduces BCX, a quantitative\nmetric that evaluates the backward compatibility of feature attribution\nexplanations between pre- and post-update models. BCX utilizes practical\nagreement metrics to calculate the average agreement between the explanations\nof pre- and post-update models, specifically among samples on which both models\naccurately predict. In addition, we propose BCXR, a BCX-aware model training\nmethod by designing surrogate losses which theoretically lower bounds agreement\nscores. Furthermore, we present a universal variant of BCXR that improves all\nagreement metrics, utilizing L2 distance among the explanations of the models.\nTo validate our approach, we conducted experiments on eight real-world\ndatasets, demonstrating that BCXR achieves superior trade-offs between\npredictive performances and BCX scores, showcasing the effectiveness of our\nBCXR methods.\n","authors":["Ryuta Matsuno"],"pdf_url":"https://arxiv.org/pdf/2408.02298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02296v1","updated":"2024-08-05T08:14:04Z","published":"2024-08-05T08:14:04Z","title":"Heart Rate and its Variability from Short-term ECG Recordings as\n  Biomarkers for Detecting Mild Cognitive Impairment in Indian Population","summary":"  Alterations in Heart Rate (HR) and Heart Rate Variability (HRV) can reflect\nautonomic dysfunction associated with neurodegeneration. We investigate the\ninfluence of Mild Cognitive Impairment (MCI) on HR and its variability measures\nin the Indian population by designing a complete signal processing pipeline to\ndetect the R-wave peaks and compute HR and HRV features from ECG recordings of\n10 seconds, for point-of-care applications. The study cohort involves 297 urban\nparticipants, among which 48.48% are male and 51.51% are female. From the\nAddenbrooke's Cognitive Examination-III (ACE-III), MCI is detected in 19.19% of\nparticipants and the rest, 80.8% of them are cognitively healthy. Statistical\nfeatures like central tendency (mean and root mean square (RMS) of the\nNormal-to-Normal (NN) intervals) and dispersion (standard deviation (SD) of all\nNN intervals (SDNN) and root mean square of successive differences of NN\nintervals (RMSSD)) of beat-to-beat intervals are computed. The Wilcoxon rank\nsum test reveals that mean of NN intervals (p = 0.0021), the RMS of NN\nintervals (p = 0.0014), the SDNN (p = 0.0192) and the RMSSD (p = 0.0206) values\ndiffer significantly between MCI and non-MCI classes, for a level of\nsignificance, 0.05. Machine learning classifiers like, Support Vector Machine\n(SVM), Discriminant Analysis (DA) and Naive Bayes (NB) driven by mean NN\nintervals, RMS, SDNN and RMSSD, show a high accuracy of 80.80% on each\nindividual feature input. Individuals with MCI are observed to have\ncomparatively higher HR than healthy subjects. HR and its variability can be\nconsidered as potential biomarkers for detecting MCI.\n","authors":["Anjo Xavier","Sneha Noble","Justin Joseph","Thomas Gregor Issac"],"pdf_url":"https://arxiv.org/pdf/2408.02296v1.pdf","comment":"Nil"},{"id":"http://arxiv.org/abs/2408.02295v1","updated":"2024-08-05T08:12:25Z","published":"2024-08-05T08:12:25Z","title":"Generalized Gaussian Temporal Difference Error For Uncertainty-aware\n  Reinforcement Learning","summary":"  Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.\n","authors":["Seyeon Kim","Joonhun Lee","Namhoon Cho","Sungjun Han","Seungeon Baek"],"pdf_url":"https://arxiv.org/pdf/2408.02295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16458v2","updated":"2024-08-05T07:59:19Z","published":"2024-01-29T10:11:05Z","title":"Credit Risk Meets Large Language Models: Building a Risk Indicator from\n  Loan Descriptions in P2P Lending","summary":"  Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism,\nlinking borrowers with lenders through online platforms. However, P2P lending\nfaces the challenge of information asymmetry, as lenders often lack sufficient\ndata to assess the creditworthiness of borrowers. This paper proposes a novel\napproach to address this issue by leveraging the textual descriptions provided\nby borrowers during the loan application process. Our methodology involves\nprocessing these textual descriptions using a Large Language Model (LLM), a\npowerful tool capable of discerning patterns and semantics within the text.\nTransfer learning is applied to adapt the LLM to the specific task at hand.\n  Our results derived from the analysis of the Lending Club dataset show that\nthe risk score generated by BERT, a widely used LLM, significantly improves the\nperformance of credit risk classifiers. However, the inherent opacity of\nLLM-based systems, coupled with uncertainties about potential biases,\nunderscores critical considerations for regulatory frameworks and engenders\ntrust-related concerns among end-users, opening new avenues for future research\nin the dynamic landscape of P2P lending and artificial intelligence.\n","authors":["Mario Sanz-Guerrero","Javier Arroyo"],"pdf_url":"https://arxiv.org/pdf/2401.16458v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09780v2","updated":"2024-08-05T07:56:33Z","published":"2024-02-15T08:09:17Z","title":"TinyCL: An Efficient Hardware Architecture for Continual Learning on\n  Autonomous Systems","summary":"  The Continuous Learning (CL) paradigm consists of continuously evolving the\nparameters of the Deep Neural Network (DNN) model to progressively learn to\nperform new tasks without reducing the performance on previous tasks, i.e.,\navoiding the so-called catastrophic forgetting. However, the DNN parameter\nupdate in CL-based autonomous systems is extremely resource-hungry. The\nexisting DNN accelerators cannot be directly employed in CL because they only\nsupport the execution of the forward propagation. Only a few prior\narchitectures execute the backpropagation and weight update, but they lack the\ncontrol and management for CL. Towards this, we design a hardware architecture,\nTinyCL, to perform CL on resource-constrained autonomous systems. It consists\nof a processing unit that executes both forward and backward propagation, and a\ncontrol unit that manages memory-based CL workload. To minimize the memory\naccesses, the sliding window of the convolutional layer moves in a snake-like\nfashion. Moreover, the Multiply-and-Accumulate units can be reconfigured at\nruntime to execute different operations. As per our knowledge, our proposed\nTinyCL represents the first hardware accelerator that executes CL on autonomous\nsystems. We synthesize the complete TinyCL architecture in a 65 nm CMOS\ntechnology node with the conventional ASIC design flow. It executes 1 epoch of\ntraining on a Conv + ReLU + Dense model on the CIFAR10 dataset in 1.76 s, while\n1 training epoch of the same model using an Nvidia Tesla P100 GPU takes 103 s,\nthus achieving a 58x speedup, consuming 86 mW in a 4.74 mm2 die.\n","authors":["Eugenio Ressa","Alberto Marchisio","Maurizio Martina","Guido Masera","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2402.09780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02963v3","updated":"2024-08-05T07:55:34Z","published":"2022-06-07T01:49:22Z","title":"Confidence-aware Self-Semantic Distillation on Knowledge Graph Embedding","summary":"  Knowledge Graph Embedding (KGE), which projects entities and relations into\ncontinuous vector spaces, has garnered significant attention. Although\nhigh-dimensional KGE methods offer better performance, they come at the expense\nof significant computation and memory overheads. Decreasing embedding\ndimensions significantly deteriorates model performance. While several recent\nefforts utilize knowledge distillation or non-Euclidean representation learning\nto augment the effectiveness of low-dimensional KGE, they either necessitate a\npre-trained high-dimensional teacher model or involve complex non-Euclidean\noperations, thereby incurring considerable additional computational costs. To\naddress this, this work proposes Confidence-aware Self-Knowledge Distillation\n(CSD) that learns from the model itself to enhance KGE in a low-dimensional\nspace. Specifically, CSD extracts knowledge from embeddings in previous\niterations, which would be utilized to supervise the learning of the model in\nthe next iterations. Moreover, a specific semantic module is developed to\nfilter reliable knowledge by estimating the confidence of previously learned\nembeddings. This straightforward strategy bypasses the need for time-consuming\npre-training of teacher models and can be integrated into various KGE methods\nto improve their performance. Our comprehensive experiments on six KGE\nbackbones and four datasets underscore the effectiveness of the proposed CSD.\n","authors":["Yichen Liu","Jiawei Chen","Defang Chen","Zhehui Zhou","Yan Feng","Can Wang"],"pdf_url":"https://arxiv.org/pdf/2206.02963v3.pdf","comment":"CIKM 2024"},{"id":"http://arxiv.org/abs/2408.02280v1","updated":"2024-08-05T07:30:18Z","published":"2024-08-05T07:30:18Z","title":"Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and\n  Cost","summary":"  Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.\n","authors":["Jannis Maier","Felix Möller","Lennart Purucker"],"pdf_url":"https://arxiv.org/pdf/2408.02280v1.pdf","comment":"Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024), Workshop Track; for code, see\n  https://github.com/Atraxus/HA-ES"},{"id":"http://arxiv.org/abs/2408.02279v1","updated":"2024-08-05T07:26:47Z","published":"2024-08-05T07:26:47Z","title":"DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for\n  Long Time-Series Forecasting","summary":"  Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.\n","authors":["Ruixin Ding","Yuqi Chen","Yu-Ting Lan","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17900v4","updated":"2024-08-05T07:06:14Z","published":"2024-07-25T09:42:24Z","title":"The Power of Combining Data and Knowledge: GPT-4o is an Effective\n  Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of\n  Lung Cancer","summary":"  Lymph node metastasis (LNM) is a crucial factor in determining the initial\ntreatment for patients with lung cancer, yet accurate preoperative diagnosis of\nLNM remains challenging. Recently, large language models (LLMs) have garnered\nsignificant attention due to their remarkable text generation capabilities.\nLeveraging the extensive medical knowledge learned from vast corpora, LLMs can\nestimate probabilities for clinical problems, though their performance has\nhistorically been inferior to data-driven machine learning models. In this\npaper, we propose a novel ensemble method that combines the medical knowledge\nacquired by LLMs with the latent patterns identified by machine learning models\nto enhance LNM prediction performance. Initially, we developed machine learning\nmodels using patient data. We then designed a prompt template to integrate the\npatient data with the predicted probability from the machine learning model.\nSubsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,\nto estimate the likelihood of LNM based on patient data and then adjust the\nestimate using the machine learning output. Finally, we collected three outputs\nfrom the GPT-4o using the same prompt and ensembled these results as the final\nprediction. Using the proposed method, our models achieved an AUC value of\n0.778 and an AP value of 0.426 for LNM prediction, significantly improving\npredictive performance compared to baseline machine learning models. The\nexperimental results indicate that GPT-4o can effectively leverage its medical\nknowledge and the probabilities predicted by machine learning models to achieve\nmore accurate LNM predictions. These findings demonstrate that LLMs can perform\nwell in clinical risk prediction tasks, offering a new paradigm for integrating\nmedical knowledge and patient data in clinical predictions.\n","authors":["Danqing Hu","Bing Liu","Xiaofeng Zhu","Nan Wu"],"pdf_url":"https://arxiv.org/pdf/2407.17900v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02266v1","updated":"2024-08-05T06:47:32Z","published":"2024-08-05T06:47:32Z","title":"One-Shot Collaborative Data Distillation","summary":"  Large machine-learning training datasets can be distilled into small\ncollections of informative synthetic data samples. These synthetic sets support\nefficient model learning and reduce the communication cost of data sharing.\nThus, high-fidelity distilled data can support the efficient deployment of\nmachine learning applications in distributed network environments. A naive way\nto construct a synthetic set in a distributed environment is to allow each\nclient to perform local data distillation and to merge local distillations at a\ncentral server. However, the quality of the resulting set is impaired by\nheterogeneity in the distributions of the local data held by clients. To\novercome this challenge, we introduce the first collaborative data distillation\ntechnique, called CollabDM, which captures the global distribution of the data\nand requires only a single round of communication between client and server.\nOur method outperforms the state-of-the-art one-shot learning method on skewed\ndata in distributed learning environments. We also show the promising practical\nbenefits of our method when applied to attack detection in 5G networks.\n","authors":["Rayne Holland","Chandra Thapa","Sarah Ali Siddiqui","Wei Shao","Seyit Camtepe"],"pdf_url":"https://arxiv.org/pdf/2408.02266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02247v1","updated":"2024-08-05T05:41:16Z","published":"2024-08-05T05:41:16Z","title":"Contrastive Learning and Abstract Concepts: The Case of Natural Numbers","summary":"  Contrastive Learning (CL) has been successfully applied to classification and\nother downstream tasks related to concrete concepts, such as objects contained\nin the ImageNet dataset. No attempts seem to have been made so far in applying\nthis promising scheme to more abstract entities. A prominent example of these\ncould be the concept of (discrete) Quantity. CL can be frequently interpreted\nas a self-supervised scheme guided by some profound and ubiquitous conservation\nprinciple (e.g. conservation of identity in object classification tasks). In\nthis introductory work we apply a suitable conservation principle to the\nsemi-abstract concept of natural numbers by which discrete quantities can be\nestimated or predicted. We experimentally show, by means of a toy problem, that\ncontrastive learning can be trained to count at a glance with high accuracy\nboth at human as well as at super-human ranges.. We compare this with the\nresults of a trained-to-count at a glance supervised learning (SL) neural\nnetwork scheme of similar architecture. We show that both schemes exhibit\nsimilar good performance on baseline experiments, where the distributions of\nthe training and testing stages are equal. Importantly, we demonstrate that in\nsome generalization scenarios, where training and testing distributions differ,\nCL boasts more robust and much better error performance.\n","authors":["Daniel N. Nissani"],"pdf_url":"https://arxiv.org/pdf/2408.02247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02242v1","updated":"2024-08-05T05:27:19Z","published":"2024-08-05T05:27:19Z","title":"Methods to improve run time of hydrologic models: opportunities and\n  challenges in the machine learning era","summary":"  The application of Machine Learning (ML) to hydrologic modeling is fledgling.\nIts applicability to capture the dependencies on watersheds to forecast better\nwithin a short period is fascinating. One of the key reasons to adopt ML\nalgorithms over physics-based models is its computational efficiency advantage\nand flexibility to work with various data sets. The diverse applications,\nparticularly in emergency response and expanding over a large scale, demand the\nhydrological model in a short time and make researchers adopt data-driven\nmodeling approaches unhesitatingly. In this work, in the era of ML and deep\nlearning (DL), how it can help to improve the overall run time of physics-based\nmodel and potential constraints that should be addressed while modeling. This\npaper covers the opportunities and challenges of adopting ML for hydrological\nmodeling and subsequently how it can help to improve the simulation time of\nphysics-based models and future works that should be addressed.\n","authors":["Supath Dhital"],"pdf_url":"https://arxiv.org/pdf/2408.02242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03560v3","updated":"2024-08-05T04:35:48Z","published":"2022-12-07T10:25:59Z","title":"SeqLink: A Robust Neural-ODE Architecture for Modelling Partially\n  Observed Time Series","summary":"  Ordinary Differential Equations (ODE) based models have become popular as\nfoundation models for solving many time series problems. Combining neural ODEs\nwith traditional RNN models has provided the best representation for irregular\ntime series. However, ODE-based models typically require the trajectory of\nhidden states to be defined based on either the initial observed value or the\nmost recent observation, raising questions about their effectiveness when\ndealing with longer sequences and extended time intervals. In this article, we\nexplore the behaviour of the ODE models in the context of time series data with\nvarying degrees of sparsity. We introduce SeqLink, an innovative neural\narchitecture designed to enhance the robustness of sequence representation.\nUnlike traditional approaches that solely rely on the hidden state generated\nfrom the last observed value, SeqLink leverages ODE latent representations\nderived from multiple data samples, enabling it to generate robust data\nrepresentations regardless of sequence length or data sparsity level. The core\nconcept behind our model is the definition of hidden states for the unobserved\nvalues based on the relationships between samples (links between sequences).\nThrough extensive experiments on partially observed synthetic and real-world\ndatasets, we demonstrate that SeqLink improves the modelling of intermittent\ntime series, consistently outperforming state-of-the-art approaches.\n","authors":["Futoon M. Abushaqra","Hao Xue","Yongli Ren","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2212.03560v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02223v1","updated":"2024-08-05T03:54:52Z","published":"2024-08-05T03:54:52Z","title":"Large Language Model Aided QoS Prediction for Service Recommendation","summary":"  Large language models (LLMs) have seen rapid improvement in the recent years,\nand are used in a wider range of applications. After being trained on large\ntext corpus, LLMs obtain the capability of extracting rich features from\ntextual data. Such capability is potentially useful for the web service\nrecommendation task, where the web users and services have intrinsic attributes\nthat can be described using natural language sentences and are useful for\nrecommendation. In this paper, we explore the possibility and practicality of\nusing LLMs for web service recommendation. We propose the large language model\naided QoS prediction (llmQoS) model, which use LLMs to extract useful\ninformation from attributes of web users and services via descriptive\nsentences. This information is then used in combination with the QoS values of\nhistorical interactions of users and services, to predict QoS values for any\ngiven user-service pair. Our proposed model is shown to overcome the data\nsparsity issue for QoS prediction. We show that on the WSDream dataset, llmQoS\noutperforms comparable baseline models consistently.\n","authors":["Huiying Liu","Zekun Zhang","Qilin Wu","Yiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00861v2","updated":"2024-08-05T03:47:54Z","published":"2022-06-02T03:48:29Z","title":"Dynamic Structure Estimation from Bandit Feedback using Nonvanishing\n  Exponential Sums","summary":"  This work tackles the dynamic structure estimation problems for periodically\nbehaved discrete dynamical system in the Euclidean space. We assume the\nobservations become sequentially available in a form of bandit feedback\ncontaminated by a sub-Gaussian noise. Under such fairly general assumptions on\nthe noise distribution, we carefully identify a set of recoverable information\nof periodic structures. Our main results are the (computation and sample)\nefficient algorithms that exploit asymptotic behaviors of exponential sums to\neffectively average out the noise effect while preventing the information to be\nestimated from vanishing. In particular, the novel use of the Weyl sum, a\nvariant of exponential sums, allows us to extract spectrum information for\nlinear systems. We provide sample complexity bounds for our algorithms, and we\nexperimentally validate our theoretical claims on simulations of toy examples,\nincluding Cellular Automata.\n","authors":["Motoya Ohnishi","Isao Ishikawa","Yuko Kuroki","Masahiro Ikeda"],"pdf_url":"https://arxiv.org/pdf/2206.00861v2.pdf","comment":"35 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.02217v1","updated":"2024-08-05T03:38:38Z","published":"2024-08-05T03:38:38Z","title":"Climate-Driven Doubling of Maize Loss Probability in U.S. Crop\n  Insurance: Spatiotemporal Prediction and Possible Policy Responses","summary":"  Climate change not only threatens agricultural producers but also strains\nfinancial institutions. These important food system actors include government\nentities tasked with both insuring grower livelihoods and supporting response\nto continued global warming. We use an artificial neural network to predict\nfuture maize yields in the U.S. Corn Belt, finding alarming changes to\ninstitutional risk exposure within the Federal Crop Insurance Program.\nSpecifically, our machine learning method anticipates more frequent and more\nsevere yield losses that would result in the annual probability of Yield\nProtection (YP) claims to more than double at mid-century relative to\nsimulations without continued climate change. Furthermore, our dual finding of\nrelatively unchanged average yields paired with decreasing yield stability\nreveals targeted opportunities to adjust coverage formulas to include\nvariability. This important structural shift may help regulators support grower\nadaptation to continued climate change by recognizing the value of\nrisk-reducing strategies such as regenerative agriculture. Altogether, paired\nwith open source interactive tools for deeper investigation, our risk profile\nsimulations fill an actionable gap in current understanding, bridging granular\nhistoric yield estimation and climate-informed prediction of future\ninsurer-relevant loss.\n","authors":["A Samuel Pottinger","Lawson Connor","Brookie Guzder-Williams","Maya Weltman-Fahs","Timothy Bowles"],"pdf_url":"https://arxiv.org/pdf/2408.02217v1.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.00657v2","updated":"2024-08-05T03:25:01Z","published":"2024-08-01T15:46:22Z","title":"Disentangling Dense Embeddings with Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.\n","authors":["Charles O'Neill","Christine Ye","Kartheik Iyer","John F. Wu"],"pdf_url":"https://arxiv.org/pdf/2408.00657v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02903v4","updated":"2024-08-05T03:24:09Z","published":"2023-10-04T15:42:23Z","title":"FroSSL: Frobenius Norm Minimization for Efficient Multiview\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) is a popular paradigm for representation\nlearning. Recent multiview methods can be classified as sample-contrastive,\ndimension-contrastive, or asymmetric network-based, with each family having its\nown approach to avoiding informational collapse. While these families converge\nto solutions of similar quality, it can be empirically shown that some methods\nare epoch-inefficient and require longer training to reach a target\nperformance. Two main approaches to improving efficiency are covariance\neigenvalue regularization and using more views. However, these two approaches\nare difficult to combine due to the computational complexity of computing\neigenvalues. We present the objective function FroSSL which reconciles both\napproaches while avoiding eigendecomposition entirely. FroSSL works by\nminimizing covariance Frobenius norms to avoid collapse and minimizing\nmean-squared error to achieve augmentation invariance. We show that FroSSL\nreaches competitive accuracies more quickly than any other SSL method and\nprovide theoretical and empirical support that this faster convergence is due\nto how FroSSL affects the eigenvalues of the embedding covariance matrices. We\nalso show that FroSSL learns competitive representations on linear probe\nevaluation when used to train a ResNet-18 on several datasets, including\nSTL-10, Tiny ImageNet, and ImageNet-100.\n","authors":["Oscar Skean","Aayush Dhakal","Nathan Jacobs","Luis Gonzalo Sanchez Giraldo"],"pdf_url":"https://arxiv.org/pdf/2310.02903v4.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2408.02208v1","updated":"2024-08-05T03:17:44Z","published":"2024-08-05T03:17:44Z","title":"Multi-level Traffic-Responsive Tilt Camera Surveillance through\n  Predictive Correlated Online Learning","summary":"  In urban traffic management, the primary challenge of dynamically and\nefficiently monitoring traffic conditions is compounded by the insufficient\nutilization of thousands of surveillance cameras along the intelligent\ntransportation system. This paper introduces the multi-level Traffic-responsive\nTilt Camera surveillance system (TTC-X), a novel framework designed for dynamic\nand efficient monitoring and management of traffic in urban networks. By\nleveraging widely deployed pan-tilt-cameras (PTCs), TTC-X overcomes the\nlimitations of a fixed field of view in traditional surveillance systems by\nproviding mobilized and 360-degree coverage. The innovation of TTC-X lies in\nthe integration of advanced machine learning modules, including a\ndetector-predictor-controller structure, with a novel Predictive Correlated\nOnline Learning (PiCOL) methodology and the Spatial-Temporal Graph Predictor\n(STGP) for real-time traffic estimation and PTC control. The TTC-X is tested\nand evaluated under three experimental scenarios (e.g., maximum traffic flow\ncapture, dynamic route planning, traffic state estimation) based on a\nsimulation environment calibrated using real-world traffic data in Brooklyn,\nNew York. The experimental results showed that TTC-X captured over 60\\% total\nnumber of vehicles at the network level, dynamically adjusted its route\nrecommendation in reaction to unexpected full-lane closure events, and\nreconstructed link-level traffic states with best MAE less than 1.25\nvehicle/hour. Demonstrating scalability, cost-efficiency, and adaptability,\nTTC-X emerges as a powerful solution for urban traffic management in both\ncyber-physical and real-world environments.\n","authors":["Tao Li","Zilin Bian","Haozhe Lei","Fan Zuo","Ya-Ting Yang","Quanyan Zhu","Zhenning Li","Kaan Ozbay"],"pdf_url":"https://arxiv.org/pdf/2408.02208v1.pdf","comment":"Accepted to Transportation Research Part C special issue: Modelling,\n  Learning, and Control of Conventional, Cooperative and Automated Motorway and\n  Urban Traffic Systems"},{"id":"http://arxiv.org/abs/2408.02201v1","updated":"2024-08-05T03:05:02Z","published":"2024-08-05T03:05:02Z","title":"Evaluating the Performance of Large Language Models for SDG Mapping\n  (Technical Report)","summary":"  The use of large language models (LLMs) is expanding rapidly, and open-source\nversions are becoming available, offering users safer and more adaptable\noptions. These models enable users to protect data privacy by eliminating the\nneed to provide data to third parties and can be customized for specific tasks.\nIn this study, we compare the performance of various language models on the\nSustainable Development Goal (SDG) mapping task, using the output of GPT-4o as\nthe baseline. The selected open-source models for comparison include Mixtral,\nLLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more\nspecialized version of GPT-4o, was included to extend the comparison. Given the\nmulti-label nature of the SDG mapping task, we employed metrics such as F1\nscore, precision, and recall with micro-averaging to evaluate different aspects\nof the models' performance. These metrics are derived from the confusion matrix\nto ensure a comprehensive evaluation. We provide a clear observation and\nanalysis of each model's performance by plotting curves based on F1 score,\nprecision, and recall at different thresholds. According to the results of this\nexperiment, LLaMA 2 and Gemma still have significant room for improvement. The\nother four models do not exhibit particularly large differences in performance.\nThe outputs from all seven models are available on Zenodo:\nhttps://doi.org/10.5281/zenodo.12789375.\n","authors":["Hui Yin","Amir Aryani","Nakul Nambiar"],"pdf_url":"https://arxiv.org/pdf/2408.02201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02198v1","updated":"2024-08-05T02:50:58Z","published":"2024-08-05T02:50:58Z","title":"Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem\n  Solving","summary":"  Multi-task learning (MTL) is an inductive transfer mechanism designed to\nleverage useful information from multiple tasks to improve generalization\nperformance compared to single-task learning. It has been extensively explored\nin traditional machine learning to address issues such as data sparsity and\noverfitting in neural networks. In this work, we apply MTL to problems in\nscience and engineering governed by partial differential equations (PDEs).\nHowever, implementing MTL in this context is complex, as it requires\ntask-specific modifications to accommodate various scenarios representing\ndifferent physical processes. To this end, we present a multi-task deep\noperator network (MT-DeepONet) to learn solutions across various functional\nforms of source terms in a PDE and multiple geometries in a single concurrent\ntraining session. We introduce modifications in the branch network of the\nvanilla DeepONet to account for various functional forms of a parameterized\ncoefficient in a PDE. Additionally, we handle parameterized geometries by\nintroducing a binary mask in the branch network and incorporating it into the\nloss term to improve convergence and generalization to new geometry tasks. Our\napproach is demonstrated on three benchmark problems: (1) learning different\nfunctional forms of the source term in the Fisher equation; (2) learning\nmultiple geometries in a 2D Darcy Flow problem and showcasing better transfer\nlearning capabilities to new geometries; and (3) learning 3D parameterized\ngeometries for a heat transfer problem and demonstrate the ability to predict\non new but similar geometries. Our MT-DeepONet framework offers a novel\napproach to solving PDE problems in engineering and science under a unified\numbrella based on synergistic learning that reduces the overall training cost\nfor neural operators.\n","authors":["Varun Kumar","Somdatta Goswami","Katiana Kontolati","Michael D. Shields","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2408.02198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00380v2","updated":"2024-08-05T02:45:50Z","published":"2024-08-01T08:41:13Z","title":"Enhancing Whole Slide Pathology Foundation Models through Stain\n  Normalization","summary":"  Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nStain Normalized Pathology Foundational Model, a novel foundational model\ntrained on patches that have undergone stain normalization. Stain normalization\nhelps reduce color variability arising from different laboratories and\nscanners, enabling the model to learn more consistent features. Stain\nNormalized Pathology Foundational Model is trained using 285,153,903 patches\nextracted from a total of 34,795 WSIs, combining data from The Cancer Genome\nAtlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments\ndemonstrate that Stain Normalized Pathology Foundational Model significantly\nmitigates the feature collapse problem, indicating that the model has learned\nmore generalized features rather than overfitting to individual WSI\ncharacteristics. We compared Stain Normalized Pathology Foundational Model with\nstate-of-the-art models across six downstream task datasets, and our results\nshow that Stain Normalized Pathology Foundational Model achieves excellent\nperformance relative to the number of WSIs used and the model's parameter\ncount. This suggests that the application of stain normalization has\nsubstantially improved the model's efficiency and generalization capabilities.\n","authors":["Juseung Yun","Yi Hu","Jinhyung Kim","Jongseong Jang","Soonyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2408.00380v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2404.07950v2","updated":"2024-08-05T02:45:42Z","published":"2024-03-18T16:50:23Z","title":"Reinforcement Learning with Generalizable Gaussian Splatting","summary":"  An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL.\n","authors":["Jiaxu Wang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Gang Han","Wen Zhao","Weining Zhang","Yecheng Shao","Yijie Guo","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2404.07950v2.pdf","comment":"7 pages,2 figures"},{"id":"http://arxiv.org/abs/2408.02193v1","updated":"2024-08-05T02:38:48Z","published":"2024-08-05T02:38:48Z","title":"CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs","summary":"  Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.\n","authors":["Weijie Lv","Xuan Xia","Sheng-Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2408.02193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00992v2","updated":"2024-08-05T02:09:58Z","published":"2024-08-02T03:44:14Z","title":"Fairness in Large Language Models in Three Hour","summary":"  Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.\n","authors":["Thang Doan Viet","Zichong Wang","Minh Nhat Nguyen","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16020v4","updated":"2024-08-05T02:01:12Z","published":"2024-07-22T19:55:44Z","title":"Sparks of Quantum Advantage and Rapid Retraining in Machine Learning","summary":"  The advent of quantum computing holds the potential to revolutionize various\nfields by solving complex problems more efficiently than classical computers.\nDespite this promise, practical quantum advantage is hindered by current\nhardware limitations, notably the small number of qubits and high noise levels.\nIn this study, we leverage adiabatic quantum computers to optimize\nKolmogorov-Arnold Networks, a powerful neural network architecture for\nrepresenting complex functions with minimal parameters. By modifying the\nnetwork to use Bezier curves as the basis functions and formulating the\noptimization problem into a Quadratic Unconstrained Binary Optimization\nproblem, we create a fixed-sized solution space, independent of the number of\ntraining samples. This strategy allows for the optimization of an entire neural\nnetwork in a single training iteration in which, due to order of operations, a\nmajority of the processing is done using a collapsed version of the training\ndataset. This inherently creates extremely fast training speeds, which are\nvalidated experimentally, compared to classical optimizers including Adam,\nStochastic Gradient Descent, Adaptive Gradient, and simulated annealing.\nAdditionally, we introduce a novel rapid retraining capability, enabling the\nnetwork to be retrained with new data without reprocessing old samples, thus\nenhancing learning efficiency in dynamic environments. Experiments on\nretraining demonstrate a hundred times speed up using adiabatic quantum\ncomputing based optimization compared to that of the gradient descent based\noptimizers, with theoretical models allowing this speed up to be much larger!\nOur findings suggest that with further advancements in quantum hardware and\nalgorithm optimization, quantum-optimized machine learning models could have\nbroad applications across various domains, with initial focus on rapid\nretraining.\n","authors":["William Troy"],"pdf_url":"https://arxiv.org/pdf/2407.16020v4.pdf","comment":"Major updates to the paper for timings and explanations of\n  optimization strategies used. Further optimized the code and updated the\n  figures to reflect the faster timings for v3"},{"id":"http://arxiv.org/abs/2402.02977v4","updated":"2024-08-05T01:24:52Z","published":"2024-02-05T12:58:29Z","title":"Variational Flow Models: Flowing in Your Style","summary":"  We propose a systematic training-free method to transform the probability\nflow of a \"linear\" stochastic process characterized by the equation\nX_{t}=a_{t}X_{0}+\\sigma_{t}X_{1} into a straight constant-speed (SC) flow,\nreminiscent of Rectified Flow. This transformation facilitates fast sampling\nalong the original probability flow via the Euler method without training a new\nmodel of the SC flow. The flexibility of our approach allows us to extend our\ntransformation to inter-convert two posterior flows of two distinct linear\nstochastic processes. Moreover, we can easily integrate high-order numerical\nsolvers into the transformed SC flow, further enhancing the sampling accuracy\nand efficiency. Rigorous theoretical analysis and extensive experimental\nresults substantiate the advantages of our framework. Our code is available at\nthis [https://github.com/clarken92/VFM||link].\n","authors":["Kien Do","Duc Kieu","Toan Nguyen","Dang Nguyen","Hung Le","Dung Nguyen","Thin Nguyen"],"pdf_url":"https://arxiv.org/pdf/2402.02977v4.pdf","comment":"Our code is available at: https://github.com/clarken92/VFM"},{"id":"http://arxiv.org/abs/2302.00857v2","updated":"2024-08-05T01:10:35Z","published":"2023-02-02T04:02:49Z","title":"Algorithm Design for Online Meta-Learning with Task Boundary Detection","summary":"  Online meta-learning has recently emerged as a marriage between batch\nmeta-learning and online learning, for achieving the capability of quick\nadaptation on new tasks in a lifelong manner. However, most existing approaches\nfocus on the restrictive setting where the distribution of the online tasks\nremains fixed with known task boundaries. In this work, we relax these\nassumptions and propose a novel algorithm for task-agnostic online\nmeta-learning in non-stationary environments. More specifically, we first\npropose two simple but effective detection mechanisms of task switches and\ndistribution shift based on empirical observations, which serve as a key\nbuilding block for more elegant online model updates in our algorithm: the task\nswitch detection mechanism allows reusing of the best model available for the\ncurrent task at hand, and the distribution shift detection mechanism\ndifferentiates the meta model update in order to preserve the knowledge for\nin-distribution tasks and quickly learn the new knowledge for\nout-of-distribution tasks. In particular, our online meta model updates are\nbased only on the current data, which eliminates the need of storing previous\ndata as required in most existing methods. We further show that a sublinear\ntask-averaged regret can be achieved for our algorithm under mild conditions.\nEmpirical studies on three different benchmarks clearly demonstrate the\nsignificant advantage of our algorithm over related baseline approaches.\n","authors":["Daouda Sow","Sen Lin","Yingbin Liang","Junshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00857v2.pdf","comment":"CPAL 2024"},{"id":"http://arxiv.org/abs/2402.08225v3","updated":"2024-08-05T00:54:02Z","published":"2024-02-13T05:33:35Z","title":"Improving Black-box Robustness with In-Context Rewriting","summary":"  Machine learning models for text classification often excel on\nin-distribution (ID) data but struggle with unseen out-of-distribution (OOD)\ninputs. Most techniques for improving OOD robustness are not applicable to\nsettings where the model is effectively a black box, such as when the weights\nare frozen, retraining is costly, or the model is leveraged via an API.\nTest-time augmentation (TTA) is a simple post-hoc technique for improving\nrobustness that sidesteps black-box constraints by aggregating predictions\nacross multiple augmentations of the test input. TTA has seen limited use in\nNLP due to the challenge of generating effective natural language\naugmentations. In this work, we propose LLM-TTA, which uses LLM-generated\naugmentations as TTA's augmentation function. LLM-TTA outperforms conventional\naugmentation functions across sentiment, toxicity, and news classification\ntasks for BERT and T5 models, with BERT's OOD robustness improving by an\naverage of 4.48 percentage points without regressing average ID performance. We\nexplore selectively augmenting inputs based on prediction entropy to reduce the\nrate of expensive LLM augmentations, allowing us to maintain performance gains\nwhile reducing the average number of generated augmentations by 57.74\\%.\nLLM-TTA is agnostic to the task model architecture, does not require OOD\nlabels, and is effective across low and high-resource settings. We share our\ndata, models, and code for reproducibility.\n","authors":["Kyle O'Brien","Nathan Ng","Isha Puri","Jorge Mendez","Hamid Palangi","Yoon Kim","Marzyeh Ghassemi","Thomas Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2402.08225v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02866v1","updated":"2024-08-05T23:33:24Z","published":"2024-08-05T23:33:24Z","title":"Back-Projection Diffusion: Solving the Wideband Inverse Scattering\n  Problem with Diffusion Models","summary":"  We present \\textit{Wideband back-projection diffusion}, an end-to-end\nprobabilistic framework for approximating the posterior distribution induced by\nthe inverse scattering map from wideband scattering data. This framework\nleverages conditional diffusion models coupled with the underlying physics of\nwave-propagation and symmetries in the problem, to produce highly accurate\nreconstructions. The framework introduces a factorization of the score function\ninto a physics-based latent representation inspired by the filtered\nback-propagation formula and a conditional score function conditioned on this\nlatent representation. These two steps are also constrained to obey symmetries\nin the formulation while being amenable to compression by imposing the rank\nstructure found in the filtered back-projection formula. As a result,\nempirically, our framework is able to provide sharp reconstructions\neffortlessly, even recovering sub-Nyquist features in the multiple-scattering\nregime. It has low-sample and computational complexity, its number of\nparameters scales sub-linearly with the target resolution, and it has stable\ntraining dynamics.\n","authors":["Borong Zhang","Martín Guerra","Qin Li","Leonardo Zepeda-Núñez"],"pdf_url":"https://arxiv.org/pdf/2408.02866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09797v2","updated":"2024-08-05T23:23:14Z","published":"2023-07-19T07:31:37Z","title":"Probabilistic Forecasting with Coherent Aggregation","summary":"  Obtaining accurate probabilistic forecasts is an important operational\nchallenge in many applications, perhaps most obviously in energy management,\nclimate forecasting, supply chain planning, and resource allocation. In many of\nthese applications, there is a natural hierarchical structure over the\nforecasted quantities; and forecasting systems that adhere to this hierarchical\nstructure are said to be coherent. Furthermore, operational planning benefits\nfrom accuracy at all levels of the aggregation hierarchy. Building accurate and\ncoherent forecasting systems, however, is challenging: classic multivariate\ntime series tools and neural network methods are still being adapted for this\npurpose. In this paper, we augment an MQForecaster neural network architecture\nwith a novel deep Gaussian factor forecasting model that achieves coherence by\nconstruction, yielding a method we call the Deep Coherent Factor Model Neural\nNetwork (DeepCoFactor) model. DeepCoFactor generates samples that can be\ndifferentiated with respect to model parameters, allowing optimization on\nvarious sample-based learning objectives that align with the forecasting\nsystem's goals, including quantile loss and the scaled Continuous Ranked\nProbability Score (CRPS). In a comparison to state-of-the-art coherent\nforecasting methods, DeepCoFactor achieves significant improvements in scaled\nCRPS forecast accuracy, with gains between 4.16 and 54.40%, as measured on\nthree publicly available hierarchical forecasting datasets.\n","authors":["Kin G. Olivares","Geoffrey Négiar","Ruijun Ma","O. Nangba Meetei","Mengfei Cao","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2307.09797v2.pdf","comment":"10 pages of main text. Updated method and results"},{"id":"http://arxiv.org/abs/2408.02861v1","updated":"2024-08-05T23:20:32Z","published":"2024-08-05T23:20:32Z","title":"A Framework for Fine-Tuning LLMs using Heterogeneous Feedback","summary":"  Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.\n","authors":["Ryan Aponte","Ryan A. Rossi","Shunan Guo","Franck Dernoncourt","Tong Yu","Xiang Chen","Subrata Mitra","Nedim Lipka"],"pdf_url":"https://arxiv.org/pdf/2408.02861v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2405.18373v2","updated":"2024-08-05T22:25:10Z","published":"2024-05-28T17:11:34Z","title":"A Hessian-Aware Stochastic Differential Equation for Modelling SGD","summary":"  Continuous-time approximation of Stochastic Gradient Descent (SGD) is a\ncrucial tool to study its escaping behaviors from stationary points. However,\nexisting stochastic differential equation (SDE) models fail to fully capture\nthese behaviors, even for simple quadratic objectives. Built on a novel\nstochastic backward error analysis framework, we derive the Hessian-Aware\nStochastic Modified Equation (HA-SME), an SDE that incorporates Hessian\ninformation of the objective function into both its drift and diffusion terms.\nOur analysis shows that HA-SME matches the order-best approximation error\nguarantee among existing SDE models in the literature, while achieving a\nsignificantly reduced dependence on the smoothness parameter of the objective.\nFurther, for quadratic objectives, under mild conditions, HA-SME is proved to\nbe the first SDE model that recovers exactly the SGD dynamics in the\ndistributional sense. Consequently, when the local landscape near a stationary\npoint can be approximated by quadratics, HA-SME is expected to accurately\npredict the local escaping behaviors of SGD.\n","authors":["Xiang Li","Zebang Shen","Liang Zhang","Niao He"],"pdf_url":"https://arxiv.org/pdf/2405.18373v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02849v1","updated":"2024-08-05T22:19:01Z","published":"2024-08-05T22:19:01Z","title":"Active Learning for WBAN-based Health Monitoring","summary":"  We consider a novel active learning problem motivated by the need of learning\nmachine learning models for health monitoring in wireless body area network\n(WBAN). Due to the limited resources at body sensors, collecting each unlabeled\nsample in WBAN incurs a nontrivial cost. Moreover, training health monitoring\nmodels typically requires labels indicating the patient's health state that\nneed to be generated by healthcare professionals, which cannot be obtained at\nthe same pace as data collection. These challenges make our problem\nfundamentally different from classical active learning, where unlabeled samples\nare free and labels can be queried in real time. To handle these challenges, we\npropose a two-phased active learning method, consisting of an online phase\nwhere a coreset construction algorithm is proposed to select a subset of\nunlabeled samples based on their noisy predictions, and an offline phase where\nthe selected samples are labeled to train the target model. The samples\nselected by our algorithm are proved to yield a guaranteed error in\napproximating the full dataset in evaluating the loss function. Our evaluation\nbased on real health monitoring data and our own experimentation demonstrates\nthat our solution can drastically save the data curation cost without\nsacrificing the quality of the target model.\n","authors":["Cho-Chun Chiu","Tuan Nguyen","Ting He","Shiqiang Wang","Beom-Su Kim","Ki-Il Kim"],"pdf_url":"https://arxiv.org/pdf/2408.02849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02845v1","updated":"2024-08-05T22:01:13Z","published":"2024-08-05T22:01:13Z","title":"Heterogeneous graph attention network improves cancer multiomics\n  integration","summary":"  The increase in high-dimensional multiomics data demands advanced integration\nmodels to capture the complexity of human diseases. Graph-based deep learning\nintegration models, despite their promise, struggle with small patient cohorts\nand high-dimensional features, often applying independent feature selection\nwithout modeling relationships among omics. Furthermore, conventional\ngraph-based omics models focus on homogeneous graphs, lacking multiple types of\nnodes and edges to capture diverse structures. We introduce a Heterogeneous\nGraph ATtention network for omics integration (HeteroGATomics) to improve\ncancer diagnosis. HeteroGATomics performs joint feature selection through a\nmulti-agent system, creating dedicated networks of feature and patient\nsimilarity for each omic modality. These networks are then combined into one\nheterogeneous graph for learning holistic omic-specific representations and\nintegrating predictions across modalities. Experiments on three cancer\nmultiomics datasets demonstrate HeteroGATomics' superior performance in cancer\ndiagnosis. Moreover, HeteroGATomics enhances interpretability by identifying\nimportant biomarkers contributing to the diagnosis outcomes.\n","authors":["Sina Tabakhi","Charlotte Vandermeulen","Ian Sudbery","Haiping Lu"],"pdf_url":"https://arxiv.org/pdf/2408.02845v1.pdf","comment":"29 pages, 13 figures"},{"id":"http://arxiv.org/abs/2401.16803v3","updated":"2024-08-05T21:55:11Z","published":"2024-01-30T07:50:32Z","title":"PBSCR: The Piano Bootleg Score Composer Recognition Dataset","summary":"  This article motivates, describes, and presents the PBSCR dataset for\nstudying composer recognition of classical piano music. Our goal was to design\na dataset that facilitates large-scale research on composer recognition that is\nsuitable for modern architectures and training practices. To achieve this goal,\nwe utilize the abundance of sheet music images and rich metadata on IMSLP, use\na previously proposed feature representation called a bootleg score to encode\nthe location of noteheads relative to staff lines, and present the data in an\nextremely simple format (2D binary images) to encourage rapid exploration and\niteration. The dataset itself contains 40,000 62x64 bootleg score images for a\n9-class recognition task, 100,000 62x64 bootleg score images for a 100-class\nrecognition task, and 29,310 unlabeled variable-length bootleg score images for\npretraining. The labeled data is presented in a form that mirrors MNIST images,\nin order to make it extremely easy to visualize, manipulate, and train models\nin an efficient manner. We include relevant information to connect each bootleg\nscore image with its underlying raw sheet music image, and we scrape, organize,\nand compile metadata from IMSLP on all piano works to facilitate multimodal\nresearch and allow for convenient linking to other datasets. We release\nbaseline results in a supervised and low-shot setting for future works to\ncompare against, and we discuss open research questions that the PBSCR data is\nespecially well suited to facilitate research on.\n","authors":["Arhan Jain","Alec Bunn","Austin Pham","TJ Tsai"],"pdf_url":"https://arxiv.org/pdf/2401.16803v3.pdf","comment":"19 pages, 6 figures, to be published in Transactions of the\n  International Society for Music Information Retrieval"},{"id":"http://arxiv.org/abs/2309.08569v2","updated":"2024-08-05T21:54:54Z","published":"2023-09-15T17:35:51Z","title":"Local Differential Privacy in Graph Neural Networks: a Reconstruction\n  Approach","summary":"  Graph Neural Networks have achieved tremendous success in modeling complex\ngraph data in a variety of applications. However, there are limited studies\ninvestigating privacy protection in GNNs. In this work, we propose a learning\nframework that can provide node privacy at the user level, while incurring low\nutility loss. We focus on a decentralized notion of Differential Privacy,\nnamely Local Differential Privacy, and apply randomization mechanisms to\nperturb both feature and label data at the node level before the data is\ncollected by a central server for model training. Specifically, we investigate\nthe application of randomization mechanisms in high-dimensional feature\nsettings and propose an LDP protocol with strict privacy guarantees. Based on\nfrequency estimation in statistical analysis of randomized data, we develop\nreconstruction methods to approximate features and labels from perturbed data.\nWe also formulate this learning framework to utilize frequency estimates of\ngraph clusters to supervise the training procedure at a sub-graph level.\nExtensive experiments on real-world and semi-synthetic datasets demonstrate the\nvalidity of our proposed model.\n","authors":["Karuna Bhaila","Wen Huang","Yongkai Wu","Xintao Wu"],"pdf_url":"https://arxiv.org/pdf/2309.08569v2.pdf","comment":"2024 SIAM International Conference on Data Mining"},{"id":"http://arxiv.org/abs/2406.12038v2","updated":"2024-08-05T21:48:22Z","published":"2024-06-17T19:11:40Z","title":"Soft Prompting for Unlearning in Large Language Models","summary":"  The widespread popularity of Large Language Models (LLMs), partly due to\ntheir unique ability to perform in-context learning, has also brought to light\nthe importance of ethical and safety considerations when deploying these\npre-trained models. In this work, we focus on investigating machine unlearning\nfor LLMs motivated by data protection regulations. In contrast to the growing\nliterature on fine-tuning methods to achieve unlearning, we focus on a\ncomparatively lightweight alternative called soft prompting to realize the\nunlearning of a subset of training data. With losses designed to enforce\nforgetting as well as utility preservation, our framework \\textbf{S}oft\n\\textbf{P}rompting for \\textbf{U}n\\textbf{l}earning (SPUL) learns prompt tokens\nthat can be appended to an arbitrary query to induce unlearning of specific\nexamples at inference time without updating LLM parameters. We conduct a\nrigorous evaluation of the proposed method and our results indicate that SPUL\ncan significantly improve the trade-off between utility and forgetting in the\ncontext of text classification and question answering with LLMs. We further\nvalidate our method using multiple LLMs to highlight the scalability of our\nframework and provide detailed insights into the choice of hyperparameters and\nthe influence of the size of unlearning data. Our implementation is available\nat \\url{https://github.com/karuna-bhaila/llm_unlearning}.\n","authors":["Karuna Bhaila","Minh-Hao Van","Xintao Wu"],"pdf_url":"https://arxiv.org/pdf/2406.12038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02841v1","updated":"2024-08-05T21:35:51Z","published":"2024-08-05T21:35:51Z","title":"Evaluating Posterior Probabilities: Decision Theory, Proper Scoring\n  Rules, and Calibration","summary":"  Most machine learning classifiers are designed to output posterior\nprobabilities for the classes given the input sample. These probabilities may\nbe used to make the categorical decision on the class of the sample; provided\nas input to a downstream system; or provided to a human for interpretation.\nEvaluating the quality of the posteriors generated by these system is an\nessential problem which was addressed decades ago with the invention of proper\nscoring rules (PSRs). Unfortunately, much of the recent machine learning\nliterature uses calibration metrics -- most commonly, the expected calibration\nerror (ECE) -- as a proxy to assess posterior performance. The problem with\nthis approach is that calibration metrics reflect only one aspect of the\nquality of the posteriors, ignoring the discrimination performance. For this\nreason, we argue that calibration metrics should play no role in the assessment\nof posterior quality. Expected PSRs should instead be used for this job,\npreferably normalized for ease of interpretation. In this work, we first give a\nbrief review of PSRs from a practical perspective, motivating their definition\nusing Bayes decision theory. We discuss why expected PSRs provide a principled\nmeasure of the quality of a system's posteriors and why calibration metrics are\nnot the right tool for this job. We argue that calibration metrics, while not\nuseful for performance assessment, may be used as diagnostic tools during\nsystem development. With this purpose in mind, we discuss a simple and\npractical calibration metric, called calibration loss, derived from a\ndecomposition of expected PSRs. We compare this metric with the ECE and with\nthe expected score divergence calibration metric from the PSR literature and\nargue, using theoretical and empirical evidence, that calibration loss is\nsuperior to these two metrics.\n","authors":["Luciana Ferrer","Daniel Ramos"],"pdf_url":"https://arxiv.org/pdf/2408.02841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02839v1","updated":"2024-08-05T21:25:10Z","published":"2024-08-05T21:25:10Z","title":"Optimizing Cox Models with Stochastic Gradient Descent: Theoretical\n  Foundations and Practical Guidances","summary":"  Optimizing Cox regression and its neural network variants poses substantial\ncomputational challenges in large-scale studies. Stochastic gradient descent\n(SGD), known for its scalability in model optimization, has recently been\nadapted to optimize Cox models. Unlike its conventional application, which\ntypically targets a sum of independent individual loss, SGD for Cox models\nupdates parameters based on the partial likelihood of a subset of data. Despite\nits empirical success, the theoretical foundation for optimizing Cox partial\nlikelihood with SGD is largely underexplored. In this work, we demonstrate that\nthe SGD estimator targets an objective function that is batch-size-dependent.\nWe establish that the SGD estimator for the Cox neural network (Cox-NN) is\nconsistent and achieves the optimal minimax convergence rate up to a\npolylogarithmic factor. For Cox regression, we further prove the\n$\\sqrt{n}$-consistency and asymptotic normality of the SGD estimator, with\nvariance depending on the batch size. Furthermore, we quantify the impact of\nbatch size on Cox-NN training and its effect on the SGD estimator's asymptotic\nefficiency in Cox regression. These findings are validated by extensive\nnumerical experiments and provide guidance for selecting batch sizes in SGD\napplications. Finally, we demonstrate the effectiveness of SGD in a real-world\napplication where GD is unfeasible due to the large scale of data.\n","authors":["Lang Zeng","Weijing Tang","Zhao Ren","Ying Ding"],"pdf_url":"https://arxiv.org/pdf/2408.02839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02838v1","updated":"2024-08-05T21:22:36Z","published":"2024-08-05T21:22:36Z","title":"Interpretation of the Intent Detection Problem as Dynamics in a\n  Low-dimensional Space","summary":"  Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.\n","authors":["Eduardo Sanchez-Karhunen","Jose F. Quesada-Moreno","Miguel A. Gutiérrez-Naranjo"],"pdf_url":"https://arxiv.org/pdf/2408.02838v1.pdf","comment":"Camera-Ready version. Accepted paper at 27th European Conference on\n  Artificial Intelligence (ECAI-2024)"},{"id":"http://arxiv.org/abs/2408.02835v1","updated":"2024-08-05T21:12:12Z","published":"2024-08-05T21:12:12Z","title":"Training a multilayer dynamical spintronic network with standard machine\n  learning tools to perform time series classification","summary":"  The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.\n","authors":["Erwan Plouet","Dédalo Sanz-Hernández","Aymeric Vecchiola","Julie Grollier","Frank Mizrahi"],"pdf_url":"https://arxiv.org/pdf/2408.02835v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.02834v1","updated":"2024-08-05T21:11:34Z","published":"2024-08-05T21:11:34Z","title":"DaCapo: a modular deep learning framework for scalable 3D image\n  segmentation","summary":"  DaCapo is a specialized deep learning library tailored to expedite the\ntraining and application of existing machine learning approaches on large,\nnear-isotropic image data. In this correspondence, we introduce DaCapo's unique\nfeatures optimized for this specific domain, highlighting its modular\nstructure, efficient experiment management tools, and scalable deployment\ncapabilities. We discuss its potential to improve access to large-scale,\nisotropic image segmentation and invite the community to explore and contribute\nto this open-source initiative.\n","authors":["William Patton","Jeff L. Rhoades","Marwan Zouinkhi","David G. Ackerman","Caroline Malin-Mayor","Diane Adjavon","Larissa Heinrich","Davis Bennett","Yurii Zubov","CellMap Project Team","Aubrey V. Weigel","Jan Funke"],"pdf_url":"https://arxiv.org/pdf/2408.02834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19082v2","updated":"2024-08-05T21:09:50Z","published":"2024-07-26T21:02:11Z","title":"Regularized Multi-Decoder Ensemble for an Error-Aware Scene\n  Representation Network","summary":"  Feature grid Scene Representation Networks (SRNs) have been applied to\nscientific data as compact functional surrogates for analysis and\nvisualization. As SRNs are black-box lossy data representations, assessing the\nprediction quality is critical for scientific visualization applications to\nensure that scientists can trust the information being visualized. Currently,\nexisting architectures do not support inference time reconstruction quality\nassessment, as coordinate-level errors cannot be evaluated in the absence of\nground truth data. We propose a parameter-efficient multi-decoder SRN (MDSRN)\nensemble architecture consisting of a shared feature grid with multiple\nlightweight multi-layer perceptron decoders. MDSRN can generate a set of\nplausible predictions for a given input coordinate to compute the mean as the\nprediction of the multi-decoder ensemble and the variance as a confidence\nscore. The coordinate-level variance can be rendered along with the data to\ninform the reconstruction quality, or be integrated into uncertainty-aware\nvolume visualization algorithms. To prevent the misalignment between the\nquantified variance and the prediction quality, we propose a novel variance\nregularization loss for ensemble learning that promotes the Regularized\nmulti-decoder SRN (RMDSRN) to obtain a more reliable variance that correlates\nclosely to the true model error. We comprehensively evaluate the quality of\nvariance quantification and data reconstruction of Monte Carlo Dropout, Mean\nField Variational Inference, Deep Ensemble, and Predicting Variance compared to\nthe proposed MDSRN and RMDSRN across diverse scalar field datasets. We\ndemonstrate that RMDSRN attains the most accurate data reconstruction and\ncompetitive variance-error correlation among uncertain SRNs under the same\nneural network parameter budgets.\n","authors":["Tianyu Xiong","Skylar W. Wurster","Hanqi Guo","Tom Peterka","Han-Wei Shen"],"pdf_url":"https://arxiv.org/pdf/2407.19082v2.pdf","comment":"To be published in Proc. IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2408.02833v1","updated":"2024-08-05T21:09:01Z","published":"2024-08-05T21:09:01Z","title":"Adaptive Learning for Quantum Linear Regression","summary":"  The recent availability of quantum annealers as cloud-based services has\nenabled new ways to handle machine learning problems, and several relevant\nalgorithms have been adapted to run on these devices. In a recent work, linear\nregression was formulated as a quadratic binary optimization problem that can\nbe solved via quantum annealing. Although this approach promises a\ncomputational time advantage for large datasets, the quality of the solution is\nlimited by the necessary use of a precision vector, used to approximate the\nreal-numbered regression coefficients in the quantum formulation. In this work,\nwe focus on the practical challenge of improving the precision vector encoding:\ninstead of setting an array of generic values equal for all coefficients, we\nallow each one to be expressed by its specific precision, which is tuned with a\nsimple adaptive algorithm. This approach is evaluated on synthetic datasets of\nincreasing size, and linear regression is solved using the D-Wave Advantage\nquantum annealer, as well as classical solvers. To the best of our knowledge,\nthis is the largest dataset ever evaluated for linear regression on a quantum\nannealer. The results show that our formulation is able to deliver improved\nsolution quality in all instances, and could better exploit the potential of\ncurrent quantum devices.\n","authors":["Costantino Carugno","Maurizio Ferrari Dacrema","Paolo Cremonesi"],"pdf_url":"https://arxiv.org/pdf/2408.02833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02830v1","updated":"2024-08-05T20:55:14Z","published":"2024-08-05T20:55:14Z","title":"Setting the duration of online A/B experiments","summary":"  In designing an online A/B experiment, it is crucial to select a sample size\nand duration that ensure the resulting confidence interval (CI) for the\ntreatment effect is the right width to detect an effect of meaningful magnitude\nwith sufficient statistical power without wasting resources. While the\nrelationship between sample size and CI width is well understood, the effect of\nexperiment duration on CI width remains less clear. This paper provides an\nanalytical formula for the width of a CI based on a ratio treatment effect\nestimator as a function of both sample size (N) and duration (T). The formula\nis derived from a mixed effects model with two variance components. One\ncomponent, referred to as the temporal variance, persists over time for\nexperiments where the same users are kept in the same experiment arm across\ndifferent days. The remaining error variance component, by contrast, decays to\nzero as T gets large. The formula we derive introduces a key parameter that we\ncall the user-specific temporal correlation (UTC), which quantifies the\nrelative sizes of the two variance components and can be estimated from\nhistorical experiments. Higher UTC indicates a slower decay in CI width over\ntime. On the other hand, when the UTC is 0 -- as for experiments where users\nshuffle in and out of the experiment across days -- the CI width decays at the\nstandard parametric 1/T rate. We also study how access to pre-period data for\nthe users in the experiment affects the CI width decay. We show our formula\nclosely explains CI widths on real A/B experiments at YouTube.\n","authors":["Harrison H. Li","Chaoyu Yu"],"pdf_url":"https://arxiv.org/pdf/2408.02830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02824v1","updated":"2024-08-05T20:46:54Z","published":"2024-08-05T20:46:54Z","title":"Wave-RVFL: A Randomized Neural Network Based on Wave Loss Function","summary":"  The random vector functional link (RVFL) network is well-regarded for its\nstrong generalization capabilities in the field of machine learning. However,\nits inherent dependencies on the square loss function make it susceptible to\nnoise and outliers. Furthermore, the calculation of RVFL's unknown parameters\nnecessitates matrix inversion of the entire training sample, which constrains\nits scalability. To address these challenges, we propose the Wave-RVFL, an RVFL\nmodel incorporating the wave loss function. We formulate and solve the proposed\noptimization problem of the Wave-RVFL using the adaptive moment estimation\n(Adam) algorithm in a way that successfully eliminates the requirement for\nmatrix inversion and significantly enhances scalability. The Wave-RVFL exhibits\nrobustness against noise and outliers by preventing over-penalization of\ndeviations, thereby maintaining a balanced approach to managing noise and\noutliers. The proposed Wave-RVFL model is evaluated on multiple UCI datasets,\nboth with and without the addition of noise and outliers, across various\ndomains and sizes. Empirical results affirm the superior performance and\nrobustness of the Wave-RVFL compared to baseline models, establishing it as a\nhighly effective and scalable classification solution.\n","authors":["M. Sajid","A. Quadir","M. Tanveer"],"pdf_url":"https://arxiv.org/pdf/2408.02824v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02821v1","updated":"2024-08-05T20:39:06Z","published":"2024-08-05T20:39:06Z","title":"Continuous Monitoring via Repeated Significance","summary":"  Requiring statistical significance at multiple interim analyses to declare a\nstatistically significant result for an AB test allows less stringent\nrequirements for significance at each interim analysis. Repeated repeated\nsignificance competes well with methods built on assumptions about the test --\nassumptions that may be impossible to evaluate a priori and may require extra\ndata to evaluate empirically.\n  Instead, requiring repeated significance allows the data itself to prove\ndirectly that the required results are not due to chance alone. We explain how\nto apply tests with repeated significance to continuously monitor unbounded\ntests -- tests that do not have an a priori bound on running time or number of\nobservations. We show that it is impossible to maintain a constant requirement\nfor significance for unbounded tests, but that we can come arbitrarily close to\nthat goal.\n","authors":["Eric Bax","Arundhyoti Sarkar","Alex Shtoff"],"pdf_url":"https://arxiv.org/pdf/2408.02821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02814v1","updated":"2024-08-05T20:27:54Z","published":"2024-08-05T20:27:54Z","title":"Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream\n  Machine Learning Services","summary":"  Though pre-trained encoders can be easily accessed online to build downstream\nmachine learning (ML) services quickly, various attacks have been designed to\ncompromise the security and privacy of these encoders. While most attacks\ntarget encoders on the upstream side, it remains unknown how an encoder could\nbe threatened when deployed in a downstream ML service. This paper unveils a\nnew vulnerability: the Pre-trained Encoder Inference (PEI) attack, which posts\nprivacy threats toward encoders hidden behind downstream ML services. By only\nproviding API accesses to a targeted downstream service and a set of candidate\nencoders, the PEI attack can infer which encoder is secretly used by the\ntargeted service based on candidate ones. We evaluate the attack performance of\nPEI against real-world encoders on three downstream tasks: image\nclassification, text classification, and text-to-image generation. Experiments\nshow that the PEI attack succeeds in revealing the hidden encoder in most cases\nand seldom makes mistakes even when the hidden encoder is not in the candidate\nset. We also conducted a case study on one of the most recent vision-language\nmodels, LLaVA, to illustrate that the PEI attack is useful in assisting other\nML attacks such as adversarial attacks. The code is available at\nhttps://github.com/fshp971/encoder-inference.\n","authors":["Shaopeng Fu","Xuexue Sun","Ke Qing","Tianhang Zheng","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02813v1","updated":"2024-08-05T20:27:45Z","published":"2024-08-05T20:27:45Z","title":"Mitigating Malicious Attacks in Federated Learning via Confidence-aware\n  Defense","summary":"  Federated Learning (FL) is an emerging distributed machine learning paradigm\nthat allows multiple clients to collaboratively train a global model without\nsharing private local data. However, FL systems are vulnerable to attacks from\nmalicious clients, who can degrade the global model performance through data\npoisoning and model poisoning. Existing defense methods typically focus on a\nsingle type of attack, such as Byzantine attacks or backdoor attacks, and are\noften ineffective against potential data poisoning attacks like label flipping\nand label shuffling. Additionally, these methods often lack accuracy and\nrobustness in detecting and handling malicious updates. To address these\nissues, we propose a novel method based on model confidence scores, which\nevaluates the uncertainty of client model updates to detect and defend against\nmalicious clients. Our approach is comprehensively effective for both model\npoisoning and data poisoning attacks and is capable of accurately identifying\nand mitigating potential malicious updates from being aggregated. Experimental\nresults demonstrate that our method significantly improves the robustness of FL\nsystems against various types of attacks, also achieving higher model accuracy\nand stability across various scenarios.\n","authors":["Qilei Li","Ahmed M. Abdelmoniem"],"pdf_url":"https://arxiv.org/pdf/2408.02813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02802v1","updated":"2024-08-05T19:45:07Z","published":"2024-08-05T19:45:07Z","title":"Deciphering Air Travel Disruptions: A Machine Learning Approach","summary":"  This research investigates flight delay trends by examining factors such as\ndeparture time, airline, and airport. It employs regression machine learning\nmethods to predict the contributions of various sources to delays. Time-series\nmodels, including LSTM, Hybrid LSTM, and Bi-LSTM, are compared with baseline\nregression models such as Multiple Regression, Decision Tree Regression, Random\nForest Regression, and Neural Network. Despite considerable errors in the\nbaseline models, the study aims to identify influential features in delay\nprediction, potentially informing flight planning strategies. Unlike previous\nwork, this research focuses on regression tasks and explores the use of\ntime-series models for predicting flight delays. It offers insights into\naviation operations by independently analyzing each delay component (e.g.,\nsecurity, weather).\n","authors":["Aravinda Jatavallabha","Jacob Gerlach","Aadithya Naresh"],"pdf_url":"https://arxiv.org/pdf/2408.02802v1.pdf","comment":"10 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2408.02801v1","updated":"2024-08-05T19:38:45Z","published":"2024-08-05T19:38:45Z","title":"Sparse Deep Learning Models with the $\\ell_1$ Regularization","summary":"  Sparse neural networks are highly desirable in deep learning in reducing its\ncomplexity. The goal of this paper is to study how choices of regularization\nparameters influence the sparsity level of learned neural networks. We first\nderive the $\\ell_1$-norm sparsity-promoting deep learning models including\nsingle and multiple regularization parameters models, from a statistical\nviewpoint. We then characterize the sparsity level of a regularized neural\nnetwork in terms of the choice of the regularization parameters. Based on the\ncharacterizations, we develop iterative algorithms for selecting regularization\nparameters so that the weight parameters of the resulting deep neural network\nenjoy prescribed sparsity levels. Numerical experiments are presented to\ndemonstrate the effectiveness of the proposed algorithms in choosing desirable\nregularization parameters and obtaining corresponding neural networks having\nboth of predetermined sparsity levels and satisfactory approximation accuracy.\n","authors":["Lixin Shen","Rui Wang","Yuesheng Xu","Mingsong Yan"],"pdf_url":"https://arxiv.org/pdf/2408.02801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02798v1","updated":"2024-08-05T19:28:58Z","published":"2024-08-05T19:28:58Z","title":"Examining Gender and Power on Wikipedia Through Face and Politeness","summary":"  We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.\n","authors":["Adil Soubki","Shyne Choi","Owen Rambow"],"pdf_url":"https://arxiv.org/pdf/2408.02798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02797v1","updated":"2024-08-05T19:25:05Z","published":"2024-08-05T19:25:05Z","title":"Algorithm-Informed Graph Neural Networks for Leakage Detection and\n  Localization in Water Distribution Networks","summary":"  Detecting and localizing leakages is a significant challenge for the\nefficient and sustainable management of water distribution networks (WDN).\nLeveraging the inherent graph structure of WDNs, recent approaches have used\ngraph-based data-driven methods. However, these methods often learn shortcuts\nthat work well with in-distribution data but fail to generalize to\nout-of-distribution data. To address this limitation and inspired by the\nperfect generalization ability of classical algorithms, we propose an\nalgorithm-informed graph neural network (AIGNN). Recognizing that WDNs function\nas flow networks, incorporating max-flow information can be beneficial for\ninferring pressures. In the proposed framework, we first train AIGNN to emulate\nthe Ford-Fulkerson algorithm for solving max-flow problems. This algorithmic\nknowledge is then transferred to address the pressure estimation problem in\nWDNs. Two AIGNNs are deployed, one to reconstruct pressure based on the current\nmeasurements, and another to predict pressure based on previous measurements.\nLeakages are detected and localized by comparing the outputs of the\nreconstructor and the predictor. By pretraining AIGNNs to reason like\nalgorithms, they are expected to extract more task-relevant and generalizable\nfeatures. Experimental results demonstrate that the proposed algorithm-informed\napproach achieves superior results with better generalization ability compared\nto GNNs that do not incorporate algorithmic knowledge.\n","authors":["Zepeng Zhang","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2408.02797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.05490v2","updated":"2024-08-05T18:57:42Z","published":"2023-09-11T14:32:04Z","title":"Learning Semantic Segmentation with Query Points Supervision on Aerial\n  Images","summary":"  Semantic segmentation is crucial in remote sensing, where high-resolution\nsatellite images are segmented into meaningful regions. Recent advancements in\ndeep learning have significantly improved satellite image segmentation.\nHowever, most of these methods are typically trained in fully supervised\nsettings that require high-quality pixel-level annotations, which are expensive\nand time-consuming to obtain. In this work, we present a weakly supervised\nlearning algorithm to train semantic segmentation algorithms that only rely on\nquery point annotations instead of full mask labels. Our proposed approach\nperforms accurate semantic segmentation and improves efficiency by\nsignificantly reducing the cost and time required for manual annotation.\nSpecifically, we generate superpixels and extend the query point labels into\nthose superpixels that group similar meaningful semantics. Then, we train\nsemantic segmentation models supervised with images partially labeled with the\nsuperpixel pseudo-labels. We benchmark our weakly supervised training approach\non an aerial image dataset and different semantic segmentation architectures,\nshowing that we can reach competitive performance compared to fully supervised\ntraining while reducing the annotation effort. The code of our proposed\napproach is publicly available at: https://github.com/santiago2205/LSSQPS.\n","authors":["Santiago Rivier","Carlos Hinojosa","Silvio Giancola","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2309.05490v2.pdf","comment":"Paper Accepted at ICIP 2024 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2312.00761v4","updated":"2024-08-05T18:40:07Z","published":"2023-12-01T18:29:08Z","title":"Deep Unlearning: Fast and Efficient Gradient-free Approach to Class\n  Forgetting","summary":"  Machine unlearning is a prominent and challenging field, driven by regulatory\ndemands for user data deletion and heightened privacy awareness. Existing\napproaches involve retraining model or multiple finetuning steps for each\ndeletion request, often constrained by computational limits and restricted data\naccess. In this work, we introduce a novel class unlearning algorithm designed\nto strategically eliminate specific classes from the learned model. Our\nalgorithm first estimates the Retain and the Forget Spaces using Singular Value\nDecomposition on the layerwise activations for a small subset of samples from\nthe retain and unlearn classes, respectively. We then compute the shared\ninformation between these spaces and remove it from the forget space to isolate\nclass-discriminatory feature space. Finally, we obtain the unlearned model by\nupdating the weights to suppress the class discriminatory features from the\nactivation spaces. We demonstrate our algorithm's efficacy on ImageNet using a\nVision Transformer with only $\\sim 1.5\\%$ drop in retain accuracy compared to\nthe original model while maintaining under $1\\%$ accuracy on the unlearned\nclass samples. Furthermore, our algorithm exhibits competitive unlearning\nperformance and resilience against Membership Inference Attacks (MIA). Compared\nto baselines, it achieves an average accuracy improvement of $1.38\\%$ on the\nImageNet dataset while requiring up to $10 \\times$ fewer samples for\nunlearning. Additionally, under stronger MIA attacks on the CIFAR-100 dataset\nusing a ResNet18 architecture, our approach outperforms the best baseline by\n$1.8\\%$. Our code is available at\nhttps://github.com/sangamesh-kodge/class_forgetting.\n","authors":["Sangamesh Kodge","Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2312.00761v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02767v1","updated":"2024-08-05T18:36:13Z","published":"2024-08-05T18:36:13Z","title":"4D-Var using Hessian approximation and backpropagation applied to\n  automatically-differentiable numerical and machine learning models","summary":"  Constraining a numerical weather prediction (NWP) model with observations via\n4D variational (4D-Var) data assimilation is often difficult to implement in\npractice due to the need to develop and maintain a software-based tangent\nlinear model and adjoint model. One of the most common 4D-Var algorithms uses\nan incremental update procedure, which has been shown to be an approximation of\nthe Gauss-Newton method. Here we demonstrate that when using a forecast model\nthat supports automatic differentiation, an efficient and in some cases more\naccurate alternative approximation of the Gauss-Newton method can be applied by\ncombining backpropagation of errors with Hessian approximation. This approach\ncan be used with either a conventional numerical model implemented within a\nsoftware framework that supports automatic differentiation, or a machine\nlearning (ML) based surrogate model. We test the new approach on a variety of\nLorenz-96 and quasi-geostrophic models. The results indicate potential for a\ndeeper integration of modeling, data assimilation, and new technologies in a\nnext-generation of operational forecast systems that leverage weather models\ndesigned to support automatic differentiation.\n","authors":["Kylen Solvik","Stephen G. Penny","Stephan Hoyer"],"pdf_url":"https://arxiv.org/pdf/2408.02767v1.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.02766v1","updated":"2024-08-05T18:34:15Z","published":"2024-08-05T18:34:15Z","title":"ConDL: Detector-Free Dense Image Matching","summary":"  In this work, we introduce a deep-learning framework designed for estimating\ndense image correspondences. Our fully convolutional model generates dense\nfeature maps for images, where each pixel is associated with a descriptor that\ncan be matched across multiple images. Unlike previous methods, our model is\ntrained on synthetic data that includes significant distortions, such as\nperspective changes, illumination variations, shadows, and specular highlights.\nUtilizing contrastive learning, our feature maps achieve greater invariance to\nthese distortions, enabling robust matching. Notably, our method eliminates the\nneed for a keypoint detector, setting it apart from many existing\nimage-matching techniques.\n","authors":["Monika Kwiatkowski","Simon Matern","Olaf Hellwich"],"pdf_url":"https://arxiv.org/pdf/2408.02766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02761v1","updated":"2024-08-05T18:24:48Z","published":"2024-08-05T18:24:48Z","title":"Dimensionality Reduction and Nearest Neighbors for Improving\n  Out-of-Distribution Detection in Medical Image Segmentation","summary":"  Clinically deployed deep learning-based segmentation models are known to fail\non data outside of their training distributions. While clinicians review the\nsegmentations, these models tend to perform well in most instances, which could\nexacerbate automation bias. Therefore, detecting out-of-distribution images at\ninference is critical to warn the clinicians that the model likely failed. This\nwork applied the Mahalanobis distance (MD) post hoc to the bottleneck features\nof four Swin UNETR and nnU-net models that segmented the liver on T1-weighted\nmagnetic resonance imaging and computed tomography. By reducing the dimensions\nof the bottleneck features with either principal component analysis or uniform\nmanifold approximation and projection, images the models failed on were\ndetected with high performance and minimal computational load. In addition,\nthis work explored a non-parametric alternative to the MD, a k-th nearest\nneighbors distance (KNN). KNN drastically improved scalability and performance\nover MD when both were applied to raw and average-pooled bottleneck features.\n","authors":["McKell Woodland","Nihil Patel","Austin Castelo","Mais Al Taie","Mohamed Eltaher","Joshua P. Yung","Tucker J. Netherton","Tiffany L. Calderone","Jessica I. Sanchez","Darrel W. Cleere","Ahmed Elsaiey","Nakul Gupta","David Victor","Laura Beretta","Ankit B. Patel Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2408.02761v1.pdf","comment":"Expansion of \"Dimensionality Reduction for Improving\n  Out-of-Distribution Detection in Medical Image Segmentation\" arXiv:2308.03723\n  . Submitted to the Journal for Machine Learning in Biomedical Imaging. Code\n  available at https://github.com/mckellwoodland/dimen_reduce_mahal"},{"id":"http://arxiv.org/abs/2408.02760v1","updated":"2024-08-05T18:24:09Z","published":"2024-08-05T18:24:09Z","title":"Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An\n  Improved ROCKET Algorithm for Multivariate Time Series Analysis","summary":"  Multivariate Time Series Classification (MTSC) is a ubiquitous problem in\nscience and engineering, particularly in neuroscience, where most data\nacquisition modalities involve the simultaneous time-dependent recording of\nbrain activity in multiple brain regions. In recent years, Random Convolutional\nKernel models such as ROCKET and MiniRocket have emerged as highly effective\ntime series classification algorithms, capable of achieving state-of-the-art\naccuracy results with low computational load. Despite their success, these\ntypes of models face two major challenges when employed in neuroscience: 1)\nthey struggle to deal with high-dimensional data such as EEG and MEG, and 2)\nthey are difficult to interpret. In this work, we present a novel ROCKET-based\nalgorithm, named Detach-Rocket Ensemble, that is specifically designed to\naddress these two problems in MTSC. Our algorithm leverages pruning to provide\nan integrated estimation of channel importance, and ensembles to achieve better\naccuracy and provide a label probability. Using a synthetic multivariate time\nseries classification dataset in which we control the amount of information\ncarried by each of the channels, we first show that our algorithm is able to\ncorrectly recover the channel importance for classification. Then, using two\nreal-world datasets, a MEG dataset and an EEG dataset, we show that\nDetach-Rocket Ensemble is able to provide both interpretable channel relevance\nand competitive classification accuracy, even when applied directly to the raw\nbrain data, without the need for feature engineering.\n","authors":["Adrià Solana","Erik Fransén","Gonzalo Uribarri"],"pdf_url":"https://arxiv.org/pdf/2408.02760v1.pdf","comment":"To be published in European Conference on Machine Learning and Data\n  Mining 2024, 20 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2405.01531v2","updated":"2024-08-05T18:20:39Z","published":"2024-05-02T17:59:01Z","title":"Improving Intervention Efficacy via Concept Realignment in Concept\n  Bottleneck Models","summary":"  Concept Bottleneck Models (CBMs) ground image classification on\nhuman-understandable concepts to allow for interpretable model decisions.\nCrucially, the CBM design inherently allows for human interventions, in which\nexpert users are given the ability to modify potentially misaligned concept\nchoices to influence the decision behavior of the model in an interpretable\nfashion. However, existing approaches often require numerous human\ninterventions per image to achieve strong performances, posing practical\nchallenges in scenarios where obtaining human feedback is expensive. In this\npaper, we find that this is noticeably driven by an independent treatment of\nconcepts during intervention, wherein a change of one concept does not\ninfluence the use of other ones in the model's final decision. To address this\nissue, we introduce a trainable concept intervention realignment module, which\nleverages concept relations to realign concept assignments post-intervention.\nAcross standard, real-world benchmarks, we find that concept realignment can\nsignificantly improve intervention efficacy; significantly reducing the number\nof interventions needed to reach a target classification performance or concept\nprediction accuracy. In addition, it easily integrates into existing\nconcept-based architectures without requiring changes to the models themselves.\nThis reduced cost of human-model collaboration is crucial to enhancing the\nfeasibility of CBMs in resource-constrained environments. Our code is available\nat: https://github.com/ExplainableML/concept_realignment.\n","authors":["Nishad Singhi","Jae Myung Kim","Karsten Roth","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2405.01531v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.02751v1","updated":"2024-08-05T18:11:23Z","published":"2024-08-05T18:11:23Z","title":"A Novel Hybrid Approach for Tornado Prediction in the United States:\n  Kalman-Convolutional BiLSTM with Multi-Head Attention","summary":"  Tornadoes are among the most intense atmospheric vortex phenomena and pose\nsignificant challenges for detection and forecasting. Conventional methods,\nwhich heavily depend on ground-based observations and radar data, are limited\nby issues such as decreased accuracy over greater distances and a high rate of\nfalse positives. To address these challenges, this study utilizes the Seamless\nHybrid Scan Reflectivity (SHSR) dataset from the Multi-Radar Multi-Sensor\n(MRMS) system, which integrates data from multiple radar sources to enhance\naccuracy. A novel hybrid model, the Kalman-Convolutional BiLSTM with Multi-Head\nAttention, is introduced to improve dynamic state estimation and capture both\nspatial and temporal dependencies within the data. This model demonstrates\nsuperior performance in precision, recall, F1-Score, and accuracy compared to\nmethods such as K-Nearest Neighbors (KNN) and LightGBM. The results highlight\nthe considerable potential of advanced machine learning techniques to improve\ntornado prediction and reduce false alarm rates. Future research will focus on\nexpanding datasets, exploring innovative model architectures, and incorporating\nlarge language models (LLMs) to provide deeper insights. This research\nintroduces a novel model for tornado prediction, offering a robust framework\nfor enhancing forecasting accuracy and public safety.\n","authors":["Jiawei Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16778v2","updated":"2024-08-05T18:08:49Z","published":"2024-02-26T17:49:37Z","title":"On the Growth of Mistakes in Differentially Private Online Learning: A\n  Lower Bound Perspective","summary":"  In this paper, we provide lower bounds for Differentially Private (DP) Online\nLearning algorithms. Our result shows that, for a broad class of\n$(\\varepsilon,\\delta)$-DP online algorithms, for number of rounds $T$ such that\n$\\log T\\leq O(1 / \\delta)$, the expected number of mistakes incurred by the\nalgorithm grows as $\\Omega(\\log \\frac{T}{\\delta})$. This matches the upper\nbound obtained by Golowich and Livni (2021) and is in contrast to non-private\nonline learning where the number of mistakes is independent of $T$. To the best\nof our knowledge, our work is the first result towards settling lower bounds\nfor DP-Online learning and partially addresses the open question in Sanyal and\nRamponi (2022).\n","authors":["Daniil Dmitriev","Kristóf Szabó","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.16778v2.pdf","comment":"Accepted at the Conference on Learning Theory (COLT) 2024, Edmonton,\n  Canada"},{"id":"http://arxiv.org/abs/2406.11714v2","updated":"2024-08-05T18:02:55Z","published":"2024-06-17T16:32:57Z","title":"Scalable Expressiveness through Preprocessed Graph Perturbations","summary":"  Graph Neural Networks (GNNs) have emerged as the predominant method for\nanalyzing graph-structured data. However, canonical GNNs have limited\nexpressive power and generalization capability, thus triggering the development\nof more expressive yet computationally intensive methods. One such approach is\nto create a series of perturbed versions of input graphs and then repeatedly\nconduct multiple message-passing operations on all variations during training.\nDespite their expressive power, this approach does not scale well on larger\ngraphs. To address this scalability issue, we introduce Scalable Expressiveness\nthrough Preprocessed Graph Perturbation (SE2P). This model offers a flexible,\nconfigurable balance between scalability and generalizability with four\ndistinct configuration classes. At one extreme, the configuration prioritizes\nscalability through minimal learnable feature extraction and extensive\npreprocessing; at the other extreme, it enhances generalizability with more\nlearnable feature extractions, though this increases scalability costs. We\nconduct extensive experiments on real-world datasets to evaluate the\ngeneralizability and scalability of SE2P variants compared to various\nstate-of-the-art benchmarks. Our results indicate that, depending on the chosen\nSE2P configuration, the model can enhance generalizability compared to\nbenchmarks while achieving significant speed improvements of up to 8-fold.\n","authors":["Danial Saber","Amirali Salehi-Abari"],"pdf_url":"https://arxiv.org/pdf/2406.11714v2.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.02743v1","updated":"2024-08-05T18:01:07Z","published":"2024-08-05T18:01:07Z","title":"KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks\n  applied to an LHC physics example","summary":"  Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an\nalternative to multilayer perceptrons, suggesting advantages in performance and\ninterpretability. We study a typical binary event classification task in\nhigh-energy physics including high-level features and comment on the\nperformance and interpretability of KANs in this context. We find that the\nlearned activation functions of a one-layer KAN resemble the log-likelihood\nratio of the input features. In deeper KANs, the activations in the first KAN\nlayer differ from those in the one-layer KAN, which indicates that the deeper\nKANs learn more complex representations of the data. We study KANs with\ndifferent depths and widths and we compare them to multilayer perceptrons in\nterms of performance and number of trainable parameters. For the chosen\nclassification task, we do not find that KANs are more parameter efficient.\nHowever, small KANs may offer advantages in terms of interpretability that come\nat the cost of only a moderate loss in performance.\n","authors":["Johannes Erdmann","Florian Mausolf","Jan Lukas Späh"],"pdf_url":"https://arxiv.org/pdf/2408.02743v1.pdf","comment":"25 pages, 9 figures"}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2408.02558v1","updated":"2024-08-05T15:35:34Z","published":"2024-08-05T15:35:34Z","title":"Peer-induced Fairness: A Causal Approach to Reveal Algorithmic\n  Unfairness in Credit Approval","summary":"  This paper introduces a novel framework, \"peer-induced fairness\", to\nscientifically audit algorithmic fairness. It addresses a critical but often\noverlooked issue: distinguishing between adverse outcomes due to algorithmic\ndiscrimination and those resulting from individuals' insufficient capabilities.\nBy utilizing counterfactual fairness and advanced causal inference techniques,\nsuch as the Single World Intervention Graph, this model-agnostic approach\nevaluates fairness at the individual level through peer comparisons and\nhypothesis testing. It also tackles challenges like data scarcity and\nimbalance, offering a flexible, plug-and-play self-audit tool for stakeholders\nand an external audit tool for regulators, while providing explainable feedback\nfor those affected by unfavorable decisions.\n","authors":["Shiqi Fang","Zexun Chen","Jake Ansell"],"pdf_url":"https://arxiv.org/pdf/2408.02558v1.pdf","comment":"28 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.02489v1","updated":"2024-08-05T14:11:51Z","published":"2024-08-05T14:11:51Z","title":"Full error analysis of policy gradient learning algorithms for\n  exploratory linear quadratic mean-field control problem in continuous time\n  with common noise","summary":"  We consider reinforcement learning (RL) methods for finding optimal policies\nin linear quadratic (LQ) mean field control (MFC) problems over an infinite\nhorizon in continuous time, with common noise and entropy regularization. We\nstudy policy gradient (PG) learning and first demonstrate convergence in a\nmodel-based setting by establishing a suitable gradient domination\ncondition.Next, our main contribution is a comprehensive error analysis, where\nwe prove the global linear convergence and sample complexity of the PG\nalgorithm with two-point gradient estimates in a model-free setting with\nunknown parameters. In this setting, the parameterized optimal policies are\nlearned from samples of the states and population distribution.Finally, we\nprovide numerical evidence supporting the convergence of our implemented\nalgorithms.\n","authors":["Noufel Frikha","Huyên Pham","Xuanye Song"],"pdf_url":"https://arxiv.org/pdf/2408.02489v1.pdf","comment":"67 pages"},{"id":"http://arxiv.org/abs/2408.02481v1","updated":"2024-08-05T14:02:26Z","published":"2024-08-05T14:02:26Z","title":"On the influence of dependent features in classification problems: a\n  game-theoretic perspective","summary":"  This paper deals with a new measure of the influence of each feature on the\nresponse variable in classification problems, accounting for potential\ndependencies among certain feature subsets. Within this framework, we consider\na sample of individuals characterized by specific features, each feature\nencompassing a finite range of values, and classified based on a binary\nresponse variable. This measure turns out to be an influence measure explored\nin existing literature and related to cooperative game theory. We provide an\naxiomatic characterization of our proposed influence measure by tailoring\nproperties from the cooperative game theory to our specific context.\nFurthermore, we demonstrate that our influence measure becomes a general\ncharacterization of the well-known Banzhaf-Owen value for games with a priori\nunions, from the perspective of classification problems. The definitions and\nresults presented herein are illustrated through numerical examples and various\napplications, offering practical insights into our methodologies.\n","authors":["Laura Davila-Pena","Alejandro Saavedra-Nieves","Balbina Casas-Méndez"],"pdf_url":"https://arxiv.org/pdf/2408.02481v1.pdf","comment":"27 pages, 17 tables"},{"id":"http://arxiv.org/abs/2408.02433v1","updated":"2024-08-05T12:46:21Z","published":"2024-08-05T12:46:21Z","title":"On Probabilistic Embeddings in Optimal Dimension Reduction","summary":"  Dimension reduction algorithms are a crucial part of many data science\npipelines, including data exploration, feature creation and selection, and\ndenoising. Despite their wide utilization, many non-linear dimension reduction\nalgorithms are poorly understood from a theoretical perspective. In this work\nwe consider a generalized version of multidimensional scaling, which is posed\nas an optimization problem in which a mapping from a high-dimensional feature\nspace to a lower-dimensional embedding space seeks to preserve either inner\nproducts or norms of the distribution in feature space, and which encompasses\nmany commonly used dimension reduction algorithms. We analytically investigate\nthe variational properties of this problem, leading to the following insights:\n1) Solutions found using standard particle descent methods may lead to\nnon-deterministic embeddings, 2) A relaxed or probabilistic formulation of the\nproblem admits solutions with easily interpretable necessary conditions, 3) The\nglobally optimal solutions to the relaxed problem actually must give a\ndeterministic embedding. This progression of results mirrors the classical\ndevelopment of optimal transportation, and in a case relating to the\nGromov-Wasserstein distance actually gives explicit insight into the structure\nof the optimal embeddings, which are parametrically determined and\ndiscontinuous. Finally, we illustrate that a standard computational\nimplementation of this task does not learn deterministic embeddings, which\nmeans that it learns sub-optimal mappings, and that the embeddings learned in\nthat context have highly misleading clustering structure, underscoring the\ndelicate nature of solving this problem computationally.\n","authors":["Ryan Murray","Adam Pickarski"],"pdf_url":"https://arxiv.org/pdf/2408.02433v1.pdf","comment":"26 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2408.02393v1","updated":"2024-08-05T11:40:23Z","published":"2024-08-05T11:40:23Z","title":"Graphical Modelling without Independence Assumptions for Uncentered Data","summary":"  The independence assumption is a useful tool to increase the tractability of\none's modelling framework. However, this assumption does not match reality;\nfailing to take dependencies into account can cause models to fail\ndramatically. The field of multi-axis graphical modelling (also called\nmulti-way modelling, Kronecker-separable modelling) has seen growth over the\npast decade, but these models require that the data have zero mean. In the\nmulti-axis case, inference is typically done in the single sample scenario,\nmaking mean inference impossible.\n  In this paper, we demonstrate how the zero-mean assumption can cause\negregious modelling errors, as well as propose a relaxation to the zero-mean\nassumption that allows the avoidance of such errors. Specifically, we propose\nthe \"Kronecker-sum-structured mean\" assumption, which leads to models with\nnonconvex-but-unimodal log-likelihoods that can be solved efficiently with\ncoordinate descent.\n","authors":["Bailey Andrew","David R. Westhead","Luisa Cutillo"],"pdf_url":"https://arxiv.org/pdf/2408.02393v1.pdf","comment":"7 pages (13 counting refs & appendix), 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2407.10214v2","updated":"2024-08-05T10:33:24Z","published":"2024-07-14T14:16:03Z","title":"Maximum mean discrepancies of Farey sequences","summary":"  We identify a large class of positive-semidefinite kernels for which a\ncertain polynomial rate of convergence of maximum mean discrepancies of Farey\nsequences is equivalent to the Riemann hypothesis. This class includes all\nMat\\'ern kernels of order at least one-half.\n","authors":["Toni Karvonen","Anatoly Zhigljavsky"],"pdf_url":"https://arxiv.org/pdf/2407.10214v2.pdf","comment":"Corrected an inconsequential error in Lemma 5"},{"id":"http://arxiv.org/abs/2408.02355v1","updated":"2024-08-05T10:02:33Z","published":"2024-08-05T10:02:33Z","title":"Quantile Regression using Random Forest Proximities","summary":"  Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.\n","authors":["Mingshu Li","Bhaskarjit Sarmah","Dhruv Desai","Joshua Rosaler","Snigdha Bhagat","Philip Sommer","Dhagash Mehta"],"pdf_url":"https://arxiv.org/pdf/2408.02355v1.pdf","comment":"9 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2408.02346v1","updated":"2024-08-05T09:45:31Z","published":"2024-08-05T09:45:31Z","title":"Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel\n  Precision Matrices","summary":"  The Hilbert-space Gaussian Process (HGP) approach offers a\nhyperparameter-independent basis function approximation for speeding up\nGaussian Process (GP) inference by projecting the GP onto M basis functions.\nThese properties result in a favorable data-independent $\\mathcal{O}(M^3)$\ncomputational complexity during hyperparameter optimization but require a\ndominating one-time precomputation of the precision matrix costing\n$\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating\ncomputational complexity to $\\mathcal{O}(NM)$ with no additional\napproximations. We can do this because we realize that the precision matrix can\nbe split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$\nunique entries. Based on this realization we propose computing only these\nunique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems\nthat prescribe sufficient conditions for the complexity reduction to hold\ngenerally for a wide range of other approximate GP models, such as the\nVariational Fourier Feature (VFF) approach. The two theorems do this with no\nassumptions on the data and no additional approximations of the GP models\nthemselves. Thus, our contribution provides a pure speed-up of several\nexisting, widely used, GP approximations, without further approximations.\n","authors":["Frida Viset","Anton Kullberg","Frederiek Wesel","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2408.02346v1.pdf","comment":"Published in Transactions on Machine Learning (TMLR) July 2024"},{"id":"http://arxiv.org/abs/2408.02326v1","updated":"2024-08-05T09:10:29Z","published":"2024-08-05T09:10:29Z","title":"Explosive neural networks via higher-order interactions in curved\n  statistical manifolds","summary":"  Higher-order interactions underlie complex phenomena in systems such as\nbiological and artificial neural networks, but their study is challenging due\nto the lack of tractable standard models. By leveraging the maximum entropy\nprinciple in curved statistical manifolds, here we introduce curved neural\nnetworks as a class of prototypical models for studying higher-order phenomena.\nThrough exact mean-field descriptions, we show that these curved neural\nnetworks implement a self-regulating annealing process that can accelerate\nmemory retrieval, leading to explosive order-disorder phase transitions with\nmulti-stability and hysteresis effects. Moreover, by analytically exploring\ntheir memory capacity using the replica trick near ferromagnetic and spin-glass\nphase boundaries, we demonstrate that these networks enhance memory capacity\nover the classical associative-memory networks. Overall, the proposed framework\nprovides parsimonious models amenable to analytical study, revealing novel\nhigher-order phenomena in complex network systems.\n","authors":["Miguel Aguilera","Pablo A. Morales","Fernando E. Rosas","Hideaki Shimazaki"],"pdf_url":"https://arxiv.org/pdf/2408.02326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02320v1","updated":"2024-08-05T09:02:24Z","published":"2024-08-05T09:02:24Z","title":"A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion\n  Models","summary":"  Diffusion models, which convert noise into new data instances by learning to\nreverse a diffusion process, have become a cornerstone in contemporary\ngenerative modeling. In this work, we develop non-asymptotic convergence theory\nfor a popular diffusion-based sampler (i.e., the probability flow ODE sampler)\nin discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein)\nscore functions. For distributions in $\\mathbb{R}^d$, we prove that\n$d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms --\nare sufficient to approximate the target distribution to within $\\varepsilon$\ntotal-variation distance. This is the first result establishing nearly linear\ndimension-dependency (in $d$) for the probability flow ODE sampler. Imposing\nonly minimal assumptions on the target data distribution (e.g., no smoothness\nassumption is imposed), our results also characterize how $\\ell_2$ score\nestimation errors affect the quality of the data generation processes. In\ncontrast to prior works, our theory is developed based on an elementary yet\nversatile non-asymptotic approach without the need of resorting to SDE and ODE\ntoolboxes.\n","authors":["Gen Li","Yuting Wei","Yuejie Chi","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2408.02320v1.pdf","comment":"This manuscript presents improved theory for probability flow ODEs\n  compared to its earlier version arXiv:2306.09251"},{"id":"http://arxiv.org/abs/2308.09605v2","updated":"2024-08-05T08:53:12Z","published":"2023-08-18T14:58:23Z","title":"Solving PDEs on Spheres with Physics-Informed Convolutional Neural\n  Networks","summary":"  Physics-informed neural networks (PINNs) have been demonstrated to be\nefficient in solving partial differential equations (PDEs) from a variety of\nexperimental perspectives. Some recent studies have also proposed PINN\nalgorithms for PDEs on surfaces, including spheres. However, theoretical\nunderstanding of the numerical performance of PINNs, especially PINNs on\nsurfaces or manifolds, is still lacking. In this paper, we establish rigorous\nanalysis of the physics-informed convolutional neural network (PICNN) for\nsolving PDEs on the sphere. By using and improving the latest approximation\nresults of deep convolutional neural networks and spherical harmonic analysis,\nwe prove an upper bound for the approximation error with respect to the Sobolev\nnorm. Subsequently, we integrate this with innovative localization complexity\nanalysis to establish fast convergence rates for PICNN. Our theoretical results\nare also confirmed and supplemented by our experiments. In light of these\nfindings, we explore potential strategies for circumventing the curse of\ndimensionality that arises when solving high-dimensional PDEs.\n","authors":["Guanhang Lei","Zhen Lei","Lei Shi","Chenyu Zeng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2308.09605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10504v2","updated":"2024-08-05T08:22:56Z","published":"2024-02-16T08:27:55Z","title":"On the resilience of the quadratic Littlewood-Offord problem","summary":"  We study the statistical resilience of the anti-concentration properties of\nRademacher polynomials in face of adversarial deterministic noise taking the\nform of sign-flips. Given a multilinear polynomial $f:\\mathbb{R}^n \\to\n\\mathbb{R}$ and a Rademacher vector $\\boldsymbol{\\xi} \\in \\{\\pm 1\\}^n$ (with\nindependent entries), our results provide probabilistic lower bound estimations\non the number of sign-flips that $\\boldsymbol{\\xi}$ can sustain without\n``inflating\" the atom probability $\\sup_{x \\in \\mathbb{R} }\n\\mathbb{P}\\{f(\\boldsymbol{\\xi}) = x\\}$ otherwise resulting in an adversarially\nbiased distribution. Special emphasis is put on bilinear and quadratic forms,\nfor which strengthened estimates are attained. From a computational\nperspective, our results in this venue are instance-bound in such a way that\nallows for an efficient computation of the statistical resilience guarantees\nfrom the quadratic polynomial itself directly. All of our probabilistic lower\nbound resilience guarantees are asymptotically tight.\n  On route, we provide a short proof for a new small-ball probability estimate\nfitting Rademacher multilinear polynomials $f: \\mathbb{R}^n \\to \\mathbb{R}$\nremoveing a polylog-factor from the classical Meka-Nguyen-Vu bound provided the\ncoefficients are independent of $n$ (dimension-free, hereafter). This removal\nwas conjectured to be possible by Meka-Nguyen-Vu regardless of our assumption.\nBilinear Rademacher forms with dimension-free coefficients arise naturally in\nCombinatorics and specifically in the dense case of the edge-statistics\nconjecture posed by Alon, Hefetz, Krivelevich, and Tyomkyn. This case of the\nconjecture was resolved by Kwan and Sauermann. Replacing the appeal to the\nMeka-Nguyen-Vu classical bound in the work of Kwan, Sudakov, and Tran with our\nshortly proved result attains an additional proof of the dense case of the\nedge-statistics conjecture.\n","authors":["Elad Aigner-Horev","Daniel Rosenberg","Roi Weiss"],"pdf_url":"https://arxiv.org/pdf/2402.10504v2.pdf","comment":"Numerous changes from the last version: 1. An oversight in the proof\n  fixed. 2. Added treatment of high degree polynomials 3. New results added"},{"id":"http://arxiv.org/abs/2408.02295v1","updated":"2024-08-05T08:12:25Z","published":"2024-08-05T08:12:25Z","title":"Generalized Gaussian Temporal Difference Error For Uncertainty-aware\n  Reinforcement Learning","summary":"  Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.\n","authors":["Seyeon Kim","Joonhun Lee","Namhoon Cho","Sungjun Han","Seungeon Baek"],"pdf_url":"https://arxiv.org/pdf/2408.02295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02279v1","updated":"2024-08-05T07:26:47Z","published":"2024-08-05T07:26:47Z","title":"DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for\n  Long Time-Series Forecasting","summary":"  Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.\n","authors":["Ruixin Ding","Yuqi Chen","Yu-Ting Lan","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12592v2","updated":"2024-08-05T03:52:54Z","published":"2024-04-19T02:42:13Z","title":"Integer Programming for Learning Directed Acyclic Graphs from\n  Non-identifiable Gaussian Models","summary":"  We study the problem of learning directed acyclic graphs from continuous\nobservational data, generated according to a linear Gaussian structural\nequation model. State-of-the-art structure learning methods for this setting\nhave at least one of the following shortcomings: i) they cannot provide\noptimality guarantees and can suffer from learning sub-optimal models; ii) they\nrely on the stringent assumption that the noise is homoscedastic, and hence the\nunderlying model is fully identifiable. We overcome these shortcomings and\ndevelop a computationally efficient mixed-integer programming framework for\nlearning medium-sized problems that accounts for arbitrary heteroscedastic\nnoise. We present an early stopping criterion under which we can terminate the\nbranch-and-bound procedure to achieve an asymptotically optimal solution and\nestablish the consistency of this approximate solution. In addition, we show\nvia numerical experiments that our method outperforms state-of-the-art\nalgorithms and is robust to noise heteroscedasticity, whereas the performance\nof some competing methods deteriorates under strong violations of the\nidentifiability assumption. The software implementation of our method is\navailable as the Python package \\emph{micodag}.\n","authors":["Tong Xu","Armeen Taeb","Simge Küçükyavuz","Ali Shojaie"],"pdf_url":"https://arxiv.org/pdf/2404.12592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16020v4","updated":"2024-08-05T02:01:12Z","published":"2024-07-22T19:55:44Z","title":"Sparks of Quantum Advantage and Rapid Retraining in Machine Learning","summary":"  The advent of quantum computing holds the potential to revolutionize various\nfields by solving complex problems more efficiently than classical computers.\nDespite this promise, practical quantum advantage is hindered by current\nhardware limitations, notably the small number of qubits and high noise levels.\nIn this study, we leverage adiabatic quantum computers to optimize\nKolmogorov-Arnold Networks, a powerful neural network architecture for\nrepresenting complex functions with minimal parameters. By modifying the\nnetwork to use Bezier curves as the basis functions and formulating the\noptimization problem into a Quadratic Unconstrained Binary Optimization\nproblem, we create a fixed-sized solution space, independent of the number of\ntraining samples. This strategy allows for the optimization of an entire neural\nnetwork in a single training iteration in which, due to order of operations, a\nmajority of the processing is done using a collapsed version of the training\ndataset. This inherently creates extremely fast training speeds, which are\nvalidated experimentally, compared to classical optimizers including Adam,\nStochastic Gradient Descent, Adaptive Gradient, and simulated annealing.\nAdditionally, we introduce a novel rapid retraining capability, enabling the\nnetwork to be retrained with new data without reprocessing old samples, thus\nenhancing learning efficiency in dynamic environments. Experiments on\nretraining demonstrate a hundred times speed up using adiabatic quantum\ncomputing based optimization compared to that of the gradient descent based\noptimizers, with theoretical models allowing this speed up to be much larger!\nOur findings suggest that with further advancements in quantum hardware and\nalgorithm optimization, quantum-optimized machine learning models could have\nbroad applications across various domains, with initial focus on rapid\nretraining.\n","authors":["William Troy"],"pdf_url":"https://arxiv.org/pdf/2407.16020v4.pdf","comment":"Major updates to the paper for timings and explanations of\n  optimization strategies used. Further optimized the code and updated the\n  figures to reflect the faster timings for v3"},{"id":"http://arxiv.org/abs/2302.00857v2","updated":"2024-08-05T01:10:35Z","published":"2023-02-02T04:02:49Z","title":"Algorithm Design for Online Meta-Learning with Task Boundary Detection","summary":"  Online meta-learning has recently emerged as a marriage between batch\nmeta-learning and online learning, for achieving the capability of quick\nadaptation on new tasks in a lifelong manner. However, most existing approaches\nfocus on the restrictive setting where the distribution of the online tasks\nremains fixed with known task boundaries. In this work, we relax these\nassumptions and propose a novel algorithm for task-agnostic online\nmeta-learning in non-stationary environments. More specifically, we first\npropose two simple but effective detection mechanisms of task switches and\ndistribution shift based on empirical observations, which serve as a key\nbuilding block for more elegant online model updates in our algorithm: the task\nswitch detection mechanism allows reusing of the best model available for the\ncurrent task at hand, and the distribution shift detection mechanism\ndifferentiates the meta model update in order to preserve the knowledge for\nin-distribution tasks and quickly learn the new knowledge for\nout-of-distribution tasks. In particular, our online meta model updates are\nbased only on the current data, which eliminates the need of storing previous\ndata as required in most existing methods. We further show that a sublinear\ntask-averaged regret can be achieved for our algorithm under mild conditions.\nEmpirical studies on three different benchmarks clearly demonstrate the\nsignificant advantage of our algorithm over related baseline approaches.\n","authors":["Daouda Sow","Sen Lin","Yingbin Liang","Junshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00857v2.pdf","comment":"CPAL 2024"},{"id":"http://arxiv.org/abs/2405.18373v2","updated":"2024-08-05T22:25:10Z","published":"2024-05-28T17:11:34Z","title":"A Hessian-Aware Stochastic Differential Equation for Modelling SGD","summary":"  Continuous-time approximation of Stochastic Gradient Descent (SGD) is a\ncrucial tool to study its escaping behaviors from stationary points. However,\nexisting stochastic differential equation (SDE) models fail to fully capture\nthese behaviors, even for simple quadratic objectives. Built on a novel\nstochastic backward error analysis framework, we derive the Hessian-Aware\nStochastic Modified Equation (HA-SME), an SDE that incorporates Hessian\ninformation of the objective function into both its drift and diffusion terms.\nOur analysis shows that HA-SME matches the order-best approximation error\nguarantee among existing SDE models in the literature, while achieving a\nsignificantly reduced dependence on the smoothness parameter of the objective.\nFurther, for quadratic objectives, under mild conditions, HA-SME is proved to\nbe the first SDE model that recovers exactly the SGD dynamics in the\ndistributional sense. Consequently, when the local landscape near a stationary\npoint can be approximated by quadratics, HA-SME is expected to accurately\npredict the local escaping behaviors of SGD.\n","authors":["Xiang Li","Zebang Shen","Liang Zhang","Niao He"],"pdf_url":"https://arxiv.org/pdf/2405.18373v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02841v1","updated":"2024-08-05T21:35:51Z","published":"2024-08-05T21:35:51Z","title":"Evaluating Posterior Probabilities: Decision Theory, Proper Scoring\n  Rules, and Calibration","summary":"  Most machine learning classifiers are designed to output posterior\nprobabilities for the classes given the input sample. These probabilities may\nbe used to make the categorical decision on the class of the sample; provided\nas input to a downstream system; or provided to a human for interpretation.\nEvaluating the quality of the posteriors generated by these system is an\nessential problem which was addressed decades ago with the invention of proper\nscoring rules (PSRs). Unfortunately, much of the recent machine learning\nliterature uses calibration metrics -- most commonly, the expected calibration\nerror (ECE) -- as a proxy to assess posterior performance. The problem with\nthis approach is that calibration metrics reflect only one aspect of the\nquality of the posteriors, ignoring the discrimination performance. For this\nreason, we argue that calibration metrics should play no role in the assessment\nof posterior quality. Expected PSRs should instead be used for this job,\npreferably normalized for ease of interpretation. In this work, we first give a\nbrief review of PSRs from a practical perspective, motivating their definition\nusing Bayes decision theory. We discuss why expected PSRs provide a principled\nmeasure of the quality of a system's posteriors and why calibration metrics are\nnot the right tool for this job. We argue that calibration metrics, while not\nuseful for performance assessment, may be used as diagnostic tools during\nsystem development. With this purpose in mind, we discuss a simple and\npractical calibration metric, called calibration loss, derived from a\ndecomposition of expected PSRs. We compare this metric with the ECE and with\nthe expected score divergence calibration metric from the PSR literature and\nargue, using theoretical and empirical evidence, that calibration loss is\nsuperior to these two metrics.\n","authors":["Luciana Ferrer","Daniel Ramos"],"pdf_url":"https://arxiv.org/pdf/2408.02841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02839v1","updated":"2024-08-05T21:25:10Z","published":"2024-08-05T21:25:10Z","title":"Optimizing Cox Models with Stochastic Gradient Descent: Theoretical\n  Foundations and Practical Guidances","summary":"  Optimizing Cox regression and its neural network variants poses substantial\ncomputational challenges in large-scale studies. Stochastic gradient descent\n(SGD), known for its scalability in model optimization, has recently been\nadapted to optimize Cox models. Unlike its conventional application, which\ntypically targets a sum of independent individual loss, SGD for Cox models\nupdates parameters based on the partial likelihood of a subset of data. Despite\nits empirical success, the theoretical foundation for optimizing Cox partial\nlikelihood with SGD is largely underexplored. In this work, we demonstrate that\nthe SGD estimator targets an objective function that is batch-size-dependent.\nWe establish that the SGD estimator for the Cox neural network (Cox-NN) is\nconsistent and achieves the optimal minimax convergence rate up to a\npolylogarithmic factor. For Cox regression, we further prove the\n$\\sqrt{n}$-consistency and asymptotic normality of the SGD estimator, with\nvariance depending on the batch size. Furthermore, we quantify the impact of\nbatch size on Cox-NN training and its effect on the SGD estimator's asymptotic\nefficiency in Cox regression. These findings are validated by extensive\nnumerical experiments and provide guidance for selecting batch sizes in SGD\napplications. Finally, we demonstrate the effectiveness of SGD in a real-world\napplication where GD is unfeasible due to the large scale of data.\n","authors":["Lang Zeng","Weijing Tang","Zhao Ren","Ying Ding"],"pdf_url":"https://arxiv.org/pdf/2408.02839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02838v1","updated":"2024-08-05T21:22:36Z","published":"2024-08-05T21:22:36Z","title":"Interpretation of the Intent Detection Problem as Dynamics in a\n  Low-dimensional Space","summary":"  Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.\n","authors":["Eduardo Sanchez-Karhunen","Jose F. Quesada-Moreno","Miguel A. Gutiérrez-Naranjo"],"pdf_url":"https://arxiv.org/pdf/2408.02838v1.pdf","comment":"Camera-Ready version. Accepted paper at 27th European Conference on\n  Artificial Intelligence (ECAI-2024)"},{"id":"http://arxiv.org/abs/2408.02801v1","updated":"2024-08-05T19:38:45Z","published":"2024-08-05T19:38:45Z","title":"Sparse Deep Learning Models with the $\\ell_1$ Regularization","summary":"  Sparse neural networks are highly desirable in deep learning in reducing its\ncomplexity. The goal of this paper is to study how choices of regularization\nparameters influence the sparsity level of learned neural networks. We first\nderive the $\\ell_1$-norm sparsity-promoting deep learning models including\nsingle and multiple regularization parameters models, from a statistical\nviewpoint. We then characterize the sparsity level of a regularized neural\nnetwork in terms of the choice of the regularization parameters. Based on the\ncharacterizations, we develop iterative algorithms for selecting regularization\nparameters so that the weight parameters of the resulting deep neural network\nenjoy prescribed sparsity levels. Numerical experiments are presented to\ndemonstrate the effectiveness of the proposed algorithms in choosing desirable\nregularization parameters and obtaining corresponding neural networks having\nboth of predetermined sparsity levels and satisfactory approximation accuracy.\n","authors":["Lixin Shen","Rui Wang","Yuesheng Xu","Mingsong Yan"],"pdf_url":"https://arxiv.org/pdf/2408.02801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00761v4","updated":"2024-08-05T18:40:07Z","published":"2023-12-01T18:29:08Z","title":"Deep Unlearning: Fast and Efficient Gradient-free Approach to Class\n  Forgetting","summary":"  Machine unlearning is a prominent and challenging field, driven by regulatory\ndemands for user data deletion and heightened privacy awareness. Existing\napproaches involve retraining model or multiple finetuning steps for each\ndeletion request, often constrained by computational limits and restricted data\naccess. In this work, we introduce a novel class unlearning algorithm designed\nto strategically eliminate specific classes from the learned model. Our\nalgorithm first estimates the Retain and the Forget Spaces using Singular Value\nDecomposition on the layerwise activations for a small subset of samples from\nthe retain and unlearn classes, respectively. We then compute the shared\ninformation between these spaces and remove it from the forget space to isolate\nclass-discriminatory feature space. Finally, we obtain the unlearned model by\nupdating the weights to suppress the class discriminatory features from the\nactivation spaces. We demonstrate our algorithm's efficacy on ImageNet using a\nVision Transformer with only $\\sim 1.5\\%$ drop in retain accuracy compared to\nthe original model while maintaining under $1\\%$ accuracy on the unlearned\nclass samples. Furthermore, our algorithm exhibits competitive unlearning\nperformance and resilience against Membership Inference Attacks (MIA). Compared\nto baselines, it achieves an average accuracy improvement of $1.38\\%$ on the\nImageNet dataset while requiring up to $10 \\times$ fewer samples for\nunlearning. Additionally, under stronger MIA attacks on the CIFAR-100 dataset\nusing a ResNet18 architecture, our approach outperforms the best baseline by\n$1.8\\%$. Our code is available at\nhttps://github.com/sangamesh-kodge/class_forgetting.\n","authors":["Sangamesh Kodge","Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2312.00761v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02760v1","updated":"2024-08-05T18:24:09Z","published":"2024-08-05T18:24:09Z","title":"Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An\n  Improved ROCKET Algorithm for Multivariate Time Series Analysis","summary":"  Multivariate Time Series Classification (MTSC) is a ubiquitous problem in\nscience and engineering, particularly in neuroscience, where most data\nacquisition modalities involve the simultaneous time-dependent recording of\nbrain activity in multiple brain regions. In recent years, Random Convolutional\nKernel models such as ROCKET and MiniRocket have emerged as highly effective\ntime series classification algorithms, capable of achieving state-of-the-art\naccuracy results with low computational load. Despite their success, these\ntypes of models face two major challenges when employed in neuroscience: 1)\nthey struggle to deal with high-dimensional data such as EEG and MEG, and 2)\nthey are difficult to interpret. In this work, we present a novel ROCKET-based\nalgorithm, named Detach-Rocket Ensemble, that is specifically designed to\naddress these two problems in MTSC. Our algorithm leverages pruning to provide\nan integrated estimation of channel importance, and ensembles to achieve better\naccuracy and provide a label probability. Using a synthetic multivariate time\nseries classification dataset in which we control the amount of information\ncarried by each of the channels, we first show that our algorithm is able to\ncorrectly recover the channel importance for classification. Then, using two\nreal-world datasets, a MEG dataset and an EEG dataset, we show that\nDetach-Rocket Ensemble is able to provide both interpretable channel relevance\nand competitive classification accuracy, even when applied directly to the raw\nbrain data, without the need for feature engineering.\n","authors":["Adrià Solana","Erik Fransén","Gonzalo Uribarri"],"pdf_url":"https://arxiv.org/pdf/2408.02760v1.pdf","comment":"To be published in European Conference on Machine Learning and Data\n  Mining 2024, 20 pages, 7 figures, 2 tables"}]},"2024-08-04T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.02164v1","updated":"2024-08-04T23:21:46Z","published":"2024-08-04T23:21:46Z","title":"Rethinking Affect Analysis: A Protocol for Ensuring Fairness and\n  Consistency","summary":"  Evaluating affect analysis methods presents challenges due to inconsistencies\nin database partitioning and evaluation protocols, leading to unfair and biased\nresults. Previous studies claim continuous performance improvements, but our\nfindings challenge such assertions. Using these insights, we propose a unified\nprotocol for database partitioning that ensures fairness and comparability. We\nprovide detailed demographic annotations (in terms of race, gender and age),\nevaluation metrics, and a common framework for expression recognition, action\nunit detection and valence-arousal estimation. We also rerun the methods with\nthe new protocol and introduce a new leaderboards to encourage future research\nin affect recognition with a fairer comparison. Our annotations, code, and\npre-trained models are available on\n\\hyperlink{https://github.com/dkollias/Fair-Consistent-Affect-Analysis}{Github}.\n","authors":["Guanyu Hu","Dimitrios Kollias","Eleni Papadopoulou","Paraskevi Tzouveli","Jie Wei","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02164v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2405.06841"},{"id":"http://arxiv.org/abs/2408.02157v1","updated":"2024-08-04T22:23:10Z","published":"2024-08-04T22:23:10Z","title":"PanoFree: Tuning-Free Holistic Multi-view Image Generation with\n  Cross-view Self-Guidance","summary":"  Immersive scene generation, notably panorama creation, benefits significantly\nfrom the adaptation of large pre-trained text-to-image (T2I) models for\nmulti-view image generation. Due to the high cost of acquiring multi-view\nimages, tuning-free generation is preferred. However, existing methods are\neither limited to simple correspondences or require extensive fine-tuning to\ncapture complex ones. We present PanoFree, a novel method for tuning-free\nmulti-view image generation that supports an extensive array of\ncorrespondences. PanoFree sequentially generates multi-view images using\niterative warping and inpainting, addressing the key issues of inconsistency\nand artifacts from error accumulation without the need for fine-tuning. It\nimproves error accumulation by enhancing cross-view awareness and refines the\nwarping and inpainting processes via cross-view guidance, risky area estimation\nand erasing, and symmetric bidirectional guided generation for loop closure,\nalongside guidance-based semantic and density control for scene structure\npreservation. In experiments on Planar, 360{\\deg}, and Full Spherical\nPanoramas, PanoFree demonstrates significant error reduction, improves global\nconsistency, and boosts image quality without extra fine-tuning. Compared to\nexisting methods, PanoFree is up to 5x more efficient in time and 3x more\nefficient in GPU memory usage, and maintains superior diversity of results (2x\nbetter in our user study). PanoFree offers a viable alternative to costly\nfine-tuning or the use of additional pre-trained models. Project website at\nhttps://panofree.github.io/.\n","authors":["Aoming Liu","Zhong Li","Zhang Chen","Nannan Li","Yi Xu","Bryan A. Plummer"],"pdf_url":"https://arxiv.org/pdf/2408.02157v1.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2407.01996v3","updated":"2024-08-04T21:56:57Z","published":"2024-07-02T07:10:10Z","title":"ViG-Bias: Visually Grounded Bias Discovery and Mitigation","summary":"  The proliferation of machine learning models in critical decision making\nprocesses has underscored the need for bias discovery and mitigation\nstrategies. Identifying the reasons behind a biased system is not\nstraightforward, since in many occasions they are associated with hidden\nspurious correlations which are not easy to spot. Standard approaches rely on\nbias audits performed by analyzing model performance in pre-defined subgroups\nof data samples, usually characterized by common attributes like gender or\nethnicity when it comes to people, or other specific attributes defining\nsemantically coherent groups of images. However, it is not always possible to\nknow a-priori the specific attributes defining the failure modes of visual\nrecognition systems. Recent approaches propose to discover these groups by\nleveraging large vision language models, which enable the extraction of\ncross-modal embeddings and the generation of textual descriptions to\ncharacterize the subgroups where a certain model is underperforming. In this\nwork, we argue that incorporating visual explanations (e.g. heatmaps generated\nvia GradCAM or other approaches) can boost the performance of such bias\ndiscovery and mitigation frameworks. To this end, we introduce Visually\nGrounded Bias Discovery and Mitigation (ViG-Bias), a simple yet effective\ntechnique which can be integrated to a variety of existing frameworks to\nimprove both, discovery and mitigation performance. Our comprehensive\nevaluation shows that incorporating visual explanations enhances existing\ntechniques like DOMINO, FACTS and Bias-to-Text, across several challenging\ndatasets, including CelebA, Waterbirds, and NICO++.\n","authors":["Badr-Eddine Marani","Mohamed Hanini","Nihitha Malayarukil","Stergios Christodoulidis","Maria Vakalopoulou","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2407.01996v3.pdf","comment":"Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2408.02146v1","updated":"2024-08-04T21:09:09Z","published":"2024-08-04T21:09:09Z","title":"Video-based Pedestrian and Vehicle Traffic Analysis During Football\n  Games","summary":"  This paper utilizes video analytics to study pedestrian and vehicle traffic\nbehavior, focusing on analyzing traffic patterns during football gamedays. The\nUniversity of Florida (UF) hosts six to seven home football games on Saturdays\nduring the college football season, attracting significant pedestrian activity.\nThrough video analytics, this study provides valuable insights into the impact\nof these events on traffic volumes and safety at intersections. Comparing\npedestrian and vehicle activities on gamedays versus non-gamedays reveals\ndiffering patterns. For example, pedestrian volume substantially increases\nduring gamedays, which is positively correlated with the probability of the\naway team winning. This correlation is likely because fans of the home team\nenjoy watching difficult games. Win probabilities as an early predictor of\npedestrian volumes at intersections can be a tool to help traffic professionals\nanticipate traffic management needs. Pedestrian-to-vehicle (P2V) conflicts\nnotably increase on gamedays, particularly a few hours before games start.\nAddressing this, a \"Barnes Dance\" movement phase within the intersection is\nrecommended. Law enforcement presence during high-activity gamedays can help\nensure pedestrian compliance and enhance safety. In contrast, we identified\nthat vehicle-to-vehicle (V2V) conflicts generally do not increase on gamedays\nand may even decrease due to heightened driver caution.\n","authors":["Jacques P. Fleischer","Ryan Pallack","Ahan Mishra","Gustavo Riente de Andrade","Subhadipto Poddar","Emmanuel Posadas","Robert Schenck","Tania Banerjee","Anand Rangarajan","Sanjay Ranka"],"pdf_url":"https://arxiv.org/pdf/2408.02146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02140v1","updated":"2024-08-04T20:38:45Z","published":"2024-08-04T20:38:45Z","title":"VidModEx: Interpretable and Efficient Black Box Model Extraction for\n  High-Dimensional Spaces","summary":"  In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.\n","authors":["Somnath Sendhil Kumar","Yuvaraj Govindarajulu","Pavan Kulkarni","Manojkumar Parmar"],"pdf_url":"https://arxiv.org/pdf/2408.02140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02138v1","updated":"2024-08-04T20:35:33Z","published":"2024-08-04T20:35:33Z","title":"RICA^2: Rubric-Informed, Calibrated Assessment of Actions","summary":"  The ability to quantify how well an action is carried out, also known as\naction quality assessment (AQA), has attracted recent interest in the vision\ncommunity. Unfortunately, prior methods often ignore the score rubric used by\nhuman experts and fall short of quantifying the uncertainty of the model\nprediction. To bridge the gap, we present RICA^2 - a deep probabilistic model\nthat integrates score rubric and accounts for prediction uncertainty for AQA.\nCentral to our method lies in stochastic embeddings of action steps, defined on\na graph structure that encodes the score rubric. The embeddings spread\nprobabilistic density in the latent space and allow our method to represent\nmodel uncertainty. The graph encodes the scoring criteria, based on which the\nquality scores can be decoded. We demonstrate that our method establishes new\nstate of the art on public benchmarks, including FineDiving, MTL-AQA, and\nJIGSAWS, with superior performance in score prediction and uncertainty\ncalibration. Our code is available at https://abrarmajeedi.github.io/rica2_aqa/\n","authors":["Abrar Majeedi","Viswanatha Reddy Gajjala","Satya Sai Srinath Namburi GNVV","Yin Li"],"pdf_url":"https://arxiv.org/pdf/2408.02138v1.pdf","comment":"Accepted at European Conference on Computer Vision (ECCV) 2024"},{"id":"http://arxiv.org/abs/2408.02135v1","updated":"2024-08-04T20:12:38Z","published":"2024-08-04T20:12:38Z","title":"A First Look at Chebyshev-Sobolev Series for Digital Ink","summary":"  Considering digital ink as plane curves provides a valuable framework for\nvarious applications, including signature verification, note-taking, and\nmathematical handwriting recognition. These plane curves can be obtained as\nparameterized pairs of approximating truncated series (x(s), y(s)) determined\nby sampled points. Earlier work has found that representing these truncated\nseries (polynomials) in a Legendre or Legendre-Sobolev basis has a number of\ndesirable properties. These include compact data representation, meaningful\nclustering of like symbols in the vector space of polynomial coefficients,\nlinear separability of classes in this space, and highly efficient calculation\nof variation between curves. In this work, we take a first step at examining\nthe use of Chebyshev-Sobolev series for symbol recognition. The early\nindication is that this representation may be superior to Legendre-Sobolev\nrepresentation for some purposes.\n","authors":["Deepak Singh Kalhan","Stephen M. Watt"],"pdf_url":"https://arxiv.org/pdf/2408.02135v1.pdf","comment":"Accepted at MathUI 2024"},{"id":"http://arxiv.org/abs/2408.02123v1","updated":"2024-08-04T19:37:30Z","published":"2024-08-04T19:37:30Z","title":"FovEx: Human-inspired Explanations for Vision Transformers and\n  Convolutional Neural Networks","summary":"  Explainability in artificial intelligence (XAI) remains a crucial aspect for\nfostering trust and understanding in machine learning models. Current visual\nexplanation techniques, such as gradient-based or class-activation-based\nmethods, often exhibit a strong dependence on specific model architectures.\nConversely, perturbation-based methods, despite being model-agnostic, are\ncomputationally expensive as they require evaluating models on a large number\nof forward passes. In this work, we introduce Foveation-based Explanations\n(FovEx), a novel XAI method inspired by human vision. FovEx seamlessly\nintegrates biologically inspired perturbations by iteratively creating foveated\nrenderings of the image and combines them with gradient-based visual\nexplorations to determine locations of interest efficiently. These locations\nare selected to maximize the performance of the model to be explained with\nrespect to the downstream task and then combined to generate an attribution\nmap. We provide a thorough evaluation with qualitative and quantitative\nassessments on established benchmarks. Our method achieves state-of-the-art\nperformance on both transformers (on 4 out of 5 metrics) and convolutional\nmodels (on 3 out of 5 metrics), demonstrating its versatility among various\narchitectures. Furthermore, we show the alignment between the explanation map\nproduced by FovEx and human gaze patterns (+14\\% in NSS compared to RISE,\n+203\\% in NSS compared to GradCAM). This comparison enhances our confidence in\nFovEx's ability to close the interpretation gap between humans and machines.\n","authors":["Mahadev Prasad Panda","Matteo Tiezzi","Martina Vilas","Gemma Roig","Bjoern M. Eskofier","Dario Zanca"],"pdf_url":"https://arxiv.org/pdf/2408.02123v1.pdf","comment":"Under submission"},{"id":"http://arxiv.org/abs/2404.16845v2","updated":"2024-08-04T18:51:59Z","published":"2024-02-14T14:02:04Z","title":"HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring\n  Unconstrained Photo Collections","summary":"  Internet image collections containing photos captured by crowds of\nphotographers show promise for enabling digital exploration of large-scale\ntourist landmarks. However, prior works focus primarily on geometric\nreconstruction and visualization, neglecting the key role of language in\nproviding a semantic interface for navigation and fine-grained understanding.\nIn constrained 3D domains, recent methods have leveraged vision-and-language\nmodels as a strong prior of 2D visual semantics. While these models display an\nexcellent understanding of broad visual semantics, they struggle with\nunconstrained photo collections depicting such tourist landmarks, as they lack\nexpert knowledge of the architectural domain. In this work, we present a\nlocalization system that connects neural representations of scenes depicting\nlarge-scale landmarks with text describing a semantic region within the scene,\nby harnessing the power of SOTA vision-and-language models with adaptations for\nunderstanding landmark scene semantics. To bolster such models with\nfine-grained knowledge, we leverage large-scale Internet data containing images\nof similar landmarks along with weakly-related textual information. Our\napproach is built upon the premise that images physically grounded in space can\nprovide a powerful supervision signal for localizing new concepts, whose\nsemantics may be unlocked from Internet textual metadata with large language\nmodels. We use correspondences between views of scenes to bootstrap spatial\nunderstanding of these semantics, providing guidance for 3D-compatible\nsegmentation that ultimately lifts to a volumetric scene representation. Our\nresults show that HaLo-NeRF can accurately localize a variety of semantic\nconcepts related to architectural landmarks, surpassing the results of other 3D\nmodels as well as strong 2D segmentation baselines. Our project page is at\nhttps://tau-vailab.github.io/HaLo-NeRF/.\n","authors":["Chen Dudai","Morris Alper","Hana Bezalel","Rana Hanocka","Itai Lang","Hadar Averbuch-Elor"],"pdf_url":"https://arxiv.org/pdf/2404.16845v2.pdf","comment":"Eurographics 2024. Project page:\n  https://tau-vailab.github.io/HaLo-NeRF/"},{"id":"http://arxiv.org/abs/2408.02110v1","updated":"2024-08-04T18:41:35Z","published":"2024-08-04T18:41:35Z","title":"AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction\n  from Sparse Multi-view Videos","summary":"  Despite progress in human motion capture, existing multi-view methods often\nface challenges in estimating the 3D pose and shape of multiple closely\ninteracting people. This difficulty arises from reliance on accurate 2D joint\nestimations, which are hard to obtain due to occlusions and body contact when\npeople are in close interaction. To address this, we propose a novel method\nleveraging the personalized implicit neural avatar of each individual as a\nprior, which significantly improves the robustness and precision of this\nchallenging pose estimation task. Concretely, the avatars are efficiently\nreconstructed via layered volume rendering from sparse multi-view videos. The\nreconstructed avatar prior allows for the direct optimization of 3D poses based\non color and silhouette rendering loss, bypassing the issues associated with\nnoisy 2D detections. To handle interpenetration, we propose a collision loss on\nthe overlapping shape regions of avatars to add penetration constraints.\nMoreover, both 3D poses and avatars are optimized in an alternating manner. Our\nexperimental results demonstrate state-of-the-art performance on several public\ndatasets.\n","authors":["Feichi Lu","Zijian Dong","Jie Song","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2408.02110v1.pdf","comment":"Project Page: https://feichilu.github.io/AvatarPose/"},{"id":"http://arxiv.org/abs/2408.02100v1","updated":"2024-08-04T17:57:23Z","published":"2024-08-04T17:57:23Z","title":"View-consistent Object Removal in Radiance Fields","summary":"  Radiance Fields (RFs) have emerged as a crucial technology for 3D scene\nrepresentation, enabling the synthesis of novel views with remarkable realism.\nHowever, as RFs become more widely used, the need for effective editing\ntechniques that maintain coherence across different perspectives becomes\nevident. Current methods primarily depend on per-frame 2D image inpainting,\nwhich often fails to maintain consistency across views, thus compromising the\nrealism of edited RF scenes. In this work, we introduce a novel RF editing\npipeline that significantly enhances consistency by requiring the inpainting of\nonly a single reference image. This image is then projected across multiple\nviews using a depth-based approach, effectively reducing the inconsistencies\nobserved with per-frame inpainting. However, projections typically assume\nphotometric consistency across views, which is often impractical in real-world\nsettings. To accommodate realistic variations in lighting and viewpoint, our\npipeline adjusts the appearance of the projected views by generating multiple\ndirectional variants of the inpainted image, thereby adapting to different\nphotometric conditions. Additionally, we present an effective and robust\nmulti-view object segmentation approach as a valuable byproduct of our\npipeline. Extensive experiments demonstrate that our method significantly\nsurpasses existing frameworks in maintaining content consistency across views\nand enhancing visual quality. More results are available at\nhttps://vulab-ai.github.io/View-consistent_Object_Removal_in_Radiance_Fields.\n","authors":["Yiren Lu","Jing Ma","Yu Yin"],"pdf_url":"https://arxiv.org/pdf/2408.02100v1.pdf","comment":"Accepted to ACM Multimedia (MM) 2024. Project website is accessible\n  at\n  https://vulab-ai.github.io/View-consistent_Object_Removal_in_Radiance_Fields"},{"id":"http://arxiv.org/abs/2402.16033v2","updated":"2024-08-04T17:37:02Z","published":"2024-02-25T09:09:30Z","title":"Exploiting Regional Information Transformer for Single Image Deraining","summary":"  Transformer-based Single Image Deraining (SID) methods have achieved\nremarkable success, primarily attributed to their robust capability in\ncapturing long-range interactions. However, we've noticed that current methods\nhandle rain-affected and unaffected regions concurrently, overlooking the\ndisparities between these areas, resulting in confusion between rain streaks\nand background parts, and inabilities to obtain effective interactions,\nultimately resulting in suboptimal deraining outcomes. To address the above\nissue, we introduce the Region Transformer (Regformer), a novel SID method that\nunderlines the importance of independently processing rain-affected and\nunaffected regions while considering their combined impact for high-quality\nimage reconstruction. The crux of our method is the innovative Region\nTransformer Block (RTB), which integrates a Region Masked Attention (RMA)\nmechanism and a Mixed Gate Forward Block (MGFB). Our RTB is used for attention\nselection of rain-affected and unaffected regions and local modeling of mixed\nscales. The RMA generates attention maps tailored to these two regions and\ntheir interactions, enabling our model to capture comprehensive features\nessential for rain removal. To better recover high-frequency textures and\ncapture more local details, we develop the MGFB as a compensation module to\ncomplete local mixed scale modeling. Extensive experiments demonstrate that our\nmodel reaches state-of-the-art performance, significantly improving the image\nderaining quality. Our code and trained models are publicly available.\n","authors":["Baiang Li","Zhao Zhang","Huan Zheng","Xiaogang Xu","Yanyan Wei","Jingyi Zhang","Jicong Fan","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2402.16033v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02091v1","updated":"2024-08-04T17:00:37Z","published":"2024-08-04T17:00:37Z","title":"Past Movements-Guided Motion Representation Learning for Human Motion\n  Prediction","summary":"  Human motion prediction based on 3D skeleton is a significant challenge in\ncomputer vision, primarily focusing on the effective representation of motion.\nIn this paper, we propose a self-supervised learning framework designed to\nenhance motion representation. This framework consists of two stages: first,\nthe network is pretrained through the self-reconstruction of past sequences,\nand the guided reconstruction of future sequences based on past movements. We\ndesign a velocity-based mask strategy to focus on the joints with large-scale\nmoving. Subsequently, the pretrained network undergoes finetuning for specific\ntasks. Self-reconstruction, guided by patterns of past motion, substantially\nimproves the model's ability to represent the spatiotemporal relationships\namong joints but also captures the latent relationships between past and future\nsequences. This capability is crucial for motion prediction tasks that solely\ndepend on historical motion data. By employing this straightforward yet\neffective training paradigm, our method outperforms existing\n\\textit{state-of-the-art} methods, reducing the average prediction errors by\n8.8\\% across Human3.6M, 3DPW, and AMASS datasets. The code is available at\nhttps://github.com/JunyuShi02/PMG-MRL.\n","authors":["Junyu Shi","Baoxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02091v1.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.02088v1","updated":"2024-08-04T16:54:49Z","published":"2024-08-04T16:54:49Z","title":"KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for\n  autonomous driving","summary":"  Accurate 3D object detection in autonomous driving is critical yet\nchallenging due to occlusions, varying object scales, and complex urban\nenvironments. This paper introduces the RCBEV-KAN algorithm, a pioneering\nmethod designed to enhance 3D object detection by fusing multimodal sensor data\nfrom cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View\n(BEV)-based approach, utilizing a Transformer architecture, significantly\nboosts detection precision and efficiency by seamlessly integrating diverse\ndata sources, improving spatial relationship handling, and optimizing\ncomputational processes. Experimental results show that the RCBEV-KAN model\ndemonstrates superior performance across most detection categories, achieving\nhigher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score\n(0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8%\nfaster). These results indicate that RCBEV-KAN is more accurate, reliable, and\nefficient, making it ideal for dynamic and challenging autonomous driving\nenvironments.\n","authors":["Zhihao Lai","Chuanhao Liu","Shihui Sheng","Zhiqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02085v1","updated":"2024-08-04T16:50:07Z","published":"2024-08-04T16:50:07Z","title":"Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data\n  Assessment and Selection for Instruction Tuning of Language Models","summary":"  Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering.\n","authors":["Yulei Qin","Yuncheng Yang","Pengcheng Guo","Gang Li","Hang Shao","Yuchen Shi","Zihan Xu","Yun Gu","Ke Li","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02085v1.pdf","comment":"review, survey, 28 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2405.14584v2","updated":"2024-08-04T16:26:10Z","published":"2024-05-23T13:55:11Z","title":"SE3D: A Framework For Saliency Method Evaluation In 3D Imaging","summary":"  For more than a decade, deep learning models have been dominating in various\n2D imaging tasks. Their application is now extending to 3D imaging, with 3D\nConvolutional Neural Networks (3D CNNs) being able to process LIDAR, MRI, and\nCT scans, with significant implications for fields such as autonomous driving\nand medical imaging. In these critical settings, explaining the model's\ndecisions is fundamental. Despite recent advances in Explainable Artificial\nIntelligence, however, little effort has been devoted to explaining 3D CNNs,\nand many works explain these models via inadequate extensions of 2D saliency\nmethods.\n  A fundamental limitation to the development of 3D saliency methods is the\nlack of a benchmark to quantitatively assess these on 3D data. To address this\nissue, we propose SE3D: a framework for Saliency method Evaluation in 3D\nimaging. We propose modifications to ShapeNet, ScanNet, and BraTS datasets, and\nevaluation metrics to assess saliency methods for 3D CNNs. We evaluate both\nstate-of-the-art saliency methods designed for 3D data and extensions of\npopular 2D saliency methods to 3D. Our experiments show that 3D saliency\nmethods do not provide explanations of sufficient quality, and that there is\nmargin for future improvements and safer applications of 3D CNNs in critical\nfields.\n","authors":["Mariusz Wiśniewski","Loris Giulivi","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2405.14584v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02079v1","updated":"2024-08-04T16:09:46Z","published":"2024-08-04T16:09:46Z","title":"Improving Neural Surface Reconstruction with Feature Priors from\n  Multi-View Image","summary":"  Recent advancements in Neural Surface Reconstruction (NSR) have significantly\nimproved multi-view reconstruction when coupled with volume rendering. However,\nrelying solely on photometric consistency in image space falls short of\naddressing complexities posed by real-world data, including occlusions and\nnon-Lambertian surfaces. To tackle these challenges, we propose an\ninvestigation into feature-level consistent loss, aiming to harness valuable\nfeature priors from diverse pretext visual tasks and overcome current\nlimitations. It is crucial to note the existing gap in determining the most\neffective pretext visual task for enhancing NSR. In this study, we\ncomprehensively explore multi-view feature priors from seven pretext visual\ntasks, comprising thirteen methods. Our main goal is to strengthen NSR training\nby considering a wide range of possibilities. Additionally, we examine the\nimpact of varying feature resolutions and evaluate both pixel-wise and\npatch-wise consistent losses, providing insights into effective strategies for\nimproving NSR performance. By incorporating pre-trained representations from\nMVSFormer and QuadTree, our approach can generate variations of MVS-NeuS and\nMatch-NeuS, respectively. Our results, analyzed on DTU and EPFL datasets,\nreveal that feature priors from image matching and multi-view stereo outperform\nother pretext tasks. Moreover, we discover that extending patch-wise\nphotometric consistency to the feature level surpasses the performance of\npixel-wise approaches. These findings underscore the effectiveness of these\ntechniques in enhancing NSR outcomes.\n","authors":["Xinlin Ren","Chenjie Cao","Yanwei Fu","Xiangyang Xue"],"pdf_url":"https://arxiv.org/pdf/2408.02079v1.pdf","comment":"ECCV2024"},{"id":"http://arxiv.org/abs/2408.02078v1","updated":"2024-08-04T16:09:04Z","published":"2024-08-04T16:09:04Z","title":"LDFaceNet: Latent Diffusion-based Network for High-Fidelity Deepfake\n  Generation","summary":"  Over the past decade, there has been tremendous progress in the domain of\nsynthetic media generation. This is mainly due to the powerful methods based on\ngenerative adversarial networks (GANs). Very recently, diffusion probabilistic\nmodels, which are inspired by non-equilibrium thermodynamics, have taken the\nspotlight. In the realm of image generation, diffusion models (DMs) have\nexhibited remarkable proficiency in producing both realistic and heterogeneous\nimagery through their stochastic sampling procedure. This paper proposes a\nnovel facial swapping module, termed as LDFaceNet (Latent Diffusion based Face\nSwapping Network), which is based on a guided latent diffusion model that\nutilizes facial segmentation and facial recognition modules for a conditioned\ndenoising process. The model employs a unique loss function to offer\ndirectional guidance to the diffusion process. Notably, LDFaceNet can\nincorporate supplementary facial guidance for desired outcomes without any\nretraining. To the best of our knowledge, this represents the first application\nof the latent diffusion model in the face-swapping task without prior training.\nThe results of this study demonstrate that the proposed method can generate\nextremely realistic and coherent images by leveraging the potential of the\ndiffusion model for facial swapping, thereby yielding superior visual outcomes\nand greater diversity.\n","authors":["Dwij Mehta","Aditya Mehta","Pratik Narang"],"pdf_url":"https://arxiv.org/pdf/2408.02078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19735v2","updated":"2024-08-04T15:38:41Z","published":"2024-05-30T06:31:03Z","title":"Twin Deformable Point Convolutions for Point Cloud Semantic Segmentation\n  in Remote Sensing Scenes","summary":"  Thanks to the application of deep learning technology in point cloud\nprocessing of the remote sensing field, point cloud segmentation has become a\nresearch hotspot in recent years, which can be applied to real-world 3D, smart\ncities, and other fields. Although existing solutions have made unprecedented\nprogress, they ignore the inherent characteristics of point clouds in remote\nsensing fields that are strictly arranged according to latitude, longitude, and\naltitude, which brings great convenience to the segmentation of point clouds in\nremote sensing fields. To consider this property cleverly, we propose novel\nconvolution operators, termed Twin Deformable point Convolutions (TDConvs),\nwhich aim to achieve adaptive feature learning by learning deformable sampling\npoints in the latitude-longitude plane and altitude direction, respectively.\nFirst, to model the characteristics of the latitude-longitude plane, we propose\na Cylinder-wise Deformable point Convolution (CyDConv) operator, which\ngenerates a two-dimensional cylinder map by constructing a cylinder-like grid\nin the latitude-longitude direction. Furthermore, to better integrate the\nfeatures of the latitude-longitude plane and the spatial geometric features, we\nperform a multi-scale fusion of the extracted latitude-longitude features and\nspatial geometric features, and realize it through the aggregation of adjacent\npoint features of different scales. In addition, a Sphere-wise Deformable point\nConvolution (SpDConv) operator is introduced to adaptively offset the sampling\npoints in three-dimensional space by constructing a sphere grid structure,\naiming at modeling the characteristics in the altitude direction. Experiments\non existing popular benchmarks conclude that our TDConvs achieve the best\nsegmentation performance, surpassing the existing state-of-the-art methods.\n","authors":["Yong-Qiang Mao","Hanbo Bi","Xuexue Li","Kaiqiang Chen","Zhirui Wang","Xian Sun","Kun Fu"],"pdf_url":"https://arxiv.org/pdf/2405.19735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16252v2","updated":"2024-08-04T15:27:28Z","published":"2024-07-23T07:40:41Z","title":"LawLuo: A Chinese Law Firm Co-run by LLM Agents","summary":"  Large Language Models (LLMs) demonstrate substantial potential in delivering\nlegal consultation services to users without a legal background, attributed to\ntheir superior text comprehension and generation capabilities. Nonetheless,\nexisting Chinese legal LLMs limit interaction to a single model-user dialogue,\nunlike the collaborative consultations typical of law firms, where multiple\nstaff members contribute to a single consultation. This limitation prevents an\nauthentic consultation experience. Additionally, extant Chinese legal LLMs\nsuffer from critical limitations: (1) insufficient control over the quality of\ninstruction fine-tuning data; (2) increased model hallucination resulting from\nusers' ambiguous queries; and (3) a reduction in the model's ability to follow\ninstructions over multiple dialogue turns. In response to these challenges, we\npropose a novel legal dialogue framework that leverages the collaborative\ncapabilities of multiple LLM agents, termed LawLuo. This framework encompasses\nfour agents: a receptionist, a lawyer, a secretary, and a boss, each\nresponsible for different functionalities, collaboratively providing a\ncomprehensive legal consultation to users. Additionally, we constructed two\nhigh-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned\nChatGLM-3-6b using these datasets. We propose a legal query clarification\nalgorithm called ToLC. Experimental results demonstrate that LawLuo outperforms\nbaseline LLMs, including GPT-4, across three dimensions: lawyer-like language\nstyle, the usefulness of legal advice, and the accuracy of legal knowledge. Our\ncode and datasets are available at https://github.com/NEFUJing/LawLuo.\n","authors":["Jingyun Sun","Chengxiao Dai","Zhongze Luo","Yangbo Chang","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2407.16252v2.pdf","comment":"11 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2408.02061v1","updated":"2024-08-04T15:20:39Z","published":"2024-08-04T15:20:39Z","title":"ParkingE2E: Camera-based End-to-end Parking Network, from Images to\n  Planning","summary":"  Autonomous parking is a crucial task in the intelligent driving field.\nTraditional parking algorithms are usually implemented using rule-based\nschemes. However, these methods are less effective in complex parking scenarios\ndue to the intricate design of the algorithms. In contrast,\nneural-network-based methods tend to be more intuitive and versatile than the\nrule-based methods. By collecting a large number of expert parking trajectory\ndata and emulating human strategy via learning-based methods, the parking task\ncan be effectively addressed. In this paper, we employ imitation learning to\nperform end-to-end planning from RGB images to path planning by imitating human\ndriving trajectories. The proposed end-to-end approach utilizes a target query\nencoder to fuse images and target features, and a transformer-based decoder to\nautoregressively predict future waypoints. We conducted extensive experiments\nin real-world scenarios, and the results demonstrate that the proposed method\nachieved an average parking success rate of 87.8% across four different\nreal-world garages. Real-vehicle experiments further validate the feasibility\nand effectiveness of the method proposed in this paper.\n","authors":["Changze Li","Ziheng Ji","Zhe Chen","Tong Qin","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02054v1","updated":"2024-08-04T15:01:23Z","published":"2024-08-04T15:01:23Z","title":"Step Saver: Predicting Minimum Denoising Steps for Diffusion Model Image\n  Generation","summary":"  In this paper, we introduce an innovative NLP model specifically fine-tuned\nto determine the minimal number of denoising steps required for any given text\nprompt. This advanced model serves as a real-time tool that recommends the\nideal denoise steps for generating high-quality images efficiently. It is\ndesigned to work seamlessly with the Diffusion model, ensuring that images are\nproduced with superior quality in the shortest possible time. Although our\nexplanation focuses on the DDIM scheduler, the methodology is adaptable and can\nbe applied to various other schedulers like Euler, Euler Ancestral, Heun, DPM2\nKarras, UniPC, and more. This model allows our customers to conserve costly\ncomputing resources by executing the fewest necessary denoising steps to\nachieve optimal quality in the produced images.\n","authors":["Jean Yu","Haim Barad"],"pdf_url":"https://arxiv.org/pdf/2408.02054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02053v1","updated":"2024-08-04T15:01:16Z","published":"2024-08-04T15:01:16Z","title":"PanicleNeRF: low-cost, high-precision in-field phenotypingof rice\n  panicles with smartphone","summary":"  The rice panicle traits significantly influence grain yield, making them a\nprimary target for rice phenotyping studies. However, most existing techniques\nare limited to controlled indoor environments and difficult to capture the rice\npanicle traits under natural growth conditions. Here, we developed PanicleNeRF,\na novel method that enables high-precision and low-cost reconstruction of rice\npanicle three-dimensional (3D) models in the field using smartphone. The\nproposed method combined the large model Segment Anything Model (SAM) and the\nsmall model You Only Look Once version 8 (YOLOv8) to achieve high-precision\nsegmentation of rice panicle images. The NeRF technique was then employed for\n3D reconstruction using the images with 2D segmentation. Finally, the resulting\npoint clouds are processed to successfully extract panicle traits. The results\nshow that PanicleNeRF effectively addressed the 2D image segmentation task,\nachieving a mean F1 Score of 86.9% and a mean Intersection over Union (IoU) of\n79.8%, with nearly double the boundary overlap (BO) performance compared to\nYOLOv8. As for point cloud quality, PanicleNeRF significantly outperformed\ntraditional SfM-MVS (structure-from-motion and multi-view stereo) methods, such\nas COLMAP and Metashape. The panicle length was then accurately extracted with\nthe rRMSE of 2.94% for indica and 1.75% for japonica rice. The panicle volume\nestimated from 3D point clouds strongly correlated with the grain number (R2 =\n0.85 for indica and 0.82 for japonica) and grain mass (0.80 for indica and 0.76\nfor japonica). This method provides a low-cost solution for high-throughput\nin-field phenotyping of rice panicles, accelerating the efficiency of rice\nbreeding.\n","authors":["Xin Yang","Xuqi Lu","Pengyao Xie","Ziyue Guo","Hui Fang","Haowei Fu","Xiaochun Hu","Zhenbiao Sun","Haiyan Cen"],"pdf_url":"https://arxiv.org/pdf/2408.02053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02052v1","updated":"2024-08-04T15:00:22Z","published":"2024-08-04T15:00:22Z","title":"EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier\n  Logits","summary":"  In Few-Shot Learning (FSL), models are trained to recognise unseen objects\nfrom a query set, given a few labelled examples from a support set. In standard\nFSL, models are evaluated on query instances sampled from the same class\ndistribution of the support set. In this work, we explore the more nuanced and\npractical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard\nFSL, OSFSL incorporates unknown classes into the query set, thereby requiring\nthe model not only to classify known classes but also to identify outliers.\nBuilding on the groundwork laid by previous studies, we define a novel\ntransductive inference technique that leverages the InfoMax principle to\nexploit the unlabelled query set. We called our approach the Enhanced Outlier\nLogit (EOL) method. EOL refines class prototype representations through model\ncalibration, effectively balancing the inlier-outlier ratio. This calibration\nenhances pseudo-label accuracy for the query set and improves the optimisation\nobjective within the transductive inference process. We provide a comprehensive\nempirical evaluation demonstrating that EOL consistently surpasses traditional\nmethods, recording performance improvements ranging from approximately $+1.3%$\nto $+6.3%$ across a variety of classification and outlier detection metrics and\nbenchmarks, even in the presence of inlier-outlier imbalance.\n","authors":["Mateusz Ochal","Massimiliano Patacchiola","Malik Boudiaf","Sen Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02052v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2408.02049v1","updated":"2024-08-04T14:57:28Z","published":"2024-08-04T14:57:28Z","title":"3D Single-object Tracking in Point Clouds with High Temporal Variation","summary":"  The high temporal variation of the point clouds is the key challenge of 3D\nsingle-object tracking (3D SOT). Existing approaches rely on the assumption\nthat the shape variation of the point clouds and the motion of the objects\nacross neighboring frames are smooth, failing to cope with high temporal\nvariation data. In this paper, we present a novel framework for 3D SOT in point\nclouds with high temporal variation, called HVTrack. HVTrack proposes three\nnovel components to tackle the challenges in the high temporal variation\nscenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud\nshape variations; 2) a Base-Expansion Feature Cross-Attention module to deal\nwith similar object distractions in expanded search areas; 3) a Contextual\nPoint Guided Self-Attention module for suppressing heavy background noise. We\nconstruct a dataset with high temporal variation (KITTI-HV) by setting\ndifferent frame intervals for sampling in the KITTI dataset. On the KITTI-HV\nwith 5 frame intervals, our HVTrack surpasses the state-of-the-art tracker\nCXTracker by 11.3%/15.7% in Success/Precision.\n","authors":["Qiao Wu","Kun Sun","Pei An","Mathieu Salzmann","Yanning Zhang","Jiaqi Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02049v1.pdf","comment":"Accepted by ECCV24"},{"id":"http://arxiv.org/abs/2408.02043v1","updated":"2024-08-04T14:30:14Z","published":"2024-08-04T14:30:14Z","title":"Deep Spectral Methods for Unsupervised Ultrasound Image Interpretation","summary":"  Ultrasound imaging is challenging to interpret due to non-uniform\nintensities, low contrast, and inherent artifacts, necessitating extensive\ntraining for non-specialists. Advanced representation with clear tissue\nstructure separation could greatly assist clinicians in mapping underlying\nanatomy and distinguishing between tissue layers. Decomposing an image into\nsemantically meaningful segments is mainly achieved using supervised\nsegmentation algorithms. Unsupervised methods are beneficial, as acquiring\nlarge labeled datasets is difficult and costly, but despite their advantages,\nthey still need to be explored in ultrasound. This paper proposes a novel\nunsupervised deep learning strategy tailored to ultrasound to obtain easily\ninterpretable tissue separations. We integrate key concepts from unsupervised\ndeep spectral methods, which combine spectral graph theory with deep learning\nmethods. We utilize self-supervised transformer features for spectral\nclustering to generate meaningful segments based on ultrasound-specific metrics\nand shape and positional priors, ensuring semantic consistency across the\ndataset. We evaluate our unsupervised deep learning strategy on three\nultrasound datasets, showcasing qualitative results across anatomical contexts\nwithout label requirements. We also conduct a comparative analysis against\nother clustering algorithms to demonstrate superior segmentation performance,\nboundary preservation, and label consistency.\n","authors":["Oleksandra Tmenova","Yordanka Velikova","Mahdi Saleh","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2408.02043v1.pdf","comment":"Accepted at International Conference on Medical Image Computing and\n  Computer Assisted Intervention, MICCAI 2024"},{"id":"http://arxiv.org/abs/2408.02039v1","updated":"2024-08-04T14:14:54Z","published":"2024-08-04T14:14:54Z","title":"Pixel-Level Domain Adaptation: A New Perspective for Enhancing Weakly\n  Supervised Semantic Segmentation","summary":"  Recent attention has been devoted to the pursuit of learning semantic\nsegmentation models exclusively from image tags, a paradigm known as\nimage-level Weakly Supervised Semantic Segmentation (WSSS). Existing attempts\nadopt the Class Activation Maps (CAMs) as priors to mine object regions yet\nobserve the imbalanced activation issue, where only the most discriminative\nobject parts are located. In this paper, we argue that the distribution\ndiscrepancy between the discriminative and the non-discriminative parts of\nobjects prevents the model from producing complete and precise pseudo masks as\nground truths. For this purpose, we propose a Pixel-Level Domain Adaptation\n(PLDA) method to encourage the model in learning pixel-wise domain-invariant\nfeatures. Specifically, a multi-head domain classifier trained adversarially\nwith the feature extraction is introduced to promote the emergence of pixel\nfeatures that are invariant with respect to the shift between the source (i.e.,\nthe discriminative object parts) and the target (\\textit{i.e.}, the\nnon-discriminative object parts) domains. In addition, we come up with a\nConfident Pseudo-Supervision strategy to guarantee the discriminative ability\nof each pixel for the segmentation task, which serves as a complement to the\nintra-image domain adversarial training. Our method is conceptually simple,\nintuitive and can be easily integrated into existing WSSS methods. Taking\nseveral strong baseline models as instances, we experimentally demonstrate the\neffectiveness of our approach under a wide range of settings.\n","authors":["Ye Du","Zehua Fu","Qingjie Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02039v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.02036v1","updated":"2024-08-04T14:07:14Z","published":"2024-08-04T14:07:14Z","title":"LEGO: Self-Supervised Representation Learning for Scene Text Images","summary":"  In recent years, significant progress has been made in scene text recognition\nby data-driven methods. However, due to the scarcity of annotated real-world\ndata, the training of these methods predominantly relies on synthetic data. The\ndistribution gap between synthetic and real data constrains the further\nperformance improvement of these methods in real-world applications. To tackle\nthis problem, a highly promising approach is to utilize massive amounts of\nunlabeled real data for self-supervised training, which has been widely proven\neffective in many NLP and CV tasks. Nevertheless, generic self-supervised\nmethods are unsuitable for scene text images due to their sequential nature. To\naddress this issue, we propose a Local Explicit and Global Order-aware\nself-supervised representation learning method (LEGO) that accounts for the\ncharacteristics of scene text images. Inspired by the human cognitive process\nof learning words, which involves spelling, reading, and writing, we propose\nthree novel pre-text tasks for LEGO to model sequential, semantic, and\nstructural features, respectively. The entire pre-training process is optimized\nby using a consistent Text Knowledge Codebook. Extensive experiments validate\nthat LEGO outperforms previous scene text self-supervised methods. The\nrecognizer incorporated with our pre-trained model achieves superior or\ncomparable performance compared to state-of-the-art scene text recognition\nmethods on six benchmarks. Furthermore, we demonstrate that LEGO can achieve\nsuperior performance in other text-related tasks.\n","authors":["Yujin Ren","Jiaxin Zhang","Lianwen Jin"],"pdf_url":"https://arxiv.org/pdf/2408.02036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02034v1","updated":"2024-08-04T13:55:58Z","published":"2024-08-04T13:55:58Z","title":"Mini-Monkey: Alleviate the Sawtooth Effect by Multi-Scale Adaptive\n  Cropping","summary":"  Recently, there has been significant interest in enhancing the capability of\nmultimodal large language models (MLLMs) to process high-resolution images.\nMost existing methods focus on adopting a cropping strategy to improve the\nability of multimodal large language models to understand image details.\nHowever, this cropping operation inevitably causes the segmentation of objects\nand connected areas, which impairs the MLLM's ability to recognize small or\nirregularly shaped objects or text. This issue is particularly evident in\nlightweight MLLMs. Addressing this issue, we propose Mini-Monkey, a lightweight\nMLLM that incorporates a plug-and-play method called multi-scale adaptive crop\nstrategy (MSAC). Mini-Monkey adaptively generates multi-scale representations,\nallowing it to select non-segmented objects from various scales. To mitigate\nthe computational overhead introduced by MSAC, we propose a Scale Compression\nMechanism (SCM), which effectively compresses image tokens. Mini-Monkey\nachieves state-of-the-art performance among 2B-parameter MLLMs. It not only\ndemonstrates leading performance on a variety of general multimodal\nunderstanding tasks but also shows consistent improvements in document\nunderstanding capabilities. On the OCRBench, Mini-Monkey achieves a score of\n802, outperforming 8B-parameter state-of-the-art model InternVL2-8B. Besides,\nour model and training strategy are very efficient, which can be trained with\nonly eight RTX 3090. The code is available at\nhttps://github.com/Yuliang-Liu/Monkey.\n","authors":["Mingxin Huang","Yuliang Liu","Dingkang Liang","Lianwen Jin","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2408.02034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02033v1","updated":"2024-08-04T13:51:18Z","published":"2024-08-04T13:51:18Z","title":"Enhancing Human Action Recognition and Violence Detection Through Deep\n  Learning Audiovisual Fusion","summary":"  This paper proposes a hybrid fusion-based deep learning approach based on two\ndifferent modalities, audio and video, to improve human activity recognition\nand violence detection in public places. To take advantage of audiovisual\nfusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning\n(HFBDL) are used and compared. Since the objective is to detect and recognize\nhuman violence in public places, Real-life violence situation (RLVS) dataset is\nexpanded and used. Simulating results of HFBDL show 96.67\\% accuracy on\nvalidation data, which is more accurate than the other state-of-the-art methods\non this dataset. To showcase our model's ability in real-world scenarios,\nanother dataset of 54 sounded videos of both violent and non-violent situations\nwas recorded. The model could successfully detect 52 out of 54 videos\ncorrectly. The proposed method shows a promising performance on real scenarios.\nThus, it can be used for human action recognition and violence detection in\npublic places for security purposes.\n","authors":["Pooya Janani","Amirabolfazl Suratgar","Afshin Taghvaeipour"],"pdf_url":"https://arxiv.org/pdf/2408.02033v1.pdf","comment":"This work has been submitted to the IEEE for possible publication, 10\n  pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.02032v1","updated":"2024-08-04T13:50:17Z","published":"2024-08-04T13:50:17Z","title":"Self-Introspective Decoding: Alleviating Hallucinations for Large\n  Vision-Language Models","summary":"  While Large Vision-Language Models (LVLMs) have rapidly advanced in recent\nyears, the prevalent issue known as the `hallucination' problem has emerged as\na significant bottleneck, hindering their real-world deployments. Existing\nmethods mitigate this issue mainly from two perspectives: One approach\nleverages extra knowledge like robust instruction tuning LVLMs with curated\ndatasets or employing auxiliary analysis networks, which inevitable incur\nadditional costs. Another approach, known as contrastive decoding, induces\nhallucinations by manually disturbing the vision or instruction raw inputs and\nmitigates them by contrasting the outputs of the disturbed and original LVLMs.\nHowever, these approaches rely on empirical holistic input disturbances and\ndouble the inference cost. To avoid these issues, we propose a simple yet\neffective method named Self-Introspective Decoding (SID). Our empirical\ninvestigation reveals that pretrained LVLMs can introspectively assess the\nimportance of vision tokens based on preceding vision and text (both\ninstruction and generated) tokens. We develop the Context and Text-aware Token\nSelection (CT2S) strategy, which preserves only unimportant vision tokens after\nearly layers of LVLMs to adaptively amplify text-informed hallucination during\nthe auto-regressive decoding. This approach ensures that multimodal knowledge\nabsorbed in the early layers induces multimodal contextual rather than aimless\nhallucinations. Subsequently, the original token logits subtract the amplified\nvision-and-text association hallucinations, guiding LVLMs decoding faithfully.\nExtensive experiments illustrate SID generates less-hallucination and\nhigher-quality texts across various metrics, without extra knowledge and much\nadditional computation burdens.\n","authors":["Fushuo Huo","Wenchao Xu","Zhong Zhang","Haozhao Wang","Zhicheng Chen","Peilin Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.02032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02024v1","updated":"2024-08-04T13:23:18Z","published":"2024-08-04T13:23:18Z","title":"Faster Diffusion Action Segmentation","summary":"  Temporal Action Segmentation (TAS) is an essential task in video analysis,\naiming to segment and classify continuous frames into distinct action segments.\nHowever, the ambiguous boundaries between actions pose a significant challenge\nfor high-precision segmentation. Recent advances in diffusion models have\ndemonstrated substantial success in TAS tasks due to their stable training\nprocess and high-quality generation capabilities. However, the heavy sampling\nsteps required by diffusion models pose a substantial computational burden,\nlimiting their practicality in real-time applications. Additionally, most\nrelated works utilize Transformer-based encoder architectures. Although these\narchitectures excel at capturing long-range dependencies, they incur high\ncomputational costs and face feature-smoothing issues when processing long\nvideo sequences. To address these challenges, we propose EffiDiffAct, an\nefficient and high-performance TAS algorithm. Specifically, we develop a\nlightweight temporal feature encoder that reduces computational overhead and\nmitigates the rank collapse phenomenon associated with traditional\nself-attention mechanisms. Furthermore, we introduce an adaptive skip strategy\nthat allows for dynamic adjustment of timestep lengths based on computed\nsimilarity metrics during inference, thereby further enhancing computational\nefficiency. Comprehensive experiments on the 50Salads, Breakfast, and GTEA\ndatasets demonstrated the effectiveness of the proposed algorithm.\n","authors":["Shuaibing Wang","Shunli Wang","Mingcheng Li","Dingkang Yang","Haopeng Kuang","Ziyun Qian","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02024v1.pdf","comment":"25 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.02018v1","updated":"2024-08-04T13:09:06Z","published":"2024-08-04T13:09:06Z","title":"Individualized multi-horizon MRI trajectory prediction for Alzheimer's\n  Disease","summary":"  Neurodegeneration as measured through magnetic resonance imaging (MRI) is\nrecognized as a potential biomarker for diagnosing Alzheimer's disease (AD),\nbut is generally considered less specific than amyloid or tau based biomarkers.\nDue to a large amount of variability in brain anatomy between different\nindividuals, we hypothesize that leveraging MRI time series can help improve\nspecificity, by treating each patient as their own baseline. Here we turn to\nconditional variational autoencoders to generate individualized MRI predictions\ngiven the subject's age, disease status and one previous scan. Using serial\nimaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a\nnovel architecture to build a latent space distribution which can be sampled\nfrom to generate future predictions of changing anatomy. This enables us to\nextrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated\nthe model on a held-out set from ADNI and an independent dataset (from Open\nAccess Series of Imaging Studies). By comparing to several alternatives, we\nshow that our model produces more individualized images with higher resolution.\nFurther, if an individual already has a follow-up MRI, we demonstrate a usage\nof our model to compute a likelihood ratio classifier for disease status. In\npractice, the model may be able to assist in early diagnosis of AD and provide\na counterfactual baseline trajectory for treatment effect estimation.\nFurthermore, it generates a synthetic dataset that can potentially be used for\ndownstream tasks such as anomaly detection and classification.\n","authors":["Rosemary He","Gabriella Ang","Daniel Tward"],"pdf_url":"https://arxiv.org/pdf/2408.02018v1.pdf","comment":"MICCAI 2024 LDTM workshop"},{"id":"http://arxiv.org/abs/2408.02014v1","updated":"2024-08-04T12:52:44Z","published":"2024-08-04T12:52:44Z","title":"Unsupervised Representation Learning by Balanced Self Attention Matching","summary":"  Many leading self-supervised methods for unsupervised representation\nlearning, in particular those for embedding image features, are built on\nvariants of the instance discrimination task, whose optimization is known to be\nprone to instabilities that can lead to feature collapse. Different techniques\nhave been devised to circumvent this issue, including the use of negative pairs\nwith different contrastive losses, the use of external memory banks, and\nbreaking of symmetry by using separate encoding networks with possibly\ndifferent structures. Our method, termed BAM, rather than directly matching\nfeatures of different views (augmentations) of input images, is based on\nmatching their self-attention vectors, which are the distributions of\nsimilarities to the entire set of augmented images of a batch. We obtain rich\nrepresentations and avoid feature collapse by minimizing a loss that matches\nthese distributions to their globally balanced and entropy regularized version,\nwhich is obtained through a simple self-optimal-transport computation. We\nablate and verify our method through a wide set of experiments that show\ncompetitive performance with leading methods on both semi-supervised and\ntransfer-learning benchmarks. Our implementation and pre-trained models are\navailable at github.com/DanielShalam/BAM .\n","authors":["Daniel Shalam","Simon Korman"],"pdf_url":"https://arxiv.org/pdf/2408.02014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02012v1","updated":"2024-08-04T12:48:20Z","published":"2024-08-04T12:48:20Z","title":"Decision Support System to triage of liver trauma","summary":"  Trauma significantly impacts global health, accounting for over 5 million\ndeaths annually, which is comparable to mortality rates from diseases such as\ntuberculosis, AIDS, and malaria. In Iran, the financial repercussions of road\ntraffic accidents represent approximately 2% of the nation's Gross National\nProduct each year. Bleeding is the leading cause of mortality in trauma\npatients within the first 24 hours following an injury, making rapid diagnosis\nand assessment of severity crucial. Trauma patients require comprehensive scans\nof all organs, generating a large volume of data. Evaluating CT images for the\nentire body is time-consuming and requires significant expertise, underscoring\nthe need for efficient time management in diagnosis. Efficient diagnostic\nprocesses can significantly reduce treatment costs and decrease the likelihood\nof secondary complications. In this context, the development of a reliable\nDecision Support System (DSS) for trauma triage, particularly focused on the\nabdominal area, is vital. This paper presents a novel method for detecting\nliver bleeding and lacerations using CT scans, utilising the GAN Pix2Pix\ntranslation model. The effectiveness of the method is quantified by Dice score\nmetrics, with the model achieving an accuracy of 97% for liver bleeding and 93%\nfor liver laceration detection. These results represent a notable improvement\nover current state-of-the-art technologies. The system's design integrates\nseamlessly with existing medical imaging technologies, making it a practical\naddition to emergency medical services. This research underscores the potential\nof advanced image translation models like GAN Pix2Pix in improving the\nprecision and speed of medical diagnostics in critical care scenarios.\n","authors":["Ali Jamali","Azadeh Nazemi","Ashkan Sami","Rosemina Bahrololoom","Shahram Paydar","Alireza Shakibafar"],"pdf_url":"https://arxiv.org/pdf/2408.02012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02001v1","updated":"2024-08-04T11:59:09Z","published":"2024-08-04T11:59:09Z","title":"AdaCBM: An Adaptive Concept Bottleneck Model for Explainable and\n  Accurate Diagnosis","summary":"  The integration of vision-language models such as CLIP and Concept Bottleneck\nModels (CBMs) offers a promising approach to explaining deep neural network\n(DNN) decisions using concepts understandable by humans, addressing the\nblack-box concern of DNNs. While CLIP provides both explainability and\nzero-shot classification capability, its pre-training on generic image and text\ndata may limit its classification accuracy and applicability to medical image\ndiagnostic tasks, creating a transfer learning problem. To maintain\nexplainability and address transfer learning needs, CBM methods commonly design\npost-processing modules after the bottleneck module. However, this way has been\nineffective. This paper takes an unconventional approach by re-examining the\nCBM framework through the lens of its geometrical representation as a simple\nlinear classification system. The analysis uncovers that post-CBM fine-tuning\nmodules merely rescale and shift the classification outcome of the system,\nfailing to fully leverage the system's learning potential. We introduce an\nadaptive module strategically positioned between CLIP and CBM to bridge the gap\nbetween source and downstream domains. This simple yet effective approach\nenhances classification performance while preserving the explainability\nafforded by the framework. Our work offers a comprehensive solution that\nencompasses the entire process, from concept discovery to model training,\nproviding a holistic recipe for leveraging the strengths of GPT, CLIP, and CBM.\n","authors":["Townim F. Chowdhury","Vu Minh Hieu Phan","Kewen Liao","Minh-Son To","Yutong Xie","Anton van den Hengel","Johan W. Verjans","Zhibin Liao"],"pdf_url":"https://arxiv.org/pdf/2408.02001v1.pdf","comment":"Accepted at MICCAI 2024, the 27th International Conference on Medical\n  Image Computing and Computer Assisted Intervention"},{"id":"http://arxiv.org/abs/2408.01998v1","updated":"2024-08-04T11:51:00Z","published":"2024-08-04T11:51:00Z","title":"What Happens Without Background? Constructing Foreground-Only Data for\n  Fine-Grained Tasks","summary":"  Fine-grained recognition, a pivotal task in visual signal processing, aims to\ndistinguish between similar subclasses based on discriminative information\npresent in samples. However, prevailing methods often erroneously focus on\nbackground areas, neglecting the capture of genuinely effective discriminative\ninformation from the subject, thus impeding practical application. To\nfacilitate research into the impact of background noise on models and enhance\ntheir ability to concentrate on the subject's discriminative features, we\npropose an engineered pipeline that leverages the capabilities of SAM and Detic\nto create fine-grained datasets with only foreground subjects, devoid of\nbackground. Extensive cross-experiments validate this approach as a\npreprocessing step prior to training, enhancing algorithmic performance and\nholding potential for further modal expansion of the data.\n","authors":["Yuetian Wang","Wenjin Hou","Qinmu Peng","Xinge You"],"pdf_url":"https://arxiv.org/pdf/2408.01998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01986v1","updated":"2024-08-04T10:54:36Z","published":"2024-08-04T10:54:36Z","title":"DeMansia: Mamba Never Forgets Any Tokens","summary":"  This paper examines the mathematical foundations of transformer\narchitectures, highlighting their limitations particularly in handling long\nsequences. We explore prerequisite models such as Mamba, Vision Mamba (ViM),\nand LV-ViT that pave the way for our proposed architecture, DeMansia. DeMansia\nintegrates state space models with token labeling techniques to enhance\nperformance in image classification tasks, efficiently addressing the\ncomputational challenges posed by traditional transformers. The architecture,\nbenchmark, and comparisons with contemporary models demonstrate DeMansia's\neffectiveness. The implementation of this paper is available on GitHub at\nhttps://github.com/catalpaaa/DeMansia\n","authors":["Ricky Fang"],"pdf_url":"https://arxiv.org/pdf/2408.01986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13355v2","updated":"2024-08-04T10:31:41Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performs poorly in rejecting OOD inputs. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K+1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K+1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network and\nprototype classifier on vision transformer (ViT) backbone. Experiments on\npopular OSR and OOD detection datasets demonstrate that the proposed framework,\nusing a single multi-class classifier, yields competitive performance in\nclosed-set classification, OOD detection, and misclassification detection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v2.pdf","comment":"Published in Machine Intelligence Research\n  (https://link.springer.com/article/10.1007/s11633-024-1514-4)"},{"id":"http://arxiv.org/abs/2304.08386v3","updated":"2024-08-04T10:25:50Z","published":"2023-04-17T15:54:10Z","title":"Progressive Visual Prompt Learning with Contrastive Feature Re-formation","summary":"  Prompt learning has been designed as an alternative to fine-tuning for\nadapting Vision-language (V-L) models to the downstream tasks. Previous works\nmainly focus on text prompt while visual prompt works are limited for V-L\nmodels. The existing visual prompt methods endure either mediocre performance\nor unstable training process, indicating the difficulty of visual prompt\nlearning. In this paper, we propose a new Progressive Visual Prompt (ProVP)\nstructure to strengthen the interactions among prompts of different layers.\nMore importantly, our ProVP could effectively propagate the image embeddings to\ndeep layers and behave partially similar to an instance adaptive prompt method.\nTo alleviate generalization deterioration, we further propose a new contrastive\nfeature re-formation, which prevents the serious deviation of the prompted\nvisual feature from the fixed CLIP visual feature distribution. Combining both,\nour method (ProVP-Ref) is evaluated on 11 image benchmark datasets and achieves\n7/11 state-of-theart results on both few-shot and base-to-novel settings. To\nthe best of our knowledge, we are the first to demonstrate the superior\nperformance of visual prompts in V-L models to previous prompt-based methods in\ndownstream tasks. Meanwhile, it implies that our ProVP-Ref shows the best\ncapability to adapt and to generalize.\n","authors":["Chen Xu","Yuhan Zhu","Haocheng Shen","Boheng Chen","Yixuan Liao","Xiaoxin Chen","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2304.08386v3.pdf","comment":"IJCV 2024 Accepted"},{"id":"http://arxiv.org/abs/2408.01978v1","updated":"2024-08-04T09:53:50Z","published":"2024-08-04T09:53:50Z","title":"AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial\n  Contrastive Prompt Tuning","summary":"  Deep neural networks (DNNs) are known to be vulnerable to adversarial attacks\neven under a black-box setting where the adversary can only query the model.\nParticularly, query-based black-box adversarial attacks estimate adversarial\ngradients based on the returned probability vectors of the target model for a\nsequence of queries. During this process, the queries made to the target model\nare intermediate adversarial examples crafted at the previous attack step,\nwhich share high similarities in the pixel space. Motivated by this\nobservation, stateful detection methods have been proposed to detect and reject\nquery-based attacks. While demonstrating promising results, these methods\neither have been evaded by more advanced attacks or suffer from low efficiency\nin terms of the number of shots (queries) required to detect different attacks.\nArguably, the key challenge here is to assign high similarity scores for any\ntwo intermediate adversarial examples perturbed from the same clean image. To\naddress this challenge, we propose a novel Adversarial Contrastive Prompt\nTuning (ACPT) method to robustly fine-tune the CLIP image encoder to extract\nsimilar embeddings for any two intermediate adversarial queries. With ACPT, we\nfurther introduce a detection framework AdvQDet that can detect 7\nstate-of-the-art query-based attacks with $>99\\%$ detection rate within 5\nshots. We also show that ACPT is robust to 3 types of adaptive attacks. Code is\navailable at https://github.com/xinwong/AdvQDet.\n","authors":["Xin Wang","Kai Chen","Xingjun Ma","Zhineng Chen","Jingjing Chen","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.01978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01977v1","updated":"2024-08-04T09:51:14Z","published":"2024-08-04T09:51:14Z","title":"Label Augmentation for Neural Networks Robustness","summary":"  Out-of-distribution generalization can be categorized into two types: common\nperturbations arising from natural variations in the real world and adversarial\nperturbations that are intentionally crafted to deceive neural networks. While\ndeep neural networks excel in accuracy under the assumption of identical\ndistributions between training and test data, they often encounter\nout-of-distribution scenarios resulting in a significant decline in accuracy.\nData augmentation methods can effectively enhance robustness against common\ncorruptions, but they typically fall short in improving robustness against\nadversarial perturbations. In this study, we develop Label Augmentation (LA),\nwhich enhances robustness against both common and intentional perturbations and\nimproves uncertainty estimation. Our findings indicate a Clean error rate\nimprovement of up to 23.29% when employing LA in comparisons to the baseline.\nAdditionally, it enhances robustness under common corruptions benchmark by up\nto 24.23%. When tested against FGSM and PGD attacks, improvements in\nadversarial robustness are noticeable, with enhancements of up to 53.18% for\nFGSM and 24.46% for PGD attacks.\n","authors":["Fatemeh Amerehi","Patrick Healy"],"pdf_url":"https://arxiv.org/pdf/2408.01977v1.pdf","comment":"21 pages, 4 figures, Published at 3rd Conference on Lifelong Learning\n  Agents (CoLLAs), 2024"},{"id":"http://arxiv.org/abs/2408.01976v1","updated":"2024-08-04T09:44:47Z","published":"2024-08-04T09:44:47Z","title":"Single-Point Supervised High-Resolution Dynamic Network for Infrared\n  Small Target Detection","summary":"  Infrared small target detection (IRSTD) tasks are extremely challenging for\ntwo main reasons: 1) it is difficult to obtain accurate labelling information\nthat is critical to existing methods, and 2) infrared (IR) small target\ninformation is easily lost in deep networks. To address these issues, we\npropose a single-point supervised high-resolution dynamic network (SSHD-Net).\nIn contrast to existing methods, we achieve state-of-the-art (SOTA) detection\nperformance using only single-point supervision. Specifically, we first design\na high-resolution cross-feature extraction module (HCEM), that achieves\nbi-directional feature interaction through stepped feature cascade channels\n(SFCC). It balances network depth and feature resolution to maintain deep IR\nsmall-target information. Secondly, the effective integration of global and\nlocal features is achieved through the dynamic coordinate fusion module (DCFM),\nwhich enhances the anti-interference ability in complex backgrounds. In\naddition, we introduce the high-resolution multilevel residual module (HMRM) to\nenhance the semantic information extraction capability. Finally, we design the\nadaptive target localization detection head (ATLDH) to improve detection\naccuracy. Experiments on the publicly available datasets NUDT-SIRST and\nIRSTD-1k demonstrate the effectiveness of our method. Compared to other SOTA\nmethods, our method can achieve better detection performance with only a single\npoint of supervision.\n","authors":["Jing Wu","Rixiang Ni","Feng Huang","Zhaobing Qiu","Liqiong Chen","Changhai Luo","Yunxiang Li","Youli Li"],"pdf_url":"https://arxiv.org/pdf/2408.01976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01970v1","updated":"2024-08-04T09:09:35Z","published":"2024-08-04T09:09:35Z","title":"SR-CIS: Self-Reflective Incremental System with Decoupled Memory and\n  Reasoning","summary":"  The ability of humans to rapidly learn new knowledge while retaining old\nmemories poses a significant challenge for current deep learning models. To\nhandle this challenge, we draw inspiration from human memory and learning\nmechanisms and propose the Self-Reflective Complementary Incremental System\n(SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and\nComplementary Memory Module (CMM), SR-CIS features a small model for fast\ninference and a large model for slow deliberation in CIM, enabled by the\nConfidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient\ncollaboration. CMM consists of task-specific Short-Term Memory (STM) region and\na universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank\nAdaptive (LoRA) and corresponding prototype weights and biases, it instantiates\nexternal storage for parameter and representation memory, thus deconstructing\nthe memory module from the inference module. By storing textual descriptions of\nimages during training and combining them with the Scenario Replay Module (SRM)\npost-training for memory combination, along with periodic short-to-long-term\nmemory restructuring, SR-CIS achieves stable incremental memory with limited\nstorage requirements. Balancing model plasticity and memory stability under\nconstraints of limited storage and low data resources, SR-CIS surpasses\nexisting competitive baselines on multiple standard and few-shot incremental\nlearning benchmarks.\n","authors":["Biqing Qi","Junqi Gao","Xinquan Chen","Dong Li","Weinan Zhang","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.01970v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13309v2","updated":"2024-08-04T08:40:36Z","published":"2024-07-18T09:13:08Z","title":"Exposure Completing for Temporally Consistent Neural High Dynamic Range\n  Video Rendering","summary":"  High dynamic range (HDR) video rendering from low dynamic range (LDR) videos\nwhere frames are of alternate exposure encounters significant challenges, due\nto the exposure change and absence at each time stamp. The exposure change and\nabsence make existing methods generate flickering HDR results. In this paper,\nwe propose a novel paradigm to render HDR frames via completing the absent\nexposure information, hence the exposure information is complete and\nconsistent. Our approach involves interpolating neighbor LDR frames in the time\ndimension to reconstruct LDR frames for the absent exposures. Combining the\ninterpolated and given LDR frames, the complete set of exposure information is\navailable at each time stamp. This benefits the fusing process for HDR results,\nreducing noise and ghosting artifacts therefore improving temporal consistency.\nExtensive experimental evaluations on standard benchmarks demonstrate that our\nmethod achieves state-of-the-art performance, highlighting the importance of\nabsent exposure completing in HDR video rendering. The code is available at\nhttps://github.com/cuijiahao666/NECHDR.\n","authors":["Jiahao Cui","Wei Jiang","Zhan Peng","Zhiyu Pan","Zhiguo Cao"],"pdf_url":"https://arxiv.org/pdf/2407.13309v2.pdf","comment":"9 pages, 6 figures, accepted by ACM-MM 2024 (poster)"},{"id":"http://arxiv.org/abs/2408.01960v1","updated":"2024-08-04T08:33:44Z","published":"2024-08-04T08:33:44Z","title":"AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion\n  Model","summary":"  Anomaly detection is a critical task in industrial manufacturing, aiming to\nidentify defective parts of products. Most industrial anomaly detection methods\nassume the availability of sufficient normal data for training. This assumption\nmay not hold true due to the cost of labeling or data privacy policies.\nAdditionally, mainstream methods require training bespoke models for different\nobjects, which incurs heavy costs and lacks flexibility in practice. To address\nthese issues, we seek help from Stable Diffusion (SD) model due to its\ncapability of zero/few-shot inpainting, which can be leveraged to inpaint\nanomalous regions as normal. In this paper, a few-shot multi-class anomaly\ndetection framework that adopts Stable Diffusion model is proposed, named\nAnomalySD. To adapt SD to anomaly detection task, we design different\nhierarchical text descriptions and the foreground mask mechanism for\nfine-tuning SD. In the inference stage, to accurately mask anomalous regions\nfor inpainting, we propose multi-scale mask strategy and prototype-guided mask\nstrategy to handle diverse anomalous regions. Hierarchical text prompts are\nalso utilized to guide the process of inpainting in the inference stage. The\nanomaly score is estimated based on inpainting result of all masks. Extensive\nexperiments on the MVTec-AD and VisA datasets demonstrate the superiority of\nour approach. We achieved anomaly classification and segmentation results of\n93.6%/94.8% AUROC on the MVTec-AD dataset and 86.1%/96.5% AUROC on the VisA\ndataset under multi-class and one-shot settings.\n","authors":["Zhenyu Yan","Qingqing Fang","Wenxi Lv","Qinliang Su"],"pdf_url":"https://arxiv.org/pdf/2408.01960v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2407.06863v4","updated":"2024-08-04T08:28:25Z","published":"2024-07-09T13:50:43Z","title":"Beyond Aesthetics: Cultural Competence in Text-to-Image Models","summary":"  Text-to-Image (T2I) models are being increasingly adopted in diverse global\ncommunities where they create visual representations of their unique cultures.\nCurrent T2I benchmarks primarily focus on faithfulness, aesthetics, and realism\nof generated images, overlooking the critical dimension of cultural competence.\nIn this work, we introduce a framework to evaluate cultural competence of T2I\nmodels along two crucial dimensions: cultural awareness and cultural diversity,\nand present a scalable approach using a combination of structured knowledge\nbases and large language models to build a large dataset of cultural artifacts\nto enable this evaluation. In particular, we apply this approach to build CUBE\n(CUltural BEnchmark for Text-to-Image models), a first-of-its-kind benchmark to\nevaluate cultural competence of T2I models. CUBE covers cultural artifacts\nassociated with 8 countries across different geo-cultural regions and along 3\nconcepts: cuisine, landmarks, and art. CUBE consists of 1) CUBE-1K, a set of\nhigh-quality prompts that enable the evaluation of cultural awareness, and 2)\nCUBE-CSpace, a larger dataset of cultural artifacts that serves as grounding to\nevaluate cultural diversity. We also introduce cultural diversity as a novel\nT2I evaluation component, leveraging quality-weighted Vendi score. Our\nevaluations reveal significant gaps in the cultural awareness of existing\nmodels across countries and provide valuable insights into the cultural\ndiversity of T2I outputs for under-specified prompts. Our methodology is\nextendable to other cultural regions and concepts, and can facilitate the\ndevelopment of T2I models that better cater to the global population.\n","authors":["Nithish Kannen","Arif Ahmad","Marco Andreetto","Vinodkumar Prabhakaran","Utsav Prabhu","Adji Bousso Dieng","Pushpak Bhattacharyya","Shachi Dave"],"pdf_url":"https://arxiv.org/pdf/2407.06863v4.pdf","comment":"30 pages, 10 figures, preprint"},{"id":"http://arxiv.org/abs/2408.01959v1","updated":"2024-08-04T08:26:58Z","published":"2024-08-04T08:26:58Z","title":"Dataset Scale and Societal Consistency Mediate Facial Impression Bias in\n  Vision-Language AI","summary":"  Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.\n","authors":["Robert Wolfe","Aayushi Dangol","Alexis Hiniker","Bill Howe"],"pdf_url":"https://arxiv.org/pdf/2408.01959v1.pdf","comment":"Accepted at Artificial Intelligence, Ethics, and Society 2024"},{"id":"http://arxiv.org/abs/2408.01953v1","updated":"2024-08-04T07:59:17Z","published":"2024-08-04T07:59:17Z","title":"EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning","summary":"  Humans perceive and interact with the world with the awareness of\nequivariance, facilitating us in manipulating different objects in diverse\nposes. For robotic manipulation, such equivariance also exists in many\nscenarios. For example, no matter what the pose of a drawer is (translation,\nrotation and tilt), the manipulation strategy is consistent (grasp the handle\nand pull in a line). While traditional models usually do not have the awareness\nof equivariance for robotic manipulation, which might result in more data for\ntraining and poor performance in novel object poses, we propose our EqvAfford\nframework, with novel designs to guarantee the equivariance in point-level\naffordance learning for downstream robotic manipulation, with great performance\nand generalization ability on representative tasks on objects in diverse poses.\n","authors":["Yue Chen","Chenrui Tie","Ruihai Wu","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2408.01953v1.pdf","comment":"Accept to CVPRWorkshop on Equivariant Vision: From Theory to Practice\n  2024"},{"id":"http://arxiv.org/abs/2408.01952v1","updated":"2024-08-04T07:48:12Z","published":"2024-08-04T07:48:12Z","title":"CACE-Net: Co-guidance Attention and Contrastive Enhancement for\n  Effective Audio-Visual Event Localization","summary":"  The audio-visual event localization task requires identifying concurrent\nvisual and auditory events from unconstrained videos within a network model,\nlocating them, and classifying their category. The efficient extraction and\nintegration of audio and visual modal information have always been challenging\nin this field. In this paper, we introduce CACE-Net, which differs from most\nexisting methods that solely use audio signals to guide visual information. We\npropose an audio-visual co-guidance attention mechanism that allows for\nadaptive bi-directional cross-modal attentional guidance between audio and\nvisual information, thus reducing inconsistencies between modalities. Moreover,\nwe have observed that existing methods have difficulty distinguishing between\nsimilar background and event and lack the fine-grained features for event\nclassification. Consequently, we employ background-event contrast enhancement\nto increase the discrimination of fused feature and fine-tuned pre-trained\nmodel to extract more refined and discernible features from complex multimodal\ninputs. Specifically, we have enhanced the model's ability to discern subtle\ndifferences between event and background and improved the accuracy of event\nclassification in our model. Experiments on the AVE dataset demonstrate that\nCACE-Net sets a new benchmark in the audio-visual event localization task,\nproving the effectiveness of our proposed methods in handling complex\nmultimodal learning and event localization in unconstrained videos. Code is\navailable at https://github.com/Brain-Cog-Lab/CACE-Net.\n","authors":["Xiang He","Xiangxi Liu","Yang Li","Dongcheng Zhao","Guobin Shen","Qingqun Kong","Xin Yang","Yi Zeng"],"pdf_url":"https://arxiv.org/pdf/2408.01952v1.pdf","comment":"Accepted by ACM MM 2024. Code is available at this\n  https://github.com/Brain-Cog-Lab/CACE-Net"},{"id":"http://arxiv.org/abs/2408.01946v1","updated":"2024-08-04T07:12:59Z","published":"2024-08-04T07:12:59Z","title":"Masked Angle-Aware Autoencoder for Remote Sensing Images","summary":"  To overcome the inherent domain gap between remote sensing (RS) images and\nnatural images, some self-supervised representation learning methods have made\npromising progress. However, they have overlooked the diverse angles present in\nRS objects. This paper proposes the Masked Angle-Aware Autoencoder (MA3E) to\nperceive and learn angles during pre-training. We design a \\textit{scaling\ncenter crop} operation to create the rotated crop with random orientation on\neach original image, introducing the explicit angle variation. MA3E inputs this\ncomposite image while reconstruct the original image, aiming to effectively\nlearn rotation-invariant representations by restoring the angle variation\nintroduced on the rotated crop. To avoid biases caused by directly\nreconstructing the rotated crop, we propose an Optimal Transport (OT) loss that\nautomatically assigns similar original image patches to each rotated crop patch\nfor reconstruction. MA3E demonstrates more competitive performance than\nexisting pre-training methods on seven different RS image datasets in three\ndownstream tasks.\n","authors":["Zhihao Li","Biao Hou","Siteng Ma","Zitong Wu","Xianpeng Guo","Bo Ren","Licheng Jiao"],"pdf_url":"https://arxiv.org/pdf/2408.01946v1.pdf","comment":"This paper has been accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2407.13200v2","updated":"2024-08-04T07:06:04Z","published":"2024-07-18T06:32:45Z","title":"Adapt PointFormer: 3D Point Cloud Analysis via Adapting 2D Visual\n  Transformers","summary":"  Pre-trained large-scale models have exhibited remarkable efficacy in computer\nvision, particularly for 2D image analysis. However, when it comes to 3D point\nclouds, the constrained accessibility of data, in contrast to the vast\nrepositories of images, poses a challenge for the development of 3D pre-trained\nmodels. This paper therefore attempts to directly leverage pre-trained models\nwith 2D prior knowledge to accomplish the tasks for 3D point cloud analysis.\nAccordingly, we propose the Adaptive PointFormer (APF), which fine-tunes\npre-trained 2D models with only a modest number of parameters to directly\nprocess point clouds, obviating the need for mapping to images. Specifically,\nwe convert raw point clouds into point embeddings for aligning dimensions with\nimage tokens. Given the inherent disorder in point clouds, in contrast to the\nstructured nature of images, we then sequence the point embeddings to optimize\nthe utilization of 2D attention priors. To calibrate attention across 3D and 2D\ndomains and reduce computational overhead, a trainable PointFormer with a\nlimited number of parameters is subsequently concatenated to a frozen\npre-trained image model. Extensive experiments on various benchmarks\ndemonstrate the effectiveness of the proposed APF. The source code and more\ndetails are available at https://vcc.tech/research/2024/PointFormer.\n","authors":["Mengke Li","Da Li","Guoqing Yang","Yiu-ming Cheung","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2407.13200v2.pdf","comment":"ECAI 2024 main conference paper"},{"id":"http://arxiv.org/abs/2408.01945v1","updated":"2024-08-04T07:06:04Z","published":"2024-08-04T07:06:04Z","title":"Generalized Maximum Likelihood Estimation for Perspective-n-Point\n  Problem","summary":"  The Perspective-n-Point (PnP) problem has been widely studied in the\nliterature and applied in various vision-based pose estimation scenarios.\nHowever, existing methods ignore the anisotropy uncertainty of observations, as\ndemonstrated in several real-world datasets in this paper. This oversight may\nlead to suboptimal and inaccurate estimation, particularly in the presence of\nnoisy observations. To this end, we propose a generalized maximum likelihood\nPnP solver, named GMLPnP, that minimizes the determinant criterion by iterating\nthe GLS procedure to estimate the pose and uncertainty simultaneously. Further,\nthe proposed method is decoupled from the camera model. Results of synthetic\nand real experiments show that our method achieves better accuracy in common\npose estimation scenarios, GMLPnP improves rotation/translation accuracy by\n4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best\nbaseline. It is more accurate under very noisy observations in a vision-based\nUAV localization task, outperforming the best baseline by 34.4% in translation\nestimation accuracy.\n","authors":["Tian Zhan","Chunfeng Xu","Cheng Zhang","Ke Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.01945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01944v1","updated":"2024-08-04T07:04:59Z","published":"2024-08-04T07:04:59Z","title":"RobNODDI: Robust NODDI Parameter Estimation with Adaptive Sampling under\n  Continuous Representation","summary":"  Neurite Orientation Dispersion and Density Imaging (NODDI) is an important\nimaging technology used to evaluate the microstructure of brain tissue, which\nis of great significance for the discovery and treatment of various\nneurological diseases. Current deep learning-based methods perform parameter\nestimation through diffusion magnetic resonance imaging (dMRI) with a small\nnumber of diffusion gradients. These methods speed up parameter estimation and\nimprove accuracy. However, the diffusion directions used by most existing deep\nlearning models during testing needs to be strictly consistent with the\ndiffusion directions during training. This results in poor generalization and\nrobustness of deep learning models in dMRI parameter estimation. In this work,\nwe verify for the first time that the parameter estimation performance of\ncurrent mainstream methods will significantly decrease when the testing\ndiffusion directions and the training diffusion directions are inconsistent. A\nrobust NODDI parameter estimation method with adaptive sampling under\ncontinuous representation (RobNODDI) is proposed. Furthermore, long short-term\nmemory (LSTM) units and fully connected layers are selected to learn continuous\nrepresentation signals. To this end, we use a total of 100 subjects to conduct\nexperiments based on the Human Connectome Project (HCP) dataset, of which 60\nare used for training, 20 are used for validation, and 20 are used for testing.\nThe test results indicate that RobNODDI improves the generalization performance\nand robustness of the deep learning model, enhancing the stability and\nflexibility of deep learning NODDI parameter estimatimation applications.\n","authors":["Taohui Xiao","Jian Cheng","Wenxin Fan","Jing Yang","Cheng Li","Enqing Dong","Shanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01942v1","updated":"2024-08-04T06:34:24Z","published":"2024-08-04T06:34:24Z","title":"Visual Grounding for Object-Level Generalization in Reinforcement\n  Learning","summary":"  Generalization is a pivotal challenge for agents following natural language\ninstructions. To approach this goal, we leverage a vision-language model (VLM)\nfor visual grounding and transfer its vision-language knowledge into\nreinforcement learning (RL) for object-centric tasks, which makes the agent\ncapable of zero-shot generalization to unseen objects and instructions. By\nvisual grounding, we obtain an object-grounded confidence map for the target\nobject indicated in the instruction. Based on this map, we introduce two routes\nto transfer VLM knowledge into RL. Firstly, we propose an object-grounded\nintrinsic reward function derived from the confidence map to more effectively\nguide the agent towards the target object. Secondly, the confidence map offers\na more unified, accessible task representation for the agent's policy, compared\nto language embeddings. This enables the agent to process unseen objects and\ninstructions through comprehensible visual confidence maps, facilitating\nzero-shot object-level generalization. Single-task experiments prove that our\nintrinsic reward significantly improves performance on challenging skill\nlearning. In multi-task experiments, through testing on tasks beyond the\ntraining set, we show that the agent, when provided with the confidence map as\nthe task representation, possesses better generalization capabilities than\nlanguage-based conditioning. The code is available at\nhttps://github.com/PKU-RL/COPL.\n","authors":["Haobin Jiang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2408.01942v1.pdf","comment":"35 pages, 14 figures, 17 tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2209.03885v4","updated":"2024-08-04T23:45:40Z","published":"2022-09-08T15:41:31Z","title":"A Framework for Evaluating Privacy-Utility Trade-off in Vertical\n  Federated Learning","summary":"  Federated learning (FL) has emerged as a practical solution to tackle data\nsilo issues without compromising user privacy. One of its variants, vertical\nfederated learning (VFL), has recently gained increasing attention as the VFL\nmatches the enterprises' demands of leveraging more valuable features to build\nbetter machine learning models while preserving user privacy. Current works in\nVFL concentrate on developing a specific protection or attack mechanism for a\nparticular VFL algorithm. In this work, we propose an evaluation framework that\nformulates the privacy-utility evaluation problem. We then use this framework\nas a guide to comprehensively evaluate a broad range of protection mechanisms\nagainst most of the state-of-the-art privacy attacks for three widely deployed\nVFL algorithms. These evaluations may help FL practitioners select appropriate\nprotection mechanisms given specific requirements. Our evaluation results\ndemonstrate that: the model inversion and most of the label inference attacks\ncan be thwarted by existing protection mechanisms; the model completion (MC)\nattack is difficult to be prevented, which calls for more advanced MC-targeted\nprotection mechanisms. Based on our evaluation results, we offer concrete\nadvice on improving the privacy-preserving capability of VFL systems. The code\nis available at https://github.com/yankang18/Attack-Defense-VFL\n","authors":["Yan Kang","Jiahuan Luo","Yuanqin He","Xiaojin Zhang","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2209.03885v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02165v1","updated":"2024-08-04T23:23:48Z","published":"2024-08-04T23:23:48Z","title":"SelfBC: Self Behavior Cloning for Offline Reinforcement Learning","summary":"  Policy constraint methods in offline reinforcement learning employ additional\nregularization techniques to constrain the discrepancy between the learned\npolicy and the offline dataset. However, these methods tend to result in overly\nconservative policies that resemble the behavior policy, thus limiting their\nperformance. We investigate this limitation and attribute it to the static\nnature of traditional constraints. In this paper, we propose a novel dynamic\npolicy constraint that restricts the learned policy on the samples generated by\nthe exponential moving average of previously learned policies. By integrating\nthis self-constraint mechanism into off-policy methods, our method facilitates\nthe learning of non-conservative policies while avoiding policy collapse in the\noffline setting. Theoretical results show that our approach results in a nearly\nmonotonically improved reference policy. Extensive experiments on the D4RL\nMuJoCo domain demonstrate that our proposed method achieves state-of-the-art\nperformance among the policy constraint methods.\n","authors":["Shirong Liu","Chenjia Bai","Zixian Guo","Hao Zhang","Gaurav Sharma","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02161v1","updated":"2024-08-04T23:05:42Z","published":"2024-08-04T23:05:42Z","title":"Distilling Machine Learning's Added Value: Pareto Fronts in Atmospheric\n  Applications","summary":"  While the added value of machine learning (ML) for weather and climate\napplications is measurable, explaining it remains challenging, especially for\nlarge deep learning models. Inspired by climate model hierarchies, we propose\nthat a full hierarchy of Pareto-optimal models, defined within an appropriately\ndetermined error-complexity plane, can guide model development and help\nunderstand the models' added value. We demonstrate the use of Pareto fronts in\natmospheric physics through three sample applications, with hierarchies ranging\nfrom semi-empirical models with minimal tunable parameters (simplest) to deep\nlearning algorithms (most complex). First, in cloud cover parameterization, we\nfind that neural networks identify nonlinear relationships between cloud cover\nand its thermodynamic environment, and assimilate previously neglected features\nsuch as vertical gradients in relative humidity that improve the representation\nof low cloud cover. This added value is condensed into a ten-parameter equation\nthat rivals the performance of deep learning models. Second, we establish a ML\nmodel hierarchy for emulating shortwave radiative transfer, distilling the\nimportance of bidirectional vertical connectivity for accurately representing\nabsorption and scattering, especially for multiple cloud layers. Third, we\nemphasize the importance of convective organization information when modeling\nthe relationship between tropical precipitation and its surrounding\nenvironment. We discuss the added value of temporal memory when high-resolution\nspatial information is unavailable, with implications for precipitation\nparameterization. Therefore, by comparing data-driven models directly with\nexisting schemes using Pareto optimality, we promote process understanding by\nhierarchically unveiling system complexity, with the hope of improving the\ntrustworthiness of ML models in atmospheric applications.\n","authors":["Tom Beucler","Arthur Grundner","Sara Shamekh","Peter Ukkonen","Matthew Chantry","Ryan Lagerquist"],"pdf_url":"https://arxiv.org/pdf/2408.02161v1.pdf","comment":"18 pages, 4 figures, submitted to AMS Artificial Intelligence for the\n  Earth Systems (AIES)"},{"id":"http://arxiv.org/abs/2307.01357v3","updated":"2024-08-04T22:31:59Z","published":"2023-07-03T21:13:40Z","title":"Adaptive Principal Component Regression with Applications to Panel Data","summary":"  Principal component regression (PCR) is a popular technique for fixed-design\nerror-in-variables regression, a generalization of the linear regression\nsetting in which the observed covariates are corrupted with random noise. We\nprovide the first time-uniform finite sample guarantees for (regularized) PCR\nwhenever data is collected adaptively. Since the proof techniques for analyzing\nPCR in the fixed design setting do not readily extend to the online setting,\nour results rely on adapting tools from modern martingale concentration to the\nerror-in-variables setting. We demonstrate the usefulness of our bounds by\napplying them to the domain of panel data, a ubiquitous setting in econometrics\nand statistics. As our first application, we provide a framework for experiment\ndesign in panel data settings when interventions are assigned adaptively. Our\nframework may be thought of as a generalization of the synthetic control and\nsynthetic interventions frameworks, where data is collected via an adaptive\nintervention assignment policy. Our second application is a procedure for\nlearning such an intervention assignment policy in a setting where units arrive\nsequentially to be treated. In addition to providing theoretical performance\nguarantees (as measured by regret), we show that our method empirically\noutperforms a baseline which does not leverage error-in-variables regression.\n","authors":["Anish Agarwal","Keegan Harris","Justin Whitehouse","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2307.01357v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02159v1","updated":"2024-08-04T22:26:34Z","published":"2024-08-04T22:26:34Z","title":"SPINEX-TimeSeries: Similarity-based Predictions with Explainable\n  Neighbors Exploration for Time Series and Forecasting Problems","summary":"  This paper introduces a new addition to the SPINEX (Similarity-based\nPredictions with Explainable Neighbors Exploration) family, tailored\nspecifically for time series and forecasting analysis. This new algorithm\nleverages the concept of similarity and higher-order temporal interactions\nacross multiple time scales to enhance predictive accuracy and interpretability\nin forecasting. To evaluate the effectiveness of SPINEX, we present\ncomprehensive benchmarking experiments comparing it against 18 algorithms and\nacross 49 synthetic and real datasets characterized by varying trends,\nseasonality, and noise levels. Our performance assessment focused on\nforecasting accuracy and computational efficiency. Our findings reveal that\nSPINEX consistently ranks among the top 5 performers in forecasting precision\nand has a superior ability to handle complex temporal dynamics compared to\ncommonly adopted algorithms. Moreover, the algorithm's explainability features,\nPareto efficiency, and medium complexity (on the order of O(log n)) are\ndemonstrated through detailed visualizations to enhance the prediction and\ndecision-making process. We note that integrating similarity-based concepts\nopens new avenues for research in predictive analytics, promising more accurate\nand transparent decision making.\n","authors":["Ahmed Z Naser","MZ Naser"],"pdf_url":"https://arxiv.org/pdf/2408.02159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21772v2","updated":"2024-08-04T22:13:39Z","published":"2024-07-31T17:48:14Z","title":"ShieldGemma: Generative AI Content Moderation Based on Gemma","summary":"  We present ShieldGemma, a comprehensive suite of LLM-based safety content\nmoderation models built upon Gemma2. These models provide robust,\nstate-of-the-art predictions of safety risks across key harm types (sexually\nexplicit, dangerous content, harassment, hate speech) in both user input and\nLLM-generated output. By evaluating on both public and internal benchmarks, we\ndemonstrate superior performance compared to existing models, such as Llama\nGuard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\na variety of safety-related tasks and beyond. We have shown strong\ngeneralization performance for model trained mainly on synthetic data. By\nreleasing ShieldGemma, we provide a valuable resource to the research\ncommunity, advancing LLM safety and enabling the creation of more effective\ncontent moderation solutions for developers.\n","authors":["Wenjun Zeng","Yuchi Liu","Ryan Mullins","Ludovic Peran","Joe Fernandez","Hamza Harkous","Karthik Narasimhan","Drew Proud","Piyush Kumar","Bhaktipriya Radharapu","Olivia Sturman","Oscar Wahltinez"],"pdf_url":"https://arxiv.org/pdf/2407.21772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18426v2","updated":"2024-08-04T22:13:16Z","published":"2024-07-25T23:04:37Z","title":"Diffusion-based subsurface multiphysics monitoring and forecasting","summary":"  Carbon capture and storage (CCS) plays a crucial role in mitigating\ngreenhouse gas emissions, particularly from industrial outputs. Using seismic\nmonitoring can aid in an accurate and robust monitoring system to ensure the\neffectiveness of CCS and mitigate associated risks. However, conventional\nseismic wave equation-based approaches are computationally demanding, which\nhinders real-time applications. In addition to efficiency, forecasting and\nuncertainty analysis are not easy to handle using such\nnumerical-simulation-based approaches. To this end, we propose a novel\nsubsurface multiphysics monitoring and forecasting framework utilizing video\ndiffusion models. This approach can generate high-quality representations of\nCO$2$ evolution and associated changes in subsurface elastic properties. With\nreconstruction guidance, forecasting and inversion can be achieved conditioned\non historical frames and/or observational data. Meanwhile, due to the\ngenerative nature of the approach, we can quantify uncertainty in the\nprediction. Tests based on the Compass model show that the proposed method\nsuccessfully captured the inherently complex physical phenomena associated with\nCO$_2$ monitoring, and it can predict and invert the subsurface elastic\nproperties and CO$_2$ saturation with consistency in their evolution.\n","authors":["Xinquan Huang","Fu Wang","Tariq Alkhalifah"],"pdf_url":"https://arxiv.org/pdf/2407.18426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02153v1","updated":"2024-08-04T22:13:14Z","published":"2024-08-04T22:13:14Z","title":"ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software","summary":"  High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.\n","authors":["Xiang Mei","Pulkit Singh Singaria","Jordi Del Castillo","Haoran Xi"," Abdelouahab"," Benchikh","Tiffany Bao","Ruoyu Wang","Yan Shoshitaishvili","Adam Doupé","Hammond Pearce","Brendan Dolan-Gavitt"],"pdf_url":"https://arxiv.org/pdf/2408.02153v1.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.02152v1","updated":"2024-08-04T22:00:34Z","published":"2024-08-04T22:00:34Z","title":"Generative Retrieval with Few-shot Indexing","summary":"  Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.\n","authors":["Arian Askari","Chuan Meng","Mohammad Aliannejadi","Zhaochun Ren","Evangelos Kanoulas","Suzan Verberne"],"pdf_url":"https://arxiv.org/pdf/2408.02152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16056v2","updated":"2024-08-04T20:45:16Z","published":"2023-05-25T13:38:53Z","title":"Markov Decision Processes under External Temporal Processes","summary":"  Most reinforcement learning algorithms treat the context under which they\noperate as a stationary, isolated, and undisturbed environment. However, in\nreal world applications, environments constantly change due to a variety of\nexternal events. To address this problem, we study Markov Decision Processes\n(MDP) under the influence of an external temporal process. We formalize this\nnotion and discuss conditions under which the problem becomes tractable with\nsuitable solutions. We propose a policy iteration algorithm to solve this\nproblem and theoretically analyze its performance. We derive results on the\nsample complexity of the algorithm and study its dependency on the extent of\nnon-stationarity of the environment. We then conduct experiments to illustrate\nour results in a classic control environment.\n","authors":["Ranga Shaarad Ayyagari","Ambedkar Dukkipati"],"pdf_url":"https://arxiv.org/pdf/2305.16056v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02140v1","updated":"2024-08-04T20:38:45Z","published":"2024-08-04T20:38:45Z","title":"VidModEx: Interpretable and Efficient Black Box Model Extraction for\n  High-Dimensional Spaces","summary":"  In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.\n","authors":["Somnath Sendhil Kumar","Yuvaraj Govindarajulu","Pavan Kulkarni","Manojkumar Parmar"],"pdf_url":"https://arxiv.org/pdf/2408.02140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02131v1","updated":"2024-08-04T20:02:07Z","published":"2024-08-04T20:02:07Z","title":"Model Hijacking Attack in Federated Learning","summary":"  Machine learning (ML), driven by prominent paradigms such as centralized and\nfederated learning, has made significant progress in various critical\napplications ranging from autonomous driving to face recognition. However, its\nremarkable success has been accompanied by various attacks. Recently, the model\nhijacking attack has shown that ML models can be hijacked to execute tasks\ndifferent from their original tasks, which increases both accountability and\nparasitic computational risks. Nevertheless, thus far, this attack has only\nfocused on centralized learning. In this work, we broaden the scope of this\nattack to the federated learning domain, where multiple clients collaboratively\ntrain a global model without sharing their data. Specifically, we present\nHijackFL, the first-of-its-kind hijacking attack against the global model in\nfederated learning. The adversary aims to force the global model to perform a\ndifferent task (called hijacking task) from its original task without the\nserver or benign client noticing. To accomplish this, unlike existing methods\nthat use data poisoning to modify the target model's parameters, HijackFL\nsearches for pixel-level perturbations based on their local model (without\nmodifications) to align hijacking samples with the original ones in the feature\nspace. When performing the hijacking task, the adversary applies these cloaks\nto the hijacking samples, compelling the global model to identify them as\noriginal samples and predict them accordingly. We conduct extensive experiments\non four benchmark datasets and three popular models. Empirical results\ndemonstrate that its attack performance outperforms baselines. We further\ninvestigate the factors that affect its performance and discuss possible\ndefenses to mitigate its impact.\n","authors":["Zheng Li","Siyuan Wu","Ruichuan Chen","Paarijaat Aditya","Istemi Ekin Akkus","Manohar Vanga","Min Zhang","Hao Li","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.02131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02123v1","updated":"2024-08-04T19:37:30Z","published":"2024-08-04T19:37:30Z","title":"FovEx: Human-inspired Explanations for Vision Transformers and\n  Convolutional Neural Networks","summary":"  Explainability in artificial intelligence (XAI) remains a crucial aspect for\nfostering trust and understanding in machine learning models. Current visual\nexplanation techniques, such as gradient-based or class-activation-based\nmethods, often exhibit a strong dependence on specific model architectures.\nConversely, perturbation-based methods, despite being model-agnostic, are\ncomputationally expensive as they require evaluating models on a large number\nof forward passes. In this work, we introduce Foveation-based Explanations\n(FovEx), a novel XAI method inspired by human vision. FovEx seamlessly\nintegrates biologically inspired perturbations by iteratively creating foveated\nrenderings of the image and combines them with gradient-based visual\nexplorations to determine locations of interest efficiently. These locations\nare selected to maximize the performance of the model to be explained with\nrespect to the downstream task and then combined to generate an attribution\nmap. We provide a thorough evaluation with qualitative and quantitative\nassessments on established benchmarks. Our method achieves state-of-the-art\nperformance on both transformers (on 4 out of 5 metrics) and convolutional\nmodels (on 3 out of 5 metrics), demonstrating its versatility among various\narchitectures. Furthermore, we show the alignment between the explanation map\nproduced by FovEx and human gaze patterns (+14\\% in NSS compared to RISE,\n+203\\% in NSS compared to GradCAM). This comparison enhances our confidence in\nFovEx's ability to close the interpretation gap between humans and machines.\n","authors":["Mahadev Prasad Panda","Matteo Tiezzi","Martina Vilas","Gemma Roig","Bjoern M. Eskofier","Dario Zanca"],"pdf_url":"https://arxiv.org/pdf/2408.02123v1.pdf","comment":"Under submission"},{"id":"http://arxiv.org/abs/2408.02117v1","updated":"2024-08-04T19:14:36Z","published":"2024-08-04T19:14:36Z","title":"Value-Based Rationales Improve Social Experience: A Multiagent\n  Simulation Study","summary":"  We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.\n","authors":["Sz-Ting Tzeng","Nirav Ajmeri","Munindar P. Singh"],"pdf_url":"https://arxiv.org/pdf/2408.02117v1.pdf","comment":"13 pages, 13 figures, 13 tables (and supplementary material with\n  reproducibility and additional results), accepted at ECAI 2024"},{"id":"http://arxiv.org/abs/2408.02114v1","updated":"2024-08-04T18:57:21Z","published":"2024-08-04T18:57:21Z","title":"Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey\n  on Methods and Datasets","summary":"  This paper provides a thorough examination of recent developments in the\nfield of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark\ndatasets, methodologies, challenges, and future trajectories, our goal is to\noffer researchers a comprehensive overview of the current landscape in\nmulti-choice MRC. The analysis delves into 30 existing cloze-style and\nmultiple-choice MRC benchmark datasets, employing a refined classification\nmethod based on attributes such as corpus style, domain, complexity, context\nstyle, question style, and answer style. This classification system enhances\nour understanding of each dataset's diverse attributes and categorizes them\nbased on their complexity. Furthermore, the paper categorizes recent\nmethodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods\ninvolve adapting pre-trained language models (PLMs) to a specific task through\nretraining on domain-specific datasets, while prompt-tuned methods use prompts\nto guide PLM response generation, presenting potential applications in\nzero-shot or few-shot learning scenarios. By contributing to ongoing\ndiscussions, inspiring future research directions, and fostering innovations,\nthis paper aims to propel multi-choice MRC towards new frontiers of\nachievement.\n","authors":["Shima Foolad","Kourosh Kiani","Razieh Rastgoo"],"pdf_url":"https://arxiv.org/pdf/2408.02114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02111v1","updated":"2024-08-04T18:47:55Z","published":"2024-08-04T18:47:55Z","title":"Understanding Deep Learning via Notions of Rank","summary":"  Despite the extreme popularity of deep learning in science and industry, its\nformal understanding is limited. This thesis puts forth notions of rank as key\nfor developing a theory of deep learning, focusing on the fundamental aspects\nof generalization and expressiveness. In particular, we establish that\ngradient-based training can induce an implicit regularization towards low rank\nfor several neural network architectures, and demonstrate empirically that this\nphenomenon may facilitate an explanation of generalization over natural data\n(e.g., audio, images, and text). Then, we characterize the ability of graph\nneural networks to model interactions via a notion of rank, which is commonly\nused for quantifying entanglement in quantum physics. A central tool underlying\nthese results is a connection between neural networks and tensor\nfactorizations. Practical implications of our theory for designing explicit\nregularization schemes and data preprocessing algorithms are presented.\n","authors":["Noam Razin"],"pdf_url":"https://arxiv.org/pdf/2408.02111v1.pdf","comment":"PhD thesis"},{"id":"http://arxiv.org/abs/2405.01013v2","updated":"2024-08-04T18:09:39Z","published":"2024-05-02T05:29:22Z","title":"Non-clairvoyant Scheduling with Partial Predictions","summary":"  The non-clairvoyant scheduling problem has gained new interest within\nlearning-augmented algorithms, where the decision-maker is equipped with\npredictions without any quality guarantees. In practical settings, access to\npredictions may be reduced to specific instances, due to cost or data\nlimitations. Our investigation focuses on scenarios where predictions for only\n$B$ job sizes out of $n$ are available to the algorithm. We first establish\nnear-optimal lower bounds and algorithms in the case of perfect predictions.\nSubsequently, we present a learning-augmented algorithm satisfying the\nrobustness, consistency, and smoothness criteria, and revealing a novel\ntradeoff between consistency and smoothness inherent in the scenario with a\nrestricted number of predictions.\n","authors":["Ziyad Benomar","Vianney Perchet"],"pdf_url":"https://arxiv.org/pdf/2405.01013v2.pdf","comment":"Accepted as a conference paper at ICML 2024"},{"id":"http://arxiv.org/abs/2402.12668v2","updated":"2024-08-04T18:07:51Z","published":"2024-02-20T02:36:26Z","title":"Randomization Can Reduce Both Bias and Variance: A Case Study in Random\n  Forests","summary":"  We study the often overlooked phenomenon, first noted in\n\\cite{breiman2001random}, that random forests appear to reduce bias compared to\nbagging. Motivated by an interesting paper by \\cite{mentch2020randomization},\nwhere the authors argue that random forests reduce effective degrees of freedom\nand only outperform bagging ensembles in low signal-to-noise ratio (SNR)\nsettings, we explore how random forests can uncover patterns in the data missed\nby bagging. We empirically demonstrate that in the presence of such patterns,\nrandom forests reduce bias along with variance and increasingly outperform\nbagging ensembles when SNR is high. Our observations offer insights into the\nreal-world success of random forests across a range of SNRs and enhance our\nunderstanding of the difference between random forests and bagging ensembles\nwith respect to the randomization injected into each split. Our investigations\nalso yield practical insights into the importance of tuning $mtry$ in random\nforests.\n","authors":["Brian Liu","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2402.12668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00927v2","updated":"2024-08-04T18:04:50Z","published":"2024-07-01T03:17:34Z","title":"Learnability of Parameter-Bounded Bayes Nets","summary":"  Bayes nets are extensively used in practice to efficiently represent joint\nprobability distributions over a set of random variables and capture dependency\nrelations. In a seminal paper, Chickering et al. (JMLR 2004) showed that given\na distribution $\\mathbb{P}$, that is defined as the marginal distribution of a\nBayes net, it is $\\mathsf{NP}$-hard to decide whether there is a\nparameter-bounded Bayes net that represents $\\mathbb{P}$. They called this\nproblem LEARN. In this work, we extend the $\\mathsf{NP}$-hardness result of\nLEARN and prove the $\\mathsf{NP}$-hardness of a promise search variant of\nLEARN, whereby the Bayes net in question is guaranteed to exist and one is\nasked to find such a Bayes net. We complement our hardness result with a\npositive result about the sample complexity that is sufficient to recover a\nparameter-bounded Bayes net that is close (in TV distance) to a given\ndistribution $\\mathbb{P}$, that is represented by some parameter-bounded Bayes\nnet, generalizing a degree-bounded sample complexity result of Brustle et al.\n(EC 2020).\n","authors":["Arnab Bhattacharyya","Davin Choo","Sutanu Gayen","Dimitrios Myrisiotis"],"pdf_url":"https://arxiv.org/pdf/2407.00927v2.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2312.14302v2","updated":"2024-08-04T17:48:33Z","published":"2023-12-21T21:22:41Z","title":"Exploiting Novel GPT-4 APIs","summary":"  Language model attacks typically assume one of two extreme threat models:\nfull white-box access to model weights, or black-box access limited to a text\ngeneration API. However, real-world APIs are often more flexible than just text\ngeneration: these APIs expose \"gray-box\" access leading to new threat vectors.\nTo explore this, we red-team three new functionalities exposed in the GPT-4\nAPIs: fine-tuning, function calling and knowledge retrieval. We find that\nfine-tuning a model on as few as 15 harmful examples or 100 benign examples can\nremove core safeguards from GPT-4, enabling a range of harmful outputs.\nFurthermore, we find that GPT-4 Assistants readily divulge the function call\nschema and can be made to execute arbitrary function calls. Finally, we find\nthat knowledge retrieval can be hijacked by injecting instructions into\nretrieval documents. These vulnerabilities highlight that any additions to the\nfunctionality exposed by an API can create new vulnerabilities.\n","authors":["Kellin Pelrine","Mohammad Taufeeque","Michał Zając","Euan McLean","Adam Gleave"],"pdf_url":"https://arxiv.org/pdf/2312.14302v2.pdf","comment":"10 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2307.00575v2","updated":"2024-08-04T16:28:21Z","published":"2023-07-02T13:59:47Z","title":"Mode-wise Principal Subspace Pursuit and Matrix Spiked Covariance Model","summary":"  This paper introduces a novel framework called Mode-wise Principal Subspace\nPursuit (MOP-UP) to extract hidden variations in both the row and column\ndimensions for matrix data. To enhance the understanding of the framework, we\nintroduce a class of matrix-variate spiked covariance models that serve as\ninspiration for the development of the MOP-UP algorithm. The MOP-UP algorithm\nconsists of two steps: Average Subspace Capture (ASC) and Alternating\nProjection (AP). These steps are specifically designed to capture the row-wise\nand column-wise dimension-reduced subspaces which contain the most informative\nfeatures of the data. ASC utilizes a novel average projection operator as\ninitialization and achieves exact recovery in the noiseless setting. We analyze\nthe convergence and non-asymptotic error bounds of MOP-UP, introducing a\nblockwise matrix eigenvalue perturbation bound that proves the desired bound,\nwhere classic perturbation bounds fail. The effectiveness and practical merits\nof the proposed framework are demonstrated through experiments on both\nsimulated and real datasets. Lastly, we discuss generalizations of our approach\nto higher-order data.\n","authors":["Runshi Tang","Ming Yuan","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.00575v2.pdf","comment":"Journal of the Royal Statistical Society, Series B, to appear"},{"id":"http://arxiv.org/abs/2404.14462v3","updated":"2024-08-04T16:24:15Z","published":"2024-04-22T06:19:46Z","title":"Towards smaller, faster decoder-only transformers: Architectural\n  variants and their implications","summary":"  In recent times, the research on Large Language Models (LLMs) has grown\nexponentially, predominantly focusing on models underpinned by the transformer\narchitecture, as established by [1], and further developed through the\ndecoder-only variations by [2]. Contemporary efforts in this field primarily\naim to enhance model capabilities by scaling up both the architecture and data\nvolumes utilized during training. However, the exploration into reduce these\nmodel sizes while preserving their efficacy remains scant. In this study, we\nintroduce three modifications to the decoder-only transformer architecture,\nnamely ParallelGPT (pgpt), LinearGPT (lgpt), and ConvGPT (cgpt). These variants\ndemonstrate comparable performance to the conventional architecture in language\ngeneration, yet benefit from reduced model sizes and faster training processes.\nWe open-source the model weights and the complete codebase for these\nimplementation for further research.\n","authors":["Sathya Krishnan Suresh","Shunmugapriya P"],"pdf_url":"https://arxiv.org/pdf/2404.14462v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2407.02461v2","updated":"2024-08-04T15:41:23Z","published":"2024-07-02T17:40:06Z","title":"Decentralized Intelligence Network (DIN)","summary":"  Decentralized Intelligence Network (DIN) is a theoretical framework\naddressing data fragmentation and siloing challenges, enabling scalable AI\nthrough data sovereignty. It facilitates effective AI utilization within\nsovereign networks by overcoming barriers to accessing diverse data sources,\nleveraging: 1) personal data stores to ensure data sovereignty, where data\nremains securely within Participants' control; 2) a scalable federated learning\nprotocol implemented on a public blockchain for decentralized AI training,\nwhere only model parameter updates are shared, keeping data within the personal\ndata stores; and 3) a scalable, trustless cryptographic rewards mechanism on a\npublic blockchain to incentivize participation and ensure fair reward\ndistribution through a decentralized auditing protocol. This approach\nguarantees that no entity can prevent or control access to training data or\ninfluence financial benefits, as coordination and reward distribution are\nmanaged on the public blockchain with an immutable record. The framework\nsupports effective AI training by allowing Participants to maintain control\nover their data, benefit financially, and contribute to a decentralized,\nscalable ecosystem that leverages collective AI to develop beneficial\nalgorithms.\n","authors":["Abraham Nash"],"pdf_url":"https://arxiv.org/pdf/2407.02461v2.pdf","comment":"14 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.02065v1","updated":"2024-08-04T15:30:15Z","published":"2024-08-04T15:30:15Z","title":"A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal\n  Networks","summary":"  In the ride-hailing industry, subsidies are predominantly employed to\nincentivize consumers to place more orders, thereby fostering market growth.\nCausal inference techniques are employed to estimate the consumer elasticity\nwith different subsidy levels. However, the presence of confounding effects\nposes challenges in achieving an unbiased estimate of the uplift effect. We\nintroduce a consumer subsidizing system to capture relationships between\nsubsidy propensity and the treatment effect, which proves effective while\nmaintaining a lightweight online environment.\n","authors":["Zhe Yu","Chi Xia","Shaosheng Cao","Lin Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02063v3","updated":"2024-08-04T15:16:27Z","published":"2024-05-03T12:48:21Z","title":"Few-sample Variational Inference of Bayesian Neural Networks with\n  Arbitrary Nonlinearities","summary":"  Bayesian Neural Networks (BNNs) extend traditional neural networks to provide\nuncertainties associated with their outputs. On the forward pass through a BNN,\npredictions (and their uncertainties) are made either by Monte Carlo sampling\nnetwork weights from the learned posterior or by analytically propagating\nstatistical moments through the network. Though flexible, Monte Carlo sampling\nis computationally expensive and can be infeasible or impractical under\nresource constraints or for large networks. While moment propagation can\nameliorate the computational costs of BNN inference, it can be difficult or\nimpossible for networks with arbitrary nonlinearities, thereby restricting the\npossible set of network layers permitted with such a scheme. In this work, we\ndemonstrate a simple yet effective approach for propagating statistical moments\nthrough arbitrary nonlinearities with only 3 deterministic samples, enabling\nfew-sample variational inference of BNNs without restricting the set of network\nlayers used. Furthermore, we leverage this approach to demonstrate a novel\nnonlinear activation function that we use to inject physics-informed prior\ninformation into output nodes of a BNN.\n","authors":["David J. Schodt"],"pdf_url":"https://arxiv.org/pdf/2405.02063v3.pdf","comment":"Comment 1: Fixed plot markers in figure 6 to match legend and to\n  improve grayscale appearance"},{"id":"http://arxiv.org/abs/2408.02056v1","updated":"2024-08-04T15:07:44Z","published":"2024-08-04T15:07:44Z","title":"MedSyn: LLM-based Synthetic Medical Text Generation Framework","summary":"  Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.\n","authors":["Gleb Kumichev","Pavel Blinov","Yulia Kuzkina","Vasily Goncharov","Galina Zubkova","Nikolai Zenovkin","Aleksei Goncharov","Andrey Savchenko"],"pdf_url":"https://arxiv.org/pdf/2408.02056v1.pdf","comment":"16 pages, accepted to ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2408.02052v1","updated":"2024-08-04T15:00:22Z","published":"2024-08-04T15:00:22Z","title":"EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier\n  Logits","summary":"  In Few-Shot Learning (FSL), models are trained to recognise unseen objects\nfrom a query set, given a few labelled examples from a support set. In standard\nFSL, models are evaluated on query instances sampled from the same class\ndistribution of the support set. In this work, we explore the more nuanced and\npractical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard\nFSL, OSFSL incorporates unknown classes into the query set, thereby requiring\nthe model not only to classify known classes but also to identify outliers.\nBuilding on the groundwork laid by previous studies, we define a novel\ntransductive inference technique that leverages the InfoMax principle to\nexploit the unlabelled query set. We called our approach the Enhanced Outlier\nLogit (EOL) method. EOL refines class prototype representations through model\ncalibration, effectively balancing the inlier-outlier ratio. This calibration\nenhances pseudo-label accuracy for the query set and improves the optimisation\nobjective within the transductive inference process. We provide a comprehensive\nempirical evaluation demonstrating that EOL consistently surpasses traditional\nmethods, recording performance improvements ranging from approximately $+1.3%$\nto $+6.3%$ across a variety of classification and outlier detection metrics and\nbenchmarks, even in the presence of inlier-outlier imbalance.\n","authors":["Mateusz Ochal","Massimiliano Patacchiola","Malik Boudiaf","Sen Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02052v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2408.02050v1","updated":"2024-08-04T14:57:44Z","published":"2024-08-04T14:57:44Z","title":"Recovering the state and dynamics of autonomous system with partial\n  states solution using neural networks","summary":"  In this paper we explore the performance of deep hidden physics model (M.\nRaissi 2018) for autonomous system, this systems do not explicitly depend on\ntime. The dynamics of states are dependent on states itself. Such systems can\nbe found in nature and have applications\n  in modeling chemical concentrations, population dynamics, n-body problems in\nphysics etc. In this work we are going to see how we can obtain dynamics of\nstates based on solution of limited partial states. The proposed method can\nfind the state and dynamics of which the data is provided in the training,\nalthough we do not claim to accurately find the solution of states whose data\nis not utilized while training.\n","authors":["Vijay Kag"],"pdf_url":"https://arxiv.org/pdf/2408.02050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07769v3","updated":"2024-08-04T14:46:14Z","published":"2024-01-15T15:27:24Z","title":"Deep Evolutional Instant Interest Network for CTR Prediction in\n  Trigger-Induced Recommendation","summary":"  The recommendation has been playing a key role in many industries, e.g.,\ne-commerce, streaming media, social media, etc. Recently, a new recommendation\nscenario, called Trigger-Induced Recommendation (TIR), where users are able to\nexplicitly express their instant interests via trigger items, is emerging as an\nessential role in many e-commerce platforms, e.g., Alibaba.com and Amazon.\nWithout explicitly modeling the user's instant interest, traditional\nrecommendation methods usually obtain sub-optimal results in TIR. Even though\nthere are a few methods considering the trigger and target items simultaneously\nto solve this problem, they still haven't taken into account temporal\ninformation of user behaviors, the dynamic change of user instant interest when\nthe user scrolls down and the interactions between the trigger and target\nitems. To tackle these problems, we propose a novel method -- Deep Evolutional\nInstant Interest Network (DEI2N), for click-through rate prediction in TIR\nscenarios. Specifically, we design a User Instant Interest Modeling Layer to\npredict the dynamic change of the intensity of instant interest when the user\nscrolls down. Temporal information is utilized in user behavior modeling.\nMoreover, an Interaction Layer is introduced to learn better interactions\nbetween the trigger and target items. We evaluate our method on several offline\nand real-world industrial datasets. Experimental results show that our proposed\nDEI2N outperforms state-of-the-art baselines. In addition, online A/B testing\ndemonstrates the superiority over the existing baseline in real-world\nproduction environments.\n","authors":["Zhibo Xiao","Luwei Yang","Tao Zhang","Wen Jiang","Wei Ning","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2401.07769v3.pdf","comment":"7 pages, 6 figures, accepted by the 17th ACM International Conference\n  on Web Search and Data Mining(WSDM'2024)"},{"id":"http://arxiv.org/abs/2408.02045v1","updated":"2024-08-04T14:45:26Z","published":"2024-08-04T14:45:26Z","title":"DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation","summary":"  Semiparametric statistics play a pivotal role in a wide range of domains,\nincluding but not limited to missing data, causal inference, and transfer\nlearning, to name a few. In many settings, semiparametric theory leads to\n(nearly) statistically optimal procedures that yet involve numerically solving\nFredholm integral equations of the second kind. Traditional numerical methods,\nsuch as polynomial or spline approximations, are difficult to scale to\nmulti-dimensional problems. Alternatively, statisticians may choose to\napproximate the original integral equations by ones with closed-form solutions,\nresulting in computationally more efficient, but statistically suboptimal or\neven incorrect procedures. To bridge this gap, we propose a novel framework by\nformulating the semiparametric estimation problem as a bi-level optimization\nproblem; and then we develop a scalable algorithm called Deep Neural-Nets\nAssisted Semiparametric Estimation (DNA-SE) by leveraging the universal\napproximation property of Deep Neural-Nets (DNN) to streamline semiparametric\nprocedures. Through extensive numerical experiments and a real data analysis,\nwe demonstrate the numerical and statistical advantages of $\\dnase$ over\ntraditional methods. To the best of our knowledge, we are the first to bring\nDNN into semiparametric statistics as a numerical solver of integral equations\nin our proposed general framework.\n","authors":["Qinshuo Liu","Zixin Wang","Xi-An Li","Xinyao Ji","Lei Zhang","Lin Liu","Zhonghua Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02045v1.pdf","comment":"semiparametric statistics, missing data, causal inference, Fredholm\n  integral equations of the second kind, bi-level optimization, deep learning,\n  AI for science"},{"id":"http://arxiv.org/abs/2408.02033v1","updated":"2024-08-04T13:51:18Z","published":"2024-08-04T13:51:18Z","title":"Enhancing Human Action Recognition and Violence Detection Through Deep\n  Learning Audiovisual Fusion","summary":"  This paper proposes a hybrid fusion-based deep learning approach based on two\ndifferent modalities, audio and video, to improve human activity recognition\nand violence detection in public places. To take advantage of audiovisual\nfusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning\n(HFBDL) are used and compared. Since the objective is to detect and recognize\nhuman violence in public places, Real-life violence situation (RLVS) dataset is\nexpanded and used. Simulating results of HFBDL show 96.67\\% accuracy on\nvalidation data, which is more accurate than the other state-of-the-art methods\non this dataset. To showcase our model's ability in real-world scenarios,\nanother dataset of 54 sounded videos of both violent and non-violent situations\nwas recorded. The model could successfully detect 52 out of 54 videos\ncorrectly. The proposed method shows a promising performance on real scenarios.\nThus, it can be used for human action recognition and violence detection in\npublic places for security purposes.\n","authors":["Pooya Janani","Amirabolfazl Suratgar","Afshin Taghvaeipour"],"pdf_url":"https://arxiv.org/pdf/2408.02033v1.pdf","comment":"This work has been submitted to the IEEE for possible publication, 10\n  pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.02022v1","updated":"2024-08-04T13:19:45Z","published":"2024-08-04T13:19:45Z","title":"Scenario-based Thermal Management Parametrization Through Deep\n  Reinforcement Learning","summary":"  The thermal system of battery electric vehicles demands advanced control. Its\nthermal management needs to effectively control active components across\nvarying operating conditions. While robust control function parametrization is\nrequired, current methodologies show significant drawbacks. They consume\nconsiderable time, human effort, and extensive real-world testing.\nConsequently, there is a need for innovative and intelligent solutions that are\ncapable of autonomously parametrizing embedded controllers. Addressing this\nissue, our paper introduces a learning-based tuning approach. We propose a\nmethodology that benefits from automated scenario generation for increased\nrobustness across vehicle usage scenarios. Our deep reinforcement learning\nagent processes the tuning task context and incorporates an image-based\ninterpretation of embedded parameter sets. We demonstrate its applicability to\na valve controller parametrization task and verify it in real-world vehicle\ntesting. The results highlight the competitive performance to baseline methods.\nThis novel approach contributes to the shift towards virtual development of\nthermal management functions, with promising potential of large-scale parameter\ntuning in the automotive industry.\n","authors":["Thomas Rudolf","Philip Muhl","Sören Hohmann","Lutz Eckstein"],"pdf_url":"https://arxiv.org/pdf/2408.02022v1.pdf","comment":"8 pages, 7 figures, 2 tables, 1 algorithm, 10 equations, conference"},{"id":"http://arxiv.org/abs/2408.02019v1","updated":"2024-08-04T13:11:49Z","published":"2024-08-04T13:11:49Z","title":"Personalized Federated Learning on Heterogeneous and Long-Tailed Data\n  via Expert Collaborative Learning","summary":"  Personalized Federated Learning (PFL) aims to acquire customized models for\neach client without disclosing raw data by leveraging the collective knowledge\nof distributed clients. However, the data collected in real-world scenarios is\nlikely to follow a long-tailed distribution. For example, in the medical\ndomain, it is more common for the number of general health notes to be much\nlarger than those specifically relatedto certain diseases. The presence of\nlong-tailed data can significantly degrade the performance of PFL models.\nAdditionally, due to the diverse environments in which each client operates,\ndata heterogeneity is also a classic challenge in federated learning. In this\npaper, we explore the joint problem of global long-tailed distribution and data\nheterogeneity in PFL and propose a method called Expert Collaborative Learning\n(ECL) to tackle this problem. Specifically, each client has multiple experts,\nand each expert has a different training subset, which ensures that each class,\nespecially the minority classes, receives sufficient training. Multiple experts\ncollaborate synergistically to produce the final prediction output. Without\nspecial bells and whistles, the vanilla ECL outperforms other state-of-the-art\nPFL methods on several benchmark datasets under different degrees of data\nheterogeneity and long-tailed distribution.\n","authors":["Fengling Lv","Xinyi Shang","Yang Zhou","Yiqun Zhang","Mengke Li","Yang Lu"],"pdf_url":"https://arxiv.org/pdf/2408.02019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02014v1","updated":"2024-08-04T12:52:44Z","published":"2024-08-04T12:52:44Z","title":"Unsupervised Representation Learning by Balanced Self Attention Matching","summary":"  Many leading self-supervised methods for unsupervised representation\nlearning, in particular those for embedding image features, are built on\nvariants of the instance discrimination task, whose optimization is known to be\nprone to instabilities that can lead to feature collapse. Different techniques\nhave been devised to circumvent this issue, including the use of negative pairs\nwith different contrastive losses, the use of external memory banks, and\nbreaking of symmetry by using separate encoding networks with possibly\ndifferent structures. Our method, termed BAM, rather than directly matching\nfeatures of different views (augmentations) of input images, is based on\nmatching their self-attention vectors, which are the distributions of\nsimilarities to the entire set of augmented images of a batch. We obtain rich\nrepresentations and avoid feature collapse by minimizing a loss that matches\nthese distributions to their globally balanced and entropy regularized version,\nwhich is obtained through a simple self-optimal-transport computation. We\nablate and verify our method through a wide set of experiments that show\ncompetitive performance with leading methods on both semi-supervised and\ntransfer-learning benchmarks. Our implementation and pre-trained models are\navailable at github.com/DanielShalam/BAM .\n","authors":["Daniel Shalam","Simon Korman"],"pdf_url":"https://arxiv.org/pdf/2408.02014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01249v2","updated":"2024-08-04T12:34:29Z","published":"2023-09-03T19:24:34Z","title":"Large AI Model Empowered Multimodal Semantic Communications","summary":"  Multimodal signals, including text, audio, image, and video, can be\nintegrated into Semantic Communication (SC) systems to provide an immersive\nexperience with low latency and high quality at the semantic level. However,\nthe multimodal SC has several challenges, including data heterogeneity,\nsemantic ambiguity, and signal distortion during transmission. Recent\nadvancements in large AI models, particularly in the Multimodal Language Model\n(MLM) and Large Language Model (LLM), offer potential solutions for addressing\nthese issues. To this end, we propose a Large AI Model-based Multimodal SC\n(LAM-MSC) framework, where we first present the MLM-based Multimodal Alignment\n(MMA) that utilizes the MLM to enable the transformation between multimodal and\nunimodal data while preserving semantic consistency. Then, a personalized\nLLM-based Knowledge Base (LKB) is proposed, which allows users to perform\npersonalized semantic extraction or recovery through the LLM. This effectively\naddresses the semantic ambiguity. Finally, we apply the Conditional Generative\nadversarial network-based channel Estimation (CGE) for estimating the wireless\nchannel state information. This approach effectively mitigates the impact of\nfading channels in SC. Finally, we conduct simulations that demonstrate the\nsuperior performance of the LAM-MSC framework.\n","authors":["Feibo Jiang","Li Dong","Yubo Peng","Kezhi Wang","Kun Yang","Cunhua Pan","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2309.01249v2.pdf","comment":"Accepted by IEEE CM"},{"id":"http://arxiv.org/abs/2312.16019v3","updated":"2024-08-04T12:12:36Z","published":"2023-12-26T12:18:31Z","title":"Robust Survival Analysis with Adversarial Regularization","summary":"  Survival Analysis (SA) models the time until an event occurs, with\napplications in fields like medicine, defense, finance, and aerospace. Recent\nwork shows that Neural Networks (NNs) can capture complex relationships in SA.\nHowever, dataset uncertainties (e.g., noisy measurements, human error) can\ndegrade model performance. To address this, we leverage NN verification\nadvances to create algorithms for robust, fully-parametric survival models. We\nintroduce a robust loss function and use CROWN-IBP regularization to handle\ncomputational challenges in the Min-Max problem. Evaluating our approach on\nSurvSet datasets, we find that our Survival Analysis with Adversarial\nRegularization (SAWAR) method consistently outperforms baselines under various\nperturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier\nScore (IBS), and Concordance Index (CI). This demonstrates that adversarial\nregularization enhances SA performance and calibration, mitigating data\nuncertainty and improving generalization across diverse datasets up to 150%\nacross all perturbation magnitudes.\n","authors":["Michael Potter","Stefano Maxenti","Michael Everett"],"pdf_url":"https://arxiv.org/pdf/2312.16019v3.pdf","comment":"12 pages, 2 figures, submission to IEEE Journal of Biomedical and\n  Health Informatics"},{"id":"http://arxiv.org/abs/2408.01993v1","updated":"2024-08-04T11:25:07Z","published":"2024-08-04T11:25:07Z","title":"Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in EDR\n  Solutions","summary":"  Endpoint Detection and Remediation (EDR) platforms are essential for\nidentifying and responding to cyber threats. This study presents a novel\napproach using Large Language Models (LLMs) to detect Hands-on-Keyboard (HOK)\ncyberattacks. Our method involves converting endpoint activity data into\nnarrative forms that LLMs can analyze to distinguish between normal operations\nand potential HOK attacks. We address the challenges of interpreting endpoint\ndata by segmenting narratives into windows and employing a dual training\nstrategy. The results demonstrate that LLM-based models have the potential to\noutperform traditional machine learning methods, offering a promising direction\nfor enhancing EDR capabilities and apply LLMs in cybersecurity.\n","authors":["Amit Portnoy","Ehud Azikri","Shay Kels"],"pdf_url":"https://arxiv.org/pdf/2408.01993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01988v1","updated":"2024-08-04T11:00:43Z","published":"2024-08-04T11:00:43Z","title":"MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few\n  Shots","summary":"  Wearable systems provide continuous health monitoring and can lead to early\ndetection of potential health issues. However, the lifecycle of wearable\nsystems faces several challenges. First, effective model training for new\nwearable devices requires substantial labeled data from various subjects\ncollected directly by the wearable. Second, subsequent model updates require\nfurther extensive labeled data for retraining. Finally, frequent model updating\non the wearable device can decrease the battery life in long-term data\nmonitoring. Addressing these challenges, in this paper, we propose MetaWearS, a\nmeta-learning method to reduce the amount of initial data collection required.\nMoreover, our approach incorporates a prototypical updating mechanism,\nsimplifying the update process by modifying the class prototype rather than\nretraining the entire model. We explore the performance of MetaWearS in two\ncase studies, namely, the detection of epileptic seizures and the detection of\natrial fibrillation. We show that by fine-tuning with just a few samples, we\nachieve 70% and 82% AUC for the detection of epileptic seizures and the\ndetection of atrial fibrillation, respectively. Compared to a conventional\napproach, our proposed method performs better with up to 45% AUC. Furthermore,\nupdating the model with only 16 minutes of additional labeled data increases\nthe AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for\nmodel updates by 456x and 418x for epileptic seizure and AF detection,\nrespectively.\n","authors":["Alireza Amirshahi","Maedeh H. Toosi","Siamak Mohammadi","Stefano Albini","Pasquale Davide Schiavone","Giovanni Ansaloni","Amir Aminifar","David Atienza"],"pdf_url":"https://arxiv.org/pdf/2408.01988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08442v2","updated":"2024-08-04T10:42:42Z","published":"2022-06-16T20:48:19Z","title":"A Look at Value-Based Decision-Time vs. Background Planning Methods\n  Across Different Settings","summary":"  In model-based reinforcement learning (RL), an agent can leverage a learned\nmodel to improve its way of behaving in different ways. Two of the prevalent\nways to do this are through decision-time and background planning methods. In\nthis study, we are interested in understanding how the value-based versions of\nthese two planning methods will compare against each other across different\nsettings. Towards this goal, we first consider the simplest instantiations of\nvalue-based decision-time and background planning methods and provide\ntheoretical results on which one will perform better in the regular RL and\ntransfer learning settings. Then, we consider the modern instantiations of them\nand provide hypotheses on which one will perform better in the same settings.\nFinally, we perform illustrative experiments to validate these theoretical\nresults and hypotheses. Overall, our findings suggest that even though\nvalue-based versions of the two planning methods perform on par in their\nsimplest instantiations, the modern instantiations of value-based decision-time\nplanning methods can perform on par or better than the modern instantiations of\nvalue-based background planning methods in both the regular RL and transfer\nlearning settings.\n","authors":["Safa Alver","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2206.08442v2.pdf","comment":"Accepted to EWRL 2024"},{"id":"http://arxiv.org/abs/2311.13355v2","updated":"2024-08-04T10:31:41Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performs poorly in rejecting OOD inputs. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K+1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K+1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network and\nprototype classifier on vision transformer (ViT) backbone. Experiments on\npopular OSR and OOD detection datasets demonstrate that the proposed framework,\nusing a single multi-class classifier, yields competitive performance in\nclosed-set classification, OOD detection, and misclassification detection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v2.pdf","comment":"Published in Machine Intelligence Research\n  (https://link.springer.com/article/10.1007/s11633-024-1514-4)"},{"id":"http://arxiv.org/abs/2408.01981v1","updated":"2024-08-04T10:16:11Z","published":"2024-08-04T10:16:11Z","title":"Multiview learning with twin parametric margin SVM","summary":"  Multiview learning (MVL) seeks to leverage the benefits of diverse\nperspectives to complement each other, effectively extracting and utilizing the\nlatent information within the dataset. Several twin support vector\nmachine-based MVL (MvTSVM) models have been introduced and demonstrated\noutstanding performance in various learning tasks. However, MvTSVM-based models\nface significant challenges in the form of computational complexity due to four\nmatrix inversions, the need to reformulate optimization problems in order to\nemploy kernel-generated surfaces for handling non-linear cases, and the\nconstraint of uniform noise assumption in the training data. Particularly in\ncases where the data possesses a heteroscedastic error structure, these\nchallenges become even more pronounced. In view of the aforementioned\nchallenges, we propose multiview twin parametric margin support vector machine\n(MvTPMSVM). MvTPMSVM constructs parametric hyperplanes with the goal of\nmaximizing the parametric margin between two classes, aiming to regulate and\nmanage the impact of the heteroscedastic noise structure existing within the\ndata. The proposed MvTPMSVM model avoids the explicit computation of matrix\ninversions in the dual formulation, leading to enhanced computational\nefficiency. We perform an extensive assessment of the MvTPMSVM model using\nbenchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes\n(AwA). Our experimental results, coupled with rigorous statistical analyses,\nconfirm the superior generalization capabilities of the proposed MvTPMSVM model\ncompared to the baseline models. The source code of the proposed MvTPMSVM model\nis available at \\url{https://github.com/mtanveer1/MvTPMSVM}.\n","authors":["A. Quadir","M. Tanveer"],"pdf_url":"https://arxiv.org/pdf/2408.01981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01979v1","updated":"2024-08-04T09:53:57Z","published":"2024-08-04T09:53:57Z","title":"Shaping Rewards, Shaping Routes: On Multi-Agent Deep Q-Networks for\n  Routing in Satellite Constellation Networks","summary":"  Effective routing in satellite mega-constellations has become crucial to\nfacilitate the handling of increasing traffic loads, more complex network\narchitectures, as well as the integration into 6G networks. To enhance\nadaptability as well as robustness to unpredictable traffic demands, and to\nsolve dynamic routing environments efficiently, machine learning-based\nsolutions are being considered. For network control problems, such as\noptimizing packet forwarding decisions according to Quality of Service\nrequirements and maintaining network stability, deep reinforcement learning\ntechniques have demonstrated promising results. For this reason, we investigate\nthe viability of multi-agent deep Q-networks for routing in satellite\nconstellation networks. We focus specifically on reward shaping and quantifying\ntraining convergence for joint optimization of latency and load balancing in\nstatic and dynamic scenarios. To address identified drawbacks, we propose a\nnovel hybrid solution based on centralized learning and decentralized control.\n","authors":["Manuel M. H. Roth","Anupama Hegde","Thomas Delamotte","Andreas Knopp"],"pdf_url":"https://arxiv.org/pdf/2408.01979v1.pdf","comment":"5 pages, 5 figures, to be published in proceedings of European Space\n  Agency SPAICE Conference 2024, https://spaice.esa.int/"},{"id":"http://arxiv.org/abs/2408.01972v1","updated":"2024-08-04T09:26:00Z","published":"2024-08-04T09:26:00Z","title":"RVI-SAC: Average Reward Off-Policy Deep Reinforcement Learning","summary":"  In this paper, we propose an off-policy deep reinforcement learning (DRL)\nmethod utilizing the average reward criterion. While most existing DRL methods\nemploy the discounted reward criterion, this can potentially lead to a\ndiscrepancy between the training objective and performance metrics in\ncontinuing tasks, making the average reward criterion a recommended\nalternative. We introduce RVI-SAC, an extension of the state-of-the-art\noff-policy DRL method, Soft Actor-Critic (SAC), to the average reward\ncriterion. Our proposal consists of (1) Critic updates based on RVI Q-learning,\n(2) Actor updates introduced by the average reward soft policy improvement\ntheorem, and (3) automatic adjustment of Reset Cost enabling the average reward\nreinforcement learning to be applied to tasks with termination. We apply our\nmethod to the Gymnasium's Mujoco tasks, a subset of locomotion tasks, and\ndemonstrate that RVI-SAC shows competitive performance compared to existing\nmethods.\n","authors":["Yukinari Hisaki","Isao Ono"],"pdf_url":"https://arxiv.org/pdf/2408.01972v1.pdf","comment":"Accepted at ICML 2024; Code:\n  https://github.com/yhisaki/average-reward-drl"},{"id":"http://arxiv.org/abs/2408.01967v1","updated":"2024-08-04T09:08:55Z","published":"2024-08-04T09:08:55Z","title":"A multi-task deep learning approach for lane-level pavement performance\n  prediction with segment-level data","summary":"  The elaborate pavement performance prediction is an important premise of\nimplementing preventive maintenance. Our survey reveals that in practice, the\npavement performance is usually measured at segment-level, where an unique\nperformance value is obtained for all lanes within one segment of 1km length.\nIt still lacks more elaborate performance analysis at lane-level due to costly\ndata collection and difficulty in prediction modeling. Therefore, this study\ndeveloped a multi-task deep learning approach to predict the lane-level\npavement performance with a large amount of historical segment-level\nperformance measurement data. The unified prediction framework can effectively\naddress inherent correlation and differences across lanes. In specific, the\nprediction framework firstly employed an Long Short-Term Memory (LSTM) layer to\ncapture the segment-level pavement deterioration pattern. Then multiple\ntask-specific LSTM layers were designed based on number of lanes to capture\nlane-level differences in pavement performance. Finally, we concatenated\nmultiple task-specific LSTM outputs with auxiliary features for further\ntraining and obtained the lane-level predictions after fully connected layer.\nThe aforementioned prediction framework was validated with a real case in\nChina. It revealed a better model performance regardless of one-way 2-lane,\n3-lane, and 4-lane scenarios, all lower than 10% in terms of mean absolute\npercentage error. The proposed prediction framework also outperforms other\nensemble learning and shallow machine learning methods in almost every lane.\n","authors":["Bo Wang","Wenbo Zhang","Yunpeng LI"],"pdf_url":"https://arxiv.org/pdf/2408.01967v1.pdf","comment":"24 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2407.18569v3","updated":"2024-08-04T09:01:00Z","published":"2024-07-26T07:51:11Z","title":"PP-TIL: Personalized Planning for Autonomous Driving with Instance-based\n  Transfer Imitation Learning","summary":"  Personalized motion planning holds significant importance within urban\nautomated driving, catering to the unique requirements of individual users.\nNevertheless, prior endeavors have frequently encountered difficulties in\nsimultaneously addressing two crucial aspects: personalized planning within\nintricate urban settings and enhancing planning performance through data\nutilization. The challenge arises from the expensive and limited nature of user\ndata, coupled with the scene state space tending towards infinity. These\nfactors contribute to overfitting and poor generalization problems during model\ntraining. Henceforth, we propose an instance-based transfer imitation learning\napproach. This method facilitates knowledge transfer from extensive expert\ndomain data to the user domain, presenting a fundamental resolution to these\nissues. We initially train a pre-trained model using large-scale expert data.\nSubsequently, during the fine-tuning phase, we feed the batch data, which\ncomprises expert and user data. Employing the inverse reinforcement learning\ntechnique, we extract the style feature distribution from user demonstrations,\nconstructing the regularization term for the approximation of user style. In\nour experiments, we conducted extensive evaluations of the proposed method.\nCompared to the baseline methods, our approach mitigates the overfitting issue\ncaused by sparse user data. Furthermore, we discovered that integrating the\ndriving model with a differentiable nonlinear optimizer as a safety protection\nlayer for end-to-end personalized fine-tuning results in superior planning\nperformance.\n","authors":["Fangze Lin","Ying He","Fei Yu"],"pdf_url":"https://arxiv.org/pdf/2407.18569v3.pdf","comment":"IROS 2024 Accepted"},{"id":"http://arxiv.org/abs/2306.04802v4","updated":"2024-08-04T08:53:23Z","published":"2023-06-07T21:51:56Z","title":"A Review on Knowledge Graphs for Healthcare: Resources, Applications,\n  and Promises","summary":"  Healthcare knowledge graphs (HKGs) are valuable tools for organizing\nbiomedical concepts and their relationships with interpretable structures. The\nrecent advent of large language models (LLMs) has paved the way for building\nmore comprehensive and accurate HKGs. This, in turn, can improve the\nreliability of generated content and enable better evaluation of LLMs. However,\nthe challenges of HKGs such as regarding data heterogeneity and limited\ncoverage are not fully understood, highlighting the need for detailed reviews.\nThis work provides the first comprehensive review of HKGs. It summarizes the\npipeline and key techniques for HKG construction, as well as the common\nutilization approaches, i.e., model-free and model-based. The existing HKG\nresources are also organized based on the data types they capture and\napplication domains they cover, along with relevant statistical information\n(Resource available at\nhttps://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase). At the\napplication level, we delve into the successful integration of HKGs across\nvarious health domains, ranging from fine-grained basic science research to\nhigh-level clinical decision support and public health. Lastly, the paper\nhighlights the opportunities for HKGs in the era of LLMs. This work aims to\nserve as a valuable resource for understanding the potential and opportunities\nof HKG in health research.\n","authors":["Carl Yang","Hejie Cui","Jiaying Lu","Shiyu Wang","Ran Xu","Wenjing Ma","Yue Yu","Shaojun Yu","Xuan Kan","Chen Ling","Tianfan Fu","Liang Zhao","Joyce Ho","Fei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.04802v4.pdf","comment":"21 pages, preprint submitted to ACM"},{"id":"http://arxiv.org/abs/2408.01964v1","updated":"2024-08-04T08:44:00Z","published":"2024-08-04T08:44:00Z","title":"Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph\n  Node Classification","summary":"  Graph Neural Networks (GNNs) have attracted substantial interest due to their\nexceptional performance on graph-based data. However, their robustness,\nespecially on heterogeneous graphs, remains underexplored, particularly against\nadversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion\nblack-box attack method for heterogeneous graphs. By integrating reinforcement\nlearning with a Top-K algorithm to reduce the action space, our method\nefficiently identifies effective attack strategies to disrupt node\nclassification tasks. We validate the effectiveness of HeteroKRLAttack through\nexperiments on multiple heterogeneous graph datasets, showing significant\nreductions in classification accuracy compared to baseline methods. An ablation\nstudy underscores the critical role of the Top-K algorithm in enhancing attack\nperformance. Our findings highlight potential vulnerabilities in current models\nand provide guidance for future defense strategies against adversarial attacks\non heterogeneous graphs.\n","authors":["Honglin Gao","Gaoxi Xiao"],"pdf_url":"https://arxiv.org/pdf/2408.01964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16364v2","updated":"2024-08-04T08:36:08Z","published":"2024-02-26T07:33:28Z","title":"Where Do We Go from Here? Multi-scale Allocentric Relational Inference\n  from Natural Spatial Descriptions","summary":"  When communicating routes in natural language, the concept of acquired\nspatial knowledge is crucial for geographic information retrieval (GIR) and in\nspatial cognitive research. However, NLP navigation studies often overlook the\nimpact of such acquired knowledge on textual descriptions. Current navigation\nstudies concentrate on egocentric local descriptions (e.g., `it will be on your\nright') that require reasoning over the agent's local perception. These\ninstructions are typically given as a sequence of steps, with each action-step\nexplicitly mentioning and being followed by a landmark that the agent can use\nto verify they are on the right path (e.g., `turn right and then you will\nsee...'). In contrast, descriptions based on knowledge acquired through a map\nprovide a complete view of the environment and capture its overall structure.\nThese instructions (e.g., `it is south of Central Park and a block north of a\npolice station') are typically non-sequential, contain allocentric relations,\nwith multiple spatial relations and implicit actions, without any explicit\nverification. This paper introduces the Rendezvous (RVS) task and dataset,\nwhich includes 10,404 examples of English geospatial instructions for reaching\na target location using map-knowledge. Our analysis reveals that RVS exhibits a\nricher use of spatial allocentric relations, and requires resolving more\nspatial relations simultaneously compared to previous text-based navigation\nbenchmarks.\n","authors":["Tzuf Paz-Argaman","Sayali Kulkarni","John Palowitch","Jason Baldridge","Reut Tsarfaty"],"pdf_url":"https://arxiv.org/pdf/2402.16364v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01961v1","updated":"2024-08-04T08:35:02Z","published":"2024-08-04T08:35:02Z","title":"Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study","summary":"  Popular and news media often portray teenagers with sensationalism, as both a\nrisk to society and at risk from society. As AI begins to absorb some of the\nepistemic functions of traditional media, we study how teenagers in two\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\nprefer to be depicted. Specifically, we study the biases about teenagers\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\ncomparing these with the perspectives of adolescents living in the U.S. and\nNepal. We find English-language SWEs associate teenagers with societal\nproblems, and more than 50% of the 1,000 words most associated with teenagers\nin the pretrained GloVe SWE reflect such problems. Given prompts about\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\nsocietal problems, most commonly violence, but also drug use, mental illness,\nand sexual taboo. Nepali models, while not free of such associations, are less\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\nteenage life, which revolves around activities like school and friendship.\nParticipant ratings of how well 20 trait words describe teens are decorrelated\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\nGloVe. U.S. participants suggested AI could fairly present teens by\nhighlighting diversity, while Nepalese participants centered positivity.\nParticipants were optimistic that, if it learned from adolescents, rather than\nmedia sources, AI could help mitigate stereotypes. Our work offers an\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\nvulnerable group and provides a template for less sensationalized\ncharacterization.\n","authors":["Robert Wolfe","Aayushi Dangol","Bill Howe","Alexis Hiniker"],"pdf_url":"https://arxiv.org/pdf/2408.01961v1.pdf","comment":"Accepted at Artificial Intelligence, Ethics, and Society 2024"},{"id":"http://arxiv.org/abs/2408.01959v1","updated":"2024-08-04T08:26:58Z","published":"2024-08-04T08:26:58Z","title":"Dataset Scale and Societal Consistency Mediate Facial Impression Bias in\n  Vision-Language AI","summary":"  Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.\n","authors":["Robert Wolfe","Aayushi Dangol","Alexis Hiniker","Bill Howe"],"pdf_url":"https://arxiv.org/pdf/2408.01959v1.pdf","comment":"Accepted at Artificial Intelligence, Ethics, and Society 2024"},{"id":"http://arxiv.org/abs/2408.01953v1","updated":"2024-08-04T07:59:17Z","published":"2024-08-04T07:59:17Z","title":"EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning","summary":"  Humans perceive and interact with the world with the awareness of\nequivariance, facilitating us in manipulating different objects in diverse\nposes. For robotic manipulation, such equivariance also exists in many\nscenarios. For example, no matter what the pose of a drawer is (translation,\nrotation and tilt), the manipulation strategy is consistent (grasp the handle\nand pull in a line). While traditional models usually do not have the awareness\nof equivariance for robotic manipulation, which might result in more data for\ntraining and poor performance in novel object poses, we propose our EqvAfford\nframework, with novel designs to guarantee the equivariance in point-level\naffordance learning for downstream robotic manipulation, with great performance\nand generalization ability on representative tasks on objects in diverse poses.\n","authors":["Yue Chen","Chenrui Tie","Ruihai Wu","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2408.01953v1.pdf","comment":"Accept to CVPRWorkshop on Equivariant Vision: From Theory to Practice\n  2024"},{"id":"http://arxiv.org/abs/2407.10768v5","updated":"2024-08-04T07:53:03Z","published":"2024-07-15T14:50:15Z","title":"ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time\n  Series Forecasting","summary":"  Long time series forecasting aims to utilize historical information to\nforecast future states over extended horizons. Traditional RNN-based series\nforecasting methods struggle to effectively address long-term dependencies and\ngradient issues in long time series problems. Recently, SegRNN has emerged as a\nleading RNN-based model tailored for long-term series forecasting,\ndemonstrating state-of-the-art performance while maintaining a streamlined\narchitecture through innovative segmentation and parallel decoding techniques.\nNevertheless, SegRNN has several limitations: its fixed segmentation disrupts\ndata continuity and fails to effectively leverage information across different\nsegments, the segmentation strategy employed by SegRNN does not fundamentally\naddress the issue of information loss within the recurrent structure. To\naddress these issues, we propose the ISMRNN method with three key enhancements:\nwe introduce an implicit segmentation structure to decompose the time series\nand map it to segmented hidden states, resulting in denser information exchange\nduring the segmentation phase. Additionally, we incorporate residual structures\nin the encoding layer to mitigate information loss within the recurrent\nstructure. To extract information more effectively, we further integrate the\nMamba architecture to enhance time series information extraction. Experiments\non several real-world long time series forecasting datasets demonstrate that\nour model surpasses the performance of current state-of-the-art models.\n","authors":["GaoXiang Zhao","Li Zhou","XiaoQiang Wang"],"pdf_url":"https://arxiv.org/pdf/2407.10768v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11060v2","updated":"2024-08-04T05:59:13Z","published":"2023-10-17T08:06:08Z","title":"Privacy-Preserving Graph Embedding based on Local Differential Privacy","summary":"  Graph embedding has become a powerful tool for learning latent\nrepresentations of nodes in a graph. Despite its superior performance in\nvarious graph-based machine learning tasks, serious privacy concerns arise when\nthe graph data contains personal or sensitive information. To address this\nissue, we investigate and develop graph embedding algorithms that satisfy local\ndifferential privacy (LDP). We introduce a novel privacy-preserving graph\nembedding framework, named PrivGE, to protect node data privacy. Specifically,\nwe propose an LDP mechanism to obfuscate node data and utilize personalized\nPageRank as the proximity measure to learn node representations. Furthermore,\nwe provide a theoretical analysis of the privacy guarantees and utility offered\nby the PrivGE framework. Extensive experiments on several real-world graph\ndatasets demonstrate that PrivGE achieves an optimal balance between privacy\nand utility, and significantly outperforms existing methods in node\nclassification and link prediction tasks.\n","authors":["Zening Li","Rong-Hua Li","Meihao Liao","Fusheng Jin","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2310.11060v2.pdf","comment":"to be published in CIKM 2024"},{"id":"http://arxiv.org/abs/2407.15100v2","updated":"2024-08-04T05:55:40Z","published":"2024-07-21T09:32:34Z","title":"A General Framework for Data-Use Auditing of ML Models","summary":"  Auditing the use of data in training machine-learning (ML) models is an\nincreasingly pressing challenge, as myriad ML practitioners routinely leverage\nthe effort of content creators to train models without their permission. In\nthis paper, we propose a general method to audit an ML model for the use of a\ndata-owner's data in training, without prior knowledge of the ML task for which\nthe data might be used. Our method leverages any existing black-box membership\ninference method, together with a sequential hypothesis test of our own design,\nto detect data use with a quantifiable, tunable false-detection rate. We show\nthe effectiveness of our proposed framework by applying it to audit data use in\ntwo types of ML models, namely image classifiers and foundation models.\n","authors":["Zonghao Huang","Neil Zhenqiang Gong","Michael K. Reiter"],"pdf_url":"https://arxiv.org/pdf/2407.15100v2.pdf","comment":"The full paper of \"A General Framework for Data-Use Auditing of ML\n  Models\" accepted by CCS 2024"},{"id":"http://arxiv.org/abs/2407.21530v2","updated":"2024-08-04T05:53:25Z","published":"2024-07-31T11:26:57Z","title":"Data Contamination Report from the 2024 CONDA Shared Task","summary":"  The 1st Workshop on Data Contamination (CONDA 2024) focuses on all relevant\naspects of data contamination in natural language processing, where data\ncontamination is understood as situations where evaluation data is included in\npre-training corpora used to train large scale models, compromising evaluation\nresults. The workshop fostered a shared task to collect evidence on data\ncontamination in current available datasets and models. The goal of the shared\ntask and associated database is to assist the community in understanding the\nextent of the problem and to assist researchers in avoiding reporting\nevaluation results on known contaminated resources. The shared task provides a\nstructured, centralized public database for the collection of contamination\nevidence, open to contributions from the community via GitHub pool requests.\nThis first compilation paper is based on 566 reported entries over 91\ncontaminated sources from a total of 23 contributors. The details of the\nindividual contamination events are available in the platform. The platform\ncontinues to be online, open to contributions from the community.\n","authors":["Oscar Sainz","Iker García-Ferrero","Alon Jacovi","Jon Ander Campos","Yanai Elazar","Eneko Agirre","Yoav Goldberg","Wei-Lin Chen","Jenny Chim","Leshem Choshen","Luca D'Amico-Wong","Melissa Dell","Run-Ze Fan","Shahriar Golchin","Yucheng Li","Pengfei Liu","Bhavish Pahwa","Ameya Prabhu","Suryansh Sharma","Emily Silcock","Kateryna Solonko","David Stap","Mihai Surdeanu","Yu-Min Tseng","Vishaal Udandarao","Zengzhi Wang","Ruijie Xu","Jinglin Yang"],"pdf_url":"https://arxiv.org/pdf/2407.21530v2.pdf","comment":"https://huggingface.co/spaces/CONDA-Workshop/Data-Contamination-Database"}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2408.02167v1","updated":"2024-08-04T23:31:35Z","published":"2024-08-04T23:31:35Z","title":"Embedding generalization within the learning dynamics: An approach\n  based-on sample path large deviation theory","summary":"  We consider a typical learning problem of point estimations for modeling of\nnonlinear functions or dynamical systems in which generalization, i.e.,\nverifying a given learned model, can be embedded as an integral part of the\nlearning process or dynamics. In particular, we consider an empirical risk\nminimization based learning problem that exploits gradient methods from\ncontinuous-time perspective with small random perturbations, which is guided by\nthe training dataset loss. Here, we provide an asymptotic probability estimate\nin the small noise limit based-on the Freidlin-Wentzell theory of large\ndeviations, when the sample path of the random process corresponding to the\nrandomly perturbed gradient dynamical system hits a certain target set, i.e., a\nrare event, when the latter is specified by the testing dataset loss landscape.\nInterestingly, the proposed framework can be viewed as one way of improving\ngeneralization and robustness in learning problems that provides new insights\nleading to optimal point estimates which is guided by training data loss,\nwhile, at the same time, the learning dynamics has an access to the testing\ndataset loss landscape in some form of future achievable or anticipated target\ngoal. Moreover, as a by-product, we establish a connection with optimal control\nproblem, where the target set, i.e., the rare event, is considered as the\ndesired outcome or achievable target goal for a certain optimal control\nproblem, for which we also provide a verification result reinforcing the\nrationale behind the proposed framework. Finally, we present a computational\nalgorithm that solves the corresponding variational problem leading to an\noptimal point estimates and, as part of this work, we also present some\nnumerical results for a typical case of nonlinear regression problem.\n","authors":["Getachew K. Befekadu"],"pdf_url":"https://arxiv.org/pdf/2408.02167v1.pdf","comment":"13 Pages"},{"id":"http://arxiv.org/abs/2307.01357v3","updated":"2024-08-04T22:31:59Z","published":"2023-07-03T21:13:40Z","title":"Adaptive Principal Component Regression with Applications to Panel Data","summary":"  Principal component regression (PCR) is a popular technique for fixed-design\nerror-in-variables regression, a generalization of the linear regression\nsetting in which the observed covariates are corrupted with random noise. We\nprovide the first time-uniform finite sample guarantees for (regularized) PCR\nwhenever data is collected adaptively. Since the proof techniques for analyzing\nPCR in the fixed design setting do not readily extend to the online setting,\nour results rely on adapting tools from modern martingale concentration to the\nerror-in-variables setting. We demonstrate the usefulness of our bounds by\napplying them to the domain of panel data, a ubiquitous setting in econometrics\nand statistics. As our first application, we provide a framework for experiment\ndesign in panel data settings when interventions are assigned adaptively. Our\nframework may be thought of as a generalization of the synthetic control and\nsynthetic interventions frameworks, where data is collected via an adaptive\nintervention assignment policy. Our second application is a procedure for\nlearning such an intervention assignment policy in a setting where units arrive\nsequentially to be treated. In addition to providing theoretical performance\nguarantees (as measured by regret), we show that our method empirically\noutperforms a baseline which does not leverage error-in-variables regression.\n","authors":["Anish Agarwal","Keegan Harris","Justin Whitehouse","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2307.01357v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02159v1","updated":"2024-08-04T22:26:34Z","published":"2024-08-04T22:26:34Z","title":"SPINEX-TimeSeries: Similarity-based Predictions with Explainable\n  Neighbors Exploration for Time Series and Forecasting Problems","summary":"  This paper introduces a new addition to the SPINEX (Similarity-based\nPredictions with Explainable Neighbors Exploration) family, tailored\nspecifically for time series and forecasting analysis. This new algorithm\nleverages the concept of similarity and higher-order temporal interactions\nacross multiple time scales to enhance predictive accuracy and interpretability\nin forecasting. To evaluate the effectiveness of SPINEX, we present\ncomprehensive benchmarking experiments comparing it against 18 algorithms and\nacross 49 synthetic and real datasets characterized by varying trends,\nseasonality, and noise levels. Our performance assessment focused on\nforecasting accuracy and computational efficiency. Our findings reveal that\nSPINEX consistently ranks among the top 5 performers in forecasting precision\nand has a superior ability to handle complex temporal dynamics compared to\ncommonly adopted algorithms. Moreover, the algorithm's explainability features,\nPareto efficiency, and medium complexity (on the order of O(log n)) are\ndemonstrated through detailed visualizations to enhance the prediction and\ndecision-making process. We note that integrating similarity-based concepts\nopens new avenues for research in predictive analytics, promising more accurate\nand transparent decision making.\n","authors":["Ahmed Z Naser","MZ Naser"],"pdf_url":"https://arxiv.org/pdf/2408.02159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02111v1","updated":"2024-08-04T18:47:55Z","published":"2024-08-04T18:47:55Z","title":"Understanding Deep Learning via Notions of Rank","summary":"  Despite the extreme popularity of deep learning in science and industry, its\nformal understanding is limited. This thesis puts forth notions of rank as key\nfor developing a theory of deep learning, focusing on the fundamental aspects\nof generalization and expressiveness. In particular, we establish that\ngradient-based training can induce an implicit regularization towards low rank\nfor several neural network architectures, and demonstrate empirically that this\nphenomenon may facilitate an explanation of generalization over natural data\n(e.g., audio, images, and text). Then, we characterize the ability of graph\nneural networks to model interactions via a notion of rank, which is commonly\nused for quantifying entanglement in quantum physics. A central tool underlying\nthese results is a connection between neural networks and tensor\nfactorizations. Practical implications of our theory for designing explicit\nregularization schemes and data preprocessing algorithms are presented.\n","authors":["Noam Razin"],"pdf_url":"https://arxiv.org/pdf/2408.02111v1.pdf","comment":"PhD thesis"},{"id":"http://arxiv.org/abs/2402.12668v2","updated":"2024-08-04T18:07:51Z","published":"2024-02-20T02:36:26Z","title":"Randomization Can Reduce Both Bias and Variance: A Case Study in Random\n  Forests","summary":"  We study the often overlooked phenomenon, first noted in\n\\cite{breiman2001random}, that random forests appear to reduce bias compared to\nbagging. Motivated by an interesting paper by \\cite{mentch2020randomization},\nwhere the authors argue that random forests reduce effective degrees of freedom\nand only outperform bagging ensembles in low signal-to-noise ratio (SNR)\nsettings, we explore how random forests can uncover patterns in the data missed\nby bagging. We empirically demonstrate that in the presence of such patterns,\nrandom forests reduce bias along with variance and increasingly outperform\nbagging ensembles when SNR is high. Our observations offer insights into the\nreal-world success of random forests across a range of SNRs and enhance our\nunderstanding of the difference between random forests and bagging ensembles\nwith respect to the randomization injected into each split. Our investigations\nalso yield practical insights into the importance of tuning $mtry$ in random\nforests.\n","authors":["Brian Liu","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2402.12668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00927v2","updated":"2024-08-04T18:04:50Z","published":"2024-07-01T03:17:34Z","title":"Learnability of Parameter-Bounded Bayes Nets","summary":"  Bayes nets are extensively used in practice to efficiently represent joint\nprobability distributions over a set of random variables and capture dependency\nrelations. In a seminal paper, Chickering et al. (JMLR 2004) showed that given\na distribution $\\mathbb{P}$, that is defined as the marginal distribution of a\nBayes net, it is $\\mathsf{NP}$-hard to decide whether there is a\nparameter-bounded Bayes net that represents $\\mathbb{P}$. They called this\nproblem LEARN. In this work, we extend the $\\mathsf{NP}$-hardness result of\nLEARN and prove the $\\mathsf{NP}$-hardness of a promise search variant of\nLEARN, whereby the Bayes net in question is guaranteed to exist and one is\nasked to find such a Bayes net. We complement our hardness result with a\npositive result about the sample complexity that is sufficient to recover a\nparameter-bounded Bayes net that is close (in TV distance) to a given\ndistribution $\\mathbb{P}$, that is represented by some parameter-bounded Bayes\nnet, generalizing a degree-bounded sample complexity result of Brustle et al.\n(EC 2020).\n","authors":["Arnab Bhattacharyya","Davin Choo","Sutanu Gayen","Dimitrios Myrisiotis"],"pdf_url":"https://arxiv.org/pdf/2407.00927v2.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.02065v1","updated":"2024-08-04T15:30:15Z","published":"2024-08-04T15:30:15Z","title":"A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal\n  Networks","summary":"  In the ride-hailing industry, subsidies are predominantly employed to\nincentivize consumers to place more orders, thereby fostering market growth.\nCausal inference techniques are employed to estimate the consumer elasticity\nwith different subsidy levels. However, the presence of confounding effects\nposes challenges in achieving an unbiased estimate of the uplift effect. We\nintroduce a consumer subsidizing system to capture relationships between\nsubsidy propensity and the treatment effect, which proves effective while\nmaintaining a lightweight online environment.\n","authors":["Zhe Yu","Chi Xia","Shaosheng Cao","Lin Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02060v1","updated":"2024-08-04T15:20:23Z","published":"2024-08-04T15:20:23Z","title":"Winners with Confidence: Discrete Argmin Inference with an Application\n  to Model Selection","summary":"  We study the problem of finding the index of the minimum value of a vector\nfrom noisy observations. This problem is relevant in population/policy\ncomparison, discrete maximum likelihood, and model selection. We develop a test\nstatistic that is asymptotically normal, even in high-dimensional settings and\nwith potentially many ties in the population mean vector, by integrating\nconcepts and tools from cross-validation and differential privacy. The key\ntechnical ingredient is a central limit theorem for globally dependent data. We\nalso propose practical ways to select the tuning parameter that adapts to the\nsignal landscape.\n","authors":["Tianyu Zhang","Hao Lee","Jing Lei"],"pdf_url":"https://arxiv.org/pdf/2408.02060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02045v1","updated":"2024-08-04T14:45:26Z","published":"2024-08-04T14:45:26Z","title":"DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation","summary":"  Semiparametric statistics play a pivotal role in a wide range of domains,\nincluding but not limited to missing data, causal inference, and transfer\nlearning, to name a few. In many settings, semiparametric theory leads to\n(nearly) statistically optimal procedures that yet involve numerically solving\nFredholm integral equations of the second kind. Traditional numerical methods,\nsuch as polynomial or spline approximations, are difficult to scale to\nmulti-dimensional problems. Alternatively, statisticians may choose to\napproximate the original integral equations by ones with closed-form solutions,\nresulting in computationally more efficient, but statistically suboptimal or\neven incorrect procedures. To bridge this gap, we propose a novel framework by\nformulating the semiparametric estimation problem as a bi-level optimization\nproblem; and then we develop a scalable algorithm called Deep Neural-Nets\nAssisted Semiparametric Estimation (DNA-SE) by leveraging the universal\napproximation property of Deep Neural-Nets (DNN) to streamline semiparametric\nprocedures. Through extensive numerical experiments and a real data analysis,\nwe demonstrate the numerical and statistical advantages of $\\dnase$ over\ntraditional methods. To the best of our knowledge, we are the first to bring\nDNN into semiparametric statistics as a numerical solver of integral equations\nin our proposed general framework.\n","authors":["Qinshuo Liu","Zixin Wang","Xi-An Li","Xinyao Ji","Lei Zhang","Lin Liu","Zhonghua Liu"],"pdf_url":"https://arxiv.org/pdf/2408.02045v1.pdf","comment":"semiparametric statistics, missing data, causal inference, Fredholm\n  integral equations of the second kind, bi-level optimization, deep learning,\n  AI for science"},{"id":"http://arxiv.org/abs/2312.16019v3","updated":"2024-08-04T12:12:36Z","published":"2023-12-26T12:18:31Z","title":"Robust Survival Analysis with Adversarial Regularization","summary":"  Survival Analysis (SA) models the time until an event occurs, with\napplications in fields like medicine, defense, finance, and aerospace. Recent\nwork shows that Neural Networks (NNs) can capture complex relationships in SA.\nHowever, dataset uncertainties (e.g., noisy measurements, human error) can\ndegrade model performance. To address this, we leverage NN verification\nadvances to create algorithms for robust, fully-parametric survival models. We\nintroduce a robust loss function and use CROWN-IBP regularization to handle\ncomputational challenges in the Min-Max problem. Evaluating our approach on\nSurvSet datasets, we find that our Survival Analysis with Adversarial\nRegularization (SAWAR) method consistently outperforms baselines under various\nperturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier\nScore (IBS), and Concordance Index (CI). This demonstrates that adversarial\nregularization enhances SA performance and calibration, mitigating data\nuncertainty and improving generalization across diverse datasets up to 150%\nacross all perturbation magnitudes.\n","authors":["Michael Potter","Stefano Maxenti","Michael Everett"],"pdf_url":"https://arxiv.org/pdf/2312.16019v3.pdf","comment":"12 pages, 2 figures, submission to IEEE Journal of Biomedical and\n  Health Informatics"},{"id":"http://arxiv.org/abs/2408.01981v1","updated":"2024-08-04T10:16:11Z","published":"2024-08-04T10:16:11Z","title":"Multiview learning with twin parametric margin SVM","summary":"  Multiview learning (MVL) seeks to leverage the benefits of diverse\nperspectives to complement each other, effectively extracting and utilizing the\nlatent information within the dataset. Several twin support vector\nmachine-based MVL (MvTSVM) models have been introduced and demonstrated\noutstanding performance in various learning tasks. However, MvTSVM-based models\nface significant challenges in the form of computational complexity due to four\nmatrix inversions, the need to reformulate optimization problems in order to\nemploy kernel-generated surfaces for handling non-linear cases, and the\nconstraint of uniform noise assumption in the training data. Particularly in\ncases where the data possesses a heteroscedastic error structure, these\nchallenges become even more pronounced. In view of the aforementioned\nchallenges, we propose multiview twin parametric margin support vector machine\n(MvTPMSVM). MvTPMSVM constructs parametric hyperplanes with the goal of\nmaximizing the parametric margin between two classes, aiming to regulate and\nmanage the impact of the heteroscedastic noise structure existing within the\ndata. The proposed MvTPMSVM model avoids the explicit computation of matrix\ninversions in the dual formulation, leading to enhanced computational\nefficiency. We perform an extensive assessment of the MvTPMSVM model using\nbenchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes\n(AwA). Our experimental results, coupled with rigorous statistical analyses,\nconfirm the superior generalization capabilities of the proposed MvTPMSVM model\ncompared to the baseline models. The source code of the proposed MvTPMSVM model\nis available at \\url{https://github.com/mtanveer1/MvTPMSVM}.\n","authors":["A. Quadir","M. Tanveer"],"pdf_url":"https://arxiv.org/pdf/2408.01981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04071v4","updated":"2024-08-04T05:21:19Z","published":"2024-01-08T18:18:02Z","title":"Fun with Flags: Robust Principal Directions via Flag Manifolds","summary":"  Principal component analysis (PCA), along with its extensions to manifolds\nand outlier contaminated data, have been indispensable in computer vision and\nmachine learning. In this work, we present a unifying formalism for PCA and its\nvariants, and introduce a framework based on the flags of linear subspaces, ie\na hierarchy of nested linear subspaces of increasing dimension, which not only\nallows for a common implementation but also yields novel variants, not explored\npreviously. We begin by generalizing traditional PCA methods that either\nmaximize variance or minimize reconstruction error. We expand these\ninterpretations to develop a wide array of new dimensionality reduction\nalgorithms by accounting for outliers and the data manifold. To devise a common\ncomputational approach, we recast robust and dual forms of PCA as optimization\nproblems on flag manifolds. We then integrate tangent space approximations of\nprincipal geodesic analysis (tangent-PCA) into this flag-based framework,\ncreating novel robust and dual geodesic PCA variations. The remarkable\nflexibility offered by the 'flagification' introduced here enables even more\nalgorithmic variants identified by specific flag types. Last but not least, we\npropose an effective convergent solver for these flag-formulations employing\nthe Stiefel manifold. Our empirical results on both real-world and synthetic\nscenarios, demonstrate the superiority of our novel algorithms, especially in\nterms of robustness to outliers on manifolds.\n","authors":["Nathan Mankovich","Gustau Camps-Valls","Tolga Birdal"],"pdf_url":"https://arxiv.org/pdf/2401.04071v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01926v1","updated":"2024-08-04T04:42:02Z","published":"2024-08-04T04:42:02Z","title":"Efficient Decision Trees for Tensor Regressions","summary":"  We proposed the tensor-input tree (TT) method for scalar-on-tensor and\ntensor-on-tensor regression problems. We first address scalar-on-tensor problem\nby proposing scalar-output regression tree models whose input variable are\ntensors (i.e., multi-way arrays). We devised and implemented fast randomized\nand deterministic algorithms for efficient fitting of scalar-on-tensor trees,\nmaking TT competitive against tensor-input GP models. Based on scalar-on-tensor\ntree models, we extend our method to tensor-on-tensor problems using additive\ntree ensemble approaches. Theoretical justification and extensive experiments\non real and synthetic datasets are provided to illustrate the performance of\nTT.\n","authors":["Hengrui Luo","Akira Horiguchi","Li Ma"],"pdf_url":"https://arxiv.org/pdf/2408.01926v1.pdf","comment":"36 pages, 9 Figures"},{"id":"http://arxiv.org/abs/2408.02701v1","updated":"2024-08-04T18:24:02Z","published":"2024-08-04T18:24:02Z","title":"Randomized Transport Plans via Hierarchical Fully Probabilistic Design","summary":"  An optimal randomized strategy for design of balanced, normalized mass\ntransport plans is developed. It replaces -- but specializes to -- the\ndeterministic, regularized optimal transport (OT) strategy, which yields only a\ncertainty-equivalent plan. The incompletely specified -- and therefore\nuncertain -- transport plan is acknowledged to be a random process. Therefore,\nhierarchical fully probabilistic design (HFPD) is adopted, yielding an optimal\nhyperprior supported on the set of possible transport plans, and consistent\nwith prior mean constraints on the marginals of the uncertain plan. This\nBayesian resetting of the design problem for transport plans -- which we call\nHFPD-OT -- confers new opportunities. These include (i) a strategy for the\ngeneration of a random sample of joint transport plans; (ii) randomized\nmarginal contracts for individual source-target pairs; and (iii) consistent\nmeasures of uncertainty in the plan and its contracts. An application in\nalgorithmic fairness is outlined, where HFPD-OT enables the recruitment of a\nmore diverse subset of contracts -- than is possible in classical OT -- into\nthe delivery of an expected plan. Also, it permits fairness proxies to be\nendowed with uncertainty quantifiers.\n","authors":["Sarah Boufelja Y.","Anthony Quinn","Robert Shorten"],"pdf_url":"https://arxiv.org/pdf/2408.02701v1.pdf","comment":"27 pages, 26 figures"},{"id":"http://arxiv.org/abs/2210.12494v4","updated":"2024-08-04T15:00:32Z","published":"2022-10-22T16:36:41Z","title":"Learning The Likelihood Test With One-Class Classifiers for Physical\n  Layer Authentication","summary":"  In physical layer authentication (PLA) mechanisms, a verifier decides whether\na received message has been transmitted by a legitimate user or an intruder,\naccording to some features of the physical channel over which the message\ntraveled. To design the authentication check implemented at the verifier,\ntypically either the statistics or a dataset of features are available for the\nchannel from the legitimate user, while no information is available when under\nattack. When the statistics are known, a well-known good solution is the\nlikelihood test (LT). When a dataset is available, the decision problem is\none-class classification (OCC) and a good understanding of the machine learning\n(ML) techniques used for its solution is important to ensure security. Thus, in\nthis paper, we aim at obtaining ML PLA verifiers that operate as the LT. We\nshow how to do it with the neural network (NN) and the one-class least-squares\nsupport vector machine (OCLSSVM) models, trained as two-class classifiers on\nthe single-class dataset and an artificial dataset. The artificial dataset for\nthe negative class is obtained by generating channel feature (CF) vectors\nuniformly distributed over the domain of the legitimate class dataset. We also\nderive a modified stochastic gradient descent (SGD) algorithm that trains a PLA\nverifier operating as LT without the need for the artificial dataset.\nFurthermore, we show that the one-class least-squares support vector machine\nwith suitable kernels operates as the LT at convergence. Lastly, we show that\nthe widely used autoencoder classifier generally does not provide the LT.\nNumerical results are provided considering PLA on both wireless and underwater\nacoustic channels.\n","authors":["Francesco Ardizzon","Stefano Tomasin"],"pdf_url":"https://arxiv.org/pdf/2210.12494v4.pdf","comment":"submitted to IEEE TIFS"}]},"2024-08-03T00:00:00Z":{"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2408.01868v1","updated":"2024-08-03T21:39:43Z","published":"2024-08-03T21:39:43Z","title":"Meta-Posterior Consistency for the Bayesian Inference of Metastable\n  System","summary":"  The vast majority of the literature on learning dynamical systems or\nstochastic processes from time series has focused on stable or ergodic systems,\nfor both Bayesian and frequentist inference procedures. However, most\nreal-world systems are only metastable, that is, the dynamics appear to be\nstable on some time scale, but are in fact unstable over longer time scales.\nConsistency of inference for metastable systems may not be possible, but one\ncan ask about metaconsistency: Do inference procedures converge when\nobservations are taken over a large but finite time interval, but diverge on\nlonger time scales? In this paper we introduce, discuss, and quantify\nmetaconsistency in a Bayesian framework. We discuss how metaconsistency can be\nexploited to efficiently infer a model for a sub-system of a larger system,\nwhere inference on the global behavior may require much more data. We also\ndiscuss the relation between meta-consistency and the spectral properties of\nthe model dynamical system in the case of uniformly ergodic diffusions.\n","authors":["Zachary P Adams","Sayan Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2408.01868v1.pdf","comment":"32 pages, 3 figures"},{"id":"http://arxiv.org/abs/2208.07612v2","updated":"2024-08-03T20:39:34Z","published":"2022-08-16T09:02:16Z","title":"Rapid Discovery of Graphene Nanocrystals Using DFT and Bayesian\n  Optimization with Neural Network Kernel","summary":"  Density functional theory (DFT) is a powerful computational method used to\nobtain physical and chemical properties of materials. In the materials\ndiscovery framework, it is often necessary to virtually screen a large and\nhigh-dimensional chemical space to find materials with desired properties.\nHowever, grid searching a large chemical space with DFT is inefficient due to\nits high computational cost. We propose an approach utilizing Bayesian\noptimization (BO) with an artificial neural network kernel to enable smart\nsearch. This method leverages the BO algorithm, where the neural network,\ntrained on a limited number of DFT results, determines the most promising\nregions of the chemical space to explore in subsequent iterations. This\napproach aims to discover materials with target properties while minimizing the\nnumber of DFT calculations required. To demonstrate the effectiveness of this\nmethod, we investigated 63 doped graphene quantum dots (GQDs) with sizes\nranging from 1 to 2 nm to find the structure with the highest light absorbance.\nUsing time-dependent DFT (TDDFT) only 12 times, we achieved a significant\nreduction in computational cost, approximately 20% of what would be required\nfor a full grid search, by employing the BO algorithm with a neural network\nkernel. Considering that TDDFT calculations for a single GQD require about half\na day of wall time on high-performance computing nodes, this reduction is\nsubstantial. Our approach can be generalized to the discovery of new drugs,\nchemicals, crystals, and alloys with high-dimensional and large chemical\nspaces, offering a scalable solution for various applications in materials\nscience.\n","authors":["Şener Özönder","H. Kübra Küçükkartal"],"pdf_url":"https://arxiv.org/pdf/2208.07612v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01861v1","updated":"2024-08-03T20:13:47Z","published":"2024-08-03T20:13:47Z","title":"Batch Active Learning in Gaussian Process Regression using Derivatives","summary":"  We investigate the use of derivative information for Batch Active Learning in\nGaussian Process regression models. The proposed approach employs the\npredictive covariance matrix for selection of data batches to exploit full\ncorrelation of samples. We theoretically analyse our proposed algorithm taking\ndifferent optimality criteria into consideration and provide empirical\ncomparisons highlighting the advantage of incorporating derivatives\ninformation. Our results show the effectiveness of our approach across diverse\napplications.\n","authors":["Hon Sum Alec Yu","Christoph Zimmer","Duy Nguyen-Tuong"],"pdf_url":"https://arxiv.org/pdf/2408.01861v1.pdf","comment":"29 pages, 10 figures"},{"id":"http://arxiv.org/abs/2408.01851v1","updated":"2024-08-03T19:31:59Z","published":"2024-08-03T19:31:59Z","title":"Cost-constrained multi-label group feature selection using shadow\n  features","summary":"  We consider the problem of feature selection in multi-label classification,\nconsidering the costs assigned to groups of features. In this task, the goal is\nto select a subset of features that will be useful for predicting the label\nvector, but at the same time, the cost associated with the selected features\nwill not exceed the assumed budget. Solving the problem is of great importance\nin medicine, where we may be interested in predicting various diseases based on\ngroups of features. The groups may be associated with parameters obtained from\na certain diagnostic test, such as a blood test. Because diagnostic test costs\ncan be very high, considering cost information when selecting relevant features\nbecomes crucial to reducing the cost of making predictions. We focus on the\nfeature selection method based on information theory. The proposed method\nconsists of two steps. First, we select features sequentially while maximizing\nconditional mutual information until the budget is exhausted. In the second\nstep, we select additional cost-free features, i.e., those coming from groups\nthat have already been used in previous steps. Limiting the number of added\nfeatures is possible using the stop rule based on the concept of so-called\nshadow features, which are randomized counterparts of the original ones. In\ncontrast to existing approaches based on penalized criteria, in our method, we\navoid the need for computationally demanding optimization of the penalty\nparameter. Experiments conducted on the MIMIC medical database show the\neffectiveness of the method, especially when the assumed budget is limited.\n","authors":["Tomasz Klonecki","Paweł Teisseyre","Jaesung Lee"],"pdf_url":"https://arxiv.org/pdf/2408.01851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10935v2","updated":"2024-08-03T13:26:31Z","published":"2024-04-16T22:15:52Z","title":"Molecular relaxation by reverse diffusion with time step prediction","summary":"  Molecular relaxation, finding the equilibrium state of a non-equilibrium\nstructure, is an essential component of computational chemistry to understand\nreactivity. Classical force field (FF) methods often rely on insufficient local\nenergy minimization, while neural network FF models require large labeled\ndatasets encompassing both equilibrium and non-equilibrium structures. As a\nremedy, we propose MoreRed, molecular relaxation by reverse diffusion, a\nconceptually novel and purely statistical approach where non-equilibrium\nstructures are treated as noisy instances of their corresponding equilibrium\nstates. To enable the denoising of arbitrarily noisy inputs via a generative\ndiffusion model, we further introduce a novel diffusion time step predictor.\nNotably, MoreRed learns a simpler pseudo potential energy surface (PES) instead\nof the complex physical PES. It is trained on a significantly smaller, and thus\ncomputationally cheaper, dataset consisting of solely unlabeled equilibrium\nstructures, avoiding the computation of non-equilibrium structures altogether.\nWe compare MoreRed to classical FFs, equivariant neural network FFs trained on\na large dataset of equilibrium and non-equilibrium data, as well as a\nsemi-empirical tight-binding model. To assess this quantitatively, we evaluate\nthe root-mean-square deviation between the found equilibrium structures and the\nreference equilibrium structures as well as their energies.\n","authors":["Khaled Kahouli","Stefaan Simon Pierre Hessmann","Klaus-Robert Müller","Shinichi Nakajima","Stefan Gugler","Niklas Wolf Andreas Gebauer"],"pdf_url":"https://arxiv.org/pdf/2404.10935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01736v1","updated":"2024-08-03T10:35:59Z","published":"2024-08-03T10:35:59Z","title":"Can LLMs predict the convergence of Stochastic Gradient Descent?","summary":"  Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.\n","authors":["Oussama Zekri","Abdelhakim Benechehab","Ievgen Redko"],"pdf_url":"https://arxiv.org/pdf/2408.01736v1.pdf","comment":"9 pages. Accepted to 1st ICML Workshop on In-Context Learning at ICML\n  2024"},{"id":"http://arxiv.org/abs/2408.01697v1","updated":"2024-08-03T07:38:04Z","published":"2024-08-03T07:38:04Z","title":"Invariant Graph Learning Meets Information Bottleneck for\n  Out-of-Distribution Generalization","summary":"  Graph out-of-distribution (OOD) generalization remains a major challenge in\ngraph learning since graph neural networks (GNNs) often suffer from severe\nperformance degradation under distribution shifts. Invariant learning, aiming\nto extract invariant features across varied distributions, has recently emerged\nas a promising approach for OOD generation. Despite the great success of\ninvariant learning in OOD problems for Euclidean data (i.e., images), the\nexploration within graph data remains constrained by the complex nature of\ngraphs. Existing studies, such as data augmentation or causal intervention,\neither suffer from disruptions to invariance during the graph manipulation\nprocess or face reliability issues due to a lack of supervised signals for\ncausal parts. In this work, we propose a novel framework, called Invariant\nGraph Learning based on Information bottleneck theory (InfoIGL), to extract the\ninvariant features of graphs and enhance models' generalization ability to\nunseen distributions. Specifically, InfoIGL introduces a redundancy filter to\ncompress task-irrelevant information related to environmental factors.\nCooperating with our designed multi-level contrastive learning, we maximize the\nmutual information among graphs of the same class in the downstream\nclassification tasks, preserving invariant features for prediction to a great\nextent. An appealing feature of InfoIGL is its strong generalization ability\nwithout depending on supervised signal of invariance. Experiments on both\nsynthetic and real-world datasets demonstrate that our method achieves\nstate-of-the-art performance under OOD generalization for graph classification\ntasks. The source code is available at https://github.com/maowenyu-11/InfoIGL.\n","authors":["Wenyu Mao","Jiancan Wu","Haoyang Liu","Yongduo Sui","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2408.01697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01662v1","updated":"2024-08-03T04:24:48Z","published":"2024-08-03T04:24:48Z","title":"Principal component analysis balancing prediction and approximation\n  accuracy for spatial data","summary":"  Dimension reduction is often the first step in statistical modeling or\nprediction of multivariate spatial data. However, most existing dimension\nreduction techniques do not account for the spatial correlation between\nobservations and do not take the downstream modeling task into consideration\nwhen finding the lower-dimensional representation. We formalize the closeness\nof approximation to the original data and the utility of lower-dimensional\nscores for downstream modeling as two complementary, sometimes conflicting,\nmetrics for dimension reduction. We illustrate how existing methodologies fall\ninto this framework and propose a flexible dimension reduction algorithm that\nachieves the optimal trade-off. We derive a computationally simple form for our\nalgorithm and illustrate its performance through simulation studies, as well as\ntwo applications in air pollution modeling and spatial transcriptomics.\n","authors":["Si Cheng","Magali N. Blanco","Timothy V. Larson","Lianne Sheppard","Adam Szpiro","Ali Shojaie"],"pdf_url":"https://arxiv.org/pdf/2408.01662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01642v1","updated":"2024-08-03T03:00:50Z","published":"2024-08-03T03:00:50Z","title":"Neural Term Structure of Additive Process for Option Pricing","summary":"  The additive process generalizes the L\\'evy process by relaxing its\nassumption of time-homogeneous increments and hence covers a larger family of\nstochastic processes. Recent research in option pricing shows that modeling the\nunderlying log price with an additive process has advantages in easier\nconstruction of the risk-neural measure, an explicit option pricing formula and\ncharacteristic function, and more flexibility to fit the implied volatility\nsurface. Still, the challenge of calibrating an additive model arises from its\ntime-dependent parameterization, for which one has to prescribe parametric\nfunctions for the term structure. For this, we propose the neural term\nstructure model to utilize feedforward neural networks to represent the term\nstructure, which alleviates the difficulty of designing parametric functions\nand thus attenuates the misspecification risk. Numerical studies with S\\&P 500\noption data are conducted to evaluate the performance of the neural term\nstructure.\n","authors":["Jimin Lin","Guixin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.01642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01630v1","updated":"2024-08-03T02:05:43Z","published":"2024-08-03T02:05:43Z","title":"Fair Risk Minimization under Causal Path-Specific Effect Constraints","summary":"  This paper introduces a framework for estimating fair optimal predictions\nusing machine learning where the notion of fairness can be quantified using\npath-specific causal effects. We use a recently developed approach based on\nLagrange multipliers for infinite-dimensional functional estimation to derive\nclosed-form solutions for constrained optimization based on mean squared error\nand cross-entropy risk criteria. The theoretical forms of the solutions are\nanalyzed in detail and described as nuanced adjustments to the unconstrained\nminimizer. This analysis highlights important trade-offs between risk\nminimization and achieving fairnes. The theoretical solutions are also used as\nthe basis for construction of flexible semiparametric estimation strategies for\nthese nuisance components. We describe the robustness properties of our\nestimators in terms of achieving the optimal constrained risk, as well as in\nterms of controlling the value of the constraint. We study via simulation the\nimpact of using robust estimators of pathway-specific effects to validate our\ntheory. This work advances the discourse on algorithmic fairness by integrating\ncomplex causal considerations into model training, thus providing strategies\nfor implementing fair models in real-world applications.\n","authors":["Razieh Nabi","David Benkeser"],"pdf_url":"https://arxiv.org/pdf/2408.01630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15659v4","updated":"2024-08-03T17:54:40Z","published":"2022-10-27T17:59:09Z","title":"A Primal-Dual Approach to Solving Variational Inequalities with General\n  Constraints","summary":"  Yang et al. (2023) recently showed how to use first-order gradient methods to\nsolve general variational inequalities (VIs) under a limiting assumption that\nanalytic solutions of specific subproblems are available. In this paper, we\ncircumvent this assumption via a warm-starting technique where we solve\nsubproblems approximately and initialize variables with the approximate\nsolution found at the previous iteration. We prove the convergence of this\nmethod and show that the gap function of the last iterate of the method\ndecreases at a rate of $O(\\frac{1}{\\sqrt{K}})$ when the operator is\n$L$-Lipschitz and monotone. In numerical experiments, we show that this\ntechnique can converge much faster than its exact counterpart. Furthermore, for\nthe cases when the inequality constraints are simple, we introduce an\nalternative variant of ACVI and establish its convergence under the same\nconditions. Finally, we relax the smoothness assumptions in Yang et al.,\nyielding, to our knowledge, the first convergence result for VIs with general\nconstraints that does not rely on the assumption that the operator is\n$L$-Lipschitz.\n","authors":["Tatjana Chavdarova","Tong Yang","Matteo Pagliardini","Michael I. Jordan"],"pdf_url":"https://arxiv.org/pdf/2210.15659v4.pdf","comment":"Source code at https://github.com/Chavdarova/I-ACVI"}]},"2024-08-06T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.03326v1","updated":"2024-08-06T17:59:44Z","published":"2024-08-06T17:59:44Z","title":"LLaVA-OneVision: Easy Visual Task Transfer","summary":"  We present LLaVA-OneVision, a family of open large multimodal models (LMMs)\ndeveloped by consolidating our insights into data, models, and visual\nrepresentations in the LLaVA-NeXT blog series. Our experimental results\ndemonstrate that LLaVA-OneVision is the first single model that can\nsimultaneously push the performance boundaries of open LMMs in three important\ncomputer vision scenarios: single-image, multi-image, and video scenarios.\nImportantly, the design of LLaVA-OneVision allows strong transfer learning\nacross different modalities/scenarios, yielding new emerging capabilities. In\nparticular, strong video understanding and cross-scenario capabilities are\ndemonstrated through task transfer from images to videos.\n","authors":["Bo Li","Yuanhan Zhang","Dong Guo","Renrui Zhang","Feng Li","Hao Zhang","Kaichen Zhang","Yanwei Li","Ziwei Liu","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2408.03326v1.pdf","comment":"Project Homepage:\n  https://llava-vl.github.io/blog/2024-08-05-llava-onevision/"},{"id":"http://arxiv.org/abs/2408.03322v1","updated":"2024-08-06T17:58:18Z","published":"2024-08-06T17:58:18Z","title":"Segment Anything in Medical Images and Videos: Benchmark and Deployment","summary":"  Recent advances in segmentation foundation models have enabled accurate and\nefficient segmentation across a wide range of natural images and videos, but\ntheir utility to medical data remains unclear. In this work, we first present a\ncomprehensive benchmarking of the Segment Anything Model 2 (SAM2) across 11\nmedical image modalities and videos and point out its strengths and weaknesses\nby comparing it to SAM1 and MedSAM. Then, we develop a transfer learning\npipeline and demonstrate SAM2 can be quickly adapted to medical domain by\nfine-tuning. Furthermore, we implement SAM2 as a 3D slicer plugin and Gradio\nAPI for efficient 3D image and video segmentation. The code has been made\npublicly available at \\url{https://github.com/bowang-lab/MedSAM}.\n","authors":["Jun Ma","Sumin Kim","Feifei Li","Mohammed Baharoon","Reza Asakereh","Hongwei Lyu","Bo Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01197v2","updated":"2024-08-06T17:58:00Z","published":"2024-04-01T15:55:25Z","title":"Getting it Right: Improving Spatial Consistency in Text-to-Image Models","summary":"  One of the key shortcomings in current text-to-image (T2I) models is their\ninability to consistently generate images which faithfully follow the spatial\nrelationships specified in the text prompt. In this paper, we offer a\ncomprehensive investigation of this limitation, while also developing datasets\nand methods that support algorithmic solutions to improve spatial reasoning in\nT2I models. We find that spatial relationships are under-represented in the\nimage descriptions found in current vision-language datasets. To alleviate this\ndata bottleneck, we create SPRIGHT, the first spatially focused, large-scale\ndataset, by re-captioning 6 million images from 4 widely used vision datasets\nand through a 3-fold evaluation and analysis pipeline, show that SPRIGHT\nimproves the proportion of spatial relationships in existing datasets. We show\nthe efficacy of SPRIGHT data by showing that using only $\\sim$0.25% of SPRIGHT\nresults in a 22% improvement in generating spatially accurate images while also\nimproving FID and CMMD scores. We also find that training on images containing\na larger number of objects leads to substantial improvements in spatial\nconsistency, including state-of-the-art results on T2I-CompBench with a spatial\nscore of 0.2133, by fine-tuning on <500 images. Through a set of controlled\nexperiments and ablations, we document additional findings that could support\nfuture work that seeks to understand factors that affect spatial consistency in\ntext-to-image models.\n","authors":["Agneet Chatterjee","Gabriela Ben Melech Stan","Estelle Aflalo","Sayak Paul","Dhruba Ghosh","Tejas Gokhale","Ludwig Schmidt","Hannaneh Hajishirzi","Vasudev Lal","Chitta Baral","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2404.01197v2.pdf","comment":"Accepted to ECCV 2024. Project Page : https://spright-t2i.github.io/"},{"id":"http://arxiv.org/abs/2404.01282v2","updated":"2024-08-06T17:56:53Z","published":"2024-04-01T17:54:34Z","title":"LoSA: Long-Short-range Adapter for Scaling End-to-End Temporal Action\n  Localization","summary":"  Temporal Action Localization (TAL) involves localizing and classifying action\nsnippets in an untrimmed video. The emergence of large video foundation models\nhas led RGB-only video backbones to outperform previous methods needing both\nRGB and optical flow modalities. Leveraging these large models is often limited\nto training only the TAL head due to the prohibitively large GPU memory\nrequired to adapt the video backbone for TAL. To overcome this limitation, we\nintroduce LoSA, the first memory-and-parameter-efficient backbone adapter\ndesigned specifically for TAL to handle untrimmed videos. LoSA specializes for\nTAL by introducing Long-Short-range Adapters that adapt the intermediate layers\nof the video backbone over different temporal ranges. These adapters run\nparallel to the video backbone to significantly reduce memory footprint. LoSA\nalso includes Long-Short-range Gated Fusion that strategically combines the\noutput of these adapters from the video backbone layers to enhance the video\nfeatures provided to the TAL head. Experiments show that LoSA significantly\noutperforms all existing methods on standard TAL benchmarks, THUMOS-14 and\nActivityNet-v1.3, by scaling end-to-end backbone adaptation to\nbillion-parameter-plus models like VideoMAEv2~(ViT-g) and leveraging them\nbeyond head-only transfer learning.\n","authors":["Akshita Gupta","Gaurav Mittal","Ahmed Magooda","Ye Yu","Graham W. Taylor","Mei Chen"],"pdf_url":"https://arxiv.org/pdf/2404.01282v2.pdf","comment":"Under submission"},{"id":"http://arxiv.org/abs/2408.00756v2","updated":"2024-08-06T17:40:07Z","published":"2024-08-01T17:57:25Z","title":"Segment anything model 2: an application to 2D and 3D medical images","summary":"  Segment Anything Model (SAM) has gained significant attention because of its\nability to segment varous objects in images given a prompt. The recently\ndeveloped SAM 2 has extended this ability to video inputs. This opens an\nopportunity to apply SAM to 3D images, one of the fundamental tasks in the\nmedical imaging field. In this paper, we extensively evaluate SAM 2's ability\nto segment both 2D and 3D medical images by first collecting 18 medical imaging\ndatasets, including common 3D modalities such as computed tomography (CT),\nmagnetic resonance imaging (MRI), and positron emission tomography (PET) as\nwell as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of\nSAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are\nprovided to one or multiple slice(s) selected from the volume, and (2)\nsingle-frame 2D segmentation, where prompts are provided to each slice. The\nformer is only applicable to 3D modalities, while the latter applies to both 2D\nand 3D modalities. Our results show that SAM 2 exhibits similar performance as\nSAM under single-frame 2D segmentation, and has variable performance under\nmulti-frame 3D segmentation depending on the choices of slices to annotate, the\ndirection of the propagation, the predictions utilized during the propagation,\netc.\n","authors":["Haoyu Dong","Hanxue Gu","Yaqian Chen","Jichen Yang","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.00756v2.pdf","comment":"12 pages, 9 figures. An updated version with new results and\n  corrections"},{"id":"http://arxiv.org/abs/2402.00035v4","updated":"2024-08-06T17:36:06Z","published":"2024-01-08T12:19:46Z","title":"Robustness Assessment of a Runway Object Classifier for Safe Aircraft\n  Taxiing","summary":"  As deep neural networks (DNNs) are becoming the prominent solution for many\ncomputational problems, the aviation industry seeks to explore their potential\nin alleviating pilot workload and in improving operational safety. However, the\nuse of DNNs in this type of safety-critical applications requires a thorough\ncertification process. This need can be addressed through formal verification,\nwhich provides rigorous assurances -- e.g.,~by proving the absence of certain\nmispredictions. In this case-study paper, we demonstrate this process using an\nimage-classifier DNN currently under development at Airbus and intended for use\nduring the aircraft taxiing phase. We use formal methods to assess this DNN's\nrobustness to three common image perturbation types: noise, brightness and\ncontrast, and some of their combinations. This process entails multiple\ninvocations of the underlying verifier, which might be computationally\nexpensive; and we therefore propose a method that leverages the monotonicity of\nthese robustness properties, as well as the results of past verification\nqueries, in order to reduce the overall number of verification queries required\nby nearly 60%. Our results provide an indication of the level of robustness\nachieved by the DNN classifier under study, and indicate that it is\nconsiderably more vulnerable to noise than to brightness or contrast\nperturbations.\n","authors":["Yizhak Elboher","Raya Elsaleh","Omri Isac","Mélanie Ducoffe","Audrey Galametz","Guillaume Povéda","Ryma Boumazouza","Noémie Cohen","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2402.00035v4.pdf","comment":"This is a preprint version of the paper in the proceedings of 43rd\n  Digital Avionics Systems Conference (DASC)"},{"id":"http://arxiv.org/abs/2402.04492v2","updated":"2024-08-06T17:31:33Z","published":"2024-02-07T00:31:49Z","title":"ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation","summary":"  This paper introduces the ColorSwap dataset, designed to assess and improve\nthe proficiency of multimodal models in matching objects with their colors. The\ndataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000\nexamples. Each example includes a caption-image pair, along with a\n``color-swapped'' pair. We follow the Winoground schema: the two captions in an\nexample have the same words, but the color words have been rearranged to modify\ndifferent objects. The dataset was created through a novel blend of automated\ncaption and image generation with humans in the loop. We evaluate image-text\nmatching (ITM) and visual language models (VLMs) and find that even the latest\nones are still not robust at this task. GPT-4V and LLaVA score 72% and 42% on\nour main VLM metric, although they may improve with more advanced prompting\ntechniques. On the main ITM metric, contrastive models such as CLIP and SigLIP\nperform close to chance (at 12% and 30%, respectively), although the\nnon-contrastive BLIP ITM model is stronger (87%). We also find that finetuning\non fewer than 2,000 examples yields significant performance gains on this\nout-of-distribution word-order understanding task. The dataset is here:\nhttps://github.com/Top34051/colorswap and here:\nhttps://huggingface.co/datasets/stanfordnlp/colorswap.\n","authors":["Jirayu Burapacheep","Ishan Gaur","Agam Bhatia","Tristan Thrush"],"pdf_url":"https://arxiv.org/pdf/2402.04492v2.pdf","comment":"ACL Findings 2024"},{"id":"http://arxiv.org/abs/2408.03312v1","updated":"2024-08-06T17:29:01Z","published":"2024-08-06T17:29:01Z","title":"MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture\n  Generation","summary":"  Recent advancements in the field of Diffusion Transformers have substantially\nimproved the generation of high-quality 2D images, 3D videos, and 3D shapes.\nHowever, the effectiveness of the Transformer architecture in the domain of\nco-speech gesture generation remains relatively unexplored, as prior\nmethodologies have predominantly employed the Convolutional Neural Network\n(CNNs) or simple a few transformer layers. In an attempt to bridge this\nresearch gap, we introduce a novel Masked Diffusion Transformer for co-speech\ngesture generation, referred to as MDT-A2G, which directly implements the\ndenoising process on gesture sequences. To enhance the contextual reasoning\ncapability of temporally aligned speech-driven gestures, we incorporate a novel\nMasked Diffusion Transformer. This model employs a mask modeling scheme\nspecifically designed to strengthen temporal relation learning among sequence\ngestures, thereby expediting the learning process and leading to coherent and\nrealistic motions. Apart from audio, Our MDT-A2G model also integrates\nmulti-modal information, encompassing text, emotion, and identity. Furthermore,\nwe propose an efficient inference strategy that diminishes the denoising\ncomputation by leveraging previously calculated results, thereby achieving a\nspeedup with negligible performance degradation. Experimental results\ndemonstrate that MDT-A2G excels in gesture generation, boasting a learning\nspeed that is over 6$\\times$ faster than traditional diffusion transformers and\nan inference speed that is 5.7$\\times$ than the standard diffusion model.\n","authors":["Xiaofeng Mao","Zhengkai Jiang","Qilin Wang","Chencan Fu","Jiangning Zhang","Jiafu Wu","Yabiao Wang","Chengjie Wang","Wei Li","Mingmin Chi"],"pdf_url":"https://arxiv.org/pdf/2408.03312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19308v2","updated":"2024-08-06T17:22:17Z","published":"2024-07-27T17:45:20Z","title":"Comprehensive Attribution: Inherently Explainable Vision Model with\n  Feature Detector","summary":"  As deep vision models' popularity rapidly increases, there is a growing\nemphasis on explanations for model predictions. The inherently explainable\nattribution method aims to enhance the understanding of model behavior by\nidentifying the important regions in images that significantly contribute to\npredictions. It is achieved by cooperatively training a selector (generating an\nattribution map to identify important features) and a predictor (making\npredictions using the identified features). Despite many advancements, existing\nmethods suffer from the incompleteness problem, where discriminative features\nare masked out, and the interlocking problem, where the non-optimized selector\ninitially selects noise, causing the predictor to fit on this noise and\nperpetuate the cycle. To address these problems, we introduce a new objective\nthat discourages the presence of discriminative features in the masked-out\nregions thus enhancing the comprehensiveness of feature selection. A\npre-trained detector is introduced to detect discriminative features in the\nmasked-out region. If the selector selects noise instead of discriminative\nfeatures, the detector can observe and break the interlocking situation by\npenalizing the selector. Extensive experiments show that our model makes\naccurate predictions with higher accuracy than the regular black-box model, and\nproduces attribution maps with high feature coverage, localization ability,\nfidelity and robustness. Our code will be available at\n\\href{https://github.com/Zood123/COMET}{https://github.com/Zood123/COMET}.\n","authors":["Xianren Zhang","Dongwon Lee","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2407.19308v2.pdf","comment":"Accepted as a conference paper by ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03304v1","updated":"2024-08-06T17:11:40Z","published":"2024-08-06T17:11:40Z","title":"Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks","summary":"  Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.\n","authors":["Rafael Sterzinger","Christian Stippel","Robert Sablatnig"],"pdf_url":"https://arxiv.org/pdf/2408.03304v1.pdf","comment":"16 pages, accepted at ICPR2024"},{"id":"http://arxiv.org/abs/2304.05339v2","updated":"2024-08-06T17:09:59Z","published":"2023-04-11T16:58:59Z","title":"Deep-learning Assisted Detection and Quantification of (oo)cysts of\n  Giardia and Cryptosporidium on Smartphone Microscopy Images","summary":"  The consumption of microbial-contaminated food and water is responsible for\nthe deaths of millions of people annually. Smartphone-based microscopy systems\nare portable, low-cost, and more accessible alternatives for the detection of\nGiardia and Cryptosporidium than traditional brightfield microscopes. However,\nthe images from smartphone microscopes are noisier and require manual cyst\nidentification by trained technicians, usually unavailable in resource-limited\nsettings. Automatic detection of (oo)cysts using deep-learning-based object\ndetection could offer a solution for this limitation. We evaluate the\nperformance of four state-of-the-art object detectors to detect (oo)cysts of\nGiardia and Cryptosporidium on a custom dataset that includes both smartphone\nand brightfield microscopic images from vegetable samples. Faster RCNN,\nRetinaNet, You Only Look Once (YOLOv8s), and Deformable Detection Transformer\n(Deformable DETR) deep-learning models were employed to explore their efficacy\nand limitations. Our results show that while the deep-learning models perform\nbetter with the brightfield microscopy image dataset than the smartphone\nmicroscopy image dataset, the smartphone microscopy predictions are still\ncomparable to the prediction performance of non-experts. Also, we publicly\nrelease brightfield and smartphone microscopy datasets with the benchmark\nresults for the detection of Giardia and Cryptosporidium, independently\ncaptured on reference (or standard lab setting) and vegetable samples. Our code\nand dataset are available at\nhttps://github.com/naamiinepal/smartphone_microscopy and\nhttps://doi.org/10.5281/zenodo.7813183, respectively.\n","authors":["Suprim Nakarmi","Sanam Pudasaini","Safal Thapaliya","Pratima Upretee","Retina Shrestha","Basant Giri","Bhanu Bhakta Neupane","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2304.05339v2.pdf","comment":"21 pages (including supplementary information), 5 figures, 7 tables,\n  Accepted for publication at the Journal of Machine Learning for Biomedical\n  Imaging (MELBA) https://melba-journal.org/2024:014"},{"id":"http://arxiv.org/abs/2408.03302v1","updated":"2024-08-06T17:08:05Z","published":"2024-08-06T17:08:05Z","title":"TextIM: Part-aware Interactive Motion Synthesis from Text","summary":"  In this work, we propose TextIM, a novel framework for synthesizing\nTEXT-driven human Interactive Motions, with a focus on the precise alignment of\npart-level semantics. Existing methods often overlook the critical roles of\ninteractive body parts and fail to adequately capture and align part-level\nsemantics, resulting in inaccuracies and even erroneous movement outcomes. To\naddress these issues, TextIM utilizes a decoupled conditional diffusion\nframework to enhance the detailed alignment between interactive movements and\ncorresponding semantic intents from textual descriptions. Our approach\nleverages large language models, functioning as a human brain, to identify\ninteracting human body parts and to comprehend interaction semantics to\ngenerate complicated and subtle interactive motion. Guided by the refined\nmovements of the interacting parts, TextIM further extends these movements into\na coherent whole-body motion. We design a spatial coherence module to\ncomplement the entire body movements while maintaining consistency and harmony\nacross body parts using a part graph convolutional network. For training and\nevaluation, we carefully selected and re-labeled interactive motions from\nHUMANML3D to develop a specialized dataset. Experimental results demonstrate\nthat TextIM produces semantically accurate human interactive motions,\nsignificantly enhancing the realism and applicability of synthesized\ninteractive motions in diverse scenarios, even including interactions with\ndeformable and dynamically changing objects.\n","authors":["Siyuan Fan","Bo Du","Xiantao Cai","Bo Peng","Longling Sun"],"pdf_url":"https://arxiv.org/pdf/2408.03302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11914v2","updated":"2024-08-06T17:00:49Z","published":"2024-05-20T09:49:13Z","title":"PT43D: A Probabilistic Transformer for Generating 3D Shapes from Single\n  Highly-Ambiguous RGB Images","summary":"  Generating 3D shapes from single RGB images is essential in various\napplications such as robotics. Current approaches typically target images\ncontaining clear and complete visual descriptions of the object, without\nconsidering common realistic cases where observations of objects that are\nlargely occluded or truncated. We thus propose a transformer-based\nautoregressive model to generate the probabilistic distribution of 3D shapes\nconditioned on an RGB image containing potentially highly ambiguous\nobservations of the object. To handle realistic scenarios such as occlusion or\nfield-of-view truncation, we create simulated image-to-shape training pairs\nthat enable improved fine-tuning for real-world scenarios. We then adopt\ncross-attention to effectively identify the most relevant region of interest\nfrom the input image for shape generation. This enables inference of sampled\nshapes with reasonable diversity and strong alignment with the input image. We\ntrain and test our model on our synthetic data then fine-tune and test it on\nreal-world data. Experiments demonstrate that our model outperforms state of\nthe art in both scenarios.\n","authors":["Yiheng Xiong","Angela Dai"],"pdf_url":"https://arxiv.org/pdf/2405.11914v2.pdf","comment":"10 pages, 6 figures. Accepted to BMVC 2024"},{"id":"http://arxiv.org/abs/2408.03291v1","updated":"2024-08-06T16:40:04Z","published":"2024-08-06T16:40:04Z","title":"DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training\n  Quantization for Vision Transformers","summary":"  Vision transformers (ViTs) have garnered significant attention for their\nperformance in vision tasks; however, the high computational cost and\nsignificant latency issues have hinder widespread adoption. Post-training\nquantization (PTQ), a promising method for model compression, still faces\naccuracy degradation challenges with ViTs. There are two reasons for this: the\nexisting quantization paradigm does not fit the power-law distribution of\npost-Softmax activations well, and accuracy inevitably decreases after\nreparameterizing post-LayerNorm activations. We propose a Distribution-Friendly\nand Outlier-Aware Post-training Quantization method for Vision Transformers,\nnamed DopQ-ViT. DopQ-ViT analyzes the inefficiencies of current quantizers and\nintroduces a distribution-friendly Tan Quantizer called TanQ. TanQ focuses more\non values near 1, more accurately preserving the power-law distribution of\npost-Softmax activations, and achieves favorable results. Moreover, when\nreparameterizing post-LayerNorm activations from channel-wise to layer-wise\nquantization, the accuracy degradation is mainly due to the significant impact\nof outliers in the scaling factors. Therefore, DopQ-ViT proposes a method to\nSearch for the Optimal Scaling Factor, denoted as SOSF, which compensates for\nthe influence of outliers and preserves the performance of the quantization\nmodel. DopQ-ViT has undergone extensive validation and demonstrates significant\nperformance improvements in quantization models, particularly in low-bit\nsettings.\n","authors":["Lianwei Yang","Haisong Gong"],"pdf_url":"https://arxiv.org/pdf/2408.03291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14242v2","updated":"2024-08-06T16:36:11Z","published":"2023-11-24T01:15:57Z","title":"RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with\n  Occlusion Handling","summary":"  In the domain of 3D Human Pose Estimation, which finds widespread daily\napplications, the requirement for convenient acquisition equipment continues to\ngrow. To satisfy this demand, we set our sights on a short-baseline binocular\nsetting that offers both portability and a geometric measurement property that\nradically mitigates depth ambiguity. However, as the binocular baseline\nshortens, two serious challenges emerge: first, the robustness of 3D\nreconstruction against 2D errors deteriorates; and second, occlusion reoccurs\ndue to the limited visual differences between two views. To address the first\nchallenge, we propose the Stereo Co-Keypoints Estimation module to improve the\nview consistency of 2D keypoints and enhance the 3D robustness. In this module,\nthe disparity is utilized to represent the correspondence of binocular 2D\npoints and the Stereo Volume Feature is introduced to contain binocular\nfeatures across different disparities. Through the regression of SVF, two-view\n2D keypoints are simultaneously estimated in a collaborative way which\nrestricts their view consistency. Furthermore, to deal with occlusions, a\nPre-trained Pose Transformer module is introduced. Through this module, 3D\nposes are refined by perceiving pose coherence, a representation of joint\ncorrelations. This perception is injected by the Pose Transformer network and\nlearned through a pre-training task that recovers iterative masked joints.\nComprehensive experiments carried out on H36M and MHAD datasets, complemented\nby visualizations, validate the effectiveness of our approach in the\nshort-baseline binocular 3D Human Pose Estimation and occlusion handling.\n","authors":["Xiaoyue Wan","Zhuo Chen","Yiming Bao","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.14242v2.pdf","comment":"13 pages, 8 figures, currently under review at IEEE Transactions on\n  Image Processing journal"},{"id":"http://arxiv.org/abs/2406.04485v3","updated":"2024-08-06T16:35:50Z","published":"2024-06-06T20:15:42Z","title":"GenAI Arena: An Open Evaluation Platform for Generative Models","summary":"  Generative AI has made remarkable strides to revolutionize fields such as\nimage and video generation. These advancements are driven by innovative\nalgorithms, architecture, and data. However, the rapid proliferation of\ngenerative models has highlighted a critical gap: the absence of trustworthy\nevaluation metrics. Current automatic assessments such as FID, CLIP, FVD, etc\noften fail to capture the nuanced quality and user satisfaction associated with\ngenerative outputs. This paper proposes an open platform GenAI-Arena to\nevaluate different image and video generative models, where users can actively\nparticipate in evaluating these models. By leveraging collective user feedback\nand votes, GenAI-Arena aims to provide a more democratic and accurate measure\nof model performance. It covers three arenas for text-to-image generation,\ntext-to-video generation, and image editing respectively. Currently, we cover a\ntotal of 27 open-source generative models. GenAI-Arena has been operating for\nfour months, amassing over 6000 votes from the community. We describe our\nplatform, analyze the data, and explain the statistical methods for ranking the\nmodels. To further promote the research in building model-based evaluation\nmetrics, we release a cleaned version of our preference data for the three\ntasks, namely GenAI-Bench. We prompt the existing multi-modal models like\nGemini, GPT-4o to mimic human voting. We compute the correlation between model\nvoting with human voting to understand their judging abilities. Our results\nshow existing multimodal models are still lagging in assessing the generated\nvisual content, even the best model GPT-4o only achieves a Pearson correlation\nof 0.22 in the quality subscore, and behaves like random guessing in others.\n","authors":["Dongfu Jiang","Max Ku","Tianle Li","Yuansheng Ni","Shizhuo Sun","Rongqi Fan","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.04485v3.pdf","comment":"9 pages,7 figures"},{"id":"http://arxiv.org/abs/2408.03286v1","updated":"2024-08-06T16:34:04Z","published":"2024-08-06T16:34:04Z","title":"Biomedical SAM 2: Segment Anything in Biomedical Images and Videos","summary":"  Medical image segmentation and video object segmentation are essential for\ndiagnosing and analyzing diseases by identifying and measuring biological\nstructures. Recent advances in natural domain have been driven by foundation\nmodels like the Segment Anything Model 2 (SAM 2). To explore the performance of\nSAM 2 in biomedical applications, we designed two evaluation pipelines for\nsingle-frame image segmentation and multi-frame video segmentation with varied\nprompt designs, revealing SAM 2's limitations in medical contexts.\nConsequently, we developed BioSAM 2, an enhanced foundation model optimized for\nbiomedical data based on SAM 2. Our experiments show that BioSAM 2 not only\nsurpasses the performance of existing state-of-the-art foundation models but\nalso matches or even exceeds specialist models, demonstrating its efficacy and\npotential in the medical domain.\n","authors":["Zhiling Yan","Weixiang Sun","Rong Zhou","Zhengqing Yuan","Kai Zhang","Yiwei Li","Tianming Liu","Quanzheng Li","Xiang Li","Lifang He","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2408.03286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03284v1","updated":"2024-08-06T16:31:45Z","published":"2024-08-06T16:31:45Z","title":"ReSyncer: Rewiring Style-based Generator for Unified Audio-Visually\n  Synced Facial Performer","summary":"  Lip-syncing videos with given audio is the foundation for various\napplications including the creation of virtual presenters or performers. While\nrecent studies explore high-fidelity lip-sync with different techniques, their\ntask-orientated models either require long-term videos for clip-specific\ntraining or retain visible artifacts. In this paper, we propose a unified and\neffective framework ReSyncer, that synchronizes generalized audio-visual facial\ninformation. The key design is revisiting and rewiring the Style-based\ngenerator to efficiently adopt 3D facial dynamics predicted by a principled\nstyle-injected Transformer. By simply re-configuring the information insertion\nmechanisms within the noise and style space, our framework fuses motion and\nappearance with unified training. Extensive experiments demonstrate that\nReSyncer not only produces high-fidelity lip-synced videos according to audio,\nbut also supports multiple appealing properties that are suitable for creating\nvirtual presenters and performers, including fast personalized fine-tuning,\nvideo-driven lip-syncing, the transfer of speaking styles, and even face\nswapping. Resources can be found at\nhttps://guanjz20.github.io/projects/ReSyncer.\n","authors":["Jiazhi Guan","Zhiliang Xu","Hang Zhou","Kaisiyuan Wang","Shengyi He","Zhanwang Zhang","Borong Liang","Haocheng Feng","Errui Ding","Jingtuo Liu","Jingdong Wang","Youjian Zhao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2408.03284v1.pdf","comment":"Accepted to European Conference on Computer Vision (ECCV), 2024.\n  Project page: https://guanjz20.github.io/projects/ReSyncer"},{"id":"http://arxiv.org/abs/2408.03282v1","updated":"2024-08-06T16:29:51Z","published":"2024-08-06T16:29:51Z","title":"AMES: Asymmetric and Memory-Efficient Similarity Estimation for\n  Instance-level Retrieval","summary":"  This work investigates the problem of instance-level image retrieval\nre-ranking with the constraint of memory efficiency, ultimately aiming to limit\nmemory usage to 1KB per image. Departing from the prevalent focus on\nperformance enhancements, this work prioritizes the crucial trade-off between\nperformance and memory requirements. The proposed model uses a\ntransformer-based architecture designed to estimate image-to-image similarity\nby capturing interactions within and across images based on their local\ndescriptors. A distinctive property of the model is the capability for\nasymmetric similarity estimation. Database images are represented with a\nsmaller number of descriptors compared to query images, enabling performance\nimprovements without increasing memory consumption. To ensure adaptability\nacross different applications, a universal model is introduced that adjusts to\na varying number of local descriptors during the testing phase. Results on\nstandard benchmarks demonstrate the superiority of our approach over both\nhand-crafted and learned models. In particular, compared with current\nstate-of-the-art methods that overlook their memory footprint, our approach not\nonly attains superior performance but does so with a significantly reduced\nmemory footprint. The code and pretrained models are publicly available at:\nhttps://github.com/pavelsuma/ames\n","authors":["Pavel Suma","Giorgos Kordopatis-Zilos","Ahmet Iscen","Giorgos Tolias"],"pdf_url":"https://arxiv.org/pdf/2408.03282v1.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2403.15313v2","updated":"2024-08-06T15:58:35Z","published":"2024-03-22T16:06:05Z","title":"CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking","summary":"  To enable self-driving vehicles accurate detection and tracking of\nsurrounding objects is essential. While Light Detection and Ranging (LiDAR)\nsensors have set the benchmark for high-performance systems, the appeal of\ncamera-only solutions lies in their cost-effectiveness. Notably, despite the\nprevalent use of Radio Detection and Ranging (RADAR) sensors in automotive\nsystems, their potential in 3D detection and tracking has been largely\ndisregarded due to data sparsity and measurement noise. As a recent\ndevelopment, the combination of RADARs and cameras is emerging as a promising\nsolution. This paper presents Camera-RADAR 3D Detection and Tracking (CR3DT), a\ncamera-RADAR fusion model for 3D object detection, and Multi-Object Tracking\n(MOT). Building upon the foundations of the State-of-the-Art (SotA) camera-only\nBEVDet architecture, CR3DT demonstrates substantial improvements in both\ndetection and tracking capabilities, by incorporating the spatial and velocity\ninformation of the RADAR sensor. Experimental results demonstrate an absolute\nimprovement in detection performance of 5.3% in mean Average Precision (mAP)\nand a 14.9% increase in Average Multi-Object Tracking Accuracy (AMOTA) on the\nnuScenes dataset when leveraging both modalities. CR3DT bridges the gap between\nhigh-performance and cost-effective perception systems in autonomous driving,\nby capitalizing on the ubiquitous presence of RADAR in automotive applications.\nThe code is available at: https://github.com/ETH-PBL/CR3DT.\n","authors":["Nicolas Baumann","Michael Baumgartner","Edoardo Ghignone","Jonas Kühne","Tobias Fischer","Yung-Hsu Yang","Marc Pollefeys","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2403.15313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10344v3","updated":"2024-08-06T15:39:03Z","published":"2024-02-15T22:17:17Z","title":"Evaluating Neural Radiance Fields (NeRFs) for 3D Plant Geometry\n  Reconstruction in Field Conditions","summary":"  We evaluate different Neural Radiance Fields (NeRFs) techniques for the 3D\nreconstruction of plants in varied environments, from indoor settings to\noutdoor fields. Traditional methods usually fail to capture the complex\ngeometric details of plants, which is crucial for phenotyping and breeding\nstudies. We evaluate the reconstruction fidelity of NeRFs in three scenarios\nwith increasing complexity and compare the results with the point cloud\nobtained using LiDAR as ground truth. In the most realistic field scenario, the\nNeRF models achieve a 74.6% F1 score after 30 minutes of training on the GPU,\nhighlighting the efficacy of NeRFs for 3D reconstruction in challenging\nenvironments. Additionally, we propose an early stopping technique for NeRF\ntraining that almost halves the training time while achieving only a reduction\nof 7.4% in the average F1 score. This optimization process significantly\nenhances the speed and efficiency of 3D reconstruction using NeRFs. Our\nfindings demonstrate the potential of NeRFs in detailed and realistic 3D plant\nreconstruction and suggest practical approaches for enhancing the speed and\nefficiency of NeRFs in the 3D reconstruction process.\n","authors":["Muhammad Arbab Arshad","Talukder Jubery","James Afful","Anushrut Jignasu","Aditya Balu","Baskar Ganapathysubramanian","Soumik Sarkar","Adarsh Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2402.10344v3.pdf","comment":"Published in 'Plant Phenomics'"},{"id":"http://arxiv.org/abs/2402.15745v2","updated":"2024-08-06T15:28:30Z","published":"2024-02-24T06:57:15Z","title":"GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models\n  Evaluation","summary":"  The Large Vision-Language Models (LVLMs) have demonstrated great abilities in\nimage perception and language understanding. However, existing multimodal\nbenchmarks focus on primary perception abilities and commonsense knowledge\nwhich are insufficient to reflect the comprehensive capabilities of LVLMs. We\npropose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance\nExamination (GAOKAO), comprising of 8 subjects and 12 types of images, such as\ndiagrams, function graphs, maps and photos. GAOKAO-MM derives from native\nChinese context and sets human-level requirements for the model's abilities,\nincluding perception, understanding, knowledge and reasoning. We evaluate 10\nLVLMs and find that the accuracies of all of them are lower than 50%, with\nGPT-4-Vison (48.1%), Qwen-VL-Plus (41.2%) and Gemini-Pro-Vision (35.1%) ranking\nin the top three positions. The results of our multi-dimension analysis\nindicate that LVLMs have moderate distance towards Artificial General\nIntelligence (AGI) and provide insights facilitating the development of\nmultilingual LVLMs.\n","authors":["Yi Zong","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2402.15745v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03291v2","updated":"2024-08-06T15:14:01Z","published":"2024-07-03T17:24:36Z","title":"VCHAR:Variance-Driven Complex Human Activity Recognition framework with\n  Generative Representation","summary":"  Complex human activity recognition (CHAR) remains a pivotal challenge within\nubiquitous computing, especially in the context of smart environments. Existing\nstudies typically require meticulous labeling of both atomic and complex\nactivities, a task that is labor-intensive and prone to errors due to the\nscarcity and inaccuracies of available datasets. Most prior research has\nfocused on datasets that either precisely label atomic activities or, at\nminimum, their sequence approaches that are often impractical in real world\nsettings.In response, we introduce VCHAR (Variance-Driven Complex Human\nActivity Recognition), a novel framework that treats the outputs of atomic\nactivities as a distribution over specified intervals. Leveraging generative\nmethodologies, VCHAR elucidates the reasoning behind complex activity\nclassifications through video-based explanations, accessible to users without\nprior machine learning expertise. Our evaluation across three publicly\navailable datasets demonstrates that VCHAR enhances the accuracy of complex\nactivity recognition without necessitating precise temporal or sequential\nlabeling of atomic activities. Furthermore, user studies confirm that VCHAR's\nexplanations are more intelligible compared to existing methods, facilitating a\nbroader understanding of complex activity recognition among non-experts.\n","authors":["Yuan Sun","Navid Salami Pargoo","Taqiya Ehsan","Zhao Zhang","Jorge Ortiz"],"pdf_url":"https://arxiv.org/pdf/2407.03291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03238v1","updated":"2024-08-06T14:50:48Z","published":"2024-08-06T14:50:48Z","title":"LAC-Net: Linear-Fusion Attention-Guided Convolutional Network for\n  Accurate Robotic Grasping Under the Occlusion","summary":"  This paper addresses the challenge of perceiving complete object shapes\nthrough visual perception. While prior studies have demonstrated encouraging\noutcomes in segmenting the visible parts of objects within a scene, amodal\nsegmentation, in particular, has the potential to allow robots to infer the\noccluded parts of objects. To this end, this paper introduces a new framework\nthat explores amodal segmentation for robotic grasping in cluttered scenes,\nthus greatly enhancing robotic grasping abilities. Initially, we use a\nconventional segmentation algorithm to detect the visible segments of the\ntarget object, which provides shape priors for completing the full object mask.\nParticularly, to explore how to utilize semantic features from RGB images and\ngeometric information from depth images, we propose a Linear-fusion\nAttention-guided Convolutional Network (LAC-Net). LAC-Net utilizes the\nlinear-fusion strategy to effectively fuse this cross-modal data, and then uses\nthe prior visible mask as attention map to guide the network to focus on target\nfeature locations for further complete mask recovery. Using the amodal mask of\nthe target object provides advantages in selecting more accurate and robust\ngrasp points compared to relying solely on the visible segments. The results on\ndifferent datasets show that our method achieves state-of-the-art performance.\nFurthermore, the robot experiments validate the feasibility and robustness of\nthis method in the real world. Our code and demonstrations are available on the\nproject page: https://jrryzh.github.io/LAC-Net.\n","authors":["Jinyu Zhang","Yongchong Gu","Jianxiong Gao","Haitao Lin","Qiang Sun","Xinwei Sun","Xiangyang Xue","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2408.03238v1.pdf","comment":"accepted by IROS2024"},{"id":"http://arxiv.org/abs/2408.03230v1","updated":"2024-08-06T14:44:55Z","published":"2024-08-06T14:44:55Z","title":"Contrastive Learning for Image Complexity Representation","summary":"  Quantifying and evaluating image complexity can be instrumental in enhancing\nthe performance of various computer vision tasks. Supervised learning can\neffectively learn image complexity features from well-annotated datasets.\nHowever, creating such datasets requires expensive manual annotation costs. The\nmodels may learn human subjective biases from it. In this work, we introduce\nthe MoCo v2 framework. We utilize contrastive learning to represent image\ncomplexity, named CLIC (Contrastive Learning for Image Complexity). We find\nthat there are complexity differences between different local regions of an\nimage, and propose Random Crop and Mix (RCM), which can produce positive\nsamples consisting of multi-scale local crops. RCM can also expand the train\nset and increase data diversity without introducing additional data. We conduct\nextensive experiments with CLIC, comparing it with both unsupervised and\nsupervised methods. The results demonstrate that the performance of CLIC is\ncomparable to that of state-of-the-art supervised methods. In addition, we\nestablish the pipelines that can apply CLIC to computer vision tasks to\neffectively improve their performance.\n","authors":["Shipeng Liu","Liang Zhao","Dengfeng Chen","Zhanping Song"],"pdf_url":"https://arxiv.org/pdf/2408.03230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03225v1","updated":"2024-08-06T14:36:43Z","published":"2024-08-06T14:36:43Z","title":"Line-based 6-DoF Object Pose Estimation and Tracking With an Event\n  Camera","summary":"  Pose estimation and tracking of objects is a fundamental application in 3D\nvision. Event cameras possess remarkable attributes such as high dynamic range,\nlow latency, and resilience against motion blur, which enables them to address\nchallenging high dynamic range scenes or high-speed motion. These features make\nevent cameras an ideal complement over standard cameras for object pose\nestimation. In this work, we propose a line-based robust pose estimation and\ntracking method for planar or non-planar objects using an event camera.\nFirstly, we extract object lines directly from events, then provide an initial\npose using a globally-optimal Branch-and-Bound approach, where 2D-3D line\ncorrespondences are not known in advance. Subsequently, we utilize event-line\nmatching to establish correspondences between 2D events and 3D models.\nFurthermore, object poses are refined and continuously tracked by minimizing\nevent-line distances. Events are assigned different weights based on these\ndistances, employing robust estimation algorithms. To evaluate the precision of\nthe proposed methods in object pose estimation and tracking, we have devised\nand established an event-based moving object dataset. Compared against\nstate-of-the-art methods, the robustness and accuracy of our methods have been\nvalidated both on synthetic experiments and the proposed dataset. The source\ncode is available at https://github.com/Zibin6/LOPET.\n","authors":["Zibin Liu","Banglei Guan","Yang Shang","Qifeng Yu","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2408.03225v1.pdf","comment":"Accepted by IEEE Transactions on Image Processing,2024"},{"id":"http://arxiv.org/abs/2408.03219v1","updated":"2024-08-06T14:25:23Z","published":"2024-08-06T14:25:23Z","title":"Learning to Learn without Forgetting using Attention","summary":"  Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.\n","authors":["Anna Vettoruzzo","Joaquin Vanschoren","Mohamed-Rafik Bouguelia","Thorsteinn Rögnvaldsson"],"pdf_url":"https://arxiv.org/pdf/2408.03219v1.pdf","comment":"Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024"},{"id":"http://arxiv.org/abs/2408.03209v1","updated":"2024-08-06T14:08:22Z","published":"2024-08-06T14:08:22Z","title":"IPAdapter-Instruct: Resolving Ambiguity in Image-based Conditioning\n  using Instruct Prompts","summary":"  Diffusion models continuously push the boundary of state-of-the-art image\ngeneration, but the process is hard to control with any nuance: practice proves\nthat textual prompts are inadequate for accurately describing image style or\nfine structural details (such as faces). ControlNet and IPAdapter address this\nshortcoming by conditioning the generative process on imagery instead, but each\nindividual instance is limited to modeling a single conditional posterior: for\npractical use-cases, where multiple different posteriors are desired within the\nsame workflow, training and using multiple adapters is cumbersome. We propose\nIPAdapter-Instruct, which combines natural-image conditioning with ``Instruct''\nprompts to swap between interpretations for the same conditioning image: style\ntransfer, object extraction, both, or something else still? IPAdapterInstruct\nefficiently learns multiple tasks with minimal loss in quality compared to\ndedicated per-task models.\n","authors":["Ciara Rowles","Shimon Vainer","Dante De Nigris","Slava Elizarov","Konstantin Kutsy","Simon Donné"],"pdf_url":"https://arxiv.org/pdf/2408.03209v1.pdf","comment":"17 pages, 10 figures, Project page:\n  https://unity-research.github.io/IP-Adapter-Instruct.github.io/"},{"id":"http://arxiv.org/abs/2408.03208v1","updated":"2024-08-06T14:06:53Z","published":"2024-08-06T14:06:53Z","title":"Personalizing Federated Instrument Segmentation with Visual Trait Priors\n  in Robotic Surgery","summary":"  Personalized federated learning (PFL) for surgical instrument segmentation\n(SIS) is a promising approach. It enables multiple clinical sites to\ncollaboratively train a series of models in privacy, with each model tailored\nto the individual distribution of each site. Existing PFL methods rarely\nconsider the personalization of multi-headed self-attention, and do not account\nfor appearance diversity and instrument shape similarity, both inherent in\nsurgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait\npriors for SIS, incorporating global-personalized disentanglement (GPD),\nappearance-regulation personalized enhancement (APE), and shape-similarity\nglobal enhancement (SGE), to boost SIS performance in each site. GPD represents\nthe first attempt at head-wise assignment for multi-headed self-attention\npersonalization. To preserve the unique appearance representation of each site\nand gradually leverage the inter-site difference, APE introduces appearance\nregulation and provides customized layer-wise aggregation solutions via\nhypernetworks for each site's personalized parameters. The mutual shape\ninformation of instruments is maintained and shared via SGE, which enhances the\ncross-style shape consistency on the image level and computes the\nshape-similarity contribution of each site on the prediction level for updating\nthe global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%\nDice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding\ncode and models will be released at https://github.com/wzjialang/PFedSIS.\n","authors":["Jialang Xu","Jiacheng Wang","Lequan Yu","Danail Stoyanov","Yueming Jin","Evangelos B. Mazomenos"],"pdf_url":"https://arxiv.org/pdf/2408.03208v1.pdf","comment":"9 pages, 3 figures, under review"},{"id":"http://arxiv.org/abs/2408.03194v1","updated":"2024-08-06T13:53:45Z","published":"2024-08-06T13:53:45Z","title":"SGSR: Structure-Guided Multi-Contrast MRI Super-Resolution via\n  Spatio-Frequency Co-Query Attention","summary":"  Magnetic Resonance Imaging (MRI) is a leading diagnostic modality for a wide\nrange of exams, where multiple contrast images are often acquired for\ncharacterizing different tissues. However, acquiring high-resolution MRI\ntypically extends scan time, which can introduce motion artifacts.\nSuper-resolution of MRI therefore emerges as a promising approach to mitigate\nthese challenges. Earlier studies have investigated the use of multiple\ncontrasts for MRI super-resolution (MCSR), whereas majority of them did not\nfully exploit the rich contrast-invariant structural information. To fully\nutilize such crucial prior knowledge of multi-contrast MRI, in this work, we\npropose a novel structure-guided MCSR (SGSR) framework based on a new\nspatio-frequency co-query attention (CQA) mechanism. Specifically, CQA performs\nattention on features of multiple contrasts with a shared structural query,\nwhich is particularly designed to extract, fuse, and refine the common\nstructures from different contrasts. We further propose a novel\nfrequency-domain CQA module in addition to the spatial domain, to enable more\nfine-grained structural refinement. Extensive experiments on fastMRI knee data\nand low-field brain MRI show that SGSR outperforms state-of-the-art MCSR\nmethods with statistical significance.\n","authors":["Shaoming Zheng","Yinsong Wang","Siyi Du","Chen Qin"],"pdf_url":"https://arxiv.org/pdf/2408.03194v1.pdf","comment":"The 15th International Workshop on Machine Learning in Medical\n  Imaging (MLMI 2024)"},{"id":"http://arxiv.org/abs/2408.03193v1","updated":"2024-08-06T13:49:01Z","published":"2024-08-06T13:49:01Z","title":"Efficient NeRF Optimization -- Not All Samples Remain Equally Hard","summary":"  We propose an application of online hard sample mining for efficient training\nof Neural Radiance Fields (NeRF). NeRF models produce state-of-the-art quality\nfor many 3D reconstruction and rendering tasks but require substantial\ncomputational resources. The encoding of the scene information within the NeRF\nnetwork parameters necessitates stochastic sampling. We observe that during the\ntraining, a major part of the compute time and memory usage is spent on\nprocessing already learnt samples, which no longer affect the model update\nsignificantly. We identify the backward pass on the stochastic samples as the\ncomputational bottleneck during the optimization. We thus perform the first\nforward pass in inference mode as a relatively low-cost search for hard\nsamples. This is followed by building the computational graph and updating the\nNeRF network parameters using only the hard samples. To demonstrate the\neffectiveness of the proposed approach, we apply our method to Instant-NGP,\nresulting in significant improvements of the view-synthesis quality over the\nbaseline (1 dB improvement on average per training time, or 2x speedup to reach\nthe same PSNR level) along with approx. 40% memory savings coming from using\nonly the hard samples to build the computational graph. As our method only\ninterfaces with the network module, we expect it to be widely applicable.\n","authors":["Juuso Korhonen","Goutham Rangu","Hamed R. Tavakoli","Juho Kannala"],"pdf_url":"https://arxiv.org/pdf/2408.03193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15890v3","updated":"2024-08-06T13:47:24Z","published":"2023-11-27T14:56:47Z","title":"Stability-Informed Initialization of Neural Ordinary Differential\n  Equations","summary":"  This paper addresses the training of Neural Ordinary Differential Equations\n(neural ODEs), and in particular explores the interplay between numerical\nintegration techniques, stability regions, step size, and initialization\ntechniques. It is shown how the choice of integration technique implicitly\nregularizes the learned model, and how the solver's corresponding stability\nregion affects training and prediction performance. From this analysis, a\nstability-informed parameter initialization technique is introduced. The\neffectiveness of the initialization method is displayed across several learning\nbenchmarks and industrial applications.\n","authors":["Theodor Westny","Arman Mohammadi","Daniel Jung","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2311.15890v3.pdf","comment":"In Proceedings of the 41 st International Conference on Machine\n  Learning"},{"id":"http://arxiv.org/abs/2308.10015v2","updated":"2024-08-06T13:25:29Z","published":"2023-08-19T13:46:49Z","title":"DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for\n  Fingerprint Presentation Attack Detection","summary":"  Automatic fingerprint recognition systems suffer from the threat of\npresentation attacks due to their wide range of deployment in areas including\nnational borders and commercial applications. A presentation attack can be\nperformed by creating a spoof of a user's fingerprint with or without their\nconsent. This paper presents a dynamic ensemble of deep CNN and handcrafted\nfeatures to detect presentation attacks in known-material and unknown-material\nprotocols of the livness detection competition. The proposed presentation\nattack detection model, in this way, utilizes the capabilities of both deep CNN\nand handcrafted features techniques and exhibits better performance than their\nindividual performances. The proposed method is validated using benchmark\ndatabases from the Liveness Detection Competition in 2015, 2017, and 2019,\nyielding overall accuracy of 96.10\\%, 96.49\\%, and 94.99\\% on them,\nrespectively. The proposed method outperforms state-of-the-art methods in terms\nof classification accuracy.\n","authors":["Anuj Rai","Parsheel Kumar Tiwari","Jyotishna Baishya","Ram Prakash Sharma","Somnath Dey"],"pdf_url":"https://arxiv.org/pdf/2308.10015v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.09397"},{"id":"http://arxiv.org/abs/2408.03178v1","updated":"2024-08-06T13:22:51Z","published":"2024-08-06T13:22:51Z","title":"An Object is Worth 64x64 Pixels: Generating 3D Object via Image\n  Diffusion","summary":"  We introduce a new approach for generating realistic 3D models with UV maps\nthrough a representation termed \"Object Images.\" This approach encapsulates\nsurface geometry, appearance, and patch structures within a 64x64 pixel image,\neffectively converting complex 3D shapes into a more manageable 2D format. By\ndoing so, we address the challenges of both geometric and semantic irregularity\ninherent in polygonal meshes. This method allows us to use image generation\nmodels, such as Diffusion Transformers, directly for 3D shape generation.\nEvaluated on the ABO dataset, our generated shapes with patch structures\nachieve point cloud FID comparable to recent 3D generative models, while\nnaturally supporting PBR material generation.\n","authors":["Xingguang Yan","Han-Hung Lee","Ziyu Wan","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2408.03178v1.pdf","comment":"Project Page: https://omages.github.io/"},{"id":"http://arxiv.org/abs/2407.15706v5","updated":"2024-08-06T13:20:16Z","published":"2024-07-22T15:16:47Z","title":"Multi-Modality Co-Learning for Efficient Skeleton-based Action\n  Recognition","summary":"  Skeleton-based action recognition has garnered significant attention due to\nthe utilization of concise and resilient skeletons. Nevertheless, the absence\nof detailed body information in skeletons restricts performance, while other\nmultimodal methods require substantial inference resources and are inefficient\nwhen using multimodal data during both training and inference stages. To\naddress this and fully harness the complementary multimodal features, we\npropose a novel multi-modality co-learning (MMCL) framework by leveraging the\nmultimodal large language models (LLMs) as auxiliary networks for efficient\nskeleton-based action recognition, which engages in multi-modality co-learning\nduring the training stage and keeps efficiency by employing only concise\nskeletons in inference. Our MMCL framework primarily consists of two modules.\nFirst, the Feature Alignment Module (FAM) extracts rich RGB features from video\nframes and aligns them with global skeleton features via contrastive learning.\nSecond, the Feature Refinement Module (FRM) uses RGB images with temporal\ninformation and text instruction to generate instructive features based on the\npowerful generalization of multimodal LLMs. These instructive text features\nwill further refine the classification scores and the refined scores will\nenhance the model's robustness and generalization in a manner similar to soft\nlabels. Extensive experiments on NTU RGB+D, NTU RGB+D 120 and Northwestern-UCLA\nbenchmarks consistently verify the effectiveness of our MMCL, which outperforms\nthe existing skeleton-based action recognition methods. Meanwhile, experiments\non UTD-MHAD and SYSU-Action datasets demonstrate the commendable generalization\nof our MMCL in zero-shot and domain-adaptive action recognition. Our code is\npublicly available at: https://github.com/liujf69/MMCL-Action.\n","authors":["Jinfu Liu","Chen Chen","Mengyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2407.15706v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00956v3","updated":"2024-08-06T13:07:37Z","published":"2024-05-02T02:34:19Z","title":"SimEndoGS: Efficient Data-driven Scene Simulation using Robotic Surgery\n  Videos via Physics-embedded 3D Gaussians","summary":"  Surgical scene simulation plays a crucial role in surgical education and\nsimulator-based robot learning. Traditional approaches for creating these\nenvironments with surgical scene involve a labor-intensive process where\ndesigners hand-craft tissues models with textures and geometries for soft body\nsimulations. This manual approach is not only time-consuming but also limited\nin the scalability and realism. In contrast, data-driven simulation offers a\ncompelling alternative. It has the potential to automatically reconstruct 3D\nsurgical scenes from real-world surgical video data, followed by the\napplication of soft body physics. This area, however, is relatively uncharted.\nIn our research, we introduce 3D Gaussian as a learnable representation for\nsurgical scene, which is learned from stereo endoscopic video. To prevent\nover-fitting and ensure the geometrical correctness of these scenes, we\nincorporate depth supervision and anisotropy regularization into the Gaussian\nlearning process. Furthermore, we apply the Material Point Method, which is\nintegrated with physical properties, to the 3D Gaussians to achieve realistic\nscene deformations. Our method was evaluated on our collected in-house and\npublic surgical videos datasets. Results show that it can reconstruct and\nsimulate surgical scenes from endoscopic videos efficiently-taking only a few\nminutes to reconstruct the surgical scene-and produce both visually and\nphysically plausible deformations at a speed approaching real-time. The results\ndemonstrate great potential of our proposed method to enhance the efficiency\nand variety of simulations available for surgical education and robot learning.\n","authors":["Zhenya Yang","Kai Chen","Yonghao Long","Qi Dou"],"pdf_url":"https://arxiv.org/pdf/2405.00956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12705v2","updated":"2024-08-06T13:06:26Z","published":"2024-07-17T16:26:30Z","title":"IMAGDressing-v1: Customizable Virtual Dressing","summary":"  Latest advances have achieved realistic virtual try-on (VTON) through\nlocalized garment inpainting using latent diffusion models, significantly\nenhancing consumers' online shopping experience. However, existing VTON\ntechnologies neglect the need for merchants to showcase garments\ncomprehensively, including flexible control over garments, optional faces,\nposes, and scenes. To address this issue, we define a virtual dressing (VD)\ntask focused on generating freely editable human images with fixed garments and\noptional conditions. Meanwhile, we design a comprehensive affinity metric index\n(CAMI) to evaluate the consistency between generated images and reference\ngarments. Then, we propose IMAGDressing-v1, which incorporates a garment UNet\nthat captures semantic features from CLIP and texture features from VAE. We\npresent a hybrid attention module, including a frozen self-attention and a\ntrainable cross-attention, to integrate garment features from the garment UNet\ninto a frozen denoising UNet, ensuring users can control different scenes\nthrough text. IMAGDressing-v1 can be combined with other extension plugins,\nsuch as ControlNet and IP-Adapter, to enhance the diversity and controllability\nof generated images. Furthermore, to address the lack of data, we release the\ninteractive garment pairing (IGPair) dataset, containing over 300,000 pairs of\nclothing and dressed images, and establish a standard pipeline for data\nassembly. Extensive experiments demonstrate that our IMAGDressing-v1 achieves\nstate-of-the-art human image synthesis performance under various controlled\nconditions. The code and model will be available at\nhttps://github.com/muzishen/IMAGDressing.\n","authors":["Fei Shen","Xin Jiang","Xin He","Hu Ye","Cong Wang","Xiaoyu Du","Zechao Li","Jinhui Tang"],"pdf_url":"https://arxiv.org/pdf/2407.12705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03164v1","updated":"2024-08-06T13:05:32Z","published":"2024-08-06T13:05:32Z","title":"Dilated Convolution with Learnable Spacings makes visual models more\n  aligned with humans: a Grad-CAM study","summary":"  Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced\nconvolution method that allows enlarging the receptive fields (RF) without\nincreasing the number of parameters, like the dilated convolution, yet without\nimposing a regular grid. DCLS has been shown to outperform the standard and\ndilated convolutions on several computer vision benchmarks. Here, we show that,\nin addition, DCLS increases the models' interpretability, defined as the\nalignment with human visual strategies. To quantify it, we use the Spearman\ncorrelation between the models' GradCAM heatmaps and the ClickMe dataset\nheatmaps, which reflect human visual attention. We took eight reference models\n- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and\n36) - and drop-in replaced the standard convolution layers with DCLS ones. This\nimproved the interpretability score in seven of them. Moreover, we observed\nthat Grad-CAM generated random heatmaps for two models in our study: CAFormer\nand ConvFormer models, leading to low interpretability scores. We addressed\nthis issue by introducing Threshold-Grad-CAM, a modification built on top of\nGrad-CAM that enhanced interpretability across nearly all models. The code and\ncheckpoints to reproduce this study are available at:\nhttps://github.com/rabihchamas/DCLS-GradCAM-Eval.\n","authors":["Rabih Chamas","Ismail Khalfaoui-Hassani","Timothee Masquelier"],"pdf_url":"https://arxiv.org/pdf/2408.03164v1.pdf","comment":"Accepted at The Trustworthy AI Workshop, IJCAI 2024"},{"id":"http://arxiv.org/abs/2408.03156v1","updated":"2024-08-06T12:55:17Z","published":"2024-08-06T12:55:17Z","title":"Iterative CT Reconstruction via Latent Variable Optimization of Shallow\n  Diffusion Models","summary":"  Image generative AI has garnered significant attention in recent years. In\nparticular, the diffusion model, a core component of recent generative AI,\nproduces high-quality images with rich diversity. In this study, we propose a\nnovel CT reconstruction method by combining the denoising diffusion\nprobabilistic model with iterative CT reconstruction. In sharp contrast to\nprevious studies, we optimize the fidelity loss of CT reconstruction with\nrespect to the latent variable of the diffusion model, instead of the image and\nmodel parameters. To suppress anatomical structure changes produced by the\ndiffusion model, we shallow the diffusion and reverse processes, and fix a set\nof added noises in the reverse process to make it deterministic during\ninference. We demonstrate the effectiveness of the proposed method through\nsparse view CT reconstruction of 1/10 view projection data. Despite the\nsimplicity of the implementation, the proposed method shows the capability of\nreconstructing high-quality images while preserving the patient's anatomical\nstructure, and outperforms existing methods including iterative reconstruction,\niterative reconstruction with total variation, and the diffusion model alone in\nterms of quantitative indices such as SSIM and PSNR. We also explore further\nsparse view CT using 1/20 view projection data with the same trained diffusion\nmodel. As the number of iterations increases, image quality improvement\ncomparable to that of 1/10 sparse view CT reconstruction is achieved. In\nprinciple, the proposed method can be widely applied not only to CT but also to\nother imaging modalities such as MRI, PET, and SPECT.\n","authors":["Sho Ozaki","Shizuo Kaji","Toshikazu Imae","Kanabu Nawa","Hideomi Yamashita","Keiichi Nakagawa"],"pdf_url":"https://arxiv.org/pdf/2408.03156v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2407.15488v3","updated":"2024-08-06T12:54:41Z","published":"2024-07-22T09:05:16Z","title":"DiffX: Guide Your Layout to Cross-Modal Generative Modeling","summary":"  Diffusion models have made significant strides in language-driven and\nlayout-driven image generation. However, most diffusion models are limited to\nvisible RGB image generation. In fact, human perception of the world is\nenriched by diverse viewpoints, such as chromatic contrast, thermal\nillumination, and depth information. In this paper, we introduce a novel\ndiffusion model for general layout-guided cross-modal generation, called DiffX.\nNotably, DiffX presents a simple yet effective cross-modal generative modeling\npipeline, which conducts diffusion and denoising processes in the\nmodality-shared latent space. Moreover, we introduce the Joint-Modality\nEmbedder (JME) to enhance interaction between layout and text conditions by\nincorporating a gated attention mechanism. Meanwhile, the advanced Long-CLIP is\nemployed for long caption embedding for user instruction. To facilitate the\nuser-instructed generative training, we construct the cross-modal image\ndatasets with detailed text captions assisted by the Large-Multimodal Model\n(LMM). Through extensive experiments, DiffX demonstrates robustness in\ncross-modal generation across three ``RGB+X'' datasets: FLIR, MFNet, and\nCOME15K, guided by various layout conditions. It also shows the potential for\nthe adaptive generation of ``RGB+X+Y+Z'' images or more diverse modalities on\nCOME15K and MCXFace datasets. Our code and constructed cross-modal image\ndatasets are available at https://github.com/zeyuwang-zju/DiffX.\n","authors":["Zeyu Wang","Jingyu Lin","Yifei Qian","Yi Huang","Shicen Tian","Bosong Chai","Juncan Deng","Lan Du","Cunjian Chen","Yufei Guo","Kejie Huang"],"pdf_url":"https://arxiv.org/pdf/2407.15488v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01661v3","updated":"2024-08-06T12:54:26Z","published":"2024-05-02T18:31:47Z","title":"When a Relation Tells More Than a Concept: Exploring and Evaluating\n  Classifier Decisions with CoReX","summary":"  Explanations for Convolutional Neural Networks (CNNs) based on relevance of\ninput pixels might be too unspecific to evaluate which and how input features\nimpact model decisions. Especially in complex real-world domains like biology,\nthe presence of specific concepts and of relations between concepts might be\ndiscriminating between classes. Pixel relevance is not expressive enough to\nconvey this type of information. In consequence, model evaluation is limited\nand relevant aspects present in the data and influencing the model decisions\nmight be overlooked. This work presents a novel method to explain and evaluate\nCNN models, which uses a concept- and relation-based explainer (CoReX). It\nexplains the predictive behavior of a model on a set of images by masking\n(ir-)relevant concepts from the decision-making process and by constraining\nrelations in a learned interpretable surrogate model. We test our approach with\nseveral image data sets and CNN architectures. Results show that CoReX\nexplanations are faithful to the CNN model in terms of predictive outcomes. We\nfurther demonstrate through a human evaluation that CoReX is a suitable tool\nfor generating combined explanations that help assessing the classification\nquality of CNNs. We further show that CoReX supports the identification and\nre-classification of incorrect or ambiguous classifications.\n","authors":["Bettina Finzel","Patrick Hilme","Johannes Rabold","Ute Schmid"],"pdf_url":"https://arxiv.org/pdf/2405.01661v3.pdf","comment":"preliminary version, submitted to Machine Learning"},{"id":"http://arxiv.org/abs/2408.03149v1","updated":"2024-08-06T12:45:56Z","published":"2024-08-06T12:45:56Z","title":"Leveraging Entity Information for Cross-Modality Correlation Learning:\n  The Entity-Guided Multimodal Summarization","summary":"  The rapid increase in multimedia data has spurred advancements in Multimodal\nSummarization with Multimodal Output (MSMO), which aims to produce a multimodal\nsummary that integrates both text and relevant images. The inherent\nheterogeneity of content within multimodal inputs and outputs presents a\nsignificant challenge to the execution of MSMO. Traditional approaches\ntypically adopt a holistic perspective on coarse image-text data or individual\nvisual objects, overlooking the essential connections between objects and the\nentities they represent. To integrate the fine-grained entity knowledge, we\npropose an Entity-Guided Multimodal Summarization model (EGMS). Our model,\nbuilding on BART, utilizes dual multimodal encoders with shared weights to\nprocess text-image and entity-image information concurrently. A gating\nmechanism then combines visual data for enhanced textual summary generation,\nwhile image selection is refined through knowledge distillation from a\npre-trained vision-language model. Extensive experiments on public MSMO dataset\nvalidate the superiority of the EGMS method, which also prove the necessity to\nincorporate entity information into MSMO problem.\n","authors":["Yanghai Zhang","Ye Liu","Shiwei Wu","Kai Zhang","Xukai Liu","Qi Liu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2408.03149v1.pdf","comment":"In ACL-Findings 2024"},{"id":"http://arxiv.org/abs/2408.03143v1","updated":"2024-08-06T12:37:47Z","published":"2024-08-06T12:37:47Z","title":"SuperSimpleNet: Unifying Unsupervised and Supervised Learning for Fast\n  and Reliable Surface Defect Detection","summary":"  The aim of surface defect detection is to identify and localise abnormal\nregions on the surfaces of captured objects, a task that's increasingly\ndemanded across various industries. Current approaches frequently fail to\nfulfil the extensive demands of these industries, which encompass high\nperformance, consistency, and fast operation, along with the capacity to\nleverage the entirety of the available training data. Addressing these gaps, we\nintroduce SuperSimpleNet, an innovative discriminative model that evolved from\nSimpleNet. This advanced model significantly enhances its predecessor's\ntraining consistency, inference time, as well as detection performance.\nSuperSimpleNet operates in an unsupervised manner using only normal training\nimages but also benefits from labelled abnormal training images when they are\navailable. SuperSimpleNet achieves state-of-the-art results in both the\nsupervised and the unsupervised settings, as demonstrated by experiments across\nfour challenging benchmark datasets. Code:\nhttps://github.com/blaz-r/SuperSimpleNet .\n","authors":["Blaž Rolih","Matic Fučka","Danijel Skočaj"],"pdf_url":"https://arxiv.org/pdf/2408.03143v1.pdf","comment":"Accepted to ICPR 2024"},{"id":"http://arxiv.org/abs/2402.17485v2","updated":"2024-08-06T12:33:30Z","published":"2024-02-27T13:10:11Z","title":"EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with\n  Audio2Video Diffusion Model under Weak Conditions","summary":"  In this work, we tackle the challenge of enhancing the realism and\nexpressiveness in talking head video generation by focusing on the dynamic and\nnuanced relationship between audio cues and facial movements. We identify the\nlimitations of traditional techniques that often fail to capture the full\nspectrum of human expressions and the uniqueness of individual facial styles.\nTo address these issues, we propose EMO, a novel framework that utilizes a\ndirect audio-to-video synthesis approach, bypassing the need for intermediate\n3D models or facial landmarks. Our method ensures seamless frame transitions\nand consistent identity preservation throughout the video, resulting in highly\nexpressive and lifelike animations. Experimental results demonsrate that EMO is\nable to produce not only convincing speaking videos but also singing videos in\nvarious styles, significantly outperforming existing state-of-the-art\nmethodologies in terms of expressiveness and realism.\n","authors":["Linrui Tian","Qi Wang","Bang Zhang","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2402.17485v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20962v2","updated":"2024-08-06T12:25:48Z","published":"2024-07-30T16:43:24Z","title":"MMTrail: A Multimodal Trailer Video Dataset with Language and Music\n  Descriptions","summary":"  Massive multi-modality datasets play a significant role in facilitating the\nsuccess of large video-language models. However, current video-language\ndatasets primarily provide text descriptions for visual frames, considering\naudio to be weakly related information. They usually overlook exploring the\npotential of inherent audio-visual correlation, leading to monotonous\nannotation within each modality instead of comprehensive and precise\ndescriptions. Such ignorance results in the difficulty of multiple\ncross-modality studies. To fulfill this gap, we present MMTrail, a large-scale\nmulti-modality video-language dataset incorporating more than 20M trailer clips\nwith visual captions, and 2M high-quality clips with multimodal captions.\nTrailers preview full-length video works and integrate context, visual frames,\nand background music. In particular, the trailer has two main advantages: (1)\nthe topics are diverse, and the content characters are of various types, e.g.,\nfilm, news, and gaming. (2) the corresponding background music is\ncustom-designed, making it more coherent with the visual context. Upon these\ninsights, we propose a systemic captioning framework, achieving various\nmodality annotations with more than 27.1k hours of trailer videos. Here, to\nensure the caption retains music perspective while preserving the authority of\nvisual context, we leverage the advanced LLM to merge all annotations\nadaptively. In this fashion, our MMtrail dataset potentially paves the path for\nfine-grained large multimodal-language model training. In experiments, we\nprovide evaluation metrics and benchmark results on our dataset, demonstrating\nthe high quality of our annotation and its effectiveness for model training.\n","authors":["Xiaowei Chi","Yatian Wang","Aosong Cheng","Pengjun Fang","Zeyue Tian","Yingqing He","Zhaoyang Liu","Xingqun Qi","Jiahao Pan","Rongyu Zhang","Mengfei Li","Ruibin Yuan","Yanbing Jiang","Wei Xue","Wenhan Luo","Qifeng Chen","Shanghang Zhang","Qifeng Liu","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2407.20962v2.pdf","comment":"15 Pages. Dataset report"},{"id":"http://arxiv.org/abs/2408.00998v2","updated":"2024-08-06T12:01:17Z","published":"2024-08-02T04:13:38Z","title":"FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features\n  for Highly Controllable Text-Driven Image Translation","summary":"  Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nwonderful image generation with natural-language text prompt. However, the\nissue of lacking controllability of such models restricts their practical\napplicability for real-life content creation. Thus, attention has been focused\non leveraging a reference image to control text-to-image synthesis, which is\nalso regarded as manipulating (or editing) a reference image as per a text\nprompt, namely, text-driven image-to-image translation. This paper contributes\na novel, concise, and efficient approach that adapts pre-trained large-scale\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\ntranslation without any model training, model fine-tuning, or online\noptimization process. To guide T2I generation with a reference image, we\npropose to decompose diverse guiding factors with different frequency bands of\ndiffusion features in the DCT spectral space, and accordingly devise a novel\nfrequency band substitution layer which realizes dynamic control of the\nreference image to the T2I generation result in a plug-and-play manner. We\ndemonstrate that our method allows flexible control over both guiding factor\nand guiding intensity of the reference image simply by tuning the type and\nbandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability. The code is publicly available at:\nhttps://github.com/XiangGao1102/FBSDiff.\n","authors":["Xiang Gao","Jiaying Liu"],"pdf_url":"https://arxiv.org/pdf/2408.00998v2.pdf","comment":"Accepted conference paper of ACM MM 2024"},{"id":"http://arxiv.org/abs/2408.03120v1","updated":"2024-08-06T11:49:13Z","published":"2024-08-06T11:49:13Z","title":"Benchmarking In-the-wild Multimodal Disease Recognition and A Versatile\n  Baseline","summary":"  Existing plant disease classification models have achieved remarkable\nperformance in recognizing in-laboratory diseased images. However, their\nperformance often significantly degrades in classifying in-the-wild images.\nFurthermore, we observed that in-the-wild plant images may exhibit similar\nappearances across various diseases (i.e., small inter-class discrepancy) while\nthe same diseases may look quite different (i.e., large intra-class variance).\nMotivated by this observation, we propose an in-the-wild multimodal plant\ndisease recognition dataset that contains the largest number of disease classes\nbut also text-based descriptions for each disease. Particularly, the newly\nprovided text descriptions are introduced to provide rich information in\ntextual modality and facilitate in-the-wild disease classification with small\ninter-class discrepancy and large intra-class variance issues. Therefore, our\nproposed dataset can be regarded as an ideal testbed for evaluating disease\nrecognition methods in the real world. In addition, we further present a strong\nyet versatile baseline that models text descriptions and visual data through\nmultiple prototypes for a given class. By fusing the contributions of\nmultimodal prototypes in classification, our baseline can effectively address\nthe small inter-class discrepancy and large intra-class variance issues.\nRemarkably, our baseline model can not only classify diseases but also\nrecognize diseases in few-shot or training-free scenarios. Extensive\nbenchmarking results demonstrate that our proposed in-the-wild multimodal\ndataset sets many new challenges to the plant disease recognition task and\nthere is a large space to improve for future works.\n","authors":["Tianqi Wei","Zhi Chen","Zi Huang","Xin Yu"],"pdf_url":"https://arxiv.org/pdf/2408.03120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02209v2","updated":"2024-08-06T11:46:39Z","published":"2024-08-05T03:18:58Z","title":"Source-Free Domain-Invariant Performance Prediction","summary":"  Accurately estimating model performance poses a significant challenge,\nparticularly in scenarios where the source and target domains follow different\ndata distributions. Most existing performance prediction methods heavily rely\non the source data in their estimation process, limiting their applicability in\na more realistic setting where only the trained model is accessible. The few\nmethods that do not require source data exhibit considerably inferior\nperformance. In this work, we propose a source-free approach centred on\nuncertainty-based estimation, using a generative model for calibration in the\nabsence of source data. We establish connections between our approach for\nunsupervised calibration and temperature scaling. We then employ a\ngradient-based strategy to evaluate the correctness of the calibrated\npredictions. Our experiments on benchmark object recognition datasets reveal\nthat existing source-based methods fall short with limited source sample\navailability. Furthermore, our approach significantly outperforms the current\nstate-of-the-art source-free and source-based methods, affirming its\neffectiveness in domain-invariant performance estimation.\n","authors":["Ekaterina Khramtsova","Mahsa Baktashmotlagh","Guido Zuccon","Xi Wang","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2408.02209v2.pdf","comment":"Accepted in ECCV 2024"},{"id":"http://arxiv.org/abs/2311.02558v3","updated":"2024-08-06T11:35:04Z","published":"2023-11-05T03:53:42Z","title":"Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity\n  with Free-Flying Robots","summary":"  Assistive free-flyer robots autonomously caring for future crewed outposts --\nsuch as NASA's Astrobee robots on the International Space Station (ISS) -- must\nbe able to detect day-to-day interior changes to track inventory, detect and\ndiagnose faults, and monitor the outpost status. This work presents a framework\nfor multi-agent cooperative mapping and change detection to enable robotic\nmaintenance of space outposts. One agent is used to reconstruct a 3D model of\nthe environment from sequences of images and corresponding depth information.\nAnother agent is used to periodically scan the environment for inconsistencies\nagainst the 3D model. Change detection is validated after completing the\nsurveys using real image and pose data collected by Astrobee robots in a ground\ntesting environment and from microgravity aboard the ISS. This work outlines\nthe objectives, requirements, and algorithmic modules for the multi-agent\nreconstruction system, including recommendations for its use by assistive\nfree-flyers aboard future microgravity outposts.\n  *Denotes Equal Contribution\n","authors":["Holly Dinkel","Julia Di","Jamie Santos","Keenan Albee","Paulo Borges","Marina Moreira","Oleg Alexandrov","Brian Coltin","Trey Smith"],"pdf_url":"https://arxiv.org/pdf/2311.02558v3.pdf","comment":"11 pages, 8 figures, Manuscript presented at the 74th International\n  Astronautical Congress, IAC 2023, Baku, Azerbaijan, 2 - 6 October 2023. Video\n  presentation: [https://www.youtube.com/watch?v=VfjV-zwFEtU]. Code:\n  [https://github.com/hollydinkel/astrobeecd]"},{"id":"http://arxiv.org/abs/2408.03097v1","updated":"2024-08-06T10:56:53Z","published":"2024-08-06T10:56:53Z","title":"Prototype Learning for Micro-gesture Classification","summary":"  In this paper, we briefly introduce the solution developed by our team,\nHFUT-VUT, for the track of Micro-gesture Classification in the MiGA challenge\nat IJCAI 2024. The task of micro-gesture classification task involves\nrecognizing the category of a given video clip, which focuses on more\nfine-grained and subtle body movements compared to typical action recognition\ntasks. Given the inherent complexity of micro-gesture recognition, which\nincludes large intra-class variability and minimal inter-class differences, we\nutilize two innovative modules, i.e., the cross-modal fusion module and\nprototypical refinement module, to improve the discriminative ability of MG\nfeatures, thereby improving the classification accuracy. Our solution achieved\nsignificant success, ranking 1st in the track of Micro-gesture Classification.\nWe surpassed the performance of last year's leading team by a substantial\nmargin, improving Top-1 accuracy by 6.13%.\n","authors":["Guoliang Chen","Fei Wang","Kun Li","Zhiliang Wu","Hehe Fan","Yi Yang","Meng Wang","Dan Guo"],"pdf_url":"https://arxiv.org/pdf/2408.03097v1.pdf","comment":"1st Place in Micro-gesture Classification in MiGA at IJCAI-2024"},{"id":"http://arxiv.org/abs/2408.03078v1","updated":"2024-08-06T10:13:57Z","published":"2024-08-06T10:13:57Z","title":"BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical\n  Applications","summary":"  Endoscopic surgery relies on two-dimensional views, posing challenges for\nsurgeons in depth perception and instrument manipulation. While Simultaneous\nLocalization and Mapping (SLAM) has emerged as a promising solution to address\nthese limitations, its implementation in endoscopic procedures presents\nsignificant challenges due to hardware limitations, such as the use of a\nmonocular camera and the absence of odometry sensors. This study presents a\nrobust deep learning-based SLAM approach that combines state-of-the-art and\nnewly developed models. It consists of three main parts: the Monocular Pose\nEstimation Module that introduces a novel unsupervised method based on the\nCycleGAN architecture, the Monocular Depth Estimation Module that leverages the\nnovel Zoe architecture, and the 3D Reconstruction Module which uses information\nfrom the previous models to create a coherent surgical map. The performance of\nthe procedure was rigorously evaluated using three publicly available datasets\n(Hamlyn, EndoSLAM, and SCARED) and benchmarked against two state-of-the-art\nmethods, EndoSFMLearner and EndoDepth. The integration of Zoe in the MDEM\ndemonstrated superior performance compared to state-of-the-art depth estimation\nalgorithms in endoscopy, whereas the novel approach in the MPEM exhibited\ncompetitive performance and the lowest inference time. The results showcase the\nrobustness of our approach in laparoscopy, gastroscopy, and colonoscopy, three\ndifferent scenarios in endoscopic surgery. The proposed SLAM approach has the\npotential to improve the accuracy and efficiency of endoscopic procedures by\nproviding surgeons with enhanced depth perception and 3D reconstruction\ncapabilities.\n","authors":["G. Manni","C. Lauretti","F. Prata","R. Papalia","L. Zollo","P. Soda"],"pdf_url":"https://arxiv.org/pdf/2408.03078v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.02265v3","updated":"2024-08-06T10:10:58Z","published":"2024-06-04T12:41:54Z","title":"Understanding Retrieval Robustness for Retrieval-Augmented Image\n  Captioning","summary":"  Recent advances in retrieval-augmented models for image captioning highlight\nthe benefit of retrieving related captions for efficient, lightweight models\nwith strong domain-transfer capabilities. While these models demonstrate the\nsuccess of retrieval augmentation, retrieval models are still far from perfect\nin practice: the retrieved information can sometimes mislead the model,\nresulting in incorrect generation and worse performance. In this paper, we\nanalyze the robustness of a retrieval-augmented captioning model SmallCap. Our\nanalysis shows that the model is sensitive to tokens that appear in the\nmajority of the retrieved captions, and the input attribution shows that those\ntokens are likely copied into the generated output. Given these findings, we\npropose to train the model by sampling retrieved captions from more diverse\nsets. This decreases the chance that the model learns to copy majority tokens,\nand improves both in-domain and cross-domain performance.\n","authors":["Wenyan Li","Jiaang Li","Rita Ramos","Raphael Tang","Desmond Elliott"],"pdf_url":"https://arxiv.org/pdf/2406.02265v3.pdf","comment":"9 pages, long paper at ACL 2024"},{"id":"http://arxiv.org/abs/2407.14086v2","updated":"2024-08-06T09:56:36Z","published":"2024-07-19T07:48:45Z","title":"Temporal Correlation Meets Embedding: Towards a 2nd Generation of\n  JDE-based Real-Time Multi-Object Tracking","summary":"  Joint Detection and Embedding (JDE) trackers have demonstrated excellent\nperformance in Multi-Object Tracking (MOT) tasks by incorporating the\nextraction of appearance features as auxiliary tasks through embedding\nRe-Identification task (ReID) into the detector, achieving a balance between\ninference speed and tracking performance. However, solving the competition\nbetween the detector and the feature extractor has always been a challenge.\nMeanwhile, the issue of directly embedding the ReID task into MOT has remained\nunresolved. The lack of high discriminability in appearance features results in\ntheir limited utility. In this paper, a new learning approach using\ncross-correlation to capture temporal information of objects is proposed. The\nfeature extraction network is no longer trained solely on appearance features\nfrom each frame but learns richer motion features by utilizing feature heatmaps\nfrom consecutive frames, which addresses the challenge of inter-class feature\nsimilarity. Furthermore, our learning approach is applied to a more lightweight\nfeature extraction network, and treat the feature matching scores as strong\ncues rather than auxiliary cues, with an appropriate weight calculation to\nreflect the compatibility between our obtained features and the MOT task. Our\ntracker, named TCBTrack, achieves state-of-the-art performance on multiple\npublic benchmarks, i.e., MOT17, MOT20, and DanceTrack datasets. Specifically,\non the DanceTrack test set, we achieve 56.8 HOTA, 58.1 IDF1 and 92.5 MOTA,\nmaking it the best online tracker capable of achieving real-time performance.\nComparative evaluations with other trackers prove that our tracker achieves the\nbest balance between speed, robustness and accuracy. Code is available at\nhttps://github.com/yfzhang1214/TCBTrack.\n","authors":["Yunfei Zhang","Chao Liang","Jin Gao","Zhipeng Zhang","Weiming Hu","Stephen Maybank","Xue Zhou","Liang Li"],"pdf_url":"https://arxiv.org/pdf/2407.14086v2.pdf","comment":"A submission to IJCV"},{"id":"http://arxiv.org/abs/2408.03065v1","updated":"2024-08-06T09:35:50Z","published":"2024-08-06T09:35:50Z","title":"SCOPE: A Synthetic Multi-Modal Dataset for Collective Perception\n  Including Physical-Correct Weather Conditions","summary":"  Collective perception has received considerable attention as a promising\napproach to overcome occlusions and limited sensing ranges of vehicle-local\nperception in autonomous driving. In order to develop and test novel collective\nperception technologies, appropriate datasets are required. These datasets must\ninclude not only different environmental conditions, as they strongly influence\nthe perception capabilities, but also a wide range of scenarios with different\nroad users as well as realistic sensor models. Therefore, we propose the\nSynthetic COllective PErception (SCOPE) dataset. SCOPE is the first synthetic\nmulti-modal dataset that incorporates realistic camera and LiDAR models as well\nas parameterized and physically accurate weather simulations for both sensor\ntypes. The dataset contains 17,600 frames from over 40 diverse scenarios with\nup to 24 collaborative agents, infrastructure sensors, and passive traffic,\nincluding cyclists and pedestrians. In addition, recordings from two novel\ndigital-twin maps from Karlsruhe and T\\\"ubingen are included. The dataset is\navailable at https://ekut-es.github.io/scope\n","authors":["Jörg Gamerdinger","Sven Teufel","Patrick Schulz","Stephan Amann","Jan-Patrick Kirchner","Oliver Bringmann"],"pdf_url":"https://arxiv.org/pdf/2408.03065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03060v1","updated":"2024-08-06T09:23:24Z","published":"2024-08-06T09:23:24Z","title":"MGFs: Masked Gaussian Fields for Meshing Building based on Multi-View\n  Images","summary":"  Over the last few decades, image-based building surface reconstruction has\ngarnered substantial research interest and has been applied across various\nfields, such as heritage preservation, architectural planning, etc. Compared to\nthe traditional photogrammetric and NeRF-based solutions, recently, Gaussian\nfields-based methods have exhibited significant potential in generating surface\nmeshes due to their time-efficient training and detailed 3D information\npreservation. However, most gaussian fields-based methods are trained with all\nimage pixels, encompassing building and nonbuilding areas, which results in a\nsignificant noise for building meshes and degeneration in time efficiency. This\npaper proposes a novel framework, Masked Gaussian Fields (MGFs), designed to\ngenerate accurate surface reconstruction for building in a time-efficient way.\nThe framework first applies EfficientSAM and COLMAP to generate multi-level\nmasks of building and the corresponding masked point clouds. Subsequently, the\nmasked gaussian fields are trained by integrating two innovative losses: a\nmulti-level perceptual masked loss focused on constructing building regions and\na boundary loss aimed at enhancing the details of the boundaries between\ndifferent masks. Finally, we improve the tetrahedral surface mesh extraction\nmethod based on the masked gaussian spheres. Comprehensive experiments on UAV\nimages demonstrate that, compared to the traditional method and several\nNeRF-based and Gaussian-based SOTA solutions, our approach significantly\nimproves both the accuracy and efficiency of building surface reconstruction.\nNotably, as a byproduct, there is an additional gain in the novel view\nsynthesis of building.\n","authors":["Tengfei Wang","Zongqian Zhan","Rui Xia","Linxia Ji","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03046v1","updated":"2024-08-06T09:02:31Z","published":"2024-08-06T09:02:31Z","title":"Comb, Prune, Distill: Towards Unified Pruning for Vision Model\n  Compression","summary":"  Lightweight and effective models are essential for devices with limited\nresources, such as intelligent vehicles. Structured pruning offers a promising\napproach to model compression and efficiency enhancement. However, existing\nmethods often tie pruning techniques to specific model architectures or vision\ntasks. To address this limitation, we propose a novel unified pruning framework\nComb, Prune, Distill (CPD), which addresses both model-agnostic and\ntask-agnostic concerns simultaneously. Our framework employs a combing step to\nresolve hierarchical layer-wise dependency issues, enabling architecture\nindependence. Additionally, the pruning pipeline adaptively remove parameters\nbased on the importance scoring metrics regardless of vision tasks. To support\nthe model in retaining its learned information, we introduce knowledge\ndistillation during the pruning step. Extensive experiments demonstrate the\ngeneralizability of our framework, encompassing both convolutional neural\nnetwork (CNN) and transformer models, as well as image classification and\nsegmentation tasks. In image classification we achieve a speedup of up to x4.3\nwith a accuracy loss of 1.8% and in semantic segmentation up to x1.89 with a\n5.1% loss in mIoU.\n","authors":["Jonas Schmitt","Ruiping Liu","Junwei Zheng","Jiaming Zhang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2408.03046v1.pdf","comment":"Accepted by ITSC 2024. Code is publicly available at:\n  https://github.com/Cranken/CPD"},{"id":"http://arxiv.org/abs/2408.03043v1","updated":"2024-08-06T08:58:20Z","published":"2024-08-06T08:58:20Z","title":"Targeted Visual Prompting for Medical Visual Question Answering","summary":"  With growing interest in recent years, medical visual question answering\n(Med-VQA) has rapidly evolved, with multimodal large language models (MLLMs)\nemerging as an alternative to classical model architectures. Specifically,\ntheir ability to add visual information to the input of pre-trained LLMs brings\nnew capabilities for image interpretation. However, simple visual errors cast\ndoubt on the actual visual understanding abilities of these models. To address\nthis, region-based questions have been proposed as a means to assess and\nenhance actual visual understanding through compositional evaluation. To\ncombine these two perspectives, this paper introduces targeted visual prompting\nto equip MLLMs with region-based questioning capabilities. By presenting the\nmodel with both the isolated region and the region in its context in a\ncustomized visual prompt, we show the effectiveness of our method across\nmultiple datasets while comparing it to several baseline models. Our code and\ndata are available at https://github.com/sergiotasconmorales/locvqallm.\n","authors":["Sergio Tascon-Morales","Pablo Márquez-Neila","Raphael Sznitman"],"pdf_url":"https://arxiv.org/pdf/2408.03043v1.pdf","comment":"Accepted at the MICCAI AMAI Workshop 2024"},{"id":"http://arxiv.org/abs/2407.20171v2","updated":"2024-08-06T08:42:47Z","published":"2024-07-29T17:00:09Z","title":"Diffusion Feedback Helps CLIP See Better","summary":"  Contrastive Language-Image Pre-training (CLIP), which excels at abstracting\nopen-world representations across domains and modalities, has become a\nfoundation for a variety of vision and multimodal tasks. However, recent\nstudies reveal that CLIP has severe visual shortcomings, such as which can\nhardly distinguish orientation, quantity, color, structure, etc. These visual\nshortcomings also limit the perception capabilities of multimodal large\nlanguage models (MLLMs) built on CLIP. The main reason could be that the\nimage-text pairs used to train CLIP are inherently biased, due to the lack of\nthe distinctiveness of the text and the diversity of images. In this work, we\npresent a simple post-training approach for CLIP models, which largely\novercomes its visual shortcomings via a self-supervised diffusion process. We\nintroduce DIVA, which uses the DIffusion model as a Visual Assistant for CLIP.\nSpecifically, DIVA leverages generative feedback from text-to-image diffusion\nmodels to optimize CLIP representations, with only images (without\ncorresponding text). We demonstrate that DIVA improves CLIP's performance on\nthe challenging MMVP-VLM benchmark which assesses fine-grained visual abilities\nto a large extent (e.g., 3-7%), and enhances the performance of MLLMs and\nvision models on multimodal understanding and segmentation tasks. Extensive\nevaluation on 29 image classification and retrieval benchmarks confirms that\nour framework preserves CLIP's strong zero-shot capabilities. The code is\navailable at https://github.com/baaivision/DIVA.\n","authors":["Wenxuan Wang","Quan Sun","Fan Zhang","Yepeng Tang","Jing Liu","Xinlong Wang"],"pdf_url":"https://arxiv.org/pdf/2407.20171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03035v1","updated":"2024-08-06T08:31:34Z","published":"2024-08-06T08:31:34Z","title":"Training-Free Condition Video Diffusion Models for single frame\n  Spatial-Semantic Echocardiogram Synthesis","summary":"  Conditional video diffusion models (CDM) have shown promising results for\nvideo synthesis, potentially enabling the generation of realistic\nechocardiograms to address the problem of data scarcity. However, current CDMs\nrequire a paired segmentation map and echocardiogram dataset. We present a new\nmethod called Free-Echo for generating realistic echocardiograms from a single\nend-diastolic segmentation map without additional training data. Our method is\nbased on the 3D-Unet with Temporal Attention Layers model and is conditioned on\nthe segmentation map using a training-free conditioning method based on SDEdit.\nWe evaluate our model on two public echocardiogram datasets, CAMUS and\nEchoNet-Dynamic. We show that our model can generate plausible echocardiograms\nthat are spatially aligned with the input segmentation map, achieving\nperformance comparable to training-based CDMs. Our work opens up new\npossibilities for generating echocardiograms from a single segmentation map,\nwhich can be used for data augmentation, domain adaptation, and other\napplications in medical imaging. Our code is available at\n\\url{https://github.com/gungui98/echo-free}\n","authors":["Van Phi Nguyen","Tri Nhan Luong Ha","Huy Hieu Pham","Quoc Long Tran"],"pdf_url":"https://arxiv.org/pdf/2408.03035v1.pdf","comment":"Accepted to MICCAI 2024"},{"id":"http://arxiv.org/abs/2406.09913v3","updated":"2024-08-06T08:27:55Z","published":"2024-06-14T10:47:52Z","title":"OpenECAD: An Efficient Visual Language Model for Editable 3D-CAD Design","summary":"  Computer-aided design (CAD) tools are utilized in the manufacturing industry\nfor modeling everything from cups to spacecraft. These programs are complex to\nuse and typically require years of training and experience to master.\nStructured and well-constrained 2D sketches and 3D constructions are crucial\ncomponents of CAD modeling. A well-executed CAD model can be seamlessly\nintegrated into the manufacturing process, thereby enhancing production\nefficiency. Deep generative models of 3D shapes and 3D object reconstruction\nmodels have garnered significant research interest. However, most of these\nmodels produce discrete forms of 3D objects that are not editable. Moreover,\nthe few models based on CAD operations often have substantial input\nrestrictions. In this work, we fine-tuned pre-trained models to create OpenECAD\nmodels (0.55B, 0.89B, 2.4B and 3.1B), leveraging the visual, logical, coding,\nand general capabilities of visual language models. OpenECAD models can process\nimages of 3D designs as input and generate highly structured 2D sketches and 3D\nconstruction commands, ensuring that the designs are editable. These outputs\ncan be directly used with existing CAD tools' APIs to generate project files.\nTo train our network, we created a series of OpenECAD datasets. These datasets\nare derived from existing public CAD datasets, adjusted and augmented to meet\nthe specific requirements of vision language model (VLM) training.\nAdditionally, we have introduced an approach that utilizes dependency\nrelationships to define and generate sketches, further enriching the content\nand functionality of the datasets.\n","authors":["Zhe Yuan","Jianqi Shi","Yanhong Huang"],"pdf_url":"https://arxiv.org/pdf/2406.09913v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03030v1","updated":"2024-08-06T08:24:47Z","published":"2024-08-06T08:24:47Z","title":"Nighttime Pedestrian Detection Based on Fore-Background Contrast\n  Learning","summary":"  The significance of background information is frequently overlooked in\ncontemporary research concerning channel attention mechanisms. This study\naddresses the issue of suboptimal single-spectral nighttime pedestrian\ndetection performance under low-light conditions by incorporating background\ninformation into the channel attention mechanism. Despite numerous studies\nfocusing on the development of efficient channel attention mechanisms, the\nrelevance of background information has been largely disregarded. By adopting a\ncontrast learning approach, we reexamine channel attention with regard to\npedestrian objects and background information for nighttime pedestrian\ndetection, resulting in the proposed Fore-Background Contrast Attention (FBCA).\nFBCA possesses two primary attributes: (1) channel descriptors form remote\ndependencies with global spatial feature information; (2) the integration of\nbackground information enhances the distinction between channels concentrating\non low-light pedestrian features and those focusing on background information.\nConsequently, the acquired channel descriptors exhibit a higher semantic level\nand spatial accuracy. Experimental outcomes demonstrate that FBCA significantly\noutperforms existing methods in single-spectral nighttime pedestrian detection,\nachieving state-of-the-art results on the NightOwls and TJU-DHD-pedestrian\ndatasets. Furthermore, this methodology also yields performance improvements\nfor the multispectral LLVIP dataset. These findings indicate that integrating\nbackground information into the channel attention mechanism effectively\nmitigates detector performance degradation caused by illumination factors in\nnighttime scenarios.\n","authors":["He Yao","Yongjun Zhang","Huachun Jian","Li Zhang","Ruzhong Cheng"],"pdf_url":"https://arxiv.org/pdf/2408.03030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03014v1","updated":"2024-08-06T07:51:20Z","published":"2024-08-06T07:51:20Z","title":"CKNN: Cleansed k-Nearest Neighbor for Unsupervised Video Anomaly\n  Detection","summary":"  In this paper, we address the problem of unsupervised video anomaly detection\n(UVAD). The task aims to detect abnormal events in test video using unlabeled\nvideos as training data. The presence of anomalies in the training data poses a\nsignificant challenge in this task, particularly because they form clusters in\nthe feature space. We refer to this property as the \"Anomaly Cluster\" issue.\nThe condensed nature of these anomalies makes it difficult to distinguish\nbetween normal and abnormal data in the training set. Consequently, training\nconventional anomaly detection techniques using an unlabeled dataset often\nleads to sub-optimal results. To tackle this difficulty, we propose a new\nmethod called Cleansed k-Nearest Neighbor (CKNN), which explicitly filters out\nthe Anomaly Clusters by cleansing the training dataset. Following the k-nearest\nneighbor algorithm in the feature space provides powerful anomaly detection\ncapability. Although the identified Anomaly Cluster issue presents a\nsignificant challenge to applying k-nearest neighbor in UVAD, our proposed\ncleansing scheme effectively addresses this problem. We evaluate the proposed\nmethod on various benchmark datasets and demonstrate that CKNN outperforms the\nprevious state-of-the-art UVAD method by up to 8.5% (from 82.0 to 89.0) in\nterms of AUROC. Moreover, we emphasize that the performance of the proposed\nmethod is comparable to that of the state-of-the-art method trained using\nanomaly-free data.\n","authors":["Jihun Yi","Sungroh Yoon"],"pdf_url":"https://arxiv.org/pdf/2408.03014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17572v3","updated":"2024-08-06T07:36:21Z","published":"2024-07-24T18:05:13Z","title":"CityX: Controllable Procedural Content Generation for Unbounded 3D\n  Cities","summary":"  Generating a realistic, large-scale 3D virtual city remains a complex\nchallenge due to the involvement of numerous 3D assets, various city styles,\nand strict layout constraints. Existing approaches provide promising attempts\nat procedural content generation to create large-scale scenes using Blender\nagents. However, they face crucial issues such as difficulties in scaling up\ngeneration capability and achieving fine-grained control at the semantic layout\nlevel. To address these problems, we propose a novel multi-modal controllable\nprocedural content generation method, named CityX, which enhances realistic,\nunbounded 3D city generation guided by multiple layout conditions, including\nOSM, semantic maps, and satellite images. Specifically, the proposed method\ncontains a general protocol for integrating various PCG plugins and a\nmulti-agent framework for transforming instructions into executable Blender\nactions. Through this effective framework, CityX shows the potential to build\nan innovative ecosystem for 3D scene generation by bridging the gap between the\nquality of generated assets and industrial requirements. Extensive experiments\nhave demonstrated the effectiveness of our method in creating high-quality,\ndiverse, and unbounded cities guided by multi-modal conditions. Our project\npage: https://cityx-lab.github.io.\n","authors":["Shougao Zhang","Mengqi Zhou","Yuxi Wang","Chuanchen Luo","Rongyu Wang","Yiwei Li","Xucheng Yin","Zhaoxiang Zhang","Junran Peng"],"pdf_url":"https://arxiv.org/pdf/2407.17572v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14362v3","updated":"2024-08-06T07:32:46Z","published":"2024-03-21T12:45:01Z","title":"Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen\n  Domains by Intrinsic Learning from Redundant LLM Semantics","summary":"  Generalized zero-shot learning (GZSL) focuses on recognizing seen and unseen\nclasses against domain shift problem (DSP) where data of unseen classes may be\nmisclassified as seen classes. However, existing GZSL is still limited to seen\ndomains. In the current work, we pioneer cross-domain GZSL (CDGZSL) which\naddresses GZSL towards unseen domains. Different from existing GZSL methods\nwhich alleviate DSP by generating features of unseen classes with semantics,\nCDGZSL needs to construct a common feature space across domains and acquire the\ncorresponding intrinsic semantics shared among domains to transfer from seen to\nunseen domains. Considering the information asymmetry problem caused by\nredundant class semantics annotated with large language models (LLMs), we\npresent Meta Domain Alignment Semantic Refinement (MDASR). Technically, MDASR\nconsists of two parts: Inter-class Similarity Alignment (ISA), which eliminates\nthe non-intrinsic semantics not shared across all domains under the guidance of\ninter-class feature relationships, and Unseen-class Meta Generation (UMG),\nwhich preserves intrinsic semantics to maintain connectivity between seen and\nunseen classes by simulating feature generation. MDASR effectively aligns the\nredundant semantic space with the common feature space, mitigating the\ninformation asymmetry in CDGZSL. The effectiveness of MDASR is demonstrated on\nthe Office-Home and Mini-DomainNet, and we have shared the LLM-based semantics\nfor these datasets as the benchmark.\n","authors":["Jiaqi Yue","Jiancheng Zhao","Chunhui Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.14362v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03006v1","updated":"2024-08-06T07:30:53Z","published":"2024-08-06T07:30:53Z","title":"Dual-path Collaborative Generation Network for Emotional Video\n  Captioning","summary":"  Emotional Video Captioning is an emerging task that aims to describe factual\ncontent with the intrinsic emotions expressed in videos. The essential of the\nEVC task is to effectively perceive subtle and ambiguous visual emotional cues\nduring the caption generation, which is neglected by the traditional video\ncaptioning. Existing emotional video captioning methods perceive global visual\nemotional cues at first, and then combine them with the video features to guide\nthe emotional caption generation, which neglects two characteristics of the EVC\ntask. Firstly, their methods neglect the dynamic subtle changes in the\nintrinsic emotions of the video, which makes it difficult to meet the needs of\ncommon scenes with diverse and changeable emotions. Secondly, as their methods\nincorporate emotional cues into each step, the guidance role of emotion is\noveremphasized, which makes factual content more or less ignored during\ngeneration. To this end, we propose a dual-path collaborative generation\nnetwork, which dynamically perceives visual emotional cues evolutions while\ngenerating emotional captions by collaborative learning. Specifically, in the\ndynamic emotion perception path, we propose a dynamic emotion evolution module,\nwhich first aggregates visual features and historical caption features to\nsummarize the global visual emotional cues, and then dynamically selects\nemotional cues required to be re-composed at each stage. Besides, in the\nadaptive caption generation path, to balance the description of factual content\nand emotional cues, we propose an emotion adaptive decoder. Thus, our methods\ncan generate emotion-related words at the necessary time step, and our caption\ngeneration balances the guidance of factual content and emotional cues well.\nExtensive experiments on three challenging datasets demonstrate the superiority\nof our approach and each proposed module.\n","authors":["Cheng Ye","Weidong Chen","Jingyu Li","Lei Zhang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2408.03006v1.pdf","comment":"Acccepted by ACM Multimedia 2024, oral"},{"id":"http://arxiv.org/abs/2402.16907v2","updated":"2024-08-06T07:24:35Z","published":"2024-02-25T04:24:28Z","title":"Diffusion Posterior Proximal Sampling for Image Restoration","summary":"  Diffusion models have demonstrated remarkable efficacy in generating\nhigh-quality samples. Existing diffusion-based image restoration algorithms\nexploit pre-trained diffusion models to leverage data priors, yet they still\npreserve elements inherited from the unconditional generation paradigm. These\nstrategies initiate the denoising process with pure white noise and incorporate\nrandom noise at each generative step, leading to over-smoothed results. In this\npaper, we present a refined paradigm for diffusion-based image restoration.\nSpecifically, we opt for a sample consistent with the measurement identity at\neach generative step, exploiting the sampling selection as an avenue for output\nstability and enhancement. The number of candidate samples used for selection\nis adaptively determined based on the signal-to-noise ratio of the timestep.\nAdditionally, we start the restoration process with an initialization combined\nwith the measurement signal, providing supplementary information to better\nalign the generative process. Extensive experimental results and analyses\nvalidate that our proposed method significantly enhances image restoration\nperformance while consuming negligible additional computational resources.\n","authors":["Hongjie Wu","Linchao He","Mingqin Zhang","Dongdong Chen","Kunming Luo","Mengting Luo","Ji-Zhe Zhou","Hu Chen","Jiancheng Lv"],"pdf_url":"https://arxiv.org/pdf/2402.16907v2.pdf","comment":"ACM Multimedia 2024 Oral"},{"id":"http://arxiv.org/abs/2408.03001v1","updated":"2024-08-06T07:19:51Z","published":"2024-08-06T07:19:51Z","title":"Multitask and Multimodal Neural Tuning for Large Models","summary":"  In recent years, large-scale multimodal models have demonstrated impressive\ncapabilities across various domains. However, enabling these models to\neffectively perform multiple multimodal tasks simultaneously remains a\nsignificant challenge. To address this, we introduce a novel tuning method\ncalled neural tuning, designed to handle diverse multimodal tasks concurrently,\nincluding reasoning segmentation, referring segmentation, image captioning, and\ntext-to-image generation. Neural tuning emulates sparse distributed\nrepresentation in human brain, where only specific subsets of neurons are\nactivated for each task. Additionally, we present a new benchmark, MMUD, where\neach sample is annotated with multiple task labels. By applying neural tuning\nto pretrained large models on the MMUD benchmark, we achieve simultaneous task\nhandling in a streamlined and efficient manner. All models, code, and datasets\nwill be publicly available after publication, facilitating further research and\ndevelopment in this field.\n","authors":["Hao Sun","Yu Song","Jihong Hu","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2408.03001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02993v1","updated":"2024-08-06T06:59:15Z","published":"2024-08-06T06:59:15Z","title":"DreamLCM: Towards High-Quality Text-to-3D Generation via Latent\n  Consistency Model","summary":"  Recently, the text-to-3D task has developed rapidly due to the appearance of\nthe SDS method. However, the SDS method always generates 3D objects with poor\nquality due to the over-smooth issue. This issue is attributed to two factors:\n1) the DDPM single-step inference produces poor guidance gradients; 2) the\nrandomness from the input noises and timesteps averages the details of the 3D\ncontents.In this paper, to address the issue, we propose DreamLCM which\nincorporates the Latent Consistency Model (LCM). DreamLCM leverages the\npowerful image generation capabilities inherent in LCM, enabling generating\nconsistent and high-quality guidance, i.e., predicted noises or images. Powered\nby the improved guidance, the proposed method can provide accurate and detailed\ngradients to optimize the target 3D models.In addition, we propose two\nstrategies to enhance the generation quality further. Firstly, we propose a\nguidance calibration strategy, utilizing Euler Solver to calibrate the guidance\ndistribution to accelerate 3D models to converge. Secondly, we propose a dual\ntimestep strategy, increasing the consistency of guidance and optimizing 3D\nmodels from geometry to appearance in DreamLCM. Experiments show that DreamLCM\nachieves state-of-the-art results in both generation quality and training\nefficiency. The code is available at https://github.com/1YimingZhong/DreamLCM.\n","authors":["Yiming Zhong","Xiaolin Zhang","Yao Zhao","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2408.02993v1.pdf","comment":"15 pages, 9 figures, ACM MM 2024"},{"id":"http://arxiv.org/abs/2408.02983v1","updated":"2024-08-06T06:33:24Z","published":"2024-08-06T06:33:24Z","title":"Diffusion Model Meets Non-Exemplar Class-Incremental Learning and Beyond","summary":"  Non-exemplar class-incremental learning (NECIL) is to resist catastrophic\nforgetting without saving old class samples. Prior methodologies generally\nemploy simple rules to generate features for replaying, suffering from large\ndistribution gap between replayed features and real ones. To address the\naforementioned issue, we propose a simple, yet effective\n\\textbf{Diff}usion-based \\textbf{F}eature \\textbf{R}eplay (\\textbf{DiffFR})\nmethod for NECIL. First, to alleviate the limited representational capacity\ncaused by fixing the feature extractor, we employ Siamese-based self-supervised\nlearning for initial generalizable features. Second, we devise diffusion models\nto generate class-representative features highly similar to real features,\nwhich provides an effective way for exemplar-free knowledge memorization.\nThird, we introduce prototype calibration to direct the diffusion model's focus\ntowards learning the distribution shapes of features, rather than the entire\ndistribution. Extensive experiments on public datasets demonstrate significant\nperformance gains of our DiffFR, outperforming the state-of-the-art NECIL\nmethods by 3.0\\% in average. The code will be made publicly available soon.\n","authors":["Jichuan Zhang","Yali Li","Xin Liu","Shengjin Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16499v2","updated":"2024-08-06T06:31:34Z","published":"2023-11-27T15:49:41Z","title":"InceptionHuman: Controllable Prompt-to-NeRF for Photorealistic 3D Human\n  Generation","summary":"  This paper presents InceptionHuman, a prompt-to-NeRF framework that allows\neasy control via a combination of prompts in different modalities (e.g., text,\nposes, edge, segmentation map, etc) as inputs to generate photorealistic 3D\nhumans. While many works have focused on generating 3D human models, they\nsuffer one or more of the following: lack of distinctive features, unnatural\nshading/shadows, unnatural poses/clothes, limited views, etc. InceptionHuman\nachieves consistent 3D human generation within a progressively refined NeRF\nspace with two novel modules, Iterative Pose-Aware Refinement (IPAR) and\nProgressive-Augmented Reconstruction (PAR). IPAR iteratively refines the\ndiffusion-generated images and synthesizes high-quality 3D-aware views\nconsidering the close-pose RGB values. PAR employs a pretrained diffusion prior\nto augment the generated synthetic views and adds regularization for\nview-independent appearance. Overall, the synthesis of photorealistic novel\nviews empowers the resulting 3D human NeRF from 360-degree perspectives.\nExtensive qualitative and quantitative experimental comparison show that our\nInceptionHuman models achieve state-of-the-art application quality.\n","authors":["Shiu-hong Kao","Xinhang Liu","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2311.16499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02980v1","updated":"2024-08-06T06:25:39Z","published":"2024-08-06T06:25:39Z","title":"Sample-agnostic Adversarial Perturbation for Vision-Language\n  Pre-training Models","summary":"  Recent studies on AI security have highlighted the vulnerability of\nVision-Language Pre-training (VLP) models to subtle yet intentionally designed\nperturbations in images and texts. Investigating multimodal systems' robustness\nvia adversarial attacks is crucial in this field. Most multimodal attacks are\nsample-specific, generating a unique perturbation for each sample to construct\nadversarial samples. To the best of our knowledge, it is the first work through\nmultimodal decision boundaries to explore the creation of a universal,\nsample-agnostic perturbation that applies to any image. Initially, we explore\nstrategies to move sample points beyond the decision boundaries of linear\nclassifiers, refining the algorithm to ensure successful attacks under the top\n$k$ accuracy metric. Based on this foundation, in visual-language tasks, we\ntreat visual and textual modalities as reciprocal sample points and decision\nhyperplanes, guiding image embeddings to traverse text-constructed decision\nboundaries, and vice versa. This iterative process consistently refines a\nuniversal perturbation, ultimately identifying a singular direction within the\ninput space which is exploitable to impair the retrieval performance of VLP\nmodels. The proposed algorithms support the creation of global perturbations or\nadversarial patches. Comprehensive experiments validate the effectiveness of\nour method, showcasing its data, task, and model transferability across various\nVLP models and datasets. Code: https://github.com/LibertazZ/MUAP\n","authors":["Haonan Zheng","Wen Jiang","Xinyang Deng","Wenrui Li"],"pdf_url":"https://arxiv.org/pdf/2408.02980v1.pdf","comment":"13 pages, 8 figures, published in ACMMM2024"},{"id":"http://arxiv.org/abs/2408.02978v1","updated":"2024-08-06T06:24:10Z","published":"2024-08-06T06:24:10Z","title":"ASR-enhanced Multimodal Representation Learning for Cross-Domain Product\n  Retrieval","summary":"  E-commerce is increasingly multimedia-enriched, with products exhibited in a\nbroad-domain manner as images, short videos, or live stream promotions. A\nunified and vectorized cross-domain production representation is essential. Due\nto large intra-product variance and high inter-product similarity in the\nbroad-domain scenario, a visual-only representation is inadequate. While\nAutomatic Speech Recognition (ASR) text derived from the short or live-stream\nvideos is readily accessible, how to de-noise the excessively noisy text for\nmultimodal representation learning is mostly untouched. We propose ASR-enhanced\nMultimodal Product Representation Learning (AMPere). In order to extract\nproduct-specific information from the raw ASR text, AMPere uses an\neasy-to-implement LLM-based ASR text summarizer. The LLM-summarized text,\ntogether with visual data, is then fed into a multi-branch network to generate\ncompact multimodal embeddings. Extensive experiments on a large-scale\ntri-domain dataset verify the effectiveness of AMPere in obtaining a unified\nmultimodal product representation that clearly improves cross-domain product\nretrieval.\n","authors":["Ruixiang Zhao","Jian Jia","Yan Li","Xuehan Bai","Quan Chen","Han Li","Peng Jiang","Xirong Li"],"pdf_url":"https://arxiv.org/pdf/2408.02978v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2404.18136v2","updated":"2024-08-06T06:04:41Z","published":"2024-04-28T10:16:35Z","title":"SafePaint: Anti-forensic Image Inpainting with Domain Adaptation","summary":"  Existing image inpainting methods have achieved remarkable accomplishments in\ngenerating visually appealing results, often accompanied by a trend toward\ncreating more intricate structural textures. However, while these models excel\nat creating more realistic image content, they often leave noticeable traces of\ntampering, posing a significant threat to security. In this work, we take the\nanti-forensic capabilities into consideration, firstly proposing an end-to-end\ntraining framework for anti-forensic image inpainting named SafePaint.\nSpecifically, we innovatively formulated image inpainting as two major tasks:\nsemantically plausible content completion and region-wise optimization. The\nformer is similar to current inpainting methods that aim to restore the missing\nregions of corrupted images. The latter, through domain adaptation, endeavors\nto reconcile the discrepancies between the inpainted region and the unaltered\narea to achieve anti-forensic goals. Through comprehensive theoretical\nanalysis, we validate the effectiveness of domain adaptation for anti-forensic\nperformance. Furthermore, we meticulously crafted a region-wise separated\nattention (RWSA) module, which not only aligns with our objective of\nanti-forensics but also enhances the performance of the model. Extensive\nqualitative and quantitative evaluations show our approach achieves comparable\nresults to existing image inpainting methods while offering anti-forensic\ncapabilities not available in other methods.\n","authors":["Dunyun Chen","Xin Liao","Xiaoshuai Wu","Shiwei Chen"],"pdf_url":"https://arxiv.org/pdf/2404.18136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21317v2","updated":"2024-08-06T05:42:42Z","published":"2024-07-31T03:58:48Z","title":"Pathology Foundation Models","summary":"  Pathology has played a crucial role in the diagnosis and evaluation of\npatient tissue samples obtained from surgeries and biopsies for many years. The\nadvent of Whole Slide Scanners and the development of deep learning\ntechnologies have significantly advanced the field, leading to extensive\nresearch and development in pathology AI (Artificial Intelligence). These\nadvancements have contributed to reducing the workload of pathologists and\nsupporting decision-making in treatment plans. Recently, large-scale AI models\nknown as Foundation Models (FMs), which are more accurate and applicable to a\nwide range of tasks compared to traditional AI, have emerged, and expanded\ntheir application scope in the healthcare field. Numerous FMs have been\ndeveloped in pathology, and there are reported cases of their application in\nvarious tasks, such as disease diagnosis, rare cancer diagnosis, patient\nsurvival prognosis prediction, biomarker expression prediction, and the scoring\nof immunohistochemical expression intensity. However, several challenges remain\nfor the clinical application of FMs, which healthcare professionals, as users,\nmust be aware of. Research is ongoing to address these challenges. In the\nfuture, it is expected that the development of Generalist Medical AI, which\nintegrates pathology FMs with FMs from other medical domains, will progress,\nleading to the effective utilization of AI in real clinical settings to promote\nprecision and personalized medicine.\n","authors":["Mieko Ochi","Daisuke Komura","Shumpei Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2407.21317v2.pdf","comment":"19 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2408.02966v1","updated":"2024-08-06T05:24:06Z","published":"2024-08-06T05:24:06Z","title":"Fast Point Cloud Geometry Compression with Context-based Residual Coding\n  and INR-based Refinement","summary":"  Compressing a set of unordered points is far more challenging than\ncompressing images/videos of regular sample grids, because of the difficulties\nin characterizing neighboring relations in an irregular layout of points. Many\nresearchers resort to voxelization to introduce regularity, but this approach\nsuffers from quantization loss. In this research, we use the KNN method to\ndetermine the neighborhoods of raw surface points. This gives us a means to\ndetermine the spatial context in which the latent features of 3D points are\ncompressed by arithmetic coding. As such, the conditional probability model is\nadaptive to local geometry, leading to significant rate reduction.\nAdditionally, we propose a dual-layer architecture where a non-learning base\nlayer reconstructs the main structures of the point cloud at low complexity,\nwhile a learned refinement layer focuses on preserving fine details. This\ndesign leads to reductions in model complexity and coding latency by two orders\nof magnitude compared to SOTA methods. Moreover, we incorporate an implicit\nneural representation (INR) into the refinement layer, allowing the decoder to\nsample points on the underlying surface at arbitrary densities. This work is\nthe first to effectively exploit content-aware local contexts for compressing\nirregular raw point clouds, achieving high rate-distortion performance, low\ncomplexity, and the ability to function as an arbitrary-scale upsampling\nnetwork simultaneously.\n","authors":["Hao Xu","Xi Zhang","Xiaolin Wu"],"pdf_url":"https://arxiv.org/pdf/2408.02966v1.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2405.05953v4","updated":"2024-08-06T05:19:06Z","published":"2024-05-09T17:46:22Z","title":"Frame Interpolation with Consecutive Brownian Bridge Diffusion","summary":"  Recent work in Video Frame Interpolation (VFI) tries to formulate VFI as a\ndiffusion-based conditional image generation problem, synthesizing the\nintermediate frame given a random noise and neighboring frames. Due to the\nrelatively high resolution of videos, Latent Diffusion Models (LDMs) are\nemployed as the conditional generation model, where the autoencoder compresses\nimages into latent representations for diffusion and then reconstructs images\nfrom these latent representations. Such a formulation poses a crucial\nchallenge: VFI expects that the output is deterministically equal to the ground\ntruth intermediate frame, but LDMs randomly generate a diverse set of different\nimages when the model runs multiple times. The reason for the diverse\ngeneration is that the cumulative variance (variance accumulated at each step\nof generation) of generated latent representations in LDMs is large. This makes\nthe sampling trajectory random, resulting in diverse rather than deterministic\ngenerations. To address this problem, we propose our unique solution: Frame\nInterpolation with Consecutive Brownian Bridge Diffusion. Specifically, we\npropose consecutive Brownian Bridge diffusion that takes a deterministic\ninitial value as input, resulting in a much smaller cumulative variance of\ngenerated latent representations. Our experiments suggest that our method can\nimprove together with the improvement of the autoencoder and achieve\nstate-of-the-art performance in VFI, leaving strong potential for further\nenhancement.\n","authors":["Zonglin Lyu","Ming Li","Jianbo Jiao","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2405.05953v4.pdf","comment":"corrected typo"},{"id":"http://arxiv.org/abs/2407.11652v4","updated":"2024-08-06T05:10:56Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v4.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2408.02957v1","updated":"2024-08-06T04:55:33Z","published":"2024-08-06T04:55:33Z","title":"Online Temporal Action Localization with Memory-Augmented Transformer","summary":"  Online temporal action localization (On-TAL) is the task of identifying\nmultiple action instances given a streaming video. Since existing methods take\nas input only a video segment of fixed size per iteration, they are limited in\nconsidering long-term context and require tuning the segment size carefully. To\novercome these limitations, we propose memory-augmented transformer (MATR).\nMATR utilizes the memory queue that selectively preserves the past segment\nfeatures, allowing to leverage long-term context for inference. We also propose\na novel action localization method that observes the current input segment to\npredict the end time of the ongoing action and accesses the memory queue to\nestimate the start time of the action. Our method outperformed existing methods\non two datasets, THUMOS14 and MUSES, surpassing not only TAL methods in the\nonline setting but also some offline TAL methods.\n","authors":["Youngkil Song","Dongkeun Kim","Minsu Cho","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2408.02957v1.pdf","comment":"Accepted to ECCV 2024, Project page:\n  https://cvlab.postech.ac.kr/research/MATR/"},{"id":"http://arxiv.org/abs/2408.02954v1","updated":"2024-08-06T04:44:10Z","published":"2024-08-06T04:44:10Z","title":"WWW: Where, Which and Whatever Enhancing Interpretability in Multimodal\n  Deepfake Detection","summary":"  All current benchmarks for multimodal deepfake detection manipulate entire\nframes using various generation techniques, resulting in oversaturated\ndetection accuracies exceeding 94% at the video-level classification. However,\nthese benchmarks struggle to detect dynamic deepfake attacks with challenging\nframe-by-frame alterations presented in real-world scenarios. To address this\nlimitation, we introduce FakeMix, a novel clip-level evaluation benchmark aimed\nat identifying manipulated segments within both video and audio, providing\ninsight into the origins of deepfakes. Furthermore, we propose novel evaluation\nmetrics, Temporal Accuracy (TA) and Frame-wise Discrimination Metric (FDM), to\nassess the robustness of deepfake detection models. Evaluating state-of-the-art\nmodels against diverse deepfake benchmarks, particularly FakeMix, demonstrates\nthe effectiveness of our approach comprehensively. Specifically, while\nachieving an Average Precision (AP) of 94.2% at the video-level, the evaluation\nof the existing models at the clip-level using the proposed metrics, TA and\nFDM, yielded sharp declines in accuracy to 53.1%, and 52.1%, respectively.\n","authors":["Juho Jung","Sangyoun Lee","Jooeon Kang","Yunjin Na"],"pdf_url":"https://arxiv.org/pdf/2408.02954v1.pdf","comment":"4 pages, 2 figures, 2 tables, Accepted as Oral Presentation at The\n  Trustworthy AI Workshop @ IJCAI 2024"},{"id":"http://arxiv.org/abs/2408.02336v2","updated":"2024-08-06T04:04:23Z","published":"2024-08-05T09:19:52Z","title":"Infusing Environmental Captions for Long-Form Video Language Grounding","summary":"  In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.\n","authors":["Hyogun Lee","Soyeon Hong","Mujeen Sung","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2408.02336v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.16428v2","updated":"2024-08-06T03:44:00Z","published":"2024-03-25T05:12:21Z","title":"Benchmarks and Challenges in Pose Estimation for Egocentric Hand\n  Interactions with Objects","summary":"  We interact with the world with our hands and see it through our own\n(egocentric) perspective. A holistic 3Dunderstanding of such interactions from\negocentric views is important for tasks in robotics, AR/VR, action recognition\nand motion generation. Accurately reconstructing such interactions in 3D is\nchallenging due to heavy occlusion, viewpoint bias, camera distortion, and\nmotion blur from the head movement. To this end, we designed the HANDS23\nchallenge based on the AssemblyHands and ARCTIC datasets with carefully\ndesigned training and testing splits. Based on the results of the top submitted\nmethods and more recent baselines on the leaderboards, we perform a thorough\nanalysis on 3D hand(-object) reconstruction tasks. Our analysis demonstrates\nthe effectiveness of addressing distortion specific to egocentric cameras,\nadopting high-capacity transformers to learn complex hand-object interactions,\nand fusing predictions from different views. Our study further reveals\nchallenging scenarios intractable with state-of-the-art methods, such as fast\nhand motion, object reconstruction from narrow egocentric views, and close\ncontact between two hands and objects. Our efforts will enrich the community's\nknowledge foundation and facilitate future hand studies on egocentric\nhand-object interactions.\n","authors":["Zicong Fan","Takehiko Ohkawa","Linlin Yang","Nie Lin","Zhishan Zhou","Shihao Zhou","Jiajun Liang","Zhong Gao","Xuanyang Zhang","Xue Zhang","Fei Li","Zheng Liu","Feng Lu","Karim Abou Zeid","Bastian Leibe","Jeongwan On","Seungryul Baek","Aditya Prakash","Saurabh Gupta","Kun He","Yoichi Sato","Otmar Hilliges","Hyung Jin Chang","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2403.16428v2.pdf","comment":"Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2404.18203v2","updated":"2024-08-06T03:37:31Z","published":"2024-04-28T14:47:09Z","title":"LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM","summary":"  Although large multi-modality models (LMMs) have seen extensive exploration\nand application in various quality assessment studies, their integration into\nPoint Cloud Quality Assessment (PCQA) remains unexplored. Given LMMs'\nexceptional performance and robustness in low-level vision and quality\nassessment tasks, this study aims to investigate the feasibility of imparting\nPCQA knowledge to LMMs through text supervision. To achieve this, we transform\nquality labels into textual descriptions during the fine-tuning phase, enabling\nLMMs to derive quality rating logits from 2D projections of point clouds. To\ncompensate for the loss of perception in the 3D domain, structural features are\nextracted as well. These quality logits and structural features are then\ncombined and regressed into quality scores. Our experimental results affirm the\neffectiveness of our approach, showcasing a novel integration of LMMs into PCQA\nthat enhances model understanding and assessment accuracy. We hope our\ncontributions can inspire subsequent investigations into the fusion of LMMs\nwith PCQA, fostering advancements in 3D visual quality analysis and beyond. The\ncode is available at https://github.com/zzc-1998/LMM-PCQA.\n","authors":["Zicheng Zhang","Haoning Wu","Yingjie Zhou","Chunyi Li","Wei Sun","Chaofeng Chen","Xiongkuo Min","Xiaohong Liu","Weisi Lin","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2404.18203v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12794v2","updated":"2024-08-06T03:28:12Z","published":"2024-04-19T11:17:35Z","title":"MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware\n  State Space Model","summary":"  LiDAR-based Moving Object Segmentation (MOS) aims to locate and segment\nmoving objects in point clouds of the current scan using motion information\nfrom previous scans. Despite the promising results achieved by previous MOS\nmethods, several key issues, such as the weak coupling of temporal and spatial\ninformation, still need further study. In this paper, we propose a novel\nLiDAR-based 3D Moving Object Segmentation with Motion-aware State Space Model,\ntermed MambaMOS. Firstly, we develop a novel embedding module, the Time Clue\nBootstrapping Embedding (TCBE), to enhance the coupling of temporal and spatial\ninformation in point clouds and alleviate the issue of overlooked temporal\nclues. Secondly, we introduce the Motion-aware State Space Model (MSSM) to\nendow the model with the capacity to understand the temporal correlations of\nthe same object across different time steps. Specifically, MSSM emphasizes the\nmotion states of the same object at different time steps through two distinct\ntemporal modeling and correlation steps. We utilize an improved state space\nmodel to represent these motion differences, significantly modeling the motion\nstates. Finally, extensive experiments on the SemanticKITTI-MOS and KITTI-Road\nbenchmarks demonstrate that the proposed MambaMOS achieves state-of-the-art\nperformance. The source code is publicly available at\nhttps://github.com/Terminal-K/MambaMOS.\n","authors":["Kang Zeng","Hao Shi","Jiacheng Lin","Siyu Li","Jintao Cheng","Kaiwei Wang","Zhiyong Li","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2404.12794v2.pdf","comment":"Accepted to ACM MM 2024. The source code is publicly available at\n  https://github.com/Terminal-K/MambaMOS"},{"id":"http://arxiv.org/abs/2408.02929v1","updated":"2024-08-06T03:23:42Z","published":"2024-08-06T03:23:42Z","title":"Segmenting Small Stroke Lesions with Novel Labeling Strategies","summary":"  Deep neural networks have demonstrated exceptional efficacy in stroke lesion\nsegmentation. However, the delineation of small lesions, critical for stroke\ndiagnosis, remains a challenge. In this study, we propose two straightforward\nyet powerful approaches that can be seamlessly integrated into a variety of\nnetworks: Multi-Size Labeling (MSL) and Distance-Based Labeling (DBL), with the\naim of enhancing the segmentation accuracy of small lesions. MSL divides lesion\nmasks into various categories based on lesion volume while DBL emphasizes the\nlesion boundaries. Experimental evaluations on the Anatomical Tracings of\nLesions After Stroke (ATLAS) v2.0 dataset showcase that an ensemble of MSL and\nDBL achieves consistently better or equal performance on recall (3.6% and\n3.7%), F1 (2.4% and 1.5%), and Dice scores (1.3% and 0.0%) compared to the\ntop-1 winner of the 2022 MICCAI ATLAS Challenge on both the subset only\ncontaining small lesions and the entire dataset, respectively. Notably, on the\nmini-lesion subset, a single MSL model surpasses the previous best ensemble\nstrategy, with enhancements of 1.0% and 0.3% on F1 and Dice scores,\nrespectively. Our code is available at:\nhttps://github.com/nadluru/StrokeLesSeg.\n","authors":["Liang Shang","Zhengyang Lou","Andrew L. Alexander","Vivek Prabhakaran","William A. Sethares","Veena A. Nair","Nagesh Adluru"],"pdf_url":"https://arxiv.org/pdf/2408.02929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02924v1","updated":"2024-08-06T03:20:10Z","published":"2024-08-06T03:20:10Z","title":"Evaluation of Segment Anything Model 2: The Role of SAM2 in the\n  Underwater Environment","summary":"  With breakthroughs in large-scale modeling, the Segment Anything Model (SAM)\nand its extensions have been attempted for applications in various underwater\nvisualization tasks in marine sciences, and have had a significant impact on\nthe academic community. Recently, Meta has further developed the Segment\nAnything Model 2 (SAM2), which significantly improves running speed and\nsegmentation accuracy compared to its predecessor. This report aims to explore\nthe potential of SAM2 in marine science by evaluating it on the underwater\ninstance segmentation benchmark datasets UIIS and USIS10K. The experiments show\nthat the performance of SAM2 is extremely dependent on the type of\nuser-provided prompts. When using the ground truth bounding box as prompt, SAM2\nperformed excellently in the underwater instance segmentation domain. However,\nwhen running in automatic mode, SAM2's ability with point prompts to sense and\nsegment underwater instances is significantly degraded. It is hoped that this\npaper will inspire researchers to further explore the SAM model family in the\nunderwater domain. The results and evaluation codes in this paper are available\nat https://github.com/LiamLian0727/UnderwaterSAM2Eval.\n","authors":["Shijie Lian","Hua Li"],"pdf_url":"https://arxiv.org/pdf/2408.02924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02085v2","updated":"2024-08-06T03:19:25Z","published":"2024-08-04T16:50:07Z","title":"Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data\n  Assessment and Selection for Instruction Tuning of Language Models","summary":"  Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering.\n","authors":["Yulei Qin","Yuncheng Yang","Pengcheng Guo","Gang Li","Hang Shao","Yuchen Shi","Zihan Xu","Yun Gu","Ke Li","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02085v2.pdf","comment":"review, survey, 28 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2408.02922v1","updated":"2024-08-06T03:15:18Z","published":"2024-08-06T03:15:18Z","title":"Pose Magic: Efficient and Temporally Consistent Human Pose Estimation\n  with a Hybrid Mamba-GCN Network","summary":"  Current state-of-the-art (SOTA) methods in 3D Human Pose Estimation (HPE) are\nprimarily based on Transformers. However, existing Transformer-based 3D HPE\nbackbones often encounter a trade-off between accuracy and computational\nefficiency. To resolve the above dilemma, in this work, leveraging recent\nadvances in state space models, we utilize Mamba for high-quality and efficient\nlong-range modeling. Nonetheless, Mamba still faces challenges in precisely\nexploiting the local dependencies between joints. To address these issues, we\npropose a new attention-free hybrid spatiotemporal architecture named Hybrid\nMamba-GCN (Pose Magic). This architecture introduces local enhancement with GCN\nby capturing relationships between neighboring joints, thus producing new\nrepresentations to complement Mamba's outputs. By adaptively fusing\nrepresentations from Mamba and GCN, Pose Magic demonstrates superior capability\nin learning the underlying 3D structure. To meet the requirements of real-time\ninference, we also provide a fully causal version. Extensive experiments show\nthat Pose Magic achieves new SOTA results ($\\downarrow 0.9 mm$) while saving\n$74.1\\%$ FLOPs. In addition, Pose Magic exhibits optimal motion consistency and\nthe ability to generalize to unseen sequence lengths.\n","authors":["Xinyi Zhang","Qiqi Bao","Qinpeng Cui","Wenming Yang","Qingmin Liao"],"pdf_url":"https://arxiv.org/pdf/2408.02922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01351v2","updated":"2024-08-06T02:58:13Z","published":"2023-09-04T04:29:01Z","title":"Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in\n  Driving Scenarios with NeRF","summary":"  Deep neural networks (DNNs) have been proven extremely susceptible to\nadversarial examples, which raises special safety-critical concerns for\nDNN-based autonomous driving stacks (i.e., 3D object detection). Although there\nare extensive works on image-level attacks, most are restricted to 2D pixel\nspaces, and such attacks are not always physically realistic in our 3D world.\nHere we present Adv3D, the first exploration of modeling adversarial examples\nas Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic\nappearances and 3D accurate generation, yielding a more realistic and\nrealizable adversarial example. We train our adversarial NeRF by minimizing the\nsurrounding objects' confidence predicted by 3D detectors on the training set.\nThen we evaluate Adv3D on the unseen validation set and show that it can cause\na large performance reduction when rendering NeRF in any sampled pose. To\ngenerate physically realizable adversarial examples, we propose primitive-aware\nsampling and semantic-guided regularization that enable 3D patch attacks with\ncamouflage adversarial texture. Experimental results demonstrate that the\ntrained adversarial NeRF generalizes well to different poses, scenes, and 3D\ndetectors. Finally, we provide a defense method to our attacks that involves\nadversarial training through data augmentation. Project page:\nhttps://len-li.github.io/adv3d-web\n","authors":["Leheng Li","Qing Lian","Ying-Cong Chen"],"pdf_url":"https://arxiv.org/pdf/2309.01351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17379v2","updated":"2024-08-06T02:44:44Z","published":"2024-07-24T15:59:01Z","title":"MMRA: A Benchmark for Evaluating Multi-Granularity and Multi-Image\n  Relational Association Capabilities in Large Visual Language Models","summary":"  Given the remarkable success that large visual language models (LVLMs) have\nachieved in image perception tasks, the endeavor to make LVLMs perceive the\nworld like humans is drawing increasing attention. Current multi-modal\nbenchmarks primarily focus on facts or specific topic-related knowledge\ncontained within individual images. However, they often overlook the\nassociative relations between multiple images, which require the identification\nand analysis of similarities among entities or content present in different\nimages. Therefore, we propose the multi-image relation association task and a\nmeticulously curated Multi-granularity Multi-image Relational Association\n(MMRA) benchmark, comprising 1,024 samples. In order to systematically and\ncomprehensively evaluate current LVLMs, we establish an associational relation\nsystem among images that contain 11 subtasks (e.g, UsageSimilarity, SubEvent)\nat two granularity levels (i.e., image and entity) according to the relations\nin ConceptNet. Our experiments reveal that on the MMRA benchmark, current\nmulti-image LVLMs exhibit distinct advantages and disadvantages across various\nsubtasks. Notably, fine-grained, entity-level multi-image perception tasks pose\na greater challenge for LVLMs compared to image-level tasks. Moreover, LVLMs\nperform poorly on spatial-related tasks, indicating that LVLMs still have\nlimited spatial awareness. Additionally, our findings indicate that while LVLMs\ndemonstrate a strong capability to perceive image details, enhancing their\nability to associate information across multiple images hinges on improving the\nreasoning capabilities of their language model component. Moreover, we explored\nthe ability of LVLMs to perceive image sequences within the context of our\nmulti-image association task. Our experiments show that the majority of current\nLVLMs do not adequately model image sequences during the pre-training process.\n","authors":["Siwei Wu","Kang Zhu","Yu Bai","Yiming Liang","Yizhi Li","Haoning Wu","J. H. Liu","Ruibo Liu","Xingwei Qu","Xuxin Cheng","Ge Zhang","Wenhao Huang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2407.17379v2.pdf","comment":"VLMs, Multi-Image Association"},{"id":"http://arxiv.org/abs/2404.07950v3","updated":"2024-08-06T02:42:32Z","published":"2024-03-18T16:50:23Z","title":"Reinforcement Learning with Generalizable Gaussian Splatting","summary":"  An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL.\n","authors":["Jiaxu Wang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Gang Han","Wen Zhao","Weining Zhang","Yecheng Shao","Yijie Guo","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2404.07950v3.pdf","comment":"7 pages,2 figures"},{"id":"http://arxiv.org/abs/2408.01934v2","updated":"2024-08-06T02:39:46Z","published":"2024-08-04T05:22:08Z","title":"A Survey and Evaluation of Adversarial Attacks for Object Detection","summary":"  Deep learning models excel in various computer vision tasks but are\nsusceptible to adversarial examples-subtle perturbations in input data that\nlead to incorrect predictions. This vulnerability poses significant risks in\nsafety-critical applications such as autonomous vehicles, security\nsurveillance, and aircraft health monitoring. While numerous surveys focus on\nadversarial attacks in image classification, the literature on such attacks in\nobject detection is limited. This paper offers a comprehensive taxonomy of\nadversarial attacks specific to object detection, reviews existing adversarial\nrobustness evaluation metrics, and systematically assesses open-source attack\nmethods and model robustness. Key observations are provided to enhance the\nunderstanding of attack effectiveness and corresponding countermeasures.\nAdditionally, we identify crucial research challenges to guide future efforts\nin securing automated object detection systems.\n","authors":["Khoi Nguyen Tiet Nguyen","Wenyu Zhang","Kangkang Lu","Yuhuan Wu","Xingjian Zheng","Hui Li Tan","Liangli Zhen"],"pdf_url":"https://arxiv.org/pdf/2408.01934v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.00952v5","updated":"2024-08-06T02:39:05Z","published":"2023-03-02T04:12:53Z","title":"Towards Activated Muscle Group Estimation in the Wild","summary":"  In this paper, we tackle the new task of video-based Activated Muscle Group\nEstimation (AMGE) aiming at identifying active muscle regions during physical\nactivity in the wild. To this intent, we provide the MuscleMap dataset\nfeaturing >15K video clips with 135 different activities and 20 labeled muscle\ngroups. This dataset opens the vistas to multiple video-based applications in\nsports and rehabilitation medicine under flexible environment constraints. The\nproposed MuscleMap dataset is constructed with YouTube videos, specifically\ntargeting High-Intensity Interval Training (HIIT) physical exercise in the\nwild. To make the AMGE model applicable in real-life situations, it is crucial\nto ensure that the model can generalize well to numerous types of physical\nactivities not present during training and involving new combinations of\nactivated muscles. To achieve this, our benchmark also covers an evaluation\nsetting where the model is exposed to activity types excluded from the training\nset. Our experiments reveal that the generalizability of existing architectures\nadapted for the AMGE task remains a challenge. Therefore, we also propose a new\napproach, TransM3E, which employs a multi-modality feature fusion mechanism\nbetween both the video transformer model and the skeleton-based graph\nconvolution model with novel cross-modal knowledge distillation executed on\nmulti-classification tokens. The proposed method surpasses all popular video\nclassification models when dealing with both, previously seen and new types of\nphysical activities. The database and code can be found at\nhttps://github.com/KPeng9510/MuscleMap.\n","authors":["Kunyu Peng","David Schneider","Alina Roitberg","Kailun Yang","Jiaming Zhang","Chen Deng","Kaiyu Zhang","M. Saquib Sarfraz","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2303.00952v5.pdf","comment":"Accepted to ACM MM 2024. The database and code can be found at\n  https://github.com/KPeng9510/MuscleMap"},{"id":"http://arxiv.org/abs/2408.02906v1","updated":"2024-08-06T02:38:22Z","published":"2024-08-06T02:38:22Z","title":"Dual-View Pyramid Pooling in Deep Neural Networks for Improved Medical\n  Image Classification and Confidence Calibration","summary":"  Spatial pooling (SP) and cross-channel pooling (CCP) operators have been\napplied to aggregate spatial features and pixel-wise features from feature maps\nin deep neural networks (DNNs), respectively. Their main goal is to reduce\ncomputation and memory overhead without visibly weakening the performance of\nDNNs. However, SP often faces the problem of losing the subtle feature\nrepresentations, while CCP has a high possibility of ignoring salient feature\nrepresentations, which may lead to both miscalibration of confidence issues and\nsuboptimal medical classification results. To address these problems, we\npropose a novel dual-view framework, the first to systematically investigate\nthe relative roles of SP and CCP by analyzing the difference between spatial\nfeatures and pixel-wise features. Based on this framework, we propose a new\npooling method, termed dual-view pyramid pooling (DVPP), to aggregate\nmulti-scale dual-view features. DVPP aims to boost both medical image\nclassification and confidence calibration performance by fully leveraging the\nmerits of SP and CCP operators from a dual-axis perspective. Additionally, we\ndiscuss how to fulfill DVPP with five parameter-free implementations. Extensive\nexperiments on six 2D/3D medical image classification tasks show that our DVPP\nsurpasses state-of-the-art pooling methods in terms of medical image\nclassification results and confidence calibration across different DNNs.\n","authors":["Xiaoqing Zhang","Qiushi Nie","Zunjie Xiao","Jilu Zhao","Xiao Wu","Pengxin Guo","Runzhi Li","Jin Liu","Yanjie Wei","Yi Pan"],"pdf_url":"https://arxiv.org/pdf/2408.02906v1.pdf","comment":"27"},{"id":"http://arxiv.org/abs/2402.13699v4","updated":"2024-08-06T02:32:36Z","published":"2024-02-21T11:00:23Z","title":"Automation of Quantum Dot Measurement Analysis via Explainable Machine\n  Learning","summary":"  The rapid development of quantum dot (QD) devices for quantum computing has\nnecessitated more efficient and automated methods for device characterization\nand tuning. Many of the measurements acquired during the tuning process come in\nthe form of images that need to be properly analyzed to guide the subsequent\ntuning steps. By design, features present in such images capture certain\nbehaviors or states of the measured QD devices. When considered carefully, such\nfeatures can aid the control and calibration of QD devices. An important\nexample of such images are so-called \\textit{triangle plots}, which visually\nrepresent current flow and reveal characteristics important for QD device\ncalibration. While image-based classification tools, such as convolutional\nneural networks (CNNs), can be used to verify whether a given measurement is\n\\textit{good} and thus warrants the initiation of the next phase of tuning,\nthey do not provide any insights into how the device should be adjusted in the\ncase of \\textit{bad} images. This is because CNNs sacrifice prediction and\nmodel intelligibility for high accuracy. To ameliorate this trade-off, a recent\nstudy introduced an image vectorization approach that relies on the Gabor\nwavelet transform [1]. Here we propose an alternative vectorization method that\ninvolves mathematical modeling of synthetic triangles to mimic the experimental\ndata. Using explainable boosting machines, we show that this new method offers\nsuperior explainability of model prediction without sacrificing accuracy. This\nwork demonstrates the feasibility and advantages of applying explainable\nmachine learning techniques to the analysis of quantum dot measurements, paving\nthe way for further advances in automated and transparent QD device tuning.\n","authors":["Daniel Schug","Tyler J. Kovach","M. A. Wolfe","Jared Benson","Sanghyeok Park","J. P. Dodson","J. Corrigan","M. A. Eriksson","Justyna P. Zwolak"],"pdf_url":"https://arxiv.org/pdf/2402.13699v4.pdf","comment":"17 pages, 4 figures, abbreviated version published in Proceedings of\n  the XAI4Sci: Explainable machine learning for sciences workshop at AAAI 2024,\n  (Vancouver, Canada)"},{"id":"http://arxiv.org/abs/2408.02904v1","updated":"2024-08-06T02:27:54Z","published":"2024-08-06T02:27:54Z","title":"Enabling Intelligent Traffic Systems: A Deep Learning Method for\n  Accurate Arabic License Plate Recognition","summary":"  This paper introduces a novel two-stage framework for accurate Egyptian\nVehicle License Plate Recognition (EVLPR). The first stage employs image\nprocessing techniques to reliably localize license plates, while the second\nstage utilizes a custom-designed deep learning model for robust Arabic\ncharacter recognition. The proposed system achieves a remarkable 99.3% accuracy\non a diverse dataset, surpassing existing approaches. Its potential\napplications extend to intelligent traffic management, including traffic\nviolation detection and parking optimization. Future research will focus on\nenhancing the system's capabilities through architectural refinements, expanded\ndatasets, and addressing system dependencies.\n","authors":["M. A. Sayedelahl"],"pdf_url":"https://arxiv.org/pdf/2408.02904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02901v1","updated":"2024-08-06T02:15:12Z","published":"2024-08-06T02:15:12Z","title":"Lighthouse: A User-Friendly Library for Reproducible Video Moment\n  Retrieval and Highlight Detection","summary":"  We propose Lighthouse, a user-friendly library for reproducible video moment\nretrieval and highlight detection (MR-HD). Although researchers proposed\nvarious MR-HD approaches, the research community holds two main issues. The\nfirst is a lack of comprehensive and reproducible experiments across various\nmethods, datasets, and video-text features. This is because no unified training\nand evaluation codebase covers multiple settings. The second is user-unfriendly\ndesign. Because previous works use different libraries, researchers set up\nindividual environments. In addition, most works release only the training\ncodes, requiring users to implement the whole inference process of MR-HD.\nLighthouse addresses these issues by implementing a unified reproducible\ncodebase that includes six models, three features, and five datasets. In\naddition, it provides an inference API and web demo to make these methods\neasily accessible for researchers and developers. Our experiments demonstrate\nthat Lighthouse generally reproduces the reported scores in the reference\npapers. The code is available at https://github.com/line/lighthouse.\n","authors":["Taichi Nishimura","Shota Nakada","Hokuto Munakata","Tatsuya Komatsu"],"pdf_url":"https://arxiv.org/pdf/2408.02901v1.pdf","comment":"6 pages; library tech report"},{"id":"http://arxiv.org/abs/2408.02900v1","updated":"2024-08-06T02:09:35Z","published":"2024-08-06T02:09:35Z","title":"MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular\n  Annotations for Medicine","summary":"  This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal\ndataset for medicine, covering over 25 million images across 10 modalities,\nwith multigranular annotations for more than 65 diseases. These enriched\nannotations encompass both global textual information, such as disease/lesion\ntype, modality, region-specific descriptions, and inter-regional relationships,\nas well as detailed local annotations for regions of interest (ROIs), including\nbounding boxes, segmentation masks. Unlike existing approach which is limited\nby the availability of image-text pairs, we have developed the first automated\npipeline that scales up multimodal data by generating multigranular visual and\ntexual annotations (in the form of image-ROI-description triplets) without the\nneed for any paired text descriptions. Specifically, data from over 90\ndifferent sources have been collected, preprocessed, and grounded using\ndomain-specific expert models to identify ROIs related to abnormal regions. We\nthen build a comprehensive knowledge base and prompt multimodal large language\nmodels to perform retrieval-augmented generation with the identified ROIs as\nguidance, resulting in multigranular texual descriptions. Compared to existing\ndatasets, MedTrinity-25M provides the most enriched annotations, supporting a\ncomprehensive range of multimodal tasks such as captioning and report\ngeneration, as well as vision-centric tasks like classification and\nsegmentation. Pretraining on MedTrinity-25M, our model achieves\nstate-of-the-art performance on VQA-RAD and PathVQA, surpassing both multimodal\nlarge language models and other representative SoTA approaches. This dataset\ncan also be utilized to support large-scale pre-training of multimodal medical\nAI models, contributing to the development of future foundation models in the\nmedical domain.\n","authors":["Yunfei Xie","Ce Zhou","Lang Gao","Juncheng Wu","Xianhang Li","Hong-Yu Zhou","Sheng Liu","Lei Xing","James Zou","Cihang Xie","Yuyin Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02900v1.pdf","comment":"The project page is at https://yunfeixie233.github.io/MedTrinity-25M"},{"id":"http://arxiv.org/abs/2406.14643v2","updated":"2024-08-06T02:04:35Z","published":"2024-06-20T18:07:19Z","title":"Holistic Evaluation for Interleaved Text-and-Image Generation","summary":"  Interleaved text-and-image generation has been an intriguing research\ndirection, where the models are required to generate both images and text\npieces in an arbitrary order. Despite the emerging advancements in interleaved\ngeneration, the progress in its evaluation still significantly lags behind.\nExisting evaluation benchmarks do not support arbitrarily interleaved images\nand text for both inputs and outputs, and they only cover a limited number of\ndomains and use cases. Also, current works predominantly use similarity-based\nmetrics which fall short in assessing the quality in open-ended scenarios. To\nthis end, we introduce InterleavedBench, the first benchmark carefully curated\nfor the evaluation of interleaved text-and-image generation. InterleavedBench\nfeatures a rich array of tasks to cover diverse real-world use cases. In\naddition, we present InterleavedEval, a strong reference-free metric powered by\nGPT-4o to deliver accurate and explainable evaluation. We carefully define five\nessential evaluation aspects for InterleavedEval, including text quality,\nperceptual quality, image coherence, text-image coherence, and helpfulness, to\nensure a comprehensive and fine-grained assessment. Through extensive\nexperiments and rigorous human evaluation, we show that our benchmark and\nmetric can effectively evaluate the existing models with a strong correlation\nwith human judgments surpassing previous reference-based metrics. We also\nprovide substantial findings and insights to foster future research in\ninterleaved generation and its evaluation.\n","authors":["Minqian Liu","Zhiyang Xu","Zihao Lin","Trevor Ashby","Joy Rimchala","Jiaxin Zhang","Lifu Huang"],"pdf_url":"https://arxiv.org/pdf/2406.14643v2.pdf","comment":"13 pages, 6 figures, 6 tables. Website:\n  https://vt-nlp.github.io/InterleavedEval/. Dataset:\n  https://huggingface.co/mqliu/InterleavedBench"},{"id":"http://arxiv.org/abs/2408.02891v1","updated":"2024-08-06T01:41:40Z","published":"2024-08-06T01:41:40Z","title":"Diverse Generation while Maintaining Semantic Coordination: A\n  Diffusion-Based Data Augmentation Method for Object Detection","summary":"  Recent studies emphasize the crucial role of data augmentation in enhancing\nthe performance of object detection models. However,existing methodologies\noften struggle to effectively harmonize dataset diversity with semantic\ncoordination.To bridge this gap, we introduce an innovative augmentation\ntechnique leveraging pre-trained conditional diffusion models to mediate this\nbalance. Our approach encompasses the development of a Category Affinity\nMatrix, meticulously designed to enhance dataset diversity, and a Surrounding\nRegion Alignment strategy, which ensures the preservation of semantic\ncoordination in the augmented images. Extensive experimental evaluations\nconfirm the efficacy of our method in enriching dataset diversity while\nseamlessly maintaining semantic coordination. Our method yields substantial\naverage improvements of +1.4AP, +0.9AP, and +3.4AP over existing alternatives\non three distinct object detection models, respectively.\n","authors":["Sen Nie","Zhuo Wang","Xinxin Wang","Kun He"],"pdf_url":"https://arxiv.org/pdf/2408.02891v1.pdf","comment":"15 pages, 7 figures, ICPR2024"},{"id":"http://arxiv.org/abs/2408.02888v1","updated":"2024-08-06T01:34:43Z","published":"2024-08-06T01:34:43Z","title":"VizECGNet: Visual ECG Image Network for Cardiovascular Diseases\n  Classification with Multi-Modal Training and Knowledge Distillation","summary":"  An electrocardiogram (ECG) captures the heart's electrical signal to assess\nvarious heart conditions. In practice, ECG data is stored as either digitized\nsignals or printed images. Despite the emergence of numerous deep learning\nmodels for digitized signals, many hospitals prefer image storage due to cost\nconsiderations. Recognizing the unavailability of raw ECG signals in many\nclinical settings, we propose VizECGNet, which uses only printed ECG graphics\nto determine the prognosis of multiple cardiovascular diseases. During\ntraining, cross-modal attention modules (CMAM) are used to integrate\ninformation from two modalities - image and signal, while self-modality\nattention modules (SMAM) capture inherent long-range dependencies in ECG data\nof each modality. Additionally, we utilize knowledge distillation to improve\nthe similarity between two distinct predictions from each modality stream. This\ninnovative multi-modal deep learning architecture enables the utilization of\nonly ECG images during inference. VizECGNet with image input achieves higher\nperformance in precision, recall, and F1-Score compared to signal-based ECG\nclassification models, with improvements of 3.50%, 8.21%, and 7.38%,\nrespectively.\n","authors":["Ju-Hyeon Nam","Seo-Hyung Park","Su Jung Kim","Sang-Chul Lee"],"pdf_url":"https://arxiv.org/pdf/2408.02888v1.pdf","comment":"Accepted in International Conference on Image Processing (ICIP) 2024"},{"id":"http://arxiv.org/abs/2304.07444v4","updated":"2024-08-06T01:31:28Z","published":"2023-04-15T01:33:14Z","title":"The Art of Camouflage: Few-Shot Learning for Animal Detection and\n  Segmentation","summary":"  Camouflaged object detection and segmentation is a new and challenging\nresearch topic in computer vision. There is a serious issue of lacking data on\nconcealed objects such as camouflaged animals in natural scenes. In this paper,\nwe address the problem of few-shot learning for camouflaged object detection\nand segmentation. To this end, we first collect a new dataset, CAMO-FS, for the\nbenchmark. As camouflaged instances are challenging to recognize due to their\nsimilarity compared to the surroundings, we guide our models to obtain\ncamouflaged features that highly distinguish the instances from the background.\nIn this work, we propose FS-CDIS, a framework to efficiently detect and segment\ncamouflaged instances via two loss functions contributing to the training\nprocess. Firstly, the instance triplet loss with the characteristic of\ndifferentiating the anchor, which is the mean of all camouflaged foreground\npoints, and the background points are employed to work at the instance level.\nSecondly, to consolidate the generalization at the class level, we present\ninstance memory storage with the scope of storing camouflaged features of the\nsame category, allowing the model to capture further class-level information\nduring the learning process. The extensive experiments demonstrated that our\nproposed method achieves state-of-the-art performance on the newly collected\ndataset. Code is available at https://github.com/danhntd/FS-CDIS.\n","authors":["Thanh-Danh Nguyen","Anh-Khoa Nguyen Vu","Nhat-Duy Nguyen","Vinh-Tiep Nguyen","Thanh Duc Ngo","Thanh-Toan Do","Minh-Triet Tran","Tam V. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2304.07444v4.pdf","comment":"IEEE Access 2024"},{"id":"http://arxiv.org/abs/2408.02879v1","updated":"2024-08-06T01:13:09Z","published":"2024-08-06T01:13:09Z","title":"Body of Her: A Preliminary Study on End-to-End Humanoid Agent","summary":"  Interactive virtual humanoid agent is a crucial interface with the physical\nworld. A relatively complete humanoid agent first needs to have face and body,\nthen possess both verbal and non-verbal (such as eye contact, facial\nexpression, lip motion, gesture, and manipulation) abilities, and finally, it\nis capable of real-time duplex communication, e.g., the ability to actively\ninterrupt conversations. Most prior systems typically only consider a subset of\nthese elements, leaving a gap from realistic humanoid agent. In this work, we\npropose a real-time, duplex, interactive end-to-end network capable of modeling\nrealistic agent behaviors, including speech, full-body movements for talking,\nresponding, idling, and manipulation. This system is a multimodal model\nintegrating audio and visual inputs, extended from a pre-trained large language\nmodel (LLM). We collect approximately 200,000 hours of audio, around 130,000\nhours of video data, and about 20,000 alignment samples to build the model. The\nfinal model demonstrates capabilities that are difficult to achieve in previous\nsystems, such as generalized object manipulation. This work performs a\npreliminary exploration of the end-to-end approach in this field, aiming to\ninspire further research towards scaling up.\n","authors":["Tenglong Ao"],"pdf_url":"https://arxiv.org/pdf/2408.02879v1.pdf","comment":"Technical Report v1; Project Page:\n  https://aubrey-ao.github.io/BodyOfHer"},{"id":"http://arxiv.org/abs/2403.09975v2","updated":"2024-08-06T00:28:44Z","published":"2024-03-15T02:42:28Z","title":"Skeleton-Based Human Action Recognition with Noisy Labels","summary":"  Understanding human actions from body poses is critical for assistive robots\nsharing space with humans in order to make informed and safe decisions about\nthe next interaction. However, precise temporal localization and annotation of\nactivity sequences is time-consuming and the resulting labels are often noisy.\nIf not effectively addressed, label noise negatively affects the model's\ntraining, resulting in lower recognition quality. Despite its importance,\naddressing label noise for skeleton-based action recognition has been\noverlooked so far. In this study, we bridge this gap by implementing a\nframework that augments well-established skeleton-based human action\nrecognition methods with label-denoising strategies from various research areas\nto serve as the initial benchmark. Observations reveal that these baselines\nyield only marginal performance when dealing with sparse skeleton data.\nConsequently, we introduce a novel methodology, NoiseEraSAR, which integrates\nglobal sample selection, co-teaching, and Cross-Modal Mixture-of-Experts\n(CM-MOE) strategies, aimed at mitigating the adverse impacts of label noise.\nOur proposed approach demonstrates better performance on the established\nbenchmark, setting new state-of-the-art standards. The source code for this\nstudy is accessible at https://github.com/xuyizdby/NoiseEraSAR.\n","authors":["Yi Xu","Kunyu Peng","Di Wen","Ruiping Liu","Junwei Zheng","Yufan Chen","Jiaming Zhang","Alina Roitberg","Kailun Yang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2403.09975v2.pdf","comment":"Accepted to IROS 2024. The source code for this study is accessible\n  at https://github.com/xuyizdby/NoiseEraSAR"},{"id":"http://arxiv.org/abs/2310.02650v3","updated":"2024-08-06T00:08:40Z","published":"2023-10-04T08:18:30Z","title":"Active Visual Localization for Multi-Agent Collaboration: A Data-Driven\n  Approach","summary":"  Rather than having each newly deployed robot create its own map of its\nsurroundings, the growing availability of SLAM-enabled devices provides the\noption of simply localizing in a map of another robot or device. In cases such\nas multi-robot or human-robot collaboration, localizing all agents in the same\nmap is even necessary. However, localizing e.g. a ground robot in the map of a\ndrone or head-mounted MR headset presents unique challenges due to viewpoint\nchanges. This work investigates how active visual localization can be used to\novercome such challenges of viewpoint changes. Specifically, we focus on the\nproblem of selecting the optimal viewpoint at a given location. We compare\nexisting approaches in the literature with additional proposed baselines and\npropose a novel data-driven approach. The result demonstrates the superior\nperformance of the data-driven approach when compared to existing methods, both\nin controlled simulation experiments and real-world deployment.\n","authors":["Matthew Hanlon","Boyang Sun","Marc Pollefeys","Hermann Blum"],"pdf_url":"https://arxiv.org/pdf/2310.02650v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00391v3","updated":"2024-08-06T23:58:07Z","published":"2023-12-31T04:14:43Z","title":"SAFE-SIM: Safety-Critical Closed-Loop Traffic Simulation with\n  Diffusion-Controllable Adversaries","summary":"  Evaluating the performance of autonomous vehicle planning algorithms\nnecessitates simulating long-tail safety-critical traffic scenarios. However,\ntraditional methods for generating such scenarios often fall short in terms of\ncontrollability and realism; they also neglect the dynamics of agent\ninteractions. To address these limitations, we introduce SAFE-SIM, a novel\ndiffusion-based controllable closed-loop safety-critical simulation framework.\nOur approach yields two distinct advantages: 1) generating realistic long-tail\nsafety-critical scenarios that closely reflect real-world conditions, and 2)\nproviding controllable adversarial behavior for more comprehensive and\ninteractive evaluations. We develop a novel approach to simulate\nsafety-critical scenarios through an adversarial term in the denoising process\nof diffusion models, which allows an adversarial agent to challenge a planner\nwith plausible maneuvers while all agents in the scene exhibit reactive and\nrealistic behaviors. Furthermore, we propose novel guidance objectives and a\npartial diffusion process that enables users to control key aspects of the\nscenarios, such as the collision type and aggressiveness of the adversarial\nagent, while maintaining the realism of the behavior. We validate our framework\nempirically using the nuScenes and nuPlan datasets across multiple planners,\ndemonstrating improvements in both realism and controllability. These findings\naffirm that diffusion models provide a robust and versatile foundation for\nsafety-critical, interactive traffic simulation, extending their utility across\nthe broader autonomous driving landscape. Project website:\nhttps://safe-sim.github.io/.\n","authors":["Wei-Jer Chang","Francesco Pittaluga","Masayoshi Tomizuka","Wei Zhan","Manmohan Chandraker"],"pdf_url":"https://arxiv.org/pdf/2401.00391v3.pdf","comment":"Accepted by ECCV2024; Project website: https://safe-sim.github.io/"},{"id":"http://arxiv.org/abs/2408.03464v1","updated":"2024-08-06T22:39:34Z","published":"2024-08-06T22:39:34Z","title":"AI Foundation Models in Remote Sensing: A Survey","summary":"  Artificial Intelligence (AI) technologies have profoundly transformed the\nfield of remote sensing, revolutionizing data collection, processing, and\nanalysis. Traditionally reliant on manual interpretation and task-specific\nmodels, remote sensing has been significantly enhanced by the advent of\nfoundation models--large-scale, pre-trained AI models capable of performing a\nwide array of tasks with unprecedented accuracy and efficiency. This paper\nprovides a comprehensive survey of foundation models in the remote sensing\ndomain, covering models released between June 2021 and June 2024. We categorize\nthese models based on their applications in computer vision and domain-specific\ntasks, offering insights into their architectures, pre-training datasets, and\nmethodologies. Through detailed performance comparisons, we highlight emerging\ntrends and the significant advancements achieved by these foundation models.\nAdditionally, we discuss the technical challenges, practical implications, and\nfuture research directions, addressing the need for high-quality data,\ncomputational resources, and improved model generalization. Our research also\nfinds that pre-training methods, particularly self-supervised learning\ntechniques like contrastive learning and masked autoencoders, significantly\nenhance the performance and robustness of foundation models in remote sensing\ntasks such as scene classification, object detection, and other applications.\nThis survey aims to serve as a resource for researchers and practitioners by\nproviding a panorama of advances and promising pathways for continued\ndevelopment and application of foundation models in remote sensing.\n","authors":["Siqi Lu","Junlin Guo","James R Zimmer-Dauphinee","Jordan M Nieusma","Xiao Wang","Parker VanValkenburgh","Steven A Wernke","Yuankai Huo"],"pdf_url":"https://arxiv.org/pdf/2408.03464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19184v2","updated":"2024-08-06T22:36:04Z","published":"2024-07-27T05:52:31Z","title":"Enhancing Tree Type Detection in Forest Fire Risk Assessment:\n  Multi-Stage Approach and Color Encoding with Forest Fire Risk Evaluation\n  Framework for UAV Imagery","summary":"  Forest fires pose a significant threat to ecosystems, economies, and human\nhealth worldwide. Early detection and assessment of forest fires are crucial\nfor effective management and conservation efforts. Unmanned Aerial Vehicles\n(UAVs) equipped with advanced computer vision algorithms offer a promising\nsolution for forest fire detection and assessment. In this paper, we optimize\nan integrated forest fire risk assessment framework using UAVs and multi-stage\nobject detection algorithms. We introduce improvements to our previous\nframework, including the adoption of Faster R-CNN, Grid R-CNN, Sparse R-CNN,\nCascade R-CNN, Dynamic R-CNN, and Libra R-CNN detectors, and explore\noptimizations such as CBAM for attention enhancement, random erasing for\npreprocessing, and different color space representations. We evaluate these\nenhancements through extensive experimentation using aerial image footage from\nvarious regions in British Columbia, Canada. Our findings demonstrate the\neffectiveness of multi-stage detectors and optimizations in improving the\naccuracy of forest fire risk assessment. This research contributes to the\nadvancement of UAV-based forest fire detection and assessment systems,\nenhancing their efficiency and effectiveness in supporting sustainable forest\nmanagement and conservation efforts.\n","authors":["Jinda Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.19184v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12972v2","updated":"2024-08-06T22:28:25Z","published":"2024-01-23T18:58:35Z","title":"On the Efficacy of Text-Based Input Modalities for Action Anticipation","summary":"  Anticipating future actions is a highly challenging task due to the diversity\nand scale of potential future actions; yet, information from different\nmodalities help narrow down plausible action choices. Each modality can provide\ndiverse and often complementary context for the model to learn from. While\nprevious multi-modal methods leverage information from modalities such as video\nand audio, we primarily explore how text descriptions of actions and objects\ncan also lead to more accurate action anticipation by providing additional\ncontextual cues, e.g., about the environment and its contents. We propose a\nMulti-modal Contrastive Anticipative Transformer (M-CAT), a video transformer\narchitecture that jointly learns from multi-modal features and text\ndescriptions of actions and objects. We train our model in two stages, where\nthe model first learns to align video clips with descriptions of future\nactions, and is subsequently fine-tuned to predict future actions. Compared to\nexisting methods, M-CAT has the advantage of learning additional context from\ntwo types of text inputs: rich descriptions of future actions during\npre-training, and, text descriptions for detected objects and actions during\nmodality feature fusion. Through extensive experimental evaluation, we\ndemonstrate that our model outperforms previous methods on the EpicKitchens\ndatasets, and show that using simple text descriptions of actions and objects\naid in more effective action anticipation. In addition, we examine the impact\nof object and action information obtained via text, and perform extensive\nablations.\n","authors":["Apoorva Beedu","Karan Samel","Irfan Essa"],"pdf_url":"https://arxiv.org/pdf/2401.12972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01532v2","updated":"2024-08-06T21:19:20Z","published":"2024-08-02T18:45:01Z","title":"Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and\n  Localization","summary":"  In the digital age, the emergence of deepfakes and synthetic media presents a\nsignificant threat to societal and political integrity. Deepfakes based on\nmulti-modal manipulation, such as audio-visual, are more realistic and pose a\ngreater threat. Current multi-modal deepfake detectors are often based on the\nattention-based fusion of heterogeneous data streams from multiple modalities.\nHowever, the heterogeneous nature of the data (such as audio and visual\nsignals) creates a distributional modality gap and poses a significant\nchallenge in effective fusion and hence multi-modal deepfake detection. In this\npaper, we propose a novel multi-modal attention framework based on recurrent\nneural networks (RNNs) that leverages contextual information for audio-visual\ndeepfake detection. The proposed approach applies attention to multi-modal\nmulti-sequence representations and learns the contributing features among them\nfor deepfake detection and localization. Thorough experimental validations on\naudio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and\nLAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison\nwith the published studies demonstrates superior performance of our approach\nwith an improved accuracy and precision by 3.47% and 2.05% in deepfake\ndetection and localization, respectively. Thus, obtaining state-of-the-art\nperformance. To facilitate reproducibility, the code and the datasets\ninformation is available at https://github.com/vcbsl/audiovisual-deepfake/.\n","authors":["Vinaya Sree Katamneni","Ajita Rattani"],"pdf_url":"https://arxiv.org/pdf/2408.01532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02348v3","updated":"2024-08-06T21:16:43Z","published":"2024-04-02T22:49:25Z","title":"COVID-19 Detection Based on Blood Test Parameters using Various\n  Artificial Intelligence Methods","summary":"  In 2019, the world faced a new challenge: a COVID-19 disease caused by the\nnovel coronavirus, SARS-CoV-2. The virus rapidly spread across the globe,\nleading to a high rate of mortality, which prompted health organizations to\ntake measures to control its transmission. Early disease detection is crucial\nin the treatment process, and computer-based automatic detection systems have\nbeen developed to aid in this effort. These systems often rely on artificial\nintelligence (AI) approaches such as machine learning, neural networks, fuzzy\nsystems, and deep learning to classify diseases. This study aimed to\ndifferentiate COVID-19 patients from others using self-categorizing classifiers\nand employing various AI methods. This study used two datasets: the blood test\nsamples and radiography images. The best results for the blood test samples\nobtained from San Raphael Hospital, which include two classes of individuals,\nthose with COVID-19 and those with non-COVID diseases, were achieved through\nthe use of the Ensemble method (a combination of a neural network and two\nmachines learning methods). The results showed that this approach for COVID-19\ndiagnosis is cost-effective and provides results in a shorter amount of time\nthan other methods. The proposed model achieved an accuracy of 94.09% on the\ndataset used. Secondly, the radiographic images were divided into four classes:\nnormal, viral pneumonia, ground glass opacity, and COVID-19 infection. These\nwere used for segmentation and classification. The lung lobes were extracted\nfrom the images and then categorized into specific classes. We achieved an\naccuracy of 91.1% on the image dataset. Generally, this study highlights the\npotential of AI in detecting and managing COVID-19 and underscores the\nimportance of continued research and development in this field.\n","authors":["Kavian Khanjani","Seyed Rasoul Hosseini","Hamid Taheri","Shahrzad Shashaani","Mohammad Teshnehlab"],"pdf_url":"https://arxiv.org/pdf/2404.02348v3.pdf","comment":"This paper is under review by Int. J. of Computational Science and\n  Engineering"},{"id":"http://arxiv.org/abs/2403.19782v2","updated":"2024-08-06T21:14:43Z","published":"2024-03-28T19:07:26Z","title":"ENet-21: An Optimized light CNN Structure for Lane Detection","summary":"  Lane detection for autonomous vehicles is an important concept, yet it is a\nchallenging issue of driver assistance systems in modern vehicles. The\nemergence of deep learning leads to significant progress in self-driving cars.\nConventional deep learning-based methods handle lane detection problems as a\nbinary segmentation task and determine whether a pixel belongs to a line. These\nmethods rely on the assumption of a fixed number of lanes, which does not\nalways work. This study aims to develop an optimal structure for the lane\ndetection problem, offering a promising solution for driver assistance features\nin modern vehicles by utilizing a machine learning method consisting of binary\nsegmentation and Affinity Fields that can manage varying numbers of lanes and\nlane change scenarios. In this approach, the Convolutional Neural Network\n(CNN), is selected as a feature extractor, and the final output is obtained\nthrough clustering of the semantic segmentation and Affinity Field outputs. Our\nmethod uses less complex CNN architecture than existing ones. Experiments on\nthe TuSimple dataset support the effectiveness of the proposed method.\n","authors":["Seyed Rasoul Hosseini","Hamid Taheri","Mohammad Teshnehlab"],"pdf_url":"https://arxiv.org/pdf/2403.19782v2.pdf","comment":"The paper is under review by Int. J. of Mechatronics and Automation"},{"id":"http://arxiv.org/abs/2407.19305v2","updated":"2024-08-06T21:07:17Z","published":"2024-07-27T17:27:05Z","title":"GP-VLS: A general-purpose vision language model for surgery","summary":"  Surgery requires comprehensive medical knowledge, visual assessment skills,\nand procedural expertise. While recent surgical AI models have focused on\nsolving task-specific problems, there is a need for general-purpose systems\nthat can understand surgical scenes and interact through natural language. This\npaper introduces GP-VLS, a general-purpose vision language model for surgery\nthat integrates medical and surgical knowledge with visual scene understanding.\nFor comprehensively evaluating general-purpose surgical models, we propose\nSurgiQual, which evaluates across medical and surgical knowledge benchmarks as\nwell as surgical vision-language questions. To train GP-VLS, we develop six new\ndatasets spanning medical knowledge, surgical textbooks, and vision-language\npairs for tasks like phase recognition and tool identification. We show that\nGP-VLS significantly outperforms existing open- and closed-source models on\nsurgical vision-language tasks, with 8-21% improvements in accuracy across\nSurgiQual benchmarks. GP-VLS also demonstrates strong performance on medical\nand surgical knowledge tests compared to open-source alternatives. Overall,\nGP-VLS provides an open-source foundation for developing AI assistants to\nsupport surgeons across a wide range of tasks and scenarios. The code and data\nfor this work is publicly available at gpvls-surgery-vlm.github.io.\n","authors":["Samuel Schmidgall","Joseph Cho","Cyril Zakka","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2407.19305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03448v1","updated":"2024-08-06T21:00:02Z","published":"2024-08-06T21:00:02Z","title":"Post-Mortem Human Iris Segmentation Analysis with Deep Learning","summary":"  Iris recognition is widely used in several fields such as mobile phones,\nfinancial transactions, identification cards, airport security, international\nborder control, voter registration for living persons. However, the possibility\nof identifying deceased individuals based on their iris patterns has emerged\nrecently as a supplementary or alternative method valuable in forensic\nanalysis. Simultaneously, it poses numerous new technological challenges and\none of the most challenging among them is the image segmentation stage as\nconventional iris recognition approaches have struggled to reliably execute it.\nThis paper presents and compares Deep Learning (DL) models designed for\nsegmenting iris images collected from the deceased subjects, by training SegNet\nand DeepLabV3+ semantic segmentation methods where using VGG19, ResNet18,\nResNet50, MobileNetv2, Xception, or InceptionResNetv2 as backbones. In this\nstudy, our experiments demonstrate that our proposed method effectively learns\nand identifies specific deformations inherent in post-mortem samples and\nproviding a significant improvement in accuracy. By employing our novel method\nMobileNetv2 as the backbone of DeepLabV3+ and replacing the final layer with a\nhybrid loss function combining Boundary and Dice loss, we achieve Mean\nIntersection over Union of 95.54% on the Warsaw-BioBase-PostMortem-Iris-v1\ndataset. To the best of our knowledge, this study provides the most extensive\nevaluation of DL models for post-mortem iris segmentation.\n","authors":["Afzal Hossain","Tipu Sultan","Stephanie Schuckers"],"pdf_url":"https://arxiv.org/pdf/2408.03448v1.pdf","comment":"submitted to ijcb 2024 special session"},{"id":"http://arxiv.org/abs/2408.03433v1","updated":"2024-08-06T20:19:06Z","published":"2024-08-06T20:19:06Z","title":"Hybrid diffusion models: combining supervised and generative pretraining\n  for label-efficient fine-tuning of segmentation models","summary":"  We are considering in this paper the task of label-efficient fine-tuning of\nsegmentation models: We assume that a large labeled dataset is available and\nallows to train an accurate segmentation model in one domain, and that we have\nto adapt this model on a related domain where only a few samples are available.\nWe observe that this adaptation can be done using two distinct methods: The\nfirst method, supervised pretraining, is simply to take the model trained on\nthe first domain using classical supervised learning, and fine-tune it on the\nsecond domain with the available labeled samples. The second method is to\nperform self-supervised pretraining on the first domain using a generic pretext\ntask in order to get high-quality representations which can then be used to\ntrain a model on the second domain in a label-efficient way. We propose in this\npaper to fuse these two approaches by introducing a new pretext task, which is\nto perform simultaneously image denoising and mask prediction on the first\ndomain. We motivate this choice by showing that in the same way that an image\ndenoiser conditioned on the noise level can be considered as a generative model\nfor the unlabeled image distribution using the theory of diffusion models, a\nmodel trained using this new pretext task can be considered as a generative\nmodel for the joint distribution of images and segmentation masks under the\nassumption that the mapping from images to segmentation masks is deterministic.\nWe then empirically show on several datasets that fine-tuning a model\npretrained using this approach leads to better results than fine-tuning a\nsimilar model trained using either supervised or unsupervised pretraining only.\n","authors":["Bruno Sauvalle","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2408.03433v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2405.14386v2","updated":"2024-08-06T20:14:27Z","published":"2024-05-23T10:04:23Z","title":"Capsule Network Projectors are Equivariant and Invariant Learners","summary":"  Learning invariant representations has been the longstanding approach to\nself-supervised learning. However, recently progress has been made in\npreserving equivariant properties in representations, yet do so with highly\nprescribed architectures. In this work, we propose an invariant-equivariant\nself-supervised architecture that employs Capsule Networks (CapsNets) which\nhave been shown to capture equivariance with respect to novel viewpoints. We\ndemonstrate that the use of CapsNets in equivariant self-supervised\narchitectures achieves improved downstream performance on equivariant tasks\nwith higher efficiency and fewer network parameters. To accommodate the\narchitectural changes of CapsNets, we introduce a new objective function based\non entropy minimisation. This approach which we name CapsIE (Capsule Invariant\nEquivariant Network) achieves state-of-the-art performance across invariant and\nequivariant tasks on the 3DIEBench dataset compared to prior equivariant SSL\nmethods, while outperforming supervised baselines. Our results demonstrate the\nability of CapsNets to learn complex and generalised representations for\nlarge-scale, multi-task datasets compared to previous CapsNet benchmarks. Code\nis available at https://github.com/AberdeenML/CapsIE.\n","authors":["Miles Everett","Aiden Durrant","Mingjun Zhong","Georgios Leontidis"],"pdf_url":"https://arxiv.org/pdf/2405.14386v2.pdf","comment":"17 pages, 7 figures, 10 Tables; code to be released at:\n  https://github.com/AberdeenML/CapsIE V2: corrected typos, added a new Table 3\n  and additional results in Table 1 and Table 2"},{"id":"http://arxiv.org/abs/2309.15329v2","updated":"2024-08-06T19:51:49Z","published":"2023-09-27T00:20:36Z","title":"BASED: Bundle-Adjusting Surgical Endoscopic Dynamic Video Reconstruction\n  using Neural Radiance Fields","summary":"  Reconstruction of deformable scenes from endoscopic videos is important for\nmany applications such as intraoperative navigation, surgical visual\nperception, and robotic surgery. It is a foundational requirement for realizing\nautonomous robotic interventions for minimally invasive surgery. However,\nprevious approaches in this domain have been limited by their modular nature\nand are confined to specific camera and scene settings. Our work adopts the\nNeural Radiance Fields (NeRF) approach to learning 3D implicit representations\nof scenes that are both dynamic and deformable over time, and furthermore with\nunknown camera poses. We demonstrate this approach on endoscopic surgical\nscenes from robotic surgery. This work removes the constraints of known camera\nposes and overcomes the drawbacks of the state-of-the-art unstructured dynamic\nscene reconstruction technique, which relies on the static part of the scene\nfor accurate reconstruction. Through several experimental datasets, we\ndemonstrate the versatility of our proposed model to adapt to diverse camera\nand scene settings, and show its promise for both current and future robotic\nsurgical systems.\n","authors":["Shreya Saha","Zekai Liang","Shan Lin","Jingpei Lu","Michael Yip","Sainan Liu"],"pdf_url":"https://arxiv.org/pdf/2309.15329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02138v2","updated":"2024-08-06T19:27:12Z","published":"2024-08-04T20:35:33Z","title":"RICA2: Rubric-Informed, Calibrated Assessment of Actions","summary":"  The ability to quantify how well an action is carried out, also known as\naction quality assessment (AQA), has attracted recent interest in the vision\ncommunity. Unfortunately, prior methods often ignore the score rubric used by\nhuman experts and fall short of quantifying the uncertainty of the model\nprediction. To bridge the gap, we present RICA^2 - a deep probabilistic model\nthat integrates score rubric and accounts for prediction uncertainty for AQA.\nCentral to our method lies in stochastic embeddings of action steps, defined on\na graph structure that encodes the score rubric. The embeddings spread\nprobabilistic density in the latent space and allow our method to represent\nmodel uncertainty. The graph encodes the scoring criteria, based on which the\nquality scores can be decoded. We demonstrate that our method establishes new\nstate of the art on public benchmarks, including FineDiving, MTL-AQA, and\nJIGSAWS, with superior performance in score prediction and uncertainty\ncalibration. Our code is available at https://abrarmajeedi.github.io/rica2_aqa/\n","authors":["Abrar Majeedi","Viswanatha Reddy Gajjala","Satya Sai Srinath Namburi GNVV","Yin Li"],"pdf_url":"https://arxiv.org/pdf/2408.02138v2.pdf","comment":"Accepted at European Conference on Computer Vision (ECCV) 2024"},{"id":"http://arxiv.org/abs/2408.02226v2","updated":"2024-08-06T19:12:35Z","published":"2024-08-05T04:10:52Z","title":"ProCreate, Don't Reproduce! Propulsive Energy Diffusion for Creative\n  Generation","summary":"  In this paper, we propose ProCreate, a simple and easy-to-implement method to\nimprove sample diversity and creativity of diffusion-based image generative\nmodels and to prevent training data reproduction. ProCreate operates on a set\nof reference images and actively propels the generated image embedding away\nfrom the reference embeddings during the generation process. We propose FSCG-8\n(Few-Shot Creative Generation 8), a few-shot creative generation dataset on\neight different categories -- encompassing different concepts, styles, and\nsettings -- in which ProCreate achieves the highest sample diversity and\nfidelity. Furthermore, we show that ProCreate is effective at preventing\nreplicating training data in a large-scale evaluation using training text\nprompts. Code and FSCG-8 are available at\nhttps://github.com/Agentic-Learning-AI-Lab/procreate-diffusion-public. The\nproject page is available at https://procreate-diffusion.github.io.\n","authors":["Jack Lu","Ryan Teehan","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2408.02226v2.pdf","comment":"Accepted to ECCV 2024. Project page:\n  https://procreate-diffusion.github.io"},{"id":"http://arxiv.org/abs/2408.03404v1","updated":"2024-08-06T18:55:31Z","published":"2024-08-06T18:55:31Z","title":"Set2Seq Transformer: Learning Permutation Aware Set Representations of\n  Artistic Sequences","summary":"  We propose Set2Seq Transformer, a novel sequential multiple instance\narchitecture, that learns to rank permutation aware set representations of\nsequences. First, we illustrate that learning temporal position-aware\nrepresentations of discrete timesteps can greatly improve static visual\nmultiple instance learning methods that do not regard temporality and\nconcentrate almost exclusively on visual content analysis. We further\ndemonstrate the significant advantages of end-to-end sequential multiple\ninstance learning, integrating visual content and temporal information in a\nmultimodal manner. As application we focus on fine art analysis related tasks.\nTo that end, we show that our Set2Seq Transformer can leverage visual set and\ntemporal position-aware representations for modelling visual artists' oeuvres\nfor predicting artistic success. Finally, through extensive quantitative and\nqualitative evaluation using a novel dataset, WikiArt-Seq2Rank, and a visual\nlearning-to-rank downstream task, we show that our Set2Seq Transformer captures\nessential temporal information improving the performance of strong static and\nsequential multiple instance learning methods for predicting artistic success.\n","authors":["Athanasios Efthymiou","Stevan Rudinac","Monika Kackovic","Nachoem Wijnberg","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2408.03404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00448v2","updated":"2024-08-06T18:52:25Z","published":"2024-06-01T14:10:45Z","title":"Bilateral Guided Radiance Field Processing","summary":"  Neural Radiance Fields (NeRF) achieves unprecedented performance in\nsynthesizing novel view synthesis, utilizing multi-view consistency. When\ncapturing multiple inputs, image signal processing (ISP) in modern cameras will\nindependently enhance them, including exposure adjustment, color correction,\nlocal tone mapping, etc. While these processings greatly improve image quality,\nthey often break the multi-view consistency assumption, leading to \"floaters\"\nin the reconstructed radiance fields. To address this concern without\ncompromising visual aesthetics, we aim to first disentangle the enhancement by\nISP at the NeRF training stage and re-apply user-desired enhancements to the\nreconstructed radiance fields at the finishing stage. Furthermore, to make the\nre-applied enhancements consistent between novel views, we need to perform\nimaging signal processing in 3D space (i.e. \"3D ISP\"). For this goal, we adopt\nthe bilateral grid, a locally-affine model, as a generalized representation of\nISP processing. Specifically, we optimize per-view 3D bilateral grids with\nradiance fields to approximate the effects of camera pipelines for each input\nview. To achieve user-adjustable 3D finishing, we propose to learn a low-rank\n4D bilateral grid from a given single view edit, lifting photo enhancements to\nthe whole 3D scene. We demonstrate our approach can boost the visual quality of\nnovel view synthesis by effectively removing floaters and performing\nenhancements from user retouching. The source code and our data are available\nat: https://bilarfpro.github.io.\n","authors":["Yuehao Wang","Chaoyi Wang","Bingchen Gong","Tianfan Xue"],"pdf_url":"https://arxiv.org/pdf/2406.00448v2.pdf","comment":"SIGGRAPH (ACM TOG), 2024. Project page: https://bilarfpro.github.io"},{"id":"http://arxiv.org/abs/2407.19166v2","updated":"2024-08-06T18:52:04Z","published":"2024-07-27T04:37:16Z","title":"Revisit Self-supervised Depth Estimation with Local\n  Structure-from-Motion","summary":"  Both self-supervised depth estimation and Structure-from-Motion (SfM) recover\nscene depth from RGB videos. Despite sharing a similar objective, the two\napproaches are disconnected. Prior works of self-supervision backpropagate\nlosses defined within immediate neighboring frames. Instead of\nlearning-through-loss, this work proposes an alternative scheme by performing\nlocal SfM. First, with calibrated RGB or RGB-D images, we employ a depth and\ncorrespondence estimator to infer depthmaps and pair-wise correspondence maps.\nThen, a novel bundle-RANSAC-adjustment algorithm jointly optimizes camera poses\nand one depth adjustment for each depthmap. Finally, we fix camera poses and\nemploy a NeRF, however, without a neural network, for dense triangulation and\ngeometric verification. Poses, depth adjustments, and triangulated sparse\ndepths are our outputs. For the first time, we show self-supervision within $5$\nframes already benefits SoTA supervised depth and correspondence models. The\nproject page is held in the link (https://shngjz.github.io/SSfM.github.io/).\n","authors":["Shengjie Zhu","Xiaoming Liu"],"pdf_url":"https://arxiv.org/pdf/2407.19166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03393v1","updated":"2024-08-06T18:38:55Z","published":"2024-08-06T18:38:55Z","title":"Biomedical Image Segmentation: A Systematic Literature Review of Deep\n  Learning Based Object Detection Methods","summary":"  Biomedical image segmentation plays a vital role in diagnosis of diseases\nacross various organs. Deep learning-based object detection methods are\ncommonly used for such segmentation. There exists an extensive research in this\ntopic. However, there is no standard review on this topic. Existing surveys\noften lack a standardized approach or focus on broader segmentation techniques.\nIn this paper, we conducted a systematic literature review (SLR), collected and\nanalysed 148 articles that explore deep learning object detection methods for\nbiomedical image segmentation. We critically analyzed these methods, identified\nthe key challenges, and discussed the future directions. From the selected\narticles we extracted the results including the deep learning models, targeted\nimaging modalities, targeted diseases, and the metrics for the analysis of the\nmethods. The results have been presented in tabular and/or charted forms. The\nresults are presented in three major categories including two stage detection\nmodels, one stage detection models and point-based detection models. Each\narticle is individually analyzed along with its pros and cons. Finally, we\ndiscuss open challenges, potential benefits, and future research directions.\nThis SLR aims to provide the research community with a quick yet deeper\nunderstanding of these segmentation models, ultimately facilitating the\ndevelopment of more powerful solutions for biomedical image analysis.\n","authors":["Fazli Wahid","Yingliang Ma","Dawar Khan","Muhammad Aamir","Syed U. K. Bukhari"],"pdf_url":"https://arxiv.org/pdf/2408.03393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11645v2","updated":"2024-08-06T18:31:05Z","published":"2024-06-17T15:28:35Z","title":"SeamPose: Repurposing Seams as Capacitive Sensors in a Shirt for\n  Upper-Body Pose Tracking","summary":"  Seams are areas of overlapping fabric formed by stitching two or more pieces\nof fabric together in the cut-and-sew apparel manufacturing process. In\nSeamPose, we repurposed seams as capacitive sensors in a shirt for continuous\nupper-body pose estimation. Compared to previous all-textile motion-capturing\ngarments that place the electrodes on the clothing surface, our solution\nleverages existing seams inside of a shirt by machine-sewing insulated\nconductive threads over the seams. The unique invisibilities and placements of\nthe seams afford the sensing shirt to look and wear similarly as a conventional\nshirt while providing exciting pose-tracking capabilities. To validate this\napproach, we implemented a proof-of-concept untethered shirt with 8 capacitive\nsensing seams. With a 12-participant user study, our customized deep-learning\npipeline accurately estimates the relative (to the pelvis) upper-body 3D joint\npositions with a mean per joint position error (MPJPE) of 6.0 cm. SeamPose\nrepresents a step towards unobtrusive integration of smart clothing for\neveryday pose estimation.\n","authors":["Tianhong Catherine Yu","Manru Mary Zhang","Peter He","Chi-Jung Lee","Cassidy Cheesman","Saif Mahmud","Ruidong Zhang","François Guimbretière","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.11645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03388v1","updated":"2024-08-06T18:18:37Z","published":"2024-08-06T18:18:37Z","title":"A Non-negative VAE:the Generalized Gamma Belief Network","summary":"  The gamma belief network (GBN), often regarded as a deep topic model, has\ndemonstrated its potential for uncovering multi-layer interpretable latent\nrepresentations in text data. Its notable capability to acquire interpretable\nlatent factors is partially attributed to sparse and non-negative\ngamma-distributed latent variables. However, the existing GBN and its\nvariations are constrained by the linear generative model, thereby limiting\ntheir expressiveness and applicability. To address this limitation, we\nintroduce the generalized gamma belief network (Generalized GBN) in this paper,\nwhich extends the original linear generative model to a more expressive\nnon-linear generative model. Since the parameters of the Generalized GBN no\nlonger possess an analytic conditional posterior, we further propose an\nupward-downward Weibull inference network to approximate the posterior\ndistribution of the latent variables. The parameters of both the generative\nmodel and the inference network are jointly trained within the variational\ninference framework. Finally, we conduct comprehensive experiments on both\nexpressivity and disentangled representation learning tasks to evaluate the\nperformance of the Generalized GBN against state-of-the-art Gaussian\nvariational autoencoders serving as baselines.\n","authors":["Zhibin Duan","Tiansheng Wen","Muyao Wang","Bo Chen","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.03388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03361v1","updated":"2024-08-06T17:59:21Z","published":"2024-08-06T17:59:21Z","title":"GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards\n  General Medical AI","summary":"  Large Vision-Language Models (LVLMs) are capable of handling diverse data\ntypes such as imaging, text, and physiological signals, and can be applied in\nvarious fields. In the medical field, LVLMs have a high potential to offer\nsubstantial assistance for diagnosis and treatment. Before that, it is crucial\nto develop benchmarks to evaluate LVLMs' effectiveness in various medical\napplications. Current benchmarks are often built upon specific academic\nliterature, mainly focusing on a single domain, and lacking varying perceptual\ngranularities. Thus, they face specific challenges, including limited clinical\nrelevance, incomplete evaluations, and insufficient guidance for interactive\nLVLMs. To address these limitations, we developed the GMAI-MMBench, the most\ncomprehensive general medical AI benchmark with well-categorized data structure\nand multi-perceptual granularity to date. It is constructed from 285 datasets\nacross 39 medical image modalities, 18 clinical-related tasks, 18 departments,\nand 4 perceptual granularities in a Visual Question Answering (VQA) format.\nAdditionally, we implemented a lexical tree structure that allows users to\ncustomize evaluation tasks, accommodating various assessment needs and\nsubstantially supporting medical AI research and applications. We evaluated 50\nLVLMs, and the results show that even the advanced GPT-4o only achieves an\naccuracy of 52\\%, indicating significant room for improvement. Moreover, we\nidentified five key insufficiencies in current cutting-edge LVLMs that need to\nbe addressed to advance the development of better medical applications. We\nbelieve that GMAI-MMBench will stimulate the community to build the next\ngeneration of LVLMs toward GMAI.\n","authors":["Pengcheng Chen","Jin Ye","Guoan Wang","Yanjun Li","Zhongying Deng","Wei Li","Tianbin Li","Haodong Duan","Ziyan Huang","Yanzhou Su","Benyou Wang","Shaoting Zhang","Bin Fu","Jianfei Cai","Bohan Zhuang","Eric J Seibel","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.03361v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2408.03323v1","updated":"2024-08-06T17:58:29Z","published":"2024-08-06T17:58:29Z","title":"ClassiFIM: An Unsupervised Method To Detect Phase Transitions","summary":"  Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.\n","authors":["Victor Kasatkin","Evgeny Mozgunov","Nicholas Ezzell","Utkarsh Mishra","Itay Hen","Daniel Lidar"],"pdf_url":"https://arxiv.org/pdf/2408.03323v1.pdf","comment":"23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.21770v2","updated":"2024-08-06T17:57:41Z","published":"2024-07-31T17:46:51Z","title":"MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware\n  Experts","summary":"  We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)\narchitecture designed for pre-training mixed-modal, early-fusion language\nmodels. MoMa processes images and text in arbitrary sequences by dividing\nexpert modules into modality-specific groups. These groups exclusively process\ndesignated tokens while employing learned routing within each group to maintain\nsemantically informed adaptivity. Our empirical results reveal substantial\npre-training efficiency gains through this modality-specific parameter\nallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,\nfeaturing 4 text experts and 4 image experts, achieves impressive FLOPs\nsavings: 3.7x overall, with 2.6x for text and 5.2x for image processing\ncompared to a compute-equivalent dense baseline, measured by pre-training loss.\nThis outperforms the standard expert-choice MoE with 8 mixed-modal experts,\nwhich achieves 3x overall FLOPs savings (3x for text, 2.8x for image).\nCombining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs\nsavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination\nhurts performance in causal inference due to increased sensitivity to router\naccuracy. These results demonstrate MoMa's potential to significantly advance\nthe efficiency of mixed-modal, early-fusion language model pre-training, paving\nthe way for more resource-efficient and capable multimodal AI systems.\n","authors":["Xi Victoria Lin","Akshat Shrivastava","Liang Luo","Srinivasan Iyer","Mike Lewis","Gargi Gosh","Luke Zettlemoyer","Armen Aghajanyan"],"pdf_url":"https://arxiv.org/pdf/2407.21770v2.pdf","comment":"v2 -> update related work section"},{"id":"http://arxiv.org/abs/2408.03320v1","updated":"2024-08-06T17:55:58Z","published":"2024-08-06T17:55:58Z","title":"Hedge Fund Portfolio Construction Using PolyModel Theory and\n  iTransformer","summary":"  When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.\n","authors":["Siqiao Zhao","Zhikang Dong","Zeyu Cao","Raphael Douady"],"pdf_url":"https://arxiv.org/pdf/2408.03320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17403v2","updated":"2024-08-06T17:41:52Z","published":"2023-09-29T17:04:06Z","title":"Maximal Volume Matrix Cross Approximation for Image Compression and\n  Least Squares Solution","summary":"  We study the classic matrix cross approximation based on the maximal volume\nsubmatrices. Our main results consist of an improvement of the classic estimate\nfor matrix cross approximation and a greedy approach for finding the maximal\nvolume submatrices. More precisely, we present a new proof of the classic\nestimate of the inequality with an improved constant. Also, we present a family\nof greedy maximal volume algorithms to improve the computational efficiency of\nmatrix cross approximation. The proposed algorithms are shown to have\ntheoretical guarantees of convergence. Finally, we present two applications:\nimage compression and the least squares approximation of continuous functions.\nOur numerical results at the end of the paper demonstrate the effective\nperformance of our approach.\n","authors":["Kenneth Allen","Ming-Jun Lai","Zhaiming Shen"],"pdf_url":"https://arxiv.org/pdf/2309.17403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.00035v4","updated":"2024-08-06T17:36:06Z","published":"2024-01-08T12:19:46Z","title":"Robustness Assessment of a Runway Object Classifier for Safe Aircraft\n  Taxiing","summary":"  As deep neural networks (DNNs) are becoming the prominent solution for many\ncomputational problems, the aviation industry seeks to explore their potential\nin alleviating pilot workload and in improving operational safety. However, the\nuse of DNNs in this type of safety-critical applications requires a thorough\ncertification process. This need can be addressed through formal verification,\nwhich provides rigorous assurances -- e.g.,~by proving the absence of certain\nmispredictions. In this case-study paper, we demonstrate this process using an\nimage-classifier DNN currently under development at Airbus and intended for use\nduring the aircraft taxiing phase. We use formal methods to assess this DNN's\nrobustness to three common image perturbation types: noise, brightness and\ncontrast, and some of their combinations. This process entails multiple\ninvocations of the underlying verifier, which might be computationally\nexpensive; and we therefore propose a method that leverages the monotonicity of\nthese robustness properties, as well as the results of past verification\nqueries, in order to reduce the overall number of verification queries required\nby nearly 60%. Our results provide an indication of the level of robustness\nachieved by the DNN classifier under study, and indicate that it is\nconsiderably more vulnerable to noise than to brightness or contrast\nperturbations.\n","authors":["Yizhak Elboher","Raya Elsaleh","Omri Isac","Mélanie Ducoffe","Audrey Galametz","Guillaume Povéda","Ryma Boumazouza","Noémie Cohen","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2402.00035v4.pdf","comment":"This is a preprint version of the paper in the proceedings of 43rd\n  Digital Avionics Systems Conference (DASC)"},{"id":"http://arxiv.org/abs/2408.03314v1","updated":"2024-08-06T17:35:05Z","published":"2024-08-06T17:35:05Z","title":"Scaling LLM Test-Time Compute Optimally can be More Effective than\n  Scaling Model Parameters","summary":"  Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.\n","authors":["Charlie Snell","Jaehoon Lee","Kelvin Xu","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2408.03314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03720v3","updated":"2024-08-06T17:26:55Z","published":"2023-10-05T17:40:09Z","title":"SteP: Stacked LLM Policies for Web Actions","summary":"  Performing tasks on the web presents fundamental challenges to large language\nmodels (LLMs), including combinatorially large open-world tasks and variations\nacross web interfaces. Simply specifying a large prompt to handle all possible\nbehaviors and states is extremely complex, and results in behavior leaks\nbetween unrelated behaviors. Decomposition to distinct policies can address\nthis challenge, but requires carefully handing off control between policies. We\npropose Stacked LLM Policies for Web Actions (SteP), an approach to dynamically\ncompose policies to solve a diverse set of web tasks. SteP defines a Markov\nDecision Process where the state is a stack of policies representing the\ncontrol state, i.e., the chain of policy calls. Unlike traditional methods that\nare restricted to static hierarchies, SteP enables dynamic control that adapts\nto the complexity of the task. We evaluate SteP against multiple baselines and\nweb environments including WebArena, MiniWoB++, and a CRM. On WebArena, SteP\nimproves (14.9\\% to 33.5\\%) over SOTA that use GPT-4 policies, while on\nMiniWob++, SteP is competitive with prior works while using significantly less\ndata. Our code and data are available at\nhttps://asappresearch.github.io/webagents-step.\n","authors":["Paloma Sodhi","S. R. K. Branavan","Yoav Artzi","Ryan McDonald"],"pdf_url":"https://arxiv.org/pdf/2310.03720v3.pdf","comment":"Accepted at Conference on Language Modeling (COLM) 2024. 30 pages, 15\n  figures"},{"id":"http://arxiv.org/abs/2408.03307v1","updated":"2024-08-06T17:16:10Z","published":"2024-08-06T17:16:10Z","title":"Pre-training and in-context learning IS Bayesian inference a la De\n  Finetti","summary":"  Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.\n","authors":["Naimeng Ye","Hanming Yang","Andrew Siah","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2408.03307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03304v1","updated":"2024-08-06T17:11:40Z","published":"2024-08-06T17:11:40Z","title":"Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks","summary":"  Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.\n","authors":["Rafael Sterzinger","Christian Stippel","Robert Sablatnig"],"pdf_url":"https://arxiv.org/pdf/2408.03304v1.pdf","comment":"16 pages, accepted at ICPR2024"},{"id":"http://arxiv.org/abs/2304.05339v2","updated":"2024-08-06T17:09:59Z","published":"2023-04-11T16:58:59Z","title":"Deep-learning Assisted Detection and Quantification of (oo)cysts of\n  Giardia and Cryptosporidium on Smartphone Microscopy Images","summary":"  The consumption of microbial-contaminated food and water is responsible for\nthe deaths of millions of people annually. Smartphone-based microscopy systems\nare portable, low-cost, and more accessible alternatives for the detection of\nGiardia and Cryptosporidium than traditional brightfield microscopes. However,\nthe images from smartphone microscopes are noisier and require manual cyst\nidentification by trained technicians, usually unavailable in resource-limited\nsettings. Automatic detection of (oo)cysts using deep-learning-based object\ndetection could offer a solution for this limitation. We evaluate the\nperformance of four state-of-the-art object detectors to detect (oo)cysts of\nGiardia and Cryptosporidium on a custom dataset that includes both smartphone\nand brightfield microscopic images from vegetable samples. Faster RCNN,\nRetinaNet, You Only Look Once (YOLOv8s), and Deformable Detection Transformer\n(Deformable DETR) deep-learning models were employed to explore their efficacy\nand limitations. Our results show that while the deep-learning models perform\nbetter with the brightfield microscopy image dataset than the smartphone\nmicroscopy image dataset, the smartphone microscopy predictions are still\ncomparable to the prediction performance of non-experts. Also, we publicly\nrelease brightfield and smartphone microscopy datasets with the benchmark\nresults for the detection of Giardia and Cryptosporidium, independently\ncaptured on reference (or standard lab setting) and vegetable samples. Our code\nand dataset are available at\nhttps://github.com/naamiinepal/smartphone_microscopy and\nhttps://doi.org/10.5281/zenodo.7813183, respectively.\n","authors":["Suprim Nakarmi","Sanam Pudasaini","Safal Thapaliya","Pratima Upretee","Retina Shrestha","Basant Giri","Bhanu Bhakta Neupane","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2304.05339v2.pdf","comment":"21 pages (including supplementary information), 5 figures, 7 tables,\n  Accepted for publication at the Journal of Machine Learning for Biomedical\n  Imaging (MELBA) https://melba-journal.org/2024:014"},{"id":"http://arxiv.org/abs/2408.03290v1","updated":"2024-08-06T16:39:42Z","published":"2024-08-06T16:39:42Z","title":"SARA: Singular-Value Based Adaptive Low-Rank Adaption","summary":"  With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.\n","authors":["Jihao Gu","Shuai Chen","Zelin Wang","Yibo Zhang","Ping Gong"],"pdf_url":"https://arxiv.org/pdf/2408.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08871v3","updated":"2024-08-06T16:38:41Z","published":"2024-02-14T00:35:10Z","title":"Position: Topological Deep Learning is the New Frontier for Relational\n  Learning","summary":"  Topological deep learning (TDL) is a rapidly evolving field that uses\ntopological features to understand and design deep learning models. This paper\nposits that TDL is the new frontier for relational learning. TDL may complement\ngraph representation learning and geometric deep learning by incorporating\ntopological concepts, and can thus provide a natural choice for various machine\nlearning settings. To this end, this paper discusses open problems in TDL,\nranging from practical benefits to theoretical foundations. For each problem,\nit outlines potential solutions and future research opportunities. At the same\ntime, this paper serves as an invitation to the scientific community to\nactively participate in TDL research to unlock the potential of this emerging\nfield.\n","authors":["Theodore Papamarkou","Tolga Birdal","Michael Bronstein","Gunnar Carlsson","Justin Curry","Yue Gao","Mustafa Hajij","Roland Kwitt","Pietro Liò","Paolo Di Lorenzo","Vasileios Maroulas","Nina Miolane","Farzana Nasrin","Karthikeyan Natesan Ramamurthy","Bastian Rieck","Simone Scardapane","Michael T. Schaub","Petar Veličković","Bei Wang","Yusu Wang","Guo-Wei Wei","Ghada Zamzmi"],"pdf_url":"https://arxiv.org/pdf/2402.08871v3.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024"},{"id":"http://arxiv.org/abs/2408.03287v1","updated":"2024-08-06T16:35:25Z","published":"2024-08-06T16:35:25Z","title":"Malicious Internet Entity Detection Using Local Graph Inference","summary":"  Detection of malicious behavior in a large network is a challenging problem\nfor machine learning in computer security, since it requires a model with high\nexpressive power and scalable inference. Existing solutions struggle to achieve\nthis feat -- current cybersec-tailored approaches are still limited in\nexpressivity, and methods successful in other domains do not scale well for\nlarge volumes of data, rendering frequent retraining impossible. This work\nproposes a new perspective for learning from graph data that is modeling\nnetwork entity interactions as a large heterogeneous graph. High expressivity\nof the method is achieved with neural network architecture HMILnet that\nnaturally models this type of data and provides theoretical guarantees. The\nscalability is achieved by pursuing local graph inference, i.e., classifying\nindividual vertices and their neighborhood as independent samples. Our\nexperiments exhibit improvement over the state-of-the-art Probabilistic Threat\nPropagation (PTP) algorithm, show a further threefold accuracy improvement when\nadditional data is used, which is not possible with the PTP algorithm, and\ndemonstrate the generalization capabilities of the method to new, previously\nunseen entities.\n","authors":["Simon Mandlik","Tomas Pevny","Vaclav Smidl","Lukas Bajer"],"pdf_url":"https://arxiv.org/pdf/2408.03287v1.pdf","comment":"A preprint. Full publication:\n  https://ieeexplore.ieee.org/document/10418120"},{"id":"http://arxiv.org/abs/2402.00809v5","updated":"2024-08-06T16:32:38Z","published":"2024-02-01T17:45:26Z","title":"Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI","summary":"  In the current landscape of deep learning research, there is a predominant\nemphasis on achieving high predictive accuracy in supervised tasks involving\nlarge image and language datasets. However, a broader perspective reveals a\nmultitude of overlooked metrics, tasks, and data types, such as uncertainty,\nactive and continual learning, and scientific data, that demand attention.\nBayesian deep learning (BDL) constitutes a promising avenue, offering\nadvantages across these diverse settings. This paper posits that BDL can\nelevate the capabilities of deep learning. It revisits the strengths of BDL,\nacknowledges existing challenges, and highlights some exciting research avenues\naimed at addressing these obstacles. Looking ahead, the discussion focuses on\npossible ways to combine large-scale foundation models with BDL to unlock their\nfull potential.\n","authors":["Theodore Papamarkou","Maria Skoularidou","Konstantina Palla","Laurence Aitchison","Julyan Arbel","David Dunson","Maurizio Filippone","Vincent Fortuin","Philipp Hennig","José Miguel Hernández-Lobato","Aliaksandr Hubin","Alexander Immer","Theofanis Karaletsos","Mohammad Emtiyaz Khan","Agustinus Kristiadi","Yingzhen Li","Stephan Mandt","Christopher Nemeth","Michael A. Osborne","Tim G. J. Rudner","David Rügamer","Yee Whye Teh","Max Welling","Andrew Gordon Wilson","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.00809v5.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024"},{"id":"http://arxiv.org/abs/2408.03281v1","updated":"2024-08-06T16:28:30Z","published":"2024-08-06T16:28:30Z","title":"StructEval: Deepen and Broaden Large Language Model Assessment via\n  Structured Evaluation","summary":"  Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.\n","authors":["Boxi Cao","Mengjie Ren","Hongyu Lin","Xianpei Han","Feng Zhang","Junfeng Zhan","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2408.03281v1.pdf","comment":"ACL 2024;Benchmark at https://github.com/c-box/StructEval;Leaderboard\n  at https://huggingface.co/spaces/Bowieee/StructEval_leaderboard"},{"id":"http://arxiv.org/abs/2408.03274v1","updated":"2024-08-06T16:17:51Z","published":"2024-08-06T16:17:51Z","title":"Compress and Compare: Interactively Evaluating Efficiency and Behavior\n  Across ML Model Compression Experiments","summary":"  To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.\n","authors":["Angie Boggust","Venkatesh Sivaraman","Yannick Assogba","Donghao Ren","Dominik Moritz","Fred Hohman"],"pdf_url":"https://arxiv.org/pdf/2408.03274v1.pdf","comment":"Accepted to VIS 2024"},{"id":"http://arxiv.org/abs/2312.03179v4","updated":"2024-08-06T16:11:29Z","published":"2023-12-05T23:05:36Z","title":"CaloQVAE : Simulating high-energy particle-calorimeter interactions\n  using hybrid quantum-classical generative models","summary":"  The Large Hadron Collider's high luminosity era presents major computational\nchallenges in the analysis of collision events. Large amounts of Monte Carlo\n(MC) simulation will be required to constrain the statistical uncertainties of\nthe simulated datasets below these of the experimental data. Modelling of\nhigh-energy particles propagating through the calorimeter section of the\ndetector is the most computationally intensive MC simulation task. We introduce\na technique combining recent advancements in generative models and quantum\nannealing for fast and efficient simulation of high-energy particle-calorimeter\ninteractions.\n","authors":["Sehmimul Hoque","Hao Jia","Abhishek Abhishek","Mojde Fadaie","J. Quetzalcoatl Toledo-Marín","Tiago Vale","Roger G. Melko","Maximilian Swiatlowski","Wojciech T. Fedorko"],"pdf_url":"https://arxiv.org/pdf/2312.03179v4.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.03559v3","updated":"2024-08-06T15:56:31Z","published":"2022-12-07T10:19:39Z","title":"GraphLearner: Graph Node Clustering with Fully Learnable Augmentation","summary":"  Contrastive deep graph clustering (CDGC) leverages the power of contrastive\nlearning to group nodes into different clusters. The quality of contrastive\nsamples is crucial for achieving better performance, making augmentation\ntechniques a key factor in the process. However, the augmentation samples in\nexisting methods are always predefined by human experiences, and agnostic from\nthe downstream task clustering, thus leading to high human resource costs and\npoor performance. To overcome these limitations, we propose a Graph Node\nClustering with Fully Learnable Augmentation, termed GraphLearner. It\nintroduces learnable augmentors to generate high-quality and task-specific\naugmented samples for CDGC. GraphLearner incorporates two learnable augmentors\nspecifically designed for capturing attribute and structural information.\nMoreover, we introduce two refinement matrices, including the high-confidence\npseudo-label matrix and the cross-view sample similarity matrix, to enhance the\nreliability of the learned affinity matrix. During the training procedure, we\nnotice the distinct optimization goals for training learnable augmentors and\ncontrastive learning networks. In other words, we should both guarantee the\nconsistency of the embeddings as well as the diversity of the augmented\nsamples. To address this challenge, we propose an adversarial learning\nmechanism within our method. Besides, we leverage a two-stage training strategy\nto refine the high-confidence matrices. Extensive experimental results on six\nbenchmark datasets validate the effectiveness of GraphLearner.The code and\nappendix of GraphLearner are available at\nhttps://github.com/xihongyang1999/GraphLearner on Github.\n","authors":["Xihong Yang","Erxue Min","Ke Liang","Yue Liu","Siwei Wang","Sihang Zhou","Huijun Wu","Xinwang Liu","En Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.03559v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10799v2","updated":"2024-08-06T15:33:20Z","published":"2024-05-17T14:10:24Z","title":"Training Compute Thresholds: Features and Functions in AI Regulation","summary":"  Regulators in the US and EU are using thresholds based on training\ncompute--the number of computational operations used in training--to identify\ngeneral-purpose artificial intelligence (GPAI) models that may pose risks of\nlarge-scale societal harm. We argue that training compute currently is the most\nsuitable metric to identify GPAI models that deserve regulatory oversight and\nfurther scrutiny. Training compute correlates with model capabilities and\nrisks, is quantifiable, can be measured early in the AI lifecycle, and can be\nverified by external actors, among other advantageous features. These features\nmake compute thresholds considerably more suitable than other proposed metrics\nto serve as an initial filter to trigger additional regulatory requirements and\nscrutiny. However, training compute is an imperfect proxy for risk. As such,\ncompute thresholds should not be used in isolation to determine appropriate\nmitigation measures. Instead, they should be used to detect potentially risky\nGPAI models that warrant regulatory oversight, such as through notification\nrequirements, and further scrutiny, such as via model evaluations and risk\nassessments, the results of which may inform which mitigation measures are\nappropriate. In fact, this appears largely consistent with how compute\nthresholds are used today. As GPAI technology and market structures evolve,\nregulators should update compute thresholds and complement them with other\nmetrics into regulatory review processes.\n","authors":["Lennart Heim","Leonie Koessler"],"pdf_url":"https://arxiv.org/pdf/2405.10799v2.pdf","comment":"v2: Major revision of earlier working paper"},{"id":"http://arxiv.org/abs/2405.06605v3","updated":"2024-08-06T15:20:00Z","published":"2024-05-10T17:12:48Z","title":"Calo-VQ: Vector-Quantized Two-Stage Generative Model in Calorimeter\n  Simulation","summary":"  We introduce a novel machine learning method developed for the fast\nsimulation of calorimeter detector response, adapting vector-quantized\nvariational autoencoder (VQ-VAE). Our model adopts a two-stage generation\nstrategy: initially compressing geometry-aware calorimeter data into a discrete\nlatent space, followed by the application of a sequence model to learn and\ngenerate the latent tokens. Extensive experimentation on the Calo-challenge\ndataset underscores the efficiency of our approach, showcasing a remarkable\nimprovement in the generation speed compared with conventional method by a\nfactor of 2000. Remarkably, our model achieves the generation of calorimeter\nshowers within milliseconds. Furthermore, comprehensive quantitative\nevaluations across various metrics are performed to validate physics\nperformance of generation.\n","authors":["Qibin Liu","Chase Shimmin","Xiulong Liu","Eli Shlizerman","Shu Li","Shih-Chieh Hsu"],"pdf_url":"https://arxiv.org/pdf/2405.06605v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.08354v3","updated":"2024-08-06T15:14:36Z","published":"2023-04-17T15:16:10Z","title":"Tool Learning with Foundation Models","summary":"  Humans possess an extraordinary ability to create and utilize tools, allowing\nthem to overcome physical limitations and explore new frontiers. With the\nadvent of foundation models, AI systems have the potential to be equally adept\nin tool use as humans. This paradigm, i.e., tool learning with foundation\nmodels, combines the strengths of specialized tools and foundation models to\nachieve enhanced accuracy, efficiency, and automation in problem-solving.\nDespite its immense potential, there is still a lack of a comprehensive\nunderstanding of key challenges, opportunities, and future endeavors in this\nfield. To this end, we present a systematic investigation of tool learning in\nthis paper. We first introduce the background of tool learning, including its\ncognitive origins, the paradigm shift of foundation models, and the\ncomplementary roles of tools and models. Then we recapitulate existing tool\nlearning research into tool-augmented and tool-oriented learning. We formulate\na general tool learning framework: starting from understanding the user\ninstruction, models should learn to decompose a complex task into several\nsubtasks, dynamically adjust their plan through reasoning, and effectively\nconquer each sub-task by selecting appropriate tools. We also discuss how to\ntrain models for improved tool-use capabilities and facilitate the\ngeneralization in tool learning. Considering the lack of a systematic tool\nlearning evaluation in prior works, we experiment with 18 representative tools\nand show the potential of current foundation models in skillfully utilizing\ntools. Finally, we discuss several open problems that require further\ninvestigation for tool learning. In general, we hope this paper could inspire\nfuture research in integrating tools with foundation models.\n","authors":["Yujia Qin","Shengding Hu","Yankai Lin","Weize Chen","Ning Ding","Ganqu Cui","Zheni Zeng","Yufei Huang","Chaojun Xiao","Chi Han","Yi Ren Fung","Yusheng Su","Huadong Wang","Cheng Qian","Runchu Tian","Kunlun Zhu","Shihao Liang","Xingyu Shen","Bokai Xu","Zhen Zhang","Yining Ye","Bowen Li","Ziwei Tang","Jing Yi","Yuzhang Zhu","Zhenning Dai","Lan Yan","Xin Cong","Yaxi Lu","Weilin Zhao","Yuxiang Huang","Junxi Yan","Xu Han","Xian Sun","Dahai Li","Jason Phang","Cheng Yang","Tongshuang Wu","Heng Ji","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2304.08354v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17216v2","updated":"2024-08-06T15:08:44Z","published":"2024-07-24T12:15:59Z","title":"An Adaptive Second-order Method for a Class of Nonconvex Nonsmooth\n  Composite Optimization","summary":"  This paper explores a specific type of nonconvex sparsity-promoting\nregularization problems, namely those involving $\\ell_p$-norm regularization,\nin conjunction with a twice continuously differentiable loss function. We\npropose a novel second-order algorithm designed to effectively address this\nclass of challenging nonconvex and nonsmooth problems, showcasing several\ninnovative features: (i) The use of an alternating strategy to solve a\nreweighted $\\ell_1$ regularized subproblem and the subspace approximate Newton\nstep. (ii) The reweighted $\\ell_1$ regularized subproblem relies on a convex\napproximation to the nonconvex regularization term, enabling a closed-form\nsolution characterized by the soft-thresholding operator. This feature allows\nour method to be applied to various nonconvex regularization problems. (iii)\nOur algorithm ensures that the iterates maintain their sign values and that\nnonzero components are kept away from 0 for a sufficient number of iterations,\neventually transitioning to a perturbed Newton method. (iv) We provide\ntheoretical guarantees of global convergence, local superlinear convergence in\nthe presence of the Kurdyka-\\L ojasiewicz (KL) property, and local quadratic\nconvergence when employing the exact Newton step in our algorithm. We also\nshowcase the effectiveness of our approach through experiments on a diverse set\nof model prediction problems.\n","authors":["Hao Wang","Xiangyu Yang","Yichen Zhu"],"pdf_url":"https://arxiv.org/pdf/2407.17216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16495v2","updated":"2024-08-06T15:03:50Z","published":"2024-04-25T10:40:49Z","title":"T-Explainer: A Model-Agnostic Explainability Framework Based on\n  Gradients","summary":"  The development of machine learning applications has increased significantly\nin recent years, motivated by the remarkable ability of learning-powered\nsystems to discover and generalize intricate patterns hidden in massive\ndatasets. Modern learning models, while powerful, often have a level of\ncomplexity that renders them opaque black boxes, resulting in a notable lack of\ntransparency that hinders our ability to decipher their reasoning. Opacity\nchallenges the interpretability and practical application of machine learning,\nespecially in critical domains where understanding the underlying reasons is\nessential for informed decision-making. Explainable Artificial Intelligence\n(XAI) rises to address that challenge, unraveling the complexity of black boxes\nby providing elucidating explanations. Among the various XAI approaches,\nfeature attribution/importance stands out for its capacity to delineate the\nsignificance of input features in the prediction process. However, most\nexisting attribution methods have limitations, such as instability, when\ndivergent explanations may result from similar or even the same instance. This\nwork introduces T-Explainer, a novel local additive attribution explainer based\non Taylor expansion. It has desirable properties, such as local accuracy and\nconsistency, making T-Explainer stable over multiple runs. We demonstrate\nT-Explainer's effectiveness in quantitative benchmark experiments against\nwell-known attribution methods. Additionally, we provide several tools to\nevaluate and visualize explanations, turning T-Explainer into a comprehensive\nXAI framework.\n","authors":["Evandro S. Ortigossa","Fábio F. Dias","Brian Barr","Claudio T. Silva","Luis Gustavo Nonato"],"pdf_url":"https://arxiv.org/pdf/2404.16495v2.pdf","comment":"16 pages -- 2 figures and 20 tables -- Under review. This work has\n  been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2407.13605v2","updated":"2024-08-06T14:55:04Z","published":"2024-07-18T15:44:23Z","title":"Physics-guided Active Sample Reweighting for Urban Flow Prediction","summary":"  Urban flow prediction is a spatio-temporal modeling task that estimates the\nthroughput of transportation services like buses, taxis, and ride-sharing,\nwhere data-driven models have become the most popular solution in the past\ndecade. Meanwhile, the implicitly learned mapping between historical\nobservations to the prediction targets tend to over-simplify the dynamics of\nreal-world urban flows, leading to suboptimal predictions. Some recent\nspatio-temporal prediction solutions bring remedies with the notion of\nphysics-guided machine learning (PGML), which describes spatio-temporal data\nwith nuanced and principled physics laws, thus enhancing both the prediction\naccuracy and interpretability. However, these spatio-temporal PGML methods are\nbuilt upon a strong assumption that the observed data fully conforms to the\ndifferential equations that define the physical system, which can quickly\nbecome ill-posed in urban flow prediction tasks. The observed urban flow data,\nespecially when sliced into time-dependent snapshots to facilitate predictions,\nis typically incomplete and sparse, and prone to inherent noise incurred in the\ncollection process. As a result, such physical inconsistency between the data\nand PGML model significantly limits the predictive power and robustness of the\nsolution. Moreover, due to the interval-based predictions and intermittent\nnature of data filing in many transportation services, the instantaneous\ndynamics of urban flows can hardly be captured, rendering differential\nequation-based continuous modeling a loose fit for this setting. To overcome\nthe challenges, we develop a discretized physics-guided network (PN), and\npropose a data-aware framework Physics-guided Active Sample Reweighting\n(P-GASR) to enhance PN. Experimental results in four real-world datasets\ndemonstrate that our method achieves state-of-the-art performance with a\ndemonstrable improvement in robustness.\n","authors":["Wei Jiang","Tong Chen","Guanhua Ye","Wentao Zhang","Lizhen Cui","Zi Huang","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2407.13605v2.pdf","comment":"This paper is accepted by Proceedings of the 33nd ACM International\n  Conference on Information and Knowledge Management (CIKM '24)"},{"id":"http://arxiv.org/abs/2408.03236v1","updated":"2024-08-06T14:48:34Z","published":"2024-08-06T14:48:34Z","title":"Analysis of Partially-Calibrated Sparse Subarrays for Direction Finding\n  with Extended Degrees of Freedom","summary":"  This paper investigates the problem of direction-of-arrival (DOA) estimation\nusing multiple partially-calibrated sparse subarrays. In particular, we present\nthe Generalized Coarray Multiple Signal Classification (GCA-MUSIC) DOA\nestimation algorithm to scenarios with partially-calibrated sparse subarrays.\nThe proposed GCA-MUSIC algorithm exploits the difference coarray for each\nsubarray, followed by a specific pseudo-spectrum merging rule that is based on\nthe intersection of the signal subspaces associated to each subarray. This rule\nassumes that there is no a priori knowledge about the cross-covariance between\nsubarrays. In that way, only the second-order statistics of each subarray are\nused to estimate the directions with increased degrees of freedom, i.e., the\nestimation procedure preserves the coarray Multiple Signal Classification and\nsparse arrays properties to estimate more sources than the number of physical\nsensors in each subarray. Numerical simulations show that the proposed\nGCA-MUSIC has better performance than other similar strategies.\n","authors":["W. S. Leite","R. C. de Lamare"],"pdf_url":"https://arxiv.org/pdf/2408.03236v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.03223v1","updated":"2024-08-06T14:36:29Z","published":"2024-08-06T14:36:29Z","title":"Don't Think It Twice: Exploit Shift Invariance for Efficient Online\n  Streaming Inference of CNNs","summary":"  Deep learning time-series processing often relies on convolutional neural\nnetworks with overlapping windows. This overlap allows the network to produce\nan output faster than the window length. However, it introduces additional\ncomputations. This work explores the potential to optimize computational\nefficiency during inference by exploiting convolution's shift-invariance\nproperties to skip the calculation of layer activations between successive\noverlapping windows. Although convolutions are shift-invariant, zero-padding\nand pooling operations, widely used in such networks, are not efficient and\ncomplicate efficient streaming inference. We introduce StreamiNNC, a strategy\nto deploy Convolutional Neural Networks for online streaming inference. We\nexplore the adverse effects of zero padding and pooling on the accuracy of\nstreaming inference, deriving theoretical error upper bounds for pooling during\nstreaming. We address these limitations by proposing signal padding and pooling\nalignment and provide guidelines for designing and deploying models for\nStreamiNNC. We validate our method in simulated data and on three real-world\nbiomedical signal processing applications. StreamiNNC achieves a low deviation\nbetween streaming output and normal inference for all three networks (2.03 -\n3.55% NRMSE). This work demonstrates that it is possible to linearly speed up\nthe inference of streaming CNNs processing overlapping windows, negating the\nadditional computation typically incurred by overlapping windows.\n","authors":["Christodoulos Kechris","Jonathan Dan","Jose Miranda","David Atienza"],"pdf_url":"https://arxiv.org/pdf/2408.03223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09146v4","updated":"2024-08-06T14:30:52Z","published":"2024-02-14T12:55:28Z","title":"ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural\n  Networks","summary":"  In this paper, we present a novel framework for enhancing the performance of\nQuanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional\nlayers and addressing the critical challenges associated with them. Traditional\nquanvolutional layers, although beneficial for feature extraction, have largely\nbeen static, offering limited adaptability. Unlike state-of-the-art, our\nresearch overcomes this limitation by enabling training within these layers,\nsignificantly increasing the flexibility and potential of QuNNs. However, the\nintroduction of multiple trainable quanvolutional layers induces complexities\nin gradient-based optimization, primarily due to the difficulty in accessing\ngradients across these layers. To resolve this, we propose a novel\narchitecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging\nthe concept of residual learning, which facilitates the flow of gradients by\nadding skip connections between layers. By inserting residual blocks between\nquanvolutional layers, we ensure enhanced gradient access throughout the\nnetwork, leading to improved training performance. Moreover, we provide\nempirical evidence on the strategic placement of these residual blocks within\nQuNNs. Through extensive experimentation, we identify an efficient\nconfiguration of residual blocks, which enables gradients across all the layers\nin the network that eventually results in efficient training. Our findings\nsuggest that the precise location of residual blocks plays a crucial role in\nmaximizing the performance gains in QuNNs. Our results mark a substantial step\nforward in the evolution of quantum deep learning, offering new avenues for\nboth theoretical development and practical quantum computing applications.\n","authors":["Muhammad Kashif","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2402.09146v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.05530v2","updated":"2024-08-06T14:30:31Z","published":"2024-04-08T13:59:02Z","title":"Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data","summary":"  Reinforcement Learning from Human Feedback (RLHF) is a popular method for\naligning Language Models (LM) with human values and preferences. RLHF requires\na large number of preference pairs as training data, which are often used in\nboth the Supervised Fine-Tuning and Reward Model training and therefore\npublicly available datasets are commonly used. In this work, we study to what\nextent a malicious actor can manipulate the LMs generations by poisoning the\npreferences, i.e., injecting poisonous preference pairs into these datasets and\nthe RLHF training process. We propose strategies to build poisonous preference\npairs and test their performance by poisoning two widely used preference\ndatasets. Our results show that preference poisoning is highly effective:\ninjecting a small amount of poisonous data (1-5\\% of the original dataset), we\ncan effectively manipulate the LM to generate a target entity in a target\nsentiment (positive or negative). The findings from our experiments also shed\nlight on strategies to defend against the preference poisoning attack.\n","authors":["Tim Baumgärtner","Yang Gao","Dana Alon","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2404.05530v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03220v1","updated":"2024-08-06T14:26:09Z","published":"2024-08-06T14:26:09Z","title":"Masked Random Noise for Communication Efficient Federaetd Learning","summary":"  Federated learning is a promising distributed training paradigm that\neffectively safeguards data privacy. However, it may involve significant\ncommunication costs, which hinders training efficiency. In this paper, we aim\nto enhance communication efficiency from a new perspective. Specifically, we\nrequest the distributed clients to find optimal model updates relative to\nglobal model parameters within predefined random noise. For this purpose, we\npropose Federated Masked Random Noise (FedMRN), a novel framework that enables\nclients to learn a 1-bit mask for each model parameter and apply masked random\nnoise (i.e., the Hadamard product of random noise and masks) to represent model\nupdates. To make FedMRN feasible, we propose an advanced mask training\nstrategy, called progressive stochastic masking (PSM). After local training,\neach client only need to transmit local masks and a random seed to the server.\nAdditionally, we provide theoretical guarantees for the convergence of FedMRN\nunder both strongly convex and non-convex assumptions. Extensive experiments\nare conducted on four popular datasets. The results show that FedMRN exhibits\nsuperior convergence speed and test accuracy compared to relevant baselines,\nwhile attaining a similar level of accuracy as FedAvg.\n","authors":["Shiwei Li","Yingyi Cheng","Haozhao Wang","Xing Tang","Shijie Xu","Weihong Luo","Yuhua Li","Dugang Liu","Xiuqiang He","and Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2408.03220v1.pdf","comment":"Accepted by MM 2024"},{"id":"http://arxiv.org/abs/2408.03219v1","updated":"2024-08-06T14:25:23Z","published":"2024-08-06T14:25:23Z","title":"Learning to Learn without Forgetting using Attention","summary":"  Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.\n","authors":["Anna Vettoruzzo","Joaquin Vanschoren","Mohamed-Rafik Bouguelia","Thorsteinn Rögnvaldsson"],"pdf_url":"https://arxiv.org/pdf/2408.03219v1.pdf","comment":"Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024"},{"id":"http://arxiv.org/abs/2408.03215v1","updated":"2024-08-06T14:19:06Z","published":"2024-08-06T14:19:06Z","title":"FedBAT: Communication-Efficient Federated Learning via Learnable\n  Binarization","summary":"  Federated learning is a promising distributed machine learning paradigm that\ncan effectively exploit large-scale data without exposing users' privacy.\nHowever, it may incur significant communication overhead, thereby potentially\nimpairing the training efficiency. To address this challenge, numerous studies\nsuggest binarizing the model updates. Nonetheless, traditional methods usually\nbinarize model updates in a post-training manner, resulting in significant\napproximation errors and consequent degradation in model accuracy. To this end,\nwe propose Federated Binarization-Aware Training (FedBAT), a novel framework\nthat directly learns binary model updates during the local training process,\nthus inherently reducing the approximation errors. FedBAT incorporates an\ninnovative binarization operator, along with meticulously designed derivatives\nto facilitate efficient learning. In addition, we establish theoretical\nguarantees regarding the convergence of FedBAT. Extensive experiments are\nconducted on four popular datasets. The results show that FedBAT significantly\naccelerates the convergence and exceeds the accuracy of baselines by up to 9\\%,\neven surpassing that of FedAvg in some cases.\n","authors":["Shiwei Li","Wenchao Xu","Haozhao Wang","Xing Tang","Yining Qi","Shijie Xu","Weihong Luo","Yuhua Li","Xiuqiang He","Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2408.03215v1.pdf","comment":"Accepted by ICML 2024"},{"id":"http://arxiv.org/abs/2405.11647v3","updated":"2024-08-06T14:12:26Z","published":"2024-05-19T18:57:25Z","title":"Hummer: Towards Limited Competitive Preference Dataset","summary":"  Preference datasets are essential for incorporating human preferences into\npre-trained language models, playing a key role in the success of Reinforcement\nLearning from Human Feedback. However, these datasets often demonstrate\nconflicting alignment objectives, leading to increased vulnerability to\njailbreak attacks and challenges in adapting downstream tasks to prioritize\nspecific alignment objectives without negatively impacting others. In this\nwork, we introduce a novel statistical metric, Alignment Dimension Conflict, to\nquantify the degree of conflict within preference datasets. We then present\n\\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative\npairwise preference datasets with reduced-conflict alignment objectives.\n\\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback\nfrom GPT-4, marking as the first preference dataset aimed at reducing the\ncompetition between alignment objectives. Furthermore, we develop reward\nmodels, HummerRM and HummerRM-F, which employ a hybrid sampling approach to\nbalance diverse alignment objectives effectively. This sampling method\npositions HummerRM as an ideal model for domain-specific further fine-tuning\nand reducing vulnerabilities to attacks.\n","authors":["Li Jiang","Yusen Wu","Junwu Xiong","Jingqing Ruan","Yichuan Ding","Qingpei Guo","Zujie Wen","Jun Zhou","Xiaotie Deng"],"pdf_url":"https://arxiv.org/pdf/2405.11647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03199v1","updated":"2024-08-06T13:58:37Z","published":"2024-08-06T13:58:37Z","title":"Convergence Conditions for Stochastic Line Search Based Optimization of\n  Over-parametrized Models","summary":"  In this paper, we deal with algorithms to solve the finite-sum problems\nrelated to fitting over-parametrized models, that typically satisfy the\ninterpolation condition. In particular, we focus on approaches based on\nstochastic line searches and employing general search directions. We define\nconditions on the sequence of search directions that guarantee finite\ntermination and bounds for the backtracking procedure. Moreover, we shed light\non the additional property of directions needed to prove fast (linear)\nconvergence of the general class of algorithms when applied to PL functions in\nthe interpolation regime. From the point of view of algorithms design, the\nproposed analysis identifies safeguarding conditions that could be employed in\nrelevant algorithmic framework. In particular, it could be of interest to\nintegrate stochastic line searches within momentum, conjugate gradient or\nadaptive preconditioning methods.\n","authors":["Matteo Lapucci","Davide Pucci"],"pdf_url":"https://arxiv.org/pdf/2408.03199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03195v1","updated":"2024-08-06T13:55:51Z","published":"2024-08-06T13:55:51Z","title":"RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning","summary":"  The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.\n","authors":["Jiapeng Zhu","Zichen Ding","Jianxiang Yu","Jiaqi Tan","Xiang Li","Weining Qian"],"pdf_url":"https://arxiv.org/pdf/2408.03195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07186v5","updated":"2024-08-06T13:47:50Z","published":"2023-12-12T11:48:56Z","title":"Towards Optimal Sobolev Norm Rates for the Vector-Valued Regularized\n  Least-Squares Algorithm","summary":"  We present the first optimal rates for infinite-dimensional vector-valued\nridge regression on a continuous scale of norms that interpolate between $L_2$\nand the hypothesis space, which we consider as a vector-valued reproducing\nkernel Hilbert space. These rates allow to treat the misspecified case in which\nthe true regression function is not contained in the hypothesis space. We\ncombine standard assumptions on the capacity of the hypothesis space with a\nnovel tensor product construction of vector-valued interpolation spaces in\norder to characterize the smoothness of the regression function. Our upper\nbound not only attains the same rate as real-valued kernel ridge regression,\nbut also removes the assumption that the target regression function is bounded.\nFor the lower bound, we reduce the problem to the scalar setting using a\nprojection argument. We show that these rates are optimal in most cases and\nindependent of the dimension of the output space. We illustrate our results for\nthe special case of vector-valued Sobolev spaces.\n","authors":["Zhu Li","Dimitri Meunier","Mattes Mollenhauer","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2312.07186v5.pdf","comment":"Published JMLR version. arXiv admin note: text overlap with\n  arXiv:2208.01711"},{"id":"http://arxiv.org/abs/2311.15890v3","updated":"2024-08-06T13:47:24Z","published":"2023-11-27T14:56:47Z","title":"Stability-Informed Initialization of Neural Ordinary Differential\n  Equations","summary":"  This paper addresses the training of Neural Ordinary Differential Equations\n(neural ODEs), and in particular explores the interplay between numerical\nintegration techniques, stability regions, step size, and initialization\ntechniques. It is shown how the choice of integration technique implicitly\nregularizes the learned model, and how the solver's corresponding stability\nregion affects training and prediction performance. From this analysis, a\nstability-informed parameter initialization technique is introduced. The\neffectiveness of the initialization method is displayed across several learning\nbenchmarks and industrial applications.\n","authors":["Theodor Westny","Arman Mohammadi","Daniel Jung","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2311.15890v3.pdf","comment":"In Proceedings of the 41 st International Conference on Machine\n  Learning"},{"id":"http://arxiv.org/abs/2408.03178v1","updated":"2024-08-06T13:22:51Z","published":"2024-08-06T13:22:51Z","title":"An Object is Worth 64x64 Pixels: Generating 3D Object via Image\n  Diffusion","summary":"  We introduce a new approach for generating realistic 3D models with UV maps\nthrough a representation termed \"Object Images.\" This approach encapsulates\nsurface geometry, appearance, and patch structures within a 64x64 pixel image,\neffectively converting complex 3D shapes into a more manageable 2D format. By\ndoing so, we address the challenges of both geometric and semantic irregularity\ninherent in polygonal meshes. This method allows us to use image generation\nmodels, such as Diffusion Transformers, directly for 3D shape generation.\nEvaluated on the ABO dataset, our generated shapes with patch structures\nachieve point cloud FID comparable to recent 3D generative models, while\nnaturally supporting PBR material generation.\n","authors":["Xingguang Yan","Han-Hung Lee","Ziyu Wan","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2408.03178v1.pdf","comment":"Project Page: https://omages.github.io/"},{"id":"http://arxiv.org/abs/2408.03172v1","updated":"2024-08-06T13:16:16Z","published":"2024-08-06T13:16:16Z","title":"Leveraging Parameter Efficient Training Methods for Low Resource Text\n  Classification: A Case Study in Marathi","summary":"  With the surge in digital content in low-resource languages, there is an\nescalating demand for advanced Natural Language Processing (NLP) techniques\ntailored to these languages. BERT (Bidirectional Encoder Representations from\nTransformers), serving as the foundational framework for numerous NLP\narchitectures and language models, is increasingly employed for the development\nof low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method\nfor fine-tuning Large Language Models (LLMs) and reducing the training\nparameters to some extent to decrease the computational costs needed for\ntraining the model and achieve results comparable to a fully fine-tuned model.\nIn this work, we present a study of PEFT methods for the Indic low-resource\nlanguage Marathi. We conduct a comprehensive analysis of PEFT methods applied\nto various monolingual and multilingual Marathi BERT models. These approaches\nare evaluated on prominent text classification datasets like MahaSent,\nMahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to\nsignificantly expedite the training speed of the models, addressing a critical\naspect of model development and deployment. In this study, we explore Low-Rank\nAdaptation of Large Language Models (LoRA) and adapter methods for low-resource\ntext classification. We show that these methods are competitive with full\nfine-tuning and can be used without loss in accuracy. This study contributes\nvaluable insights into the effectiveness of Marathi BERT models, offering a\nfoundation for the continued advancement of NLP capabilities in Marathi and\nsimilar Indic languages.\n","authors":["Pranita Deshmukh","Nikita Kulkarni","Sanhita Kulkarni","Kareena Manghani","Raviraj Joshi"],"pdf_url":"https://arxiv.org/pdf/2408.03172v1.pdf","comment":"Accepted at I2CT 2024"},{"id":"http://arxiv.org/abs/2408.03156v1","updated":"2024-08-06T12:55:17Z","published":"2024-08-06T12:55:17Z","title":"Iterative CT Reconstruction via Latent Variable Optimization of Shallow\n  Diffusion Models","summary":"  Image generative AI has garnered significant attention in recent years. In\nparticular, the diffusion model, a core component of recent generative AI,\nproduces high-quality images with rich diversity. In this study, we propose a\nnovel CT reconstruction method by combining the denoising diffusion\nprobabilistic model with iterative CT reconstruction. In sharp contrast to\nprevious studies, we optimize the fidelity loss of CT reconstruction with\nrespect to the latent variable of the diffusion model, instead of the image and\nmodel parameters. To suppress anatomical structure changes produced by the\ndiffusion model, we shallow the diffusion and reverse processes, and fix a set\nof added noises in the reverse process to make it deterministic during\ninference. We demonstrate the effectiveness of the proposed method through\nsparse view CT reconstruction of 1/10 view projection data. Despite the\nsimplicity of the implementation, the proposed method shows the capability of\nreconstructing high-quality images while preserving the patient's anatomical\nstructure, and outperforms existing methods including iterative reconstruction,\niterative reconstruction with total variation, and the diffusion model alone in\nterms of quantitative indices such as SSIM and PSNR. We also explore further\nsparse view CT using 1/20 view projection data with the same trained diffusion\nmodel. As the number of iterations increases, image quality improvement\ncomparable to that of 1/10 sparse view CT reconstruction is achieved. In\nprinciple, the proposed method can be widely applied not only to CT but also to\nother imaging modalities such as MRI, PET, and SPECT.\n","authors":["Sho Ozaki","Shizuo Kaji","Toshikazu Imae","Kanabu Nawa","Hideomi Yamashita","Keiichi Nakagawa"],"pdf_url":"https://arxiv.org/pdf/2408.03156v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.01661v3","updated":"2024-08-06T12:54:26Z","published":"2024-05-02T18:31:47Z","title":"When a Relation Tells More Than a Concept: Exploring and Evaluating\n  Classifier Decisions with CoReX","summary":"  Explanations for Convolutional Neural Networks (CNNs) based on relevance of\ninput pixels might be too unspecific to evaluate which and how input features\nimpact model decisions. Especially in complex real-world domains like biology,\nthe presence of specific concepts and of relations between concepts might be\ndiscriminating between classes. Pixel relevance is not expressive enough to\nconvey this type of information. In consequence, model evaluation is limited\nand relevant aspects present in the data and influencing the model decisions\nmight be overlooked. This work presents a novel method to explain and evaluate\nCNN models, which uses a concept- and relation-based explainer (CoReX). It\nexplains the predictive behavior of a model on a set of images by masking\n(ir-)relevant concepts from the decision-making process and by constraining\nrelations in a learned interpretable surrogate model. We test our approach with\nseveral image data sets and CNN architectures. Results show that CoReX\nexplanations are faithful to the CNN model in terms of predictive outcomes. We\nfurther demonstrate through a human evaluation that CoReX is a suitable tool\nfor generating combined explanations that help assessing the classification\nquality of CNNs. We further show that CoReX supports the identification and\nre-classification of incorrect or ambiguous classifications.\n","authors":["Bettina Finzel","Patrick Hilme","Johannes Rabold","Ute Schmid"],"pdf_url":"https://arxiv.org/pdf/2405.01661v3.pdf","comment":"preliminary version, submitted to Machine Learning"},{"id":"http://arxiv.org/abs/2408.03152v1","updated":"2024-08-06T12:52:03Z","published":"2024-08-06T12:52:03Z","title":"TSC: A Simple Two-Sided Constraint against Over-Smoothing","summary":"  Graph Convolutional Neural Network (GCN), a widely adopted method for\nanalyzing relational data, enhances node discriminability through the\naggregation of neighboring information. Usually, stacking multiple layers can\nimprove the performance of GCN by leveraging information from high-order\nneighbors. However, the increase of the network depth will induce the\nover-smoothing problem, which can be attributed to the quality and quantity of\nneighbors changing: (a) neighbor quality, node's neighbors become overlapping\nin high order, leading to aggregated information becoming indistinguishable,\n(b) neighbor quantity, the exponentially growing aggregated neighbors submerges\nthe node's initial feature by recursively aggregating operations. Current\nsolutions mainly focus on one of the above causes and seldom consider both at\nonce.\n  Aiming at tackling both causes of over-smoothing in one shot, we introduce a\nsimple Two-Sided Constraint (TSC) for GCNs, comprising two straightforward yet\npotent techniques: random masking and contrastive constraint. The random\nmasking acts on the representation matrix's columns to regulate the degree of\ninformation aggregation from neighbors, thus preventing the convergence of node\nrepresentations. Meanwhile, the contrastive constraint, applied to the\nrepresentation matrix's rows, enhances the discriminability of the nodes.\nDesigned as a plug-in module, TSC can be easily coupled with GCN or SGC\narchitectures. Experimental analyses on diverse real-world graph datasets\nverify that our approach markedly reduces the convergence of node's\nrepresentation and the performance degradation in deeper GCN.\n","authors":["Furong Peng","Kang Liu","Xuan Lu","Yuhua Qian","Hongren Yan","Chao Ma"],"pdf_url":"https://arxiv.org/pdf/2408.03152v1.pdf","comment":"accept by KDD2024"},{"id":"http://arxiv.org/abs/2408.03150v1","updated":"2024-08-06T12:49:33Z","published":"2024-08-06T12:49:33Z","title":"Conditioning LLMs with Emotion in Neural Machine Translation","summary":"  Large Language Models (LLMs) have shown remarkable performance in Natural\nLanguage Processing tasks, including Machine Translation (MT). In this work, we\npropose a novel MT pipeline that integrates emotion information extracted from\na Speech Emotion Recognition (SER) model into LLMs to enhance translation\nquality. We first fine-tune five existing LLMs on the Libri-trans dataset and\nselect the most performant model. Subsequently, we augment LLM prompts with\ndifferent dimensional emotions and train the selected LLM under these different\nconfigurations. Our experiments reveal that integrating emotion information,\nespecially arousal, into LLM prompts leads to notable improvements in\ntranslation quality.\n","authors":["Charles Brazier","Jean-Luc Rouas"],"pdf_url":"https://arxiv.org/pdf/2408.03150v1.pdf","comment":"6 pages, In Proceedings of the 21st International Conference on\n  Spoken Language Translation (IWSLT), Bangkok, Thailand, 2024"},{"id":"http://arxiv.org/abs/2408.03144v1","updated":"2024-08-06T12:39:12Z","published":"2024-08-06T12:39:12Z","title":"Active Learning for Level Set Estimation Using Randomized Straddle\n  Algorithms","summary":"  Level set estimation (LSE), the problem of identifying the set of input\npoints where a function takes value above (or below) a given threshold, is\nimportant in practical applications. When the function is expensive-to-evaluate\nand black-box, the \\textit{straddle} algorithm, which is a representative\nheuristic for LSE based on Gaussian process models, and its extensions having\ntheoretical guarantees have been developed. However, many of existing methods\ninclude a confidence parameter $\\beta^{1/2}_t$ that must be specified by the\nuser, and methods that choose $\\beta^{1/2}_t$ heuristically do not provide\ntheoretical guarantees. In contrast, theoretically guaranteed values of\n$\\beta^{1/2}_t$ need to be increased depending on the number of iterations and\ncandidate points, and are conservative and not good for practical performance.\nIn this study, we propose a novel method, the \\textit{randomized straddle}\nalgorithm, in which $\\beta_t$ in the straddle algorithm is replaced by a random\nsample from the chi-squared distribution with two degrees of freedom. The\nconfidence parameter in the proposed method has the advantages of not needing\nadjustment, not depending on the number of iterations and candidate points, and\nnot being conservative. Furthermore, we show that the proposed method has\ntheoretical guarantees that depend on the sample complexity and the number of\niterations. Finally, we confirm the usefulness of the proposed method through\nnumerical experiments using synthetic and real data.\n","authors":["Yu Inatsu","Shion Takeno","Kentaro Kutsukake","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2408.03144v1.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.00573v2","updated":"2024-08-06T12:36:57Z","published":"2024-08-01T14:06:34Z","title":"Convergence Analysis of Natural Gradient Descent for Over-parameterized\n  Physics-Informed Neural Networks","summary":"  First-order methods, such as gradient descent (GD) and stochastic gradient\ndescent (SGD), have been proven effective in training neural networks. In the\ncontext of over-parameterization, there is a line of work demonstrating that\nrandomly initialized (stochastic) gradient descent converges to a globally\noptimal solution at a linear convergence rate for the quadratic loss function.\nHowever, the learning rate of GD for training two-layer neural networks\nexhibits poor dependence on the sample size and the Gram matrix, leading to a\nslow training process. In this paper, we show that for the $L^2$ regression\nproblems, the learning rate can be improved from $\\mathcal{O}(\\lambda_0/n^2)$\nto $\\mathcal{O}(1/\\|\\bm{H}^{\\infty}\\|_2)$, which implies that GD actually\nenjoys a faster convergence rate. Furthermore, we generalize the method to GD\nin training two-layer Physics-Informed Neural Networks (PINNs), showing a\nsimilar improvement for the learning rate. Although the improved learning rate\nhas a mild dependence on the Gram matrix, we still need to set it small enough\nin practice due to the unknown eigenvalues of the Gram matrix. More\nimportantly, the convergence rate is tied to the least eigenvalue of the Gram\nmatrix, which can lead to slow convergence. In this work, we provide the\nconvergence analysis of natural gradient descent (NGD) in training two-layer\nPINNs, demonstrating that the learning rate can be $\\mathcal{O}(1)$, and at\nthis rate, the convergence rate is independent of the Gram matrix.\n","authors":["Xianliang Xu","Ting Du","Wang Kong","Ye Li","Zhongyi Huang"],"pdf_url":"https://arxiv.org/pdf/2408.00573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01294v2","updated":"2024-08-06T12:24:07Z","published":"2024-08-02T14:31:37Z","title":"Feature Clock: High-Dimensional Effects in Two-Dimensional Plots","summary":"  Humans struggle to perceive and interpret high-dimensional data. Therefore,\nhigh-dimensional data are often projected into two dimensions for\nvisualization. Many applications benefit from complex nonlinear dimensionality\nreduction techniques, but the effects of individual high-dimensional features\nare hard to explain in the two-dimensional space. Most visualization solutions\nuse multiple two-dimensional plots, each showing the effect of one\nhigh-dimensional feature in two dimensions; this approach creates a need for a\nvisual inspection of k plots for a k-dimensional input space. Our solution,\nFeature Clock, provides a novel approach that eliminates the need to inspect\nthese k plots to grasp the influence of original features on the data structure\ndepicted in two dimensions. Feature Clock enhances the explainability and\ncompactness of visualizations of embedded data and is available in an\nopen-source Python library.\n","authors":["Olga Ovcharenko","Rita Sevastjanova","Valentina Boeva"],"pdf_url":"https://arxiv.org/pdf/2408.01294v2.pdf","comment":"To be published in IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2407.09064v2","updated":"2024-08-06T11:43:53Z","published":"2024-07-12T07:34:10Z","title":"Multi-Modal Dataset Creation for Federated Learning with DICOM\n  Structured Reports","summary":"  Purpose: Federated training is often hindered by heterogeneous datasets due\nto divergent data storage options, inconsistent naming schemes, varied\nannotation procedures, and disparities in label quality. This is particularly\nevident in the emerging multi-modal learning paradigms, where dataset\nharmonization including a uniform data representation and filtering options are\nof paramount importance.\n  Methods: DICOM structured reports enable the standardized linkage of\narbitrary information beyond the imaging domain and can be used within Python\ndeep learning pipelines with highdicom. Building on this, we developed an open\nplatform for data integration and interactive filtering capabilities that\nsimplifies the process of assembling multi-modal datasets.\n  Results: In this study, we extend our prior work by showing its applicability\nto more and divergent data types, as well as streamlining datasets for\nfederated training within an established consortium of eight university\nhospitals in Germany. We prove its concurrent filtering ability by creating\nharmonized multi-modal datasets across all locations for predicting the outcome\nafter minimally invasive heart valve replacement. The data includes DICOM data\n(i.e. computed tomography images, electrocardiography scans) as well as\nannotations (i.e. calcification segmentations, pointsets and pacemaker\ndependency), and metadata (i.e. prosthesis and diagnoses).\n  Conclusion: Structured reports bridge the traditional gap between imaging\nsystems and information systems. Utilizing the inherent DICOM reference system\narbitrary data types can be queried concurrently to create meaningful cohorts\nfor clinical studies. The graphical interface as well as example structured\nreport templates will be made publicly available.\n","authors":["Malte Tölle","Lukas Burger","Halvar Kelm","Florian André","Peter Bannas","Gerhard Diller","Norbert Frey","Philipp Garthe","Stefan Groß","Anja Hennemuth","Lars Kaderali","Nina Krüger","Andreas Leha","Simon Martin","Alexander Meyer","Eike Nagel","Stefan Orwat","Clemens Scherer","Moritz Seiffert","Jan Moritz Seliger","Stefan Simm","Tim Friede","Tim Seidler","Sandy Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2407.09064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.11044v2","updated":"2024-08-06T11:29:06Z","published":"2024-01-19T22:11:54Z","title":"Preservation of Feature Stability in Machine Learning Under Data\n  Uncertainty for Decision Support in Critical Domains","summary":"  In a world where Machine Learning (ML) is increasingly deployed to support\ndecision-making in critical domains, providing decision-makers with\nexplainable, stable, and relevant inputs becomes fundamental. Understanding how\nmachine learning works under missing data and how this affects feature\nvariability is paramount. This is even more relevant as machine learning\napproaches focus on standardising decision-making approaches that rely on an\nidealised set of features. However, decision-making in human activities often\nrelies on incomplete data, even in critical domains. This paper addresses this\ngap by conducting a set of experiments using traditional machine learning\nmethods that look for optimal decisions in comparison to a recently deployed\nmachine learning method focused on a classification that is more descriptive\nand mimics human decision making, allowing for the natural integration of\nexplainability. We found that the ML descriptive approach maintains higher\nclassification accuracy while ensuring the stability of feature selection as\ndata incompleteness increases. This suggests that descriptive classification\nmethods can be helpful in uncertain decision-making scenarios.\n","authors":["Karol Capała","Paulina Tworek","Jose Sousa"],"pdf_url":"https://arxiv.org/pdf/2401.11044v2.pdf","comment":"30 pages, 6 figures, supplementary materials"},{"id":"http://arxiv.org/abs/2407.03234v3","updated":"2024-08-06T11:15:00Z","published":"2024-07-03T16:03:42Z","title":"Self-Evaluation as a Defense Against Adversarial Attacks on LLMs","summary":"  We introduce a defense against adversarial attacks on LLMs utilizing\nself-evaluation. Our method requires no model fine-tuning, instead using\npre-trained models to evaluate the inputs and outputs of a generator model,\nsignificantly reducing the cost of implementation in comparison to other,\nfinetuning-based methods. Our method can significantly reduce the attack\nsuccess rate of attacks on both open and closed-source LLMs, beyond the\nreductions demonstrated by Llama-Guard2 and commonly used content moderation\nAPIs. We present an analysis of the effectiveness of our method, including\nattempts to attack the evaluator in various settings, demonstrating that it is\nalso more resilient to attacks than existing methods. Code and data will be\nmade available at https://github.com/Linlt-leon/self-eval.\n","authors":["Hannah Brown","Leon Lin","Kenji Kawaguchi","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2407.03234v3.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.03099v1","updated":"2024-08-06T11:04:07Z","published":"2024-08-06T11:04:07Z","title":"Topic Modeling with Fine-tuning LLMs and Bag of Sentences","summary":"  Large language models (LLM)'s are increasingly used for topic modeling\noutperforming classical topic models such as LDA. Commonly, pre-trained LLM\nencoders such as BERT are used out-of-the-box despite the fact that fine-tuning\nis known to improve LLMs considerably. The challenge lies in obtaining a\nsuitable (labeled) dataset for fine-tuning. In this paper, we use the recent\nidea to use bag of sentences as the elementary unit in computing topics. In\nturn, we derive an approach FT-Topic to perform unsupervised fine-tuning\nrelying primarily on two steps for constructing a training dataset in an\nautomatic fashion. First, a heuristic method to identifies pairs of sentence\ngroups that are either assumed to be of the same or different topics. Second,\nwe remove sentence pairs that are likely labeled incorrectly. The dataset is\nthen used to fine-tune an encoder LLM, which can be leveraged by any topic\nmodeling approach using embeddings. However, in this work, we demonstrate its\neffectiveness by deriving a novel state-of-the-art topic modeling method called\nSenClu, which achieves fast inference through an expectation-maximization\nalgorithm and hard assignments of sentence groups to a single topic, while\ngiving users the possibility to encode prior knowledge on the topic-document\ndistribution. Code is at \\url{https://github.com/JohnTailor/FT-Topic}\n","authors":["Johannes Schneider"],"pdf_url":"https://arxiv.org/pdf/2408.03099v1.pdf","comment":"This is the submitted journal version of enhanced with the novel\n  fine-tuning part of \"Efficient and Flexible Topic Modeling using Pretrained\n  Embeddings and Bag of Sentences'' which appeared at the International\n  Conference on Agents and Artificial Intelligence(ICAART) in 2024"},{"id":"http://arxiv.org/abs/2211.16237v4","updated":"2024-08-06T10:51:40Z","published":"2022-11-29T14:21:34Z","title":"Closing the gap between SVRG and TD-SVRG with Gradient Splitting","summary":"  Temporal difference (TD) learning is a policy evaluation in reinforcement\nlearning whose performance can be enhanced by variance reduction methods.\nRecently, multiple works have sought to fuse TD learning with Stochastic\nVariance Reduced Gradient (SVRG) method to achieve a geometric rate of\nconvergence. However, the resulting convergence rate is significantly weaker\nthan what is achieved by SVRG in the setting of convex optimization. In this\nwork we utilize a recent interpretation of TD-learning as the splitting of the\ngradient of an appropriately chosen function, thus simplifying the algorithm\nand fusing TD with SVRG. Our main result is a geometric convergence bound with\npredetermined learning rate of $1/8$, which is identical to the convergence\nbound available for SVRG in the convex setting. Our theoretical findings are\nsupported by a set of experiments.\n","authors":["Arsenii Mustafin","Alex Olshevsky","Ioannis Ch. Paschalidis"],"pdf_url":"https://arxiv.org/pdf/2211.16237v4.pdf","comment":"42 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2408.03093v1","updated":"2024-08-06T10:48:15Z","published":"2024-08-06T10:48:15Z","title":"Learning Provably Robust Policies in Uncertain Parametric Environments","summary":"  We present a data-driven approach for learning MDP policies that are robust\nacross stochastic environments whose transition probabilities are defined by\nparameters with an unknown distribution. We produce probably approximately\ncorrect (PAC) guarantees for the performance of these learned policies in a\nnew, unseen environment over the unknown distribution. Our approach is based on\nfinite samples of the MDP environments, for each of which we build an\napproximation of the model as an interval MDP, by exploring a set of generated\ntrajectories. We use the built approximations to synthesise a single policy\nthat performs well (meets given requirements) across the sampled environments,\nand furthermore bound its risk (of not meeting the given requirements) when\ndeployed in an unseen environment. Our procedure offers a trade-off between the\nguaranteed performance of the learned policy and the risk of not meeting the\nguarantee in an unseen environment. Our approach exploits knowledge of the\nenvironment's state space and graph structure, and we show how additional\nknowledge of its parametric structure can be leveraged to optimize learning and\nto obtain tighter guarantees from less samples. We evaluate our approach on a\ndiverse range of established benchmarks, demonstrating that we can generate\nhighly performing and robust policies, along with guarantees that tightly\nquantify their performance and the associated risk.\n","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_url":"https://arxiv.org/pdf/2408.03093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20800v2","updated":"2024-08-06T10:45:42Z","published":"2024-05-31T14:01:12Z","title":"Shape Constraints in Symbolic Regression using Penalized Least Squares","summary":"  We study the addition of shape constraints (SC) and their consideration\nduring the parameter identification step of symbolic regression (SR). SC serve\nas a means to introduce prior knowledge about the shape of the otherwise\nunknown model function into SR. Unlike previous works that have explored SC in\nSR, we propose minimizing SC violations during parameter identification using\ngradient-based numerical optimization. We test three algorithm variants to\nevaluate their performance in identifying three symbolic expressions from\nsynthetically generated data sets. This paper examines two benchmark scenarios:\none with varying noise levels and another with reduced amounts of training\ndata. The results indicate that incorporating SC into the expression search is\nparticularly beneficial when data is scarce. Compared to using SC only in the\nselection process, our approach of minimizing violations during parameter\nidentification shows a statistically significant benefit in some of our test\ncases, without being significantly worse in any instance.\n","authors":["Viktor Martinek","Julia Reuter","Ophelia Frotscher","Sanaz Mostaghim","Markus Richter","Roland Herzog"],"pdf_url":"https://arxiv.org/pdf/2405.20800v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03088v1","updated":"2024-08-06T10:41:46Z","published":"2024-08-06T10:41:46Z","title":"QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction","summary":"  Financial market prediction and optimal trading strategy development remain\nchallenging due to market complexity and volatility. Our research in quantum\nfinance and reinforcement learning for decision-making demonstrates the\napproach of quantum-classical hybrid algorithms to tackling real-world\nfinancial challenges. In this respect, we corroborate the concept with rigorous\nbacktesting and validate the framework's performance under realistic market\nconditions, by including fixed transaction cost per trade. This paper\nintroduces a Quantum Attention Deep Q-Network (QADQN) approach to address these\nchallenges through quantum-enhanced reinforcement learning. Our QADQN\narchitecture uses a variational quantum circuit inside a traditional deep\nQ-learning framework to take advantage of possible quantum advantages in\ndecision-making. We gauge the QADQN agent's performance on historical data from\nmajor market indices, including the S&P 500. We evaluate the agent's learning\nprocess by examining its reward accumulation and the effectiveness of its\nexperience replay mechanism. Our empirical results demonstrate the QADQN's\nsuperior performance, achieving better risk-adjusted returns with Sortino\nratios of 1.28 and 1.19 for non-overlapping and overlapping test periods\nrespectively, indicating effective downside risk management.\n","authors":["Siddhant Dutta","Nouhaila Innan","Alberto Marchisio","Sadok Ben Yahia","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2408.03088v1.pdf","comment":"Accepted at the 2024 IEEE International Conference on Quantum\n  Computing and Engineering (QCE24), QCRL, September 2024"},{"id":"http://arxiv.org/abs/2308.09310v3","updated":"2024-08-06T10:38:22Z","published":"2023-08-18T05:11:50Z","title":"Variance reduction techniques for stochastic proximal point algorithms","summary":"  In the context of finite sums minimization, variance reduction techniques are\nwidely used to improve the performance of state-of-the-art stochastic gradient\nmethods. Their practical impact is clear, as well as their theoretical\nproperties. Stochastic proximal point algorithms have been studied as an\nalternative to stochastic gradient algorithms since they are more stable with\nrespect to the choice of the step size. However, their variance-reduced\nversions are not as well studied as the gradient ones. In this work, we propose\nthe first unified study of variance reduction techniques for stochastic\nproximal point algorithms. We introduce a generic stochastic proximal-based\nalgorithm that can be specified to give the proximal version of SVRG, SAGA, and\nsome of their variants. For this algorithm, in the smooth setting, we provide\nseveral convergence rates for the iterates and the objective function values,\nwhich are faster than those of the vanilla stochastic proximal point algorithm.\nMore specifically, for convex functions, we prove a sublinear convergence rate\nof $O(1/k)$. In addition, under the Polyak-{\\L}ojasiewicz (PL) condition, we\nobtain linear convergence rates. Finally, our numerical experiments demonstrate\nthe advantages of the proximal variance reduction methods over their gradient\ncounterparts in terms of the stability with respect to the choice of the step\nsize in most cases, especially for difficult problems.\n","authors":["Cheik Traoré","Vassilis Apidopoulos","Saverio Salzo","Silvia Villa"],"pdf_url":"https://arxiv.org/pdf/2308.09310v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03085v1","updated":"2024-08-06T10:25:02Z","published":"2024-08-06T10:25:02Z","title":"Matrix Multiplication on Quantum Computer","summary":"  This paper introduces an innovative and practical approach to universal\nquantum matrix multiplication. We designed optimized quantum adders and\nmultipliers based on Quantum Fourier Transform (QFT), which significantly\nreduced the number of gates used compared to classical adders and multipliers.\nSubsequently, we construct a basic universal quantum matrix multiplication and\nextend it to the Strassen algorithm. We conduct comparative experiments to\nanalyze the performance of the quantum matrix multiplication and evaluate the\nacceleration provided by the optimized quantum adder and multiplier.\nFurthermore, we investigate the advantages and disadvantages of the quantum\nStrassen algorithm compared to basic quantum matrix multiplication.\n","authors":["Jiaqi Yao","Ding Liu"],"pdf_url":"https://arxiv.org/pdf/2408.03085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03084v1","updated":"2024-08-06T10:24:54Z","published":"2024-08-06T10:24:54Z","title":"Research on Autonomous Driving Decision-making Strategies based Deep\n  Reinforcement Learning","summary":"  The behavior decision-making subsystem is a key component of the autonomous\ndriving system, which reflects the decision-making ability of the vehicle and\nthe driver, and is an important symbol of the high-level intelligence of the\nvehicle. However, the existing rule-based decision-making schemes are limited\nby the prior knowledge of designers, and it is difficult to cope with complex\nand changeable traffic scenarios. In this work, an advanced deep reinforcement\nlearning model is adopted, which can autonomously learn and optimize driving\nstrategies in a complex and changeable traffic environment by modeling the\ndriving decision-making process as a reinforcement learning problem.\nSpecifically, we used Deep Q-Network (DQN) and Proximal Policy Optimization\n(PPO) for comparative experiments. DQN guides the agent to choose the best\naction by approximating the state-action value function, while PPO improves the\ndecision-making quality by optimizing the policy function. We also introduce\nimprovements in the design of the reward function to promote the robustness and\nadaptability of the model in real-world driving situations. Experimental\nresults show that the decision-making strategy based on deep reinforcement\nlearning has better performance than the traditional rule-based method in a\nvariety of driving tasks.\n","authors":["Zixiang Wang","Hao Yan","Changsong Wei","Junyu Wang","Shi Bo","Minheng Xiao"],"pdf_url":"https://arxiv.org/pdf/2408.03084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02354v2","updated":"2024-08-06T10:11:28Z","published":"2024-08-05T10:02:29Z","title":"RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential\n  Recommenders","summary":"  Scalability is a major challenge in modern recommender systems. In sequential\nrecommendations, full Cross-Entropy (CE) loss achieves state-of-the-art\nrecommendation quality but consumes excessive GPU memory with large item\ncatalogs, limiting its practicality. Using a GPU-efficient locality-sensitive\nhashing-like algorithm for approximating large tensor of logits, this paper\nintroduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly\nreduces memory consumption while allowing one to enjoy the state-of-the-art\nperformance of full CE loss. Experimental results on various datasets show that\nRECE cuts training peak memory usage by up to 12 times compared to existing\nmethods while retaining or exceeding performance metrics of CE loss. The\napproach also opens up new possibilities for large-scale applications in other\ndomains.\n","authors":["Danil Gusak","Gleb Mezentsev","Ivan Oseledets","Evgeny Frolov"],"pdf_url":"https://arxiv.org/pdf/2408.02354v2.pdf","comment":"5 pages, accepted for CIKM'24"},{"id":"http://arxiv.org/abs/2307.15325v2","updated":"2024-08-06T10:09:47Z","published":"2023-07-28T06:03:19Z","title":"Equivariance and partial observations in Koopman operator theory for\n  partial differential equations","summary":"  The Koopman operator has become an essential tool for data-driven analysis,\nprediction and control of complex systems. The main reason is the enormous\npotential of identifying linear function space representations of nonlinear\ndynamics from measurements. This equally applies to ordinary, stochastic, and\npartial differential equations (PDEs). Until now, with a few exceptions only,\nthe PDE case is mostly treated rather superficially, and the specific structure\nof the underlying dynamics is largely ignored. In this paper, we show that\nsymmetries in the system dynamics can be carried over to the Koopman operator,\nwhich allows us to massively increase the model efficacy. Moreover, the\nsituation where we only have access to partial observations (i.e.,\nmeasurements, as is very common for experimental data) has not been treated to\nits full extent, either. Moreover, we address the highly-relevant case where we\ncannot measure the full state, such that alternative approaches such as delay\ncoordinates have to be considered. We derive rigorous statements on the\nrequired number of observables in this situation, based on embedding theory. We\npresent numerical evidence using various numerical examples including the wave\nequation and the Kuramoto-Sivashinsky equation.\n","authors":["Sebastian Peitz","Hans Harder","Feliks Nüske","Friedrich Philipp","Manuel Schaller","Karl Worthmann"],"pdf_url":"https://arxiv.org/pdf/2307.15325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12465v3","updated":"2024-08-06T09:57:36Z","published":"2024-05-21T02:41:40Z","title":"A finite element-based physics-informed operator learning framework for\n  spatiotemporal partial differential equations on arbitrary domains","summary":"  We propose a novel finite element-based physics-informed operator learning\nframework that allows for predicting spatiotemporal dynamics governed by\npartial differential equations (PDEs). The proposed framework employs a loss\nfunction inspired by the finite element method (FEM) with the implicit Euler\ntime integration scheme. A transient thermal conduction problem is considered\nto benchmark the performance. The proposed operator learning framework takes a\ntemperature field at the current time step as input and predicts a temperature\nfield at the next time step. The Galerkin discretized weak formulation of the\nheat equation is employed to incorporate physics into the loss function, which\nis coined finite operator learning (FOL). Upon training, the networks\nsuccessfully predict the temperature evolution over time for any initial\ntemperature field at high accuracy compared to the FEM solution. The framework\nis also confirmed to be applicable to a heterogeneous thermal conductivity and\narbitrary geometry. The advantages of FOL can be summarized as follows: First,\nthe training is performed in an unsupervised manner, avoiding the need for a\nlarge data set prepared from costly simulations or experiments. Instead, random\ntemperature patterns generated by the Gaussian random process and the Fourier\nseries, combined with constant temperature fields, are used as training data to\ncover possible temperature cases. Second, shape functions and backward\ndifference approximation are exploited for the domain discretization, resulting\nin a purely algebraic equation. This enhances training efficiency, as one\navoids time-consuming automatic differentiation when optimizing weights and\nbiases while accepting possible discretization errors. Finally, thanks to the\ninterpolation power of FEM, any arbitrary geometry can be handled with FOL,\nwhich is crucial to addressing various engineering application scenarios.\n","authors":["Yusuke Yamazaki","Ali Harandi","Mayu Muramatsu","Alexandre Viardin","Markus Apel","Tim Brepols","Stefanie Reese","Shahed Rezaei"],"pdf_url":"https://arxiv.org/pdf/2405.12465v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10107v4","updated":"2024-08-06T08:39:33Z","published":"2024-01-18T16:18:18Z","title":"Comparison analysis between standard polysomnographic data and\n  in-ear-EEG signals: A preliminary study","summary":"  Study Objectives: Polysomnography (PSG) currently serves as the benchmark for\nevaluating sleep disorders. Its discomfort makes long-term monitoring\nunfeasible, leading to bias in sleep quality assessment. Hence, less invasive,\ncost-effective, and portable alternatives need to be explored. One promising\ncontender is the in-ear-EEG sensor. This study aims to establish a methodology\nto assess the similarity between the single-channel in-ear-EEG and standard PSG\nderivations.\n  Methods: The study involves four-hour signals recorded from ten healthy\nsubjects aged 18 to 60 years. Recordings are analyzed following two\ncomplementary approaches: (i) a hypnogram-based analysis aimed at assessing the\nagreement between PSG and in-ear-EEG-derived hypnograms; and (ii) a\nfeature-based analysis based on time- and frequency- domain feature extraction,\nunsupervised feature selection, and definition of Feature-based Similarity\nIndex via Jensen-Shannon Divergence (JSD-FSI).\n  Results: We find large variability between PSG and in-ear-EEG hypnograms\nscored by the same sleep expert according to Cohen's kappa metric, with\nsignificantly greater agreements for PSG scorers than for in-ear-EEG scorers (p\n< 0.001) based on Fleiss' kappa metric. On average, we demonstrate a high\nsimilarity between PSG and in-ear-EEG signals in terms of JSD-FSI (0.79 +/-\n0.06 -awake, 0.77 +/- 0.07 -NREM, and 0.67 +/- 0.10 -REM) and in line with the\nsimilarity values computed independently on standard PSG-channel-combinations.\n  Conclusions: In-ear-EEG is a valuable solution for home-based sleep\nmonitoring, however further studies with a larger and more heterogeneous\ndataset are needed.\n","authors":["Gianpaolo Palo","Luigi Fiorillo","Giuliana Monachino","Michal Bechny","Michel Walti","Elias Meier","Francesca Pentimalli Biscaretti di Ruffia","Mark Melnykowycz","Athina Tzovara","Valentina Agostini","Francesca Dalia Faraci"],"pdf_url":"https://arxiv.org/pdf/2401.10107v4.pdf","comment":"20 figures, 6 tables"},{"id":"http://arxiv.org/abs/2408.03029v1","updated":"2024-08-06T08:22:16Z","published":"2024-08-06T08:22:16Z","title":"Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning","summary":"  Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to several baselines.\n","authors":["Haozhe Ma","Zhengding Luo","Thanh Vinh Vo","Kuankuan Sima","Tze-Yun Leong"],"pdf_url":"https://arxiv.org/pdf/2408.03029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14244v2","updated":"2024-08-06T08:11:34Z","published":"2024-04-22T14:57:17Z","title":"AI-Generated Faces in the Real World: A Large-Scale Case Study of\n  Twitter Profile Images","summary":"  Recent advances in the field of generative artificial intelligence (AI) have\nblurred the lines between authentic and machine-generated content, making it\nalmost impossible for humans to distinguish between such media. One notable\nconsequence is the use of AI-generated images for fake profiles on social\nmedia. While several types of disinformation campaigns and similar incidents\nhave been reported in the past, a systematic analysis has been lacking. In this\nwork, we conduct the first large-scale investigation of the prevalence of\nAI-generated profile pictures on Twitter. We tackle the challenges of a\nreal-world measurement study by carefully integrating various data sources and\ndesigning a multi-stage detection pipeline. Our analysis of nearly 15 million\nTwitter profile pictures shows that 0.052% were artificially generated,\nconfirming their notable presence on the platform. We comprehensively examine\nthe characteristics of these accounts and their tweet content, and uncover\npatterns of coordinated inauthentic behavior. The results also reveal several\nmotives, including spamming and political amplification campaigns. Our research\nreaffirms the need for effective detection and mitigation strategies to cope\nwith the potential negative effects of generative AI in the future.\n","authors":["Jonas Ricker","Dennis Assenmacher","Thorsten Holz","Asja Fischer","Erwin Quiring"],"pdf_url":"https://arxiv.org/pdf/2404.14244v2.pdf","comment":"Accepted to RAID 2024"},{"id":"http://arxiv.org/abs/2404.03453v3","updated":"2024-08-06T07:53:09Z","published":"2024-04-04T13:57:44Z","title":"Conditioning of Banach Space Valued Gaussian Random Variables: An\n  Approximation Approach Based on Martingales","summary":"  In this paper we investigate the conditional distributions of two Banach\nspace valued, jointly Gaussian random variables. We show that these conditional\ndistributions are again Gaussian and that their means and covariances are\ndetermined by a general finite dimensional approximation scheme based upon a\nmartingale approach. In particular, it turns out that the covariance operators\noccurring in this scheme converge with respect to the nuclear norm and that the\nconditional probabilities converge weakly. Moreover, we discuss in detail, how\nour approximation scheme can be implemented in several classes of important\nBanach spaces such as (reproducing kernel) Hilbert spaces and spaces of\ncontinuous functions. As an example, we then apply our general results to the\ncase of Gaussian processes with continuous paths conditioned to partial but\ninfinite observations of their paths. Here we show that conditioning on\nsufficiently rich, increasing sets of finitely many observations leads to\nconsistent approximations, that is, both the mean and covariance functions\nconverge uniformly and the conditional probabilities converge weakly. Moreover,\nwe discuss how these results improve our understanding of the popular Gaussian\nprocesses for machine learning.\n","authors":["Ingo Steinwart"],"pdf_url":"https://arxiv.org/pdf/2404.03453v3.pdf","comment":"55 pages plus 22 pages of supplemental material"},{"id":"http://arxiv.org/abs/2408.03013v1","updated":"2024-08-06T07:48:51Z","published":"2024-08-06T07:48:51Z","title":"NeurDB: On the Design and Implementation of an AI-powered Autonomous\n  Database","summary":"  Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.\n","authors":["Zhanhao Zhao","Shaofeng Cai","Haotian Gao","Hexiang Pan","Siqi Xiang","Naili Xing","Gang Chen","Beng Chin Ooi","Yanyan Shen","Yuncheng Wu","Meihui Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.03013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16907v2","updated":"2024-08-06T07:24:35Z","published":"2024-02-25T04:24:28Z","title":"Diffusion Posterior Proximal Sampling for Image Restoration","summary":"  Diffusion models have demonstrated remarkable efficacy in generating\nhigh-quality samples. Existing diffusion-based image restoration algorithms\nexploit pre-trained diffusion models to leverage data priors, yet they still\npreserve elements inherited from the unconditional generation paradigm. These\nstrategies initiate the denoising process with pure white noise and incorporate\nrandom noise at each generative step, leading to over-smoothed results. In this\npaper, we present a refined paradigm for diffusion-based image restoration.\nSpecifically, we opt for a sample consistent with the measurement identity at\neach generative step, exploiting the sampling selection as an avenue for output\nstability and enhancement. The number of candidate samples used for selection\nis adaptively determined based on the signal-to-noise ratio of the timestep.\nAdditionally, we start the restoration process with an initialization combined\nwith the measurement signal, providing supplementary information to better\nalign the generative process. Extensive experimental results and analyses\nvalidate that our proposed method significantly enhances image restoration\nperformance while consuming negligible additional computational resources.\n","authors":["Hongjie Wu","Linchao He","Mingqin Zhang","Dongdong Chen","Kunming Luo","Mengting Luo","Ji-Zhe Zhou","Hu Chen","Jiancheng Lv"],"pdf_url":"https://arxiv.org/pdf/2402.16907v2.pdf","comment":"ACM Multimedia 2024 Oral"},{"id":"http://arxiv.org/abs/2408.02998v1","updated":"2024-08-06T07:05:56Z","published":"2024-08-06T07:05:56Z","title":"Federated Learning Architectures: A Performance Evaluation with Crop\n  Yield Prediction Application","summary":"  Federated learning has become an emerging technology for data analysis for\nIoT applications. This paper implements centralized and decentralized federated\nlearning frameworks for crop yield prediction based on Long Short-Term Memory\nNetwork. For centralized federated learning, multiple clients and one server is\nconsidered, where the clients exchange their model updates with the server that\nworks as the aggregator to build the global model. For the decentralized\nframework, a collaborative network is formed among the devices either using\nring topology or using mesh topology. In this network, each device receives\nmodel updates from the neighbour devices, and performs aggregation to build the\nupgraded model. The performance of the centralized and decentralized federated\nlearning frameworks are evaluated in terms of prediction accuracy, precision,\nrecall, F1-Score, and training time. The experimental results present that\n$\\geq$97% and $>$97.5% prediction accuracy are achieved using the centralized\nand decentralized federated learning-based frameworks respectively. The results\nalso show that the using centralized federated learning the response time can\nbe reduced by $\\sim$75% than the cloud-only framework. Finally, the future\nresearch directions of the use of federated learning in crop yield prediction\nare explored in this paper.\n","authors":["Anwesha Mukherjee","Rajkumar Buyya"],"pdf_url":"https://arxiv.org/pdf/2408.02998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02987v1","updated":"2024-08-06T06:42:53Z","published":"2024-08-06T06:42:53Z","title":"A Differential Smoothness-based Compact-Dynamic Graph Convolutional\n  Network for Spatiotemporal Signal Recovery","summary":"  High quality spatiotemporal signal is vitally important for real application\nscenarios like energy management, traffic planning and cyber security. Due to\nthe uncontrollable factors like abrupt sensors breakdown or communication\nfault, the spatiotemporal signal collected by sensors is always incomplete. A\ndynamic graph convolutional network (DGCN) is effective for processing\nspatiotemporal signal recovery. However, it adopts a static GCN and a sequence\nneural network to explore the spatial and temporal patterns, separately. Such a\nseparated two-step processing is loose spatiotemporal, thereby failing to\ncapture the complex inner spatiotemporal correlation. To address this issue,\nthis paper proposes a Compact-Dynamic Graph Convolutional Network (CDGCN) for\nspatiotemporal signal recovery with the following two-fold ideas: a) leveraging\nthe tensor M-product to build a unified tensor graph convolution framework,\nwhich considers both spatial and temporal patterns simultaneously; and b)\nconstructing a differential smoothness-based objective function to reduce the\nnoise interference in spatiotemporal signal, thereby further improve the\nrecovery accuracy. Experiments on real-world spatiotemporal datasets\ndemonstrate that the proposed CDGCN significantly outperforms the\nstate-of-the-art models in terms of recovery accuracy.\n","authors":["Pengcheng Gao","Zicheng Gao","Ye Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.02987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01829v2","updated":"2024-08-06T06:30:08Z","published":"2024-08-03T17:43:10Z","title":"Neural Network Emulator for Atmospheric Chemical ODE","summary":"  Modeling atmospheric chemistry is complex and computationally intense. Given\nthe recent success of Deep neural networks in digital signal processing, we\npropose a Neural Network Emulator for fast chemical concentration modeling. We\nconsider atmospheric chemistry as a time-dependent Ordinary Differential\nEquation. To extract the hidden correlations between initial states and future\ntime evolution, we propose ChemNNE, an Attention based Neural Network Emulator\n(NNE) that can model the atmospheric chemistry as a neural ODE process. To\nefficiently simulate the chemical changes, we propose the sinusoidal time\nembedding to estimate the oscillating tendency over time. More importantly, we\nuse the Fourier neural operator to model the ODE process for efficient\ncomputation. We also propose three physical-informed losses to supervise the\ntraining optimization. To evaluate our model, we propose a large-scale chemical\ndataset that can be used for neural network training and evaluation. The\nextensive experiments show that our approach achieves state-of-the-art\nperformance in modeling accuracy and computational speed.\n","authors":["Zhi-Song Liu","Petri Clusius","Michael Boy"],"pdf_url":"https://arxiv.org/pdf/2408.01829v2.pdf","comment":"25 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.17963v4","updated":"2024-08-06T06:28:57Z","published":"2023-03-31T11:06:09Z","title":"Learning-Based Optimal Control with Performance Guarantees for Unknown\n  Systems with Latent States","summary":"  As control engineering methods are applied to increasingly complex systems,\ndata-driven approaches for system identification appear as a promising\nalternative to physics-based modeling. While the Bayesian approaches prevalent\nfor safety-critical applications usually rely on the availability of state\nmeasurements, the states of a complex system are often not directly measurable.\nIt may then be necessary to jointly estimate the dynamics and the latent state,\nmaking the quantification of uncertainties and the design of controllers with\nformal performance guarantees considerably more challenging. This paper\nproposes a novel method for the computation of an optimal input trajectory for\nunknown nonlinear systems with latent states based on a combination of particle\nMarkov chain Monte Carlo methods and scenario theory. Probabilistic performance\nguarantees are derived for the resulting input trajectory, and an approach to\nvalidate the performance of arbitrary control laws is presented. The\neffectiveness of the proposed method is demonstrated in a numerical simulation.\n","authors":["Robert Lefringhausen","Supitsana Srithasan","Armin Lederer","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2303.17963v4.pdf","comment":"Accepted version submitted to the 2024 European Control Conference\n  (ECC)"},{"id":"http://arxiv.org/abs/2109.03445v6","updated":"2024-08-06T06:19:46Z","published":"2021-09-08T06:06:28Z","title":"Convergence of Batch Asynchronous Stochastic Approximation With\n  Applications to Reinforcement Learning","summary":"  We begin by briefly surveying some results on the convergence of the\nStochastic Gradient Descent (SGD) Method, proved in a companion paper by the\npresent authors. These results are based on viewing SGD as a version of\nStochastic Approximation (SA). Ever since its introduction in the classic paper\nof Robbins and Monro in 1951, SA has become a standard tool for finding a\nsolution of an equation of the form $f(\\theta) = 0$, when only noisy\nmeasurements of $f(\\cdot)$ are available. In most situations, \\textit{every\ncomponent} of the putative solution $\\theta_t$ is updated at each step $t$. In\nsome applications in Reinforcement Learning (RL), \\textit{only one component}\nof $\\theta_t$ is updated at each $t$. This is known as \\textbf{asynchronous}\nSA. In this paper, we study \\textbf{Block Asynchronous SA (BASA)}, in which, at\neach step $t$, \\textit{some but not necessarily all} components of $\\theta_t$\nare updated. The theory presented here embraces both conventional (synchronous)\nSA as well as asynchronous SA, and all in-between possibilities. We provide\nsufficient conditions for the convergence of BASA, and also prove bounds on the\n\\textit{rate} of convergence of $\\theta_t$ to the solution. For the case of\nconventional SGD, these results reduce to those proved in our companion paper.\nThen we apply these results to the problem of finding a fixed point of a map\nwith only noisy measurements. This problem arises frequently in RL. We prove\nsufficient conditions for convergence as well as estimates for the rate of\nconvergence.\n","authors":["Rajeeva L. Karandikar","M. Vidyasagar"],"pdf_url":"https://arxiv.org/pdf/2109.03445v6.pdf","comment":"34 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.02971v1","updated":"2024-08-06T06:00:17Z","published":"2024-08-06T06:00:17Z","title":"Wave Interpolation Neural Operator: Interpolated Prediction of Electric\n  Fields Across Untrained Wavelengths","summary":"  Designing photonic structures requires electromagnetic simulations, which\noften require high computational costs. Researchers have developed surrogate\nsolvers for predicting electric fields to alleviate the computational issues.\nHowever, existing surrogate solvers are limited to performing inference at\nfixed simulation conditions and require retraining for different conditions. To\naddress this, we propose Wave Interpolation Neural Operator (WINO), a novel\nsurrogate solver enabling simulation condition interpolation across a\ncontinuous spectrum of broadband wavelengths. WINO introduces the Fourier Group\nConvolution Shuffling operator and a new conditioning method to efficiently\npredict electric fields from both trained and untrained wavelength data,\nachieving significant improvements in parameter efficiency and spectral\ninterpolation performance. Our model demonstrates approximately 100 times\nfaster performance than traditional finite-difference frequency-domain\nsimulations. Moreover, compared to the state-of-the-art model, we achieve a 74%\nreduction in parameters and 80.5% improvements in prediction accuracy for\nuntrained wavelengths, and 13.2% improvements for trained wavelengths.\n","authors":["Joonhyuk Seo","Chanik Kang","Dongjin Seo","Haejun Chung"],"pdf_url":"https://arxiv.org/pdf/2408.02971v1.pdf","comment":"9 pages, 5 figures, 4 tables / Appendix: 4 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2408.02965v1","updated":"2024-08-06T05:21:31Z","published":"2024-08-06T05:21:31Z","title":"Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model\n  and Neural Operator","summary":"  Closure models are widely used in simulating complex multiscale dynamical\nsystems such as turbulence and the earth system, for which direct numerical\nsimulation that resolves all scales is often too expensive. For those systems\nwithout a clear scale separation, deterministic and local closure models often\nlack enough generalization capability, which limits their performance in many\nreal-world applications. In this work, we propose a data-driven modeling\nframework for constructing stochastic and non-local closure models via\nconditional diffusion model and neural operator. Specifically, the Fourier\nneural operator is incorporated into a score-based diffusion model, which\nserves as a data-driven stochastic closure model for complex dynamical systems\ngoverned by partial differential equations (PDEs). We also demonstrate how\naccelerated sampling methods can improve the efficiency of the data-driven\nstochastic closure model. The results show that the proposed methodology\nprovides a systematic approach via generative machine learning techniques to\nconstruct data-driven stochastic closure models for multiscale dynamical\nsystems with continuous spatiotemporal fields.\n","authors":["Xinghao Dong","Chuanqi Chen","Jin-Long Wu"],"pdf_url":"https://arxiv.org/pdf/2408.02965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02961v1","updated":"2024-08-06T05:15:57Z","published":"2024-08-06T05:15:57Z","title":"Synaptic Modulation using Interspike Intervals Increases Energy\n  Efficiency of Spiking Neural Networks","summary":"  Despite basic differences between Spiking Neural Networks (SNN) and\nArtificial Neural Networks (ANN), most research on SNNs involve adapting\nANN-based methods for SNNs. Pruning (dropping connections) and quantization\n(reducing precision) are often used to improve energy efficiency of SNNs. These\nmethods are very effective for ANNs whose energy needs are determined by\nsignals transmitted on synapses. However, the event-driven paradigm in SNNs\nimplies that energy is consumed by spikes. In this paper, we propose a new\nsynapse model whose weights are modulated by Interspike Intervals (ISI) i.e.\ntime difference between two spikes. SNNs composed of this synapse model, termed\nISI Modulated SNNs (IMSNN), can use gradient descent to estimate how the ISI of\na neuron changes after updating its synaptic parameters. A higher ISI implies\nfewer spikes and vice-versa. The learning algorithm for IMSNNs exploits this\ninformation to selectively propagate gradients such that learning is achieved\nby increasing the ISIs resulting in a network that generates fewer spikes. The\nperformance of IMSNNs with dense and convolutional layers have been evaluated\nin terms of classification accuracy and the number of spikes using the MNIST\nand FashionMNIST datasets. The performance comparison with conventional SNNs\nshows that IMSNNs exhibit upto 90% reduction in the number of spikes while\nmaintaining similar classification accuracy.\n","authors":["Dylan Adams","Magda Zajaczkowska","Ashiq Anjum","Andrea Soltoggio","Shirin Dora"],"pdf_url":"https://arxiv.org/pdf/2408.02961v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.11652v4","updated":"2024-08-06T05:10:56Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v4.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2408.02950v1","updated":"2024-08-06T04:28:16Z","published":"2024-08-06T04:28:16Z","title":"Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields\n  on irregular geometries","summary":"  We present Kolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised\ndeep learning framework for the prediction of incompressible steady-state fluid\nflow fields in irregular domains, where the predicted fields are a function of\nthe geometry of the domains. In KA-PointNet, we implement shared\nKolmogorov-Arnold Networks (KANs) in the segmentation branch of the PointNet\narchitecture. We utilize Jacobi polynomials to construct shared KANs. As a\nbenchmark test case, we consider incompressible laminar steady-state flow over\na cylinder, where the geometry of its cross-section varies over the data set.\nWe investigate the performance of Jacobi polynomials with different degrees as\nwell as special cases of Jacobi polynomials such as Legendre polynomials,\nChebyshev polynomials of the first and second kinds, and Gegenbauer\npolynomials, in terms of the computational cost of training and accuracy of\nprediction of the test set. Additionally, we compare the performance of\nPointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared\nMultilayer Perceptrons (MLPs). It is observed that when the number of trainable\nparameters is approximately equal, PointNet with shared KANs (i.e.,\nKA-PointNet) outperforms PointNet with shared MLPs.\n","authors":["Ali Kashefi"],"pdf_url":"https://arxiv.org/pdf/2408.02950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02338v3","updated":"2024-08-06T04:15:27Z","published":"2024-02-04T04:21:34Z","title":"NetLLM: Adapting Large Language Models for Networking","summary":"  Many networking tasks now employ deep learning (DL) to solve complex\nprediction and optimization problems. However, current design philosophy of\nDL-based algorithms entails intensive engineering overhead due to the manual\ndesign of deep neural networks (DNNs) for different networking tasks. Besides,\nDNNs tend to achieve poor generalization performance on unseen data\ndistributions/environments.\n  Motivated by the recent success of large language models (LLMs), this work\nstudies the LLM adaptation for networking to explore a more sustainable design\nphilosophy. With the powerful pre-trained knowledge, the LLM is promising to\nserve as the foundation model to achieve \"one model for all tasks\" with even\nbetter performance and stronger generalization. In pursuit of this vision, we\npresent NetLLM, the first framework that provides a coherent design to harness\nthe powerful capabilities of LLMs with low efforts to solve networking\nproblems. Specifically, NetLLM empowers the LLM to effectively process\nmultimodal data in networking and efficiently generate task-specific answers.\nBesides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire\ndomain knowledge for networking. Across three networking-related use cases -\nviewport prediction, adaptive bitrate streaming and cluster job scheduling, we\nshowcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art\nalgorithms.\n","authors":["Duo Wu","Xianda Wang","Yaqi Qiao","Zhi Wang","Junchen Jiang","Shuguang Cui","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2402.02338v3.pdf","comment":"This paper has been accepted by ACM SIGCOMM 2024. DOI:\n  https://doi.org/10.1145/3651890.3672268"},{"id":"http://arxiv.org/abs/2408.02946v1","updated":"2024-08-06T04:14:29Z","published":"2024-08-06T04:14:29Z","title":"Scaling Laws for Data Poisoning in LLMs","summary":"  Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.\n","authors":["Dillon Bowen","Brendan Murphy","Will Cai","David Khachaturov","Adam Gleave","Kellin Pelrine"],"pdf_url":"https://arxiv.org/pdf/2408.02946v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2408.02336v2","updated":"2024-08-06T04:04:23Z","published":"2024-08-05T09:19:52Z","title":"Infusing Environmental Captions for Long-Form Video Language Grounding","summary":"  In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.\n","authors":["Hyogun Lee","Soyeon Hong","Mujeen Sung","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2408.02336v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2312.05356v4","updated":"2024-08-06T03:57:33Z","published":"2023-12-08T20:28:08Z","title":"Neuron Patching: Semantic-based Neuron-level Language Model Repair for\n  Code Generation","summary":"  Large Language Models (LLMs) have already gained widespread adoption in\nsoftware engineering, particularly in code generation tasks. However, updating\nthese models with new knowledge can be prohibitively expensive, yet it is\nessential to maximize their utility, such as implementing a hotfix technique to\naddress urgent or critical LLM errors. In this paper, we propose \\textsc{MENT},\na novel and effective model editing approach to repair LLMs in coding tasks.\n\\textsc{MENT} is effective, efficient, and reliable, capable of correcting a\nneural model by patching just one or two neurons. As pioneering work on\nneuron-level model editing of generative models, we formalize the editing\nprocess and introduce the involved concepts. We also introduce new measures to\nevaluate its generalization ability and establish a benchmark for further\nstudy. Our approach is evaluated on three coding tasks: line-level code\ngeneration, shellcode generation, and intent-to-bash translation. The\nexperimental results demonstrate that the proposed approach significantly\noutperforms the state-of-the-art in both effectiveness and efficiency measures.\nFurthermore, we showcase the applications of \\textsc{MENT} for LLM reasoning in\nsoftware engineering. By editing LLM knowledge, the directly or indirectly\ndependent behaviors of API invocation in the chain-of-thought change\naccordingly. This illustrates the significance of repairing LLMs in the context\nof software engineering.\n","authors":["Jian Gu","Aldeida Aleti","Chunyang Chen","Hongyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.05356v4.pdf","comment":"12 pages, 7 figures, 7 tables, under peer-review"},{"id":"http://arxiv.org/abs/2408.02936v1","updated":"2024-08-06T03:42:38Z","published":"2024-08-06T03:42:38Z","title":"Achieving More with Less: A Tensor-Optimization-Powered Ensemble Method","summary":"  Ensemble learning is a method that leverages weak learners to produce a\nstrong learner. However, obtaining a large number of base learners requires\nsubstantial time and computational resources. Therefore, it is meaningful to\nstudy how to achieve the performance typically obtained with many base learners\nusing only a few. We argue that to achieve this, it is essential to enhance\nboth classification performance and generalization ability during the ensemble\nprocess. To increase model accuracy, each weak base learner needs to be more\nefficiently integrated. It is observed that different base learners exhibit\nvarying levels of accuracy in predicting different classes. To capitalize on\nthis, we introduce confidence tensors $\\tilde{\\mathbf{\\Theta}}$ and\n$\\tilde{\\mathbf{\\Theta}}_{rst}$ signifies that the $t$-th base classifier\nassigns the sample to class $r$ while it actually belongs to class $s$. To the\nbest of our knowledge, this is the first time an evaluation of the performance\nof base classifiers across different classes has been proposed. The proposed\nconfidence tensor compensates for the strengths and weaknesses of each base\nclassifier in different classes, enabling the method to achieve superior\nresults with a smaller number of base learners. To enhance generalization\nperformance, we design a smooth and convex objective function that leverages\nthe concept of margin, making the strong learner more discriminative.\nFurthermore, it is proved that in gradient matrix of the loss function, the sum\nof each column's elements is zero, allowing us to solve a constrained\noptimization problem using gradient-based methods. We then compare our\nalgorithm with random forests of ten times the size and other classical methods\nacross numerous datasets, demonstrating the superiority of our approach.\n","authors":["Jinghui Yuan","Weijin Jiang","Zhe Cao","Fangyuan Xie","Rong Wang","Feiping Nie","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.02936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02932v1","updated":"2024-08-06T03:34:43Z","published":"2024-08-06T03:34:43Z","title":"Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping","summary":"  Clustering is a fundamental task in machine learning and data science, and\nsimilarity graph-based clustering is an important approach within this domain.\nDoubly stochastic symmetric similarity graphs provide numerous benefits for\nclustering problems and downstream tasks, yet learning such graphs remains a\nsignificant challenge. Marcus theorem states that a strictly positive symmetric\nmatrix can be transformed into a doubly stochastic symmetric matrix by diagonal\nmatrices. However, in clustering, learning sparse matrices is crucial for\ncomputational efficiency. We extend Marcus theorem by proposing the Marcus\nmapping, which indicates that certain sparse matrices can also be transformed\ninto doubly stochastic symmetric matrices via diagonal matrices. Additionally,\nwe introduce rank constraints into the clustering problem and propose the\nDoubly Stochastic Adaptive Neighbors Clustering algorithm based on the Marcus\nMapping (ANCMM). This ensures that the learned graph naturally divides into the\ndesired number of clusters. We validate the effectiveness of our algorithm\nthrough extensive comparisons with state-of-the-art algorithms. Finally, we\nexplore the relationship between the Marcus mapping and optimal transport. We\nprove that the Marcus mapping solves a specific type of optimal transport\nproblem and demonstrate that solving this problem through Marcus mapping is\nmore efficient than directly applying optimal transport methods.\n","authors":["Jinghui Yuan","Chusheng Zeng","Fangyuan Xie","Zhe Cao","Rong Wang","Feiping Nie","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.02932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.10838v7","updated":"2024-08-06T03:34:27Z","published":"2022-01-26T09:44:13Z","title":"Privacy-Preserving Logistic Regression Training with A Faster Gradient\n  Variant","summary":"  Logistic regression training over encrypted data has been an attractive idea\nto security concerns for years. In this paper, we propose a faster gradient\nvariant called $\\texttt{quadratic gradient}$ for privacy-preserving logistic\nregression training. The core of $\\texttt{quadratic gradient}$ can be seen as\nan extension of the simplified fixed Hessian. We enhance Nesterov's accelerated\ngradient (NAG) and Adaptive Gradient Algorithm (Adagrad) respectively with\n$\\texttt{quadratic gradient}$ and evaluate the enhanced algorithms on several\ndatasets. Experiments show that the enhanced methods have a state-of-the-art\nperformance in convergence speed compared to the raw first-order gradient\nmethods. We then adopt the enhanced NAG method to implement homomorphic\nlogistic regression training, obtaining a comparable result by only $3$\niterations. There is a promising chance that $\\texttt{quadratic gradient}$\ncould be used to enhance other first-order gradient methods for general\nnumerical optimization problems.\n","authors":["John Chiang"],"pdf_url":"https://arxiv.org/pdf/2201.10838v7.pdf","comment":"The basic work of this paper, $\\texttt{quadratic gradient}$ and the\n  enhanced full batch NAG, was nearly finished in September 2019. The initial\n  version of this paper was written in April 2020, rejected by ICANN 2020. The\n  enhanced mini-batch NAG was introduced into this paper in September 2020 and\n  later rejected by a special issue on the journal FGCS 2020"},{"id":"http://arxiv.org/abs/2402.12022v2","updated":"2024-08-06T03:34:06Z","published":"2024-02-19T10:31:53Z","title":"Distilling Large Language Models for Text-Attributed Graph Learning","summary":"  Text-Attributed Graphs (TAGs) are graphs of connected textual documents.\nGraph models can efficiently learn TAGs, but their training heavily relies on\nhuman-annotated labels, which are scarce or even unavailable in many\napplications. Large language models (LLMs) have recently demonstrated\nremarkable capabilities in few-shot and zero-shot TAG learning, but they suffer\nfrom scalability, cost, and privacy issues. Therefore, in this work, we focus\non synergizing LLMs and graph models with their complementary strengths by\ndistilling the power of LLMs to a local graph model on TAG learning. To address\nthe inherent gaps between LLMs (generative models for texts) and graph models\n(discriminative models for graphs), we propose first to let LLMs teach an\ninterpreter with rich textual rationale and then let a student model mimic the\ninterpreter's reasoning without LLMs' textual rationale. Extensive experiments\nvalidate the efficacy of our proposed framework.\n","authors":["Bo Pan","Zheng Zhang","Yifei Zhang","Yuntong Hu","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.12022v2.pdf","comment":"CIKM 2024"},{"id":"http://arxiv.org/abs/2404.06675v2","updated":"2024-08-06T03:33:41Z","published":"2024-04-10T01:35:17Z","title":"Toward Cross-Layer Energy Optimizations in AI Systems","summary":"  The \"AI for Science, Energy, and Security\" report from DOE outlines a\nsignificant focus on developing and optimizing artificial intelligence\nworkflows for a foundational impact on a broad range of DOE missions. With the\npervasive usage of artificial intelligence (AI) and machine learning (ML) tools\nand techniques, their energy efficiency is likely to become the gating factor\ntoward adoption. This is because generative AI (GenAI) models are massive\nenergy hogs: for instance, training a 200-billion parameter large language\nmodel (LLM) at Amazon is estimated to have taken 11.9 GWh, which is enough to\npower more than a thousand average U.S. households for a year. Inference\nconsumes even more energy, because a model trained once serve millions. Given\nthis scale, high energy efficiency is key to addressing the power delivery\nproblem of constructing and operating new supercomputers and datacenters\nspecialized for AI workloads. In that regard, we outline software- and\narchitecture-level research challenges and opportunities, setting the stage for\ncreating cross-layer energy optimizations in AI systems.\n","authors":["Jae-Won Chung","Nishil Talati","Mosharaf Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2404.06675v2.pdf","comment":"2024 Energy-Efficient Computing for Science Workshop"},{"id":"http://arxiv.org/abs/2408.02930v1","updated":"2024-08-06T03:26:01Z","published":"2024-08-06T03:26:01Z","title":"The Need for a Big World Simulator: A Scientific Challenge for Continual\n  Learning","summary":"  The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.\n","authors":["Saurabh Kumar","Hong Jun Jeon","Alex Lewandowski","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2408.02930v1.pdf","comment":"Accepted to the Finding the Frame Workshop at RLC 2024"},{"id":"http://arxiv.org/abs/2408.02927v1","updated":"2024-08-06T03:21:13Z","published":"2024-08-06T03:21:13Z","title":"HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy\n  Protection","summary":"  Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.\n","authors":["Yuxin Wang","Duanyu Feng","Yongfu Dai","Zhengyu Chen","Jimin Huang","Sophia Ananiadou","Qianqian Xie","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2408.02927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00799v2","updated":"2024-08-06T03:03:16Z","published":"2024-07-22T02:27:57Z","title":"Deep Uncertainty-Based Explore for Index Construction and Retrieval in\n  Recommendation System","summary":"  In recommendation systems, the relevance and novelty of the final results are\nselected through a cascade system of Matching -> Ranking -> Strategy. The\nmatching model serves as the starting point of the pipeline and determines the\nupper bound of the subsequent stages. Balancing the relevance and novelty of\nmatching results is a crucial step in the design and optimization of\nrecommendation systems, contributing significantly to improving recommendation\nquality. However, the typical matching algorithms have not simultaneously\naddressed the relevance and novelty perfectly. One main reason is that deep\nmatching algorithms exhibit significant uncertainty when estimating items in\nthe long tail (e.g., due to insufficient training samples) items.The\nuncertainty not only affects the training of the models but also influences the\nconfidence in the index construction and beam search retrieval process of these\nmodels. This paper proposes the UICR (Uncertainty-based explore for Index\nConstruction and Retrieval) algorithm, which introduces the concept of\nuncertainty modeling in the matching stage and achieves multi-task modeling of\nmodel uncertainty and index uncertainty. The final matching results are\nobtained by combining the relevance score and uncertainty score infered by the\nmodel. Experimental results demonstrate that the UICR improves novelty without\nsacrificing relevance on realworld industrial productive environments and\nmultiple open-source datasets. Remarkably, online A/B test results of display\nadvertising in Shopee demonstrates the effectiveness of the proposed algorithm.\n","authors":["Xin Jiang","Kaiqiang Wang","Yinlong Wang","Fengchang Lv","Taiyang Peng","Shuai Yang","Xianteng Wu","Pengye Zhang","Shuo Yuan","Yifan Zeng"],"pdf_url":"https://arxiv.org/pdf/2408.00799v2.pdf","comment":"accepted by cikm2024"},{"id":"http://arxiv.org/abs/2404.07950v3","updated":"2024-08-06T02:42:32Z","published":"2024-03-18T16:50:23Z","title":"Reinforcement Learning with Generalizable Gaussian Splatting","summary":"  An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL.\n","authors":["Jiaxu Wang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Gang Han","Wen Zhao","Weining Zhang","Yecheng Shao","Yijie Guo","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2404.07950v3.pdf","comment":"7 pages,2 figures"},{"id":"http://arxiv.org/abs/2402.13699v4","updated":"2024-08-06T02:32:36Z","published":"2024-02-21T11:00:23Z","title":"Automation of Quantum Dot Measurement Analysis via Explainable Machine\n  Learning","summary":"  The rapid development of quantum dot (QD) devices for quantum computing has\nnecessitated more efficient and automated methods for device characterization\nand tuning. Many of the measurements acquired during the tuning process come in\nthe form of images that need to be properly analyzed to guide the subsequent\ntuning steps. By design, features present in such images capture certain\nbehaviors or states of the measured QD devices. When considered carefully, such\nfeatures can aid the control and calibration of QD devices. An important\nexample of such images are so-called \\textit{triangle plots}, which visually\nrepresent current flow and reveal characteristics important for QD device\ncalibration. While image-based classification tools, such as convolutional\nneural networks (CNNs), can be used to verify whether a given measurement is\n\\textit{good} and thus warrants the initiation of the next phase of tuning,\nthey do not provide any insights into how the device should be adjusted in the\ncase of \\textit{bad} images. This is because CNNs sacrifice prediction and\nmodel intelligibility for high accuracy. To ameliorate this trade-off, a recent\nstudy introduced an image vectorization approach that relies on the Gabor\nwavelet transform [1]. Here we propose an alternative vectorization method that\ninvolves mathematical modeling of synthetic triangles to mimic the experimental\ndata. Using explainable boosting machines, we show that this new method offers\nsuperior explainability of model prediction without sacrificing accuracy. This\nwork demonstrates the feasibility and advantages of applying explainable\nmachine learning techniques to the analysis of quantum dot measurements, paving\nthe way for further advances in automated and transparent QD device tuning.\n","authors":["Daniel Schug","Tyler J. Kovach","M. A. Wolfe","Jared Benson","Sanghyeok Park","J. P. Dodson","J. Corrigan","M. A. Eriksson","Justyna P. Zwolak"],"pdf_url":"https://arxiv.org/pdf/2402.13699v4.pdf","comment":"17 pages, 4 figures, abbreviated version published in Proceedings of\n  the XAI4Sci: Explainable machine learning for sciences workshop at AAAI 2024,\n  (Vancouver, Canada)"},{"id":"http://arxiv.org/abs/2305.09958v3","updated":"2024-08-06T02:32:05Z","published":"2023-05-17T05:35:49Z","title":"SIGMA: Similarity-based Efficient Global Aggregation for Heterophilous\n  Graph Neural Networks","summary":"  Graph neural networks (GNNs) realize great success in graph learning but\nsuffer from performance loss when meeting heterophily, i.e. neighboring nodes\nare dissimilar, due to their local and uniform aggregation. Existing attempts\nof heterophilous GNNs incorporate long-range or global aggregations to\ndistinguish nodes in the graph. However, these aggregations usually require\niteratively maintaining and updating full-graph information, which limits their\nefficiency when applying to large-scale graphs. In this paper, we propose\nSIGMA, an efficient global heterophilous GNN aggregation integrating the\nstructural similarity measurement SimRank. Our theoretical analysis illustrates\nthat SIGMA inherently captures distant global similarity even under\nheterophily, that conventional approaches can only achieve after iterative\naggregations. Furthermore, it enjoys efficient one-time computation with a\ncomplexity only linear to the node set size $\\mathcal{O}(n)$. Comprehensive\nevaluation demonstrates that SIGMA achieves state-of-the-art performance with\nsuperior aggregation and overall efficiency. Notably, it obtains 5$\\times$\nacceleration on the large-scale heterophily dataset \\emph{pokec} with over 30\nmillion edges compared to the best baseline aggregation.\n","authors":["Haoyu Liu","Ningyi Liao","Siqiang Luo"],"pdf_url":"https://arxiv.org/pdf/2305.09958v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02897v1","updated":"2024-08-06T02:06:04Z","published":"2024-08-06T02:06:04Z","title":"A Metric Driven Approach to Mixed Precision Training","summary":"  As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.\n","authors":["Mitchelle Rasquinha","Gil Tabak"],"pdf_url":"https://arxiv.org/pdf/2408.02897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12428v3","updated":"2024-08-06T01:45:44Z","published":"2023-10-19T02:42:20Z","title":"Enhanced Local Explainability and Trust Scores with Random Forest\n  Proximities","summary":"  We initiate a novel approach to explain the predictions and out of sample\nperformance of random forest (RF) regression and classification models by\nexploiting the fact that any RF can be mathematically formulated as an adaptive\nweighted K nearest-neighbors model. Specifically, we employ a recent result\nthat, for both regression and classification tasks, any RF prediction can be\nrewritten exactly as a weighted sum of the training targets, where the weights\nare RF proximities between the corresponding pairs of data points. We show that\nthis linearity facilitates a local notion of explainability of RF predictions\nthat generates attributions for any model prediction across observations in the\ntraining set, and thereby complements established feature-based methods like\nSHAP, which generate attributions for a model prediction across input features.\nWe show how this proximity-based approach to explainability can be used in\nconjunction with SHAP to explain not just the model predictions, but also\nout-of-sample performance, in the sense that proximities furnish a novel means\nof assessing when a given model prediction is more or less likely to be\ncorrect. We demonstrate this approach in the modeling of US corporate bond\nprices and returns in both regression and classification cases.\n","authors":["Joshua Rosaler","Dhruv Desai","Bhaskarjit Sarmah","Dimitrios Vamvourellis","Deran Onay","Dhagash Mehta","Stefano Pasquali"],"pdf_url":"https://arxiv.org/pdf/2310.12428v3.pdf","comment":"5 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.19779v2","updated":"2024-08-06T01:25:33Z","published":"2024-05-30T07:44:31Z","title":"Automatic Graph Topology-Aware Transformer","summary":"  Existing efforts are dedicated to designing many topologies and graph-aware\nstrategies for the graph Transformer, which greatly improve the model's\nrepresentation capabilities. However, manually determining the suitable\nTransformer architecture for a specific graph dataset or task requires\nextensive expert knowledge and laborious trials. This paper proposes an\nevolutionary graph Transformer architecture search framework (EGTAS) to\nautomate the construction of strong graph Transformers. We build a\ncomprehensive graph Transformer search space with the micro-level and\nmacro-level designs. EGTAS evolves graph Transformer topologies at the macro\nlevel and graph-aware strategies at the micro level. Furthermore, a surrogate\nmodel based on generic architectural coding is proposed to directly predict the\nperformance of graph Transformers, substantially reducing the evaluation cost\nof evolutionary search. We demonstrate the efficacy of EGTAS across a range of\ngraph-level and node-level tasks, encompassing both small-scale and large-scale\ngraph datasets. Experimental results and ablation studies show that EGTAS can\nconstruct high-performance architectures that rival state-of-the-art manual and\nautomated baselines.\n","authors":["Chao Wang","Jiaxuan Zhao","Lingling Li","Licheng Jiao","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2405.19779v2.pdf","comment":"This work has been accepted by IEEE Transactions on Neural Networks\n  and Learning Systems. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2408.02882v1","updated":"2024-08-06T01:20:12Z","published":"2024-08-06T01:20:12Z","title":"Compromising Embodied Agents with Contextual Backdoor Attacks","summary":"  Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.\n","authors":["Aishan Liu","Yuguang Zhou","Xianglong Liu","Tianyuan Zhang","Siyuan Liang","Jiakai Wang","Yanjun Pu","Tianlin Li","Junqi Zhang","Wenbo Zhou","Qing Guo","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2408.02882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01331v2","updated":"2024-08-06T01:10:34Z","published":"2024-08-02T15:29:39Z","title":"UnifiedNN: Efficient Neural Network Training on the Cloud","summary":"  Nowadays, cloud-based services are widely favored over the traditional\napproach of locally training a Neural Network (NN) model. Oftentimes, a cloud\nservice processes multiple requests from users--thus training multiple NN\nmodels concurrently. However, training NN models concurrently is a challenging\nprocess, which typically requires significant amounts of available computing\nresources and takes a long time to complete. In this paper, we present\nUnifiedNN to effectively train multiple NN models concurrently on the cloud.\nUnifiedNN effectively \"combines\" multiple NN models and features several memory\nand time conservation mechanisms to train multiple NN models simultaneously\nwithout impacting the accuracy of the training process. Specifically, UnifiedNN\nmerges multiple NN models and creates a large singular unified model in order\nto efficiently train all models at once. We have implemented a prototype of\nUnifiedNN in PyTorch and we have compared its performance with relevant\nstate-of-the-art frameworks. Our experimental results demonstrate that\nUnifiedNN can reduce memory consumption by up to 53% and training time by up to\n81% when compared with vanilla PyTorch without impacting the model training and\ntesting accuracy. Finally, our results indicate that UnifiedNN can reduce\nmemory consumption by up to 52% and training time by up to 41% when compared to\nstate-of-the-art frameworks when training multiple models concurrently.\n","authors":["Sifat Ut Taki","Arthi Padmanabhan","Spyridon Mastorakis"],"pdf_url":"https://arxiv.org/pdf/2408.01331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.07143v2","updated":"2024-08-06T00:51:37Z","published":"2023-10-11T02:36:52Z","title":"Imitation Learning from Purified Demonstrations","summary":"  Imitation learning has emerged as a promising approach for addressing\nsequential decision-making problems, with the assumption that expert\ndemonstrations are optimal. However, in real-world scenarios, most\ndemonstrations are often imperfect, leading to challenges in the effectiveness\nof imitation learning. While existing research has focused on optimizing with\nimperfect demonstrations, the training typically requires a certain proportion\nof optimal demonstrations to guarantee performance. To tackle these problems,\nwe propose to purify the potential noises in imperfect demonstrations first,\nand subsequently conduct imitation learning from these purified demonstrations.\nMotivated by the success of diffusion model, we introduce a two-step\npurification via diffusion process. In the first step, we apply a forward\ndiffusion process to smooth potential noises in imperfect demonstrations by\nintroducing additional noise. Subsequently, a reverse generative process is\nutilized to recover the optimal demonstration from the diffused ones. We\nprovide theoretical evidence supporting our approach, demonstrating that the\ndistance between the purified and optimal demonstration can be bounded.\nEmpirical results on MuJoCo and RoboSuite demonstrate the effectiveness of our\nmethod from different aspects.\n","authors":["Yunke Wang","Minjing Dong","Yukun Zhao","Bo Du","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2310.07143v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/1912.03573v2","updated":"2024-08-06T00:50:41Z","published":"2019-12-07T23:02:02Z","title":"Deep Variable-Block Chain with Adaptive Variable Selection","summary":"  The architectures of deep neural networks (DNN) rely heavily on the\nunderlying grid structure of variables, for instance, the lattice of pixels in\nan image. For general high dimensional data with variables not associated with\na grid, the multi-layer perceptron and deep belief network are often used.\nHowever, it is frequently observed that those networks do not perform\ncompetitively and they are not helpful for identifying important variables. In\nthis paper, we propose a framework that imposes on blocks of variables a chain\nstructure obtained by step-wise greedy search so that the DNN architecture can\nleverage the constructed grid. We call this new neural network Deep\nVariable-Block Chain (DVC). Because the variable blocks are used for\nclassification in a sequential manner, we further develop the capacity of\nselecting variables adaptively according to a number of regions trained by a\ndecision tree. Our experiments show that DVC outperforms other generic DNNs and\nother strong classifiers. Moreover, DVC can achieve high accuracy at much\nreduced dimensionality and sometimes reveals drastically different sets of\nrelevant variables for different regions.\n","authors":["Lixiang Zhang","Lin Lin","Jia Li"],"pdf_url":"https://arxiv.org/pdf/1912.03573v2.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.08847v3","updated":"2024-08-06T00:01:01Z","published":"2023-10-13T04:14:51Z","title":"On the Over-Memorization During Natural, Robust and Catastrophic\n  Overfitting","summary":"  Overfitting negatively impacts the generalization ability of deep neural\nnetworks (DNNs) in both natural and adversarial training. Existing methods\nstruggle to consistently address different types of overfitting, typically\ndesigning strategies that focus separately on either natural or adversarial\npatterns. In this work, we adopt a unified perspective by solely focusing on\nnatural patterns to explore different types of overfitting. Specifically, we\nexamine the memorization effect in DNNs and reveal a shared behaviour termed\nover-memorization, which impairs their generalization capacity. This behaviour\nmanifests as DNNs suddenly becoming high-confidence in predicting certain\ntraining patterns and retaining a persistent memory for them. Furthermore, when\nDNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit\nhigh-confidence prediction for the corresponding natural pattern. These\nfindings motivate us to holistically mitigate different types of overfitting by\nhindering the DNNs from over-memorization training patterns. To this end, we\npropose a general framework, Distraction Over-Memorization (DOM), which\nexplicitly prevents over-memorization by either removing or augmenting the\nhigh-confidence natural patterns. Extensive experiments demonstrate the\neffectiveness of our proposed method in mitigating overfitting across various\ntraining paradigms.\n","authors":["Runqi Lin","Chaojian Yu","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2310.08847v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00391v3","updated":"2024-08-06T23:58:07Z","published":"2023-12-31T04:14:43Z","title":"SAFE-SIM: Safety-Critical Closed-Loop Traffic Simulation with\n  Diffusion-Controllable Adversaries","summary":"  Evaluating the performance of autonomous vehicle planning algorithms\nnecessitates simulating long-tail safety-critical traffic scenarios. However,\ntraditional methods for generating such scenarios often fall short in terms of\ncontrollability and realism; they also neglect the dynamics of agent\ninteractions. To address these limitations, we introduce SAFE-SIM, a novel\ndiffusion-based controllable closed-loop safety-critical simulation framework.\nOur approach yields two distinct advantages: 1) generating realistic long-tail\nsafety-critical scenarios that closely reflect real-world conditions, and 2)\nproviding controllable adversarial behavior for more comprehensive and\ninteractive evaluations. We develop a novel approach to simulate\nsafety-critical scenarios through an adversarial term in the denoising process\nof diffusion models, which allows an adversarial agent to challenge a planner\nwith plausible maneuvers while all agents in the scene exhibit reactive and\nrealistic behaviors. Furthermore, we propose novel guidance objectives and a\npartial diffusion process that enables users to control key aspects of the\nscenarios, such as the collision type and aggressiveness of the adversarial\nagent, while maintaining the realism of the behavior. We validate our framework\nempirically using the nuScenes and nuPlan datasets across multiple planners,\ndemonstrating improvements in both realism and controllability. These findings\naffirm that diffusion models provide a robust and versatile foundation for\nsafety-critical, interactive traffic simulation, extending their utility across\nthe broader autonomous driving landscape. Project website:\nhttps://safe-sim.github.io/.\n","authors":["Wei-Jer Chang","Francesco Pittaluga","Masayoshi Tomizuka","Wei Zhan","Manmohan Chandraker"],"pdf_url":"https://arxiv.org/pdf/2401.00391v3.pdf","comment":"Accepted by ECCV2024; Project website: https://safe-sim.github.io/"},{"id":"http://arxiv.org/abs/2408.03480v1","updated":"2024-08-06T23:43:03Z","published":"2024-08-06T23:43:03Z","title":"Advancing EEG-Based Gaze Prediction Using Depthwise Separable\n  Convolution and Enhanced Pre-Processing","summary":"  In the field of EEG-based gaze prediction, the application of deep learning\nto interpret complex neural data poses significant challenges. This study\nevaluates the effectiveness of pre-processing techniques and the effect of\nadditional depthwise separable convolution on EEG vision transformers (ViTs) in\na pretrained model architecture. We introduce a novel method, the EEG Deeper\nClustered Vision Transformer (EEG-DCViT), which combines depthwise separable\nconvolutional neural networks (CNNs) with vision transformers, enriched by a\npre-processing strategy involving data clustering. The new approach\ndemonstrates superior performance, establishing a new benchmark with a Root\nMean Square Error (RMSE) of 51.6 mm. This achievement underscores the impact of\npre-processing and model refinement in enhancing EEG-based applications.\n","authors":["Matthew L Key","Tural Mehtiyev","Xiaodong Qu"],"pdf_url":"https://arxiv.org/pdf/2408.03480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03478v1","updated":"2024-08-06T23:34:49Z","published":"2024-08-06T23:34:49Z","title":"Effect of Kernel Size on CNN-Vision-Transformer-Based Gaze Prediction\n  Using Electroencephalography Data","summary":"  In this paper, we present an algorithm of gaze prediction from\nElectroencephalography (EEG) data. EEG-based gaze prediction is a new research\ntopic that can serve as an alternative to traditional video-based eye-tracking.\nCompared to the existing state-of-the-art (SOTA) method, we improved the root\nmean-squared-error of EEG-based gaze prediction to 53.06 millimeters, while\nreducing the training time to less than 33% of its original duration. Our\nsource code can be found at https://github.com/AmCh-Q/CSCI6907Project\n","authors":["Chuhui Qiu","Bugao Liang","Matthew L Key"],"pdf_url":"https://arxiv.org/pdf/2408.03478v1.pdf","comment":"International Conference on Human-Computer Interaction (HCII 2024)"},{"id":"http://arxiv.org/abs/2408.03475v1","updated":"2024-08-06T23:14:39Z","published":"2024-08-06T23:14:39Z","title":"Can LLMs Serve As Time Series Anomaly Detectors?","summary":"  An emerging topic in large language models (LLMs) is their application to\ntime series forecasting, characterizing mainstream and patternable\ncharacteristics of time series. A relevant but rarely explored and more\nchallenging question is whether LLMs can detect and explain time series\nanomalies, a critical task across various real-world applications. In this\npaper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,\nin detecting and explaining anomalies in time series. Our studies reveal that:\n1) LLMs cannot be directly used for time series anomaly detection. 2) By\ndesigning prompt strategies such as in-context learning and chain-of-thought\nprompting, GPT-4 can detect time series anomalies with results competitive to\nbaseline methods. 3) We propose a synthesized dataset to automatically generate\ntime series anomalies with corresponding explanations. By applying instruction\nfine-tuning on this dataset, LLaMA3 demonstrates improved performance in time\nseries anomaly detection tasks. In summary, our exploration shows the promising\npotential of LLMs as time series anomaly detectors.\n","authors":["Manqing Dong","Hao Huang","Longbing Cao"],"pdf_url":"https://arxiv.org/pdf/2408.03475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.08119v3","updated":"2024-08-06T23:09:06Z","published":"2024-01-16T05:23:34Z","title":"SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic\n  Spatio-Temporal Traffic Forecasting","summary":"  Traffic forecasting, a crucial application of spatio-temporal graph (STG)\nlearning, has traditionally relied on deterministic models for accurate point\nestimations. Yet, these models fall short of quantifying future uncertainties.\nRecently, many probabilistic methods, especially variants of diffusion models,\nhave been proposed to fill this gap. However, existing diffusion methods\ntypically deal with individual sensors separately when generating future time\nseries, resulting in limited usage of spatial information in the probabilistic\nlearning process. In this work, we propose SpecSTG, a novel spectral diffusion\nframework, to better leverage spatial dependencies and systematic patterns\ninherent in traffic data. More specifically, our method generates the Fourier\nrepresentation of future time series, transforming the learning process into\nthe spectral domain enriched with spatial information. Additionally, our\napproach incorporates a fast spectral graph convolution designed for Fourier\ninput, alleviating the computational burden associated with existing models.\nCompared with state-of-the-arts, SpecSTG achieves up to 8% improvements on\npoint estimations and up to 0.78% improvements on quantifying future\nuncertainties. Furthermore, SpecSTG's training and validation speed is 3.33X of\nthe most efficient existing diffusion method for STG forecasting. The source\ncode for SpecSTG is available at https://anonymous.4open.science/r/SpecSTG.\n","authors":["Lequan Lin","Dai Shi","Andi Han","Junbin Gao"],"pdf_url":"https://arxiv.org/pdf/2401.08119v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03472v1","updated":"2024-08-06T23:05:15Z","published":"2024-08-06T23:05:15Z","title":"Integrating HCI Datasets in Project-Based Machine Learning Courses: A\n  College-Level Review and Case Study","summary":"  This study explores the integration of real-world machine learning (ML)\nprojects using human-computer interfaces (HCI) datasets in college-level\ncourses to enhance both teaching and learning experiences. Employing a\ncomprehensive literature review, course websites analysis, and a detailed case\nstudy, the research identifies best practices for incorporating HCI datasets\ninto project-based ML education. Key f indings demonstrate increased student\nengagement, motivation, and skill development through hands-on projects, while\ninstructors benefit from effective tools for teaching complex concepts. The\nstudy also addresses challenges such as data complexity and resource\nallocation, offering recommendations for future improvements. These insights\nprovide a valuable framework for educators aiming to bridge the gap between\n","authors":["Xiaodong Qu","Matthew Key","Eric Luo","Chuhui Qiu"],"pdf_url":"https://arxiv.org/pdf/2408.03472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03464v1","updated":"2024-08-06T22:39:34Z","published":"2024-08-06T22:39:34Z","title":"AI Foundation Models in Remote Sensing: A Survey","summary":"  Artificial Intelligence (AI) technologies have profoundly transformed the\nfield of remote sensing, revolutionizing data collection, processing, and\nanalysis. Traditionally reliant on manual interpretation and task-specific\nmodels, remote sensing has been significantly enhanced by the advent of\nfoundation models--large-scale, pre-trained AI models capable of performing a\nwide array of tasks with unprecedented accuracy and efficiency. This paper\nprovides a comprehensive survey of foundation models in the remote sensing\ndomain, covering models released between June 2021 and June 2024. We categorize\nthese models based on their applications in computer vision and domain-specific\ntasks, offering insights into their architectures, pre-training datasets, and\nmethodologies. Through detailed performance comparisons, we highlight emerging\ntrends and the significant advancements achieved by these foundation models.\nAdditionally, we discuss the technical challenges, practical implications, and\nfuture research directions, addressing the need for high-quality data,\ncomputational resources, and improved model generalization. Our research also\nfinds that pre-training methods, particularly self-supervised learning\ntechniques like contrastive learning and masked autoencoders, significantly\nenhance the performance and robustness of foundation models in remote sensing\ntasks such as scene classification, object detection, and other applications.\nThis survey aims to serve as a resource for researchers and practitioners by\nproviding a panorama of advances and promising pathways for continued\ndevelopment and application of foundation models in remote sensing.\n","authors":["Siqi Lu","Junlin Guo","James R Zimmer-Dauphinee","Jordan M Nieusma","Xiao Wang","Parker VanValkenburgh","Steven A Wernke","Yuankai Huo"],"pdf_url":"https://arxiv.org/pdf/2408.03464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07632v3","updated":"2024-08-06T22:37:21Z","published":"2024-03-12T13:12:24Z","title":"CardioGenAI: A Machine Learning-Based Framework for Re-Engineering Drugs\n  for Reduced hERG Liability","summary":"  The link between in vitro hERG ion channel inhibition and subsequent in vivo\nQT interval prolongation, a critical risk factor for the development of\narrythmias such as Torsade de Pointes, is so well established that in vitro\nhERG activity alone is often sufficient to end the development of an otherwise\npromising drug candidate. It is therefore of tremendous interest to develop\nadvanced methods for identifying hERG-active compounds in the early stages of\ndrug development, as well as for proposing redesigned compounds with reduced\nhERG liability and preserved on-target potency. In this work, we present\nCardioGenAI, a machine learning-based framework for re-engineering both\ndevelopmental and commercially available drugs for reduced hERG activity while\npreserving their pharmacological activity. The framework incorporates novel\nstate-of-the-art discriminative models for predicting hERG channel activity, as\nwell as activity against the voltage-gated NaV1.5 and CaV1.2 channels due to\ntheir potential implications in modulating the arrhythmogenic potential induced\nby hERG channel blockade. We applied the complete framework to pimozide, an\nFDA-approved antipsychotic agent that demonstrates high affinity to the hERG\nchannel, and generated 100 refined candidates. Remarkably, among the candidates\nis fluspirilene, a compound which is of the same class of drugs\n(diphenylmethanes) as pimozide and therefore has similar pharmacological\nactivity, yet exhibits over 700-fold weaker binding to hERG. We envision that\nthis method can effectively be applied to developmental compounds exhibiting\nhERG liabilities to provide a means of rescuing drug development programs that\nhave stalled due to hERG-related safety concerns. We have made all of our\nsoftware open-source to facilitate integration of the CardioGenAI framework for\nmolecular hypothesis generation into drug discovery workflows.\n","authors":["Gregory W. Kyro","Matthew T. Martin","Eric D. Watt","Victor S. Batista"],"pdf_url":"https://arxiv.org/pdf/2403.07632v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11704v2","updated":"2024-08-06T22:37:06Z","published":"2024-06-17T16:25:04Z","title":"Nemotron-4 340B Technical Report","summary":"  We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base,\nNemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open\naccess under the NVIDIA Open Model License Agreement, a permissive model\nlicense that allows distribution, modification, and use of the models and its\noutputs. These models perform competitively to open access models on a wide\nrange of evaluation benchmarks, and were sized to fit on a single DGX H100 with\n8 GPUs when deployed in FP8 precision. We believe that the community can\nbenefit from these models in various research studies and commercial\napplications, especially for generating synthetic data to train smaller\nlanguage models. Notably, over 98% of data used in our model alignment process\nis synthetically generated, showcasing the effectiveness of these models in\ngenerating synthetic data. To further support open research and facilitate\nmodel development, we are also open-sourcing the synthetic data generation\npipeline used in our model alignment process.\n","authors":[" Nvidia"," :","Bo Adler","Niket Agarwal","Ashwath Aithal","Dong H. Anh","Pallab Bhattacharya","Annika Brundyn","Jared Casper","Bryan Catanzaro","Sharon Clay","Jonathan Cohen","Sirshak Das","Ayush Dattagupta","Olivier Delalleau","Leon Derczynski","Yi Dong","Daniel Egert","Ellie Evans","Aleksander Ficek","Denys Fridman","Shaona Ghosh","Boris Ginsburg","Igor Gitman","Tomasz Grzegorzek","Robert Hero","Jining Huang","Vibhu Jawa","Joseph Jennings","Aastha Jhunjhunwala","John Kamalu","Sadaf Khan","Oleksii Kuchaiev","Patrick LeGresley","Hui Li","Jiwei Liu","Zihan Liu","Eileen Long","Ameya Sunil Mahabaleshwarkar","Somshubra Majumdar","James Maki","Miguel Martinez","Maer Rodrigues de Melo","Ivan Moshkov","Deepak Narayanan","Sean Narenthiran","Jesus Navarro","Phong Nguyen","Osvald Nitski","Vahid Noroozi","Guruprasad Nutheti","Christopher Parisien","Jupinder Parmar","Mostofa Patwary","Krzysztof Pawelec","Wei Ping","Shrimai Prabhumoye","Rajarshi Roy","Trisha Saar","Vasanth Rao Naik Sabavat","Sanjeev Satheesh","Jane Polak Scowcroft","Jason Sewall","Pavel Shamis","Gerald Shen","Mohammad Shoeybi","Dave Sizer","Misha Smelyanskiy","Felipe Soares","Makesh Narsimhan Sreedhar","Dan Su","Sandeep Subramanian","Shengyang Sun","Shubham Toshniwal","Hao Wang","Zhilin Wang","Jiaxuan You","Jiaqi Zeng","Jimmy Zhang","Jing Zhang","Vivienne Zhang","Yian Zhang","Chen Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.11704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18742v5","updated":"2024-08-06T22:33:26Z","published":"2024-03-27T16:39:28Z","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","summary":"  Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2403.18742v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15750v2","updated":"2024-08-06T22:29:11Z","published":"2024-05-24T17:47:20Z","title":"Filtered Corpus Training (FiCT) Shows that Language Models can\n  Generalize from Indirect Evidence","summary":"  This paper introduces Filtered Corpus Training, a method that trains language\nmodels (LMs) on corpora with certain linguistic constructions filtered out from\nthe training data, and uses it to measure the ability of LMs to perform\nlinguistic generalization on the basis of indirect evidence. We apply the\nmethod to both LSTM and Transformer LMs (of roughly comparable size),\ndeveloping filtered corpora that target a wide range of linguistic phenomena.\nOur results show that while transformers are better qua LMs (as measured by\nperplexity), both models perform equally and surprisingly well on linguistic\ngeneralization measures, suggesting that they are capable of generalizing from\nindirect evidence.\n","authors":["Abhinav Patil","Jaap Jumelet","Yu Ying Chiu","Andy Lapastora","Peter Shen","Lexie Wang","Clevis Willrich","Shane Steinert-Threlkeld"],"pdf_url":"https://arxiv.org/pdf/2405.15750v2.pdf","comment":"Forthcoming in Transactions of the Association for Computational\n  Linguistics (TACL). This is a pre-MIT Press publication version. For code and\n  trained models, see http://github.com/CLMBRs/corpus-filtering"},{"id":"http://arxiv.org/abs/2401.12972v2","updated":"2024-08-06T22:28:25Z","published":"2024-01-23T18:58:35Z","title":"On the Efficacy of Text-Based Input Modalities for Action Anticipation","summary":"  Anticipating future actions is a highly challenging task due to the diversity\nand scale of potential future actions; yet, information from different\nmodalities help narrow down plausible action choices. Each modality can provide\ndiverse and often complementary context for the model to learn from. While\nprevious multi-modal methods leverage information from modalities such as video\nand audio, we primarily explore how text descriptions of actions and objects\ncan also lead to more accurate action anticipation by providing additional\ncontextual cues, e.g., about the environment and its contents. We propose a\nMulti-modal Contrastive Anticipative Transformer (M-CAT), a video transformer\narchitecture that jointly learns from multi-modal features and text\ndescriptions of actions and objects. We train our model in two stages, where\nthe model first learns to align video clips with descriptions of future\nactions, and is subsequently fine-tuned to predict future actions. Compared to\nexisting methods, M-CAT has the advantage of learning additional context from\ntwo types of text inputs: rich descriptions of future actions during\npre-training, and, text descriptions for detected objects and actions during\nmodality feature fusion. Through extensive experimental evaluation, we\ndemonstrate that our model outperforms previous methods on the EpicKitchens\ndatasets, and show that using simple text descriptions of actions and objects\naid in more effective action anticipation. In addition, we examine the impact\nof object and action information obtained via text, and perform extensive\nablations.\n","authors":["Apoorva Beedu","Karan Samel","Irfan Essa"],"pdf_url":"https://arxiv.org/pdf/2401.12972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03461v1","updated":"2024-08-06T22:14:54Z","published":"2024-08-06T22:14:54Z","title":"When does the mean network capture the topology of a sample of networks?","summary":"  The notion of Fr\\'echet mean (also known as \"barycenter\") network is the\nworkhorse of most machine learning algorithms that require the estimation of a\n\"location\" parameter to analyse network-valued data. In this context, it is\ncritical that the network barycenter inherits the topological structure of the\nnetworks in the training dataset. The metric - which measures the proximity\nbetween networks - controls the structural properties of the barycenter. This\nwork is significant because it provides for the first time analytical estimates\nof the sample Fr\\'echet mean for the stochastic blockmodel, which is at the\ncutting edge of rigorous probabilistic analysis of random networks. We show\nthat the mean network computed with the Hamming distance is unable to capture\nthe topology of the networks in the training sample, whereas the mean network\ncomputed using the effective resistance distance recovers the correct\npartitions and associated edge density. From a practical standpoint, our work\ninforms the choice of metrics in the context where the sample Fr\\'echet mean\nnetwork is used to characterise the topology of networks for network-valued\nmachine learning\n","authors":["François G Meyer"],"pdf_url":"https://arxiv.org/pdf/2408.03461v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2408.03459v1","updated":"2024-08-06T22:11:00Z","published":"2024-08-06T22:11:00Z","title":"On the Generalization of Preference Learning with DPO","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities but\noften struggle to align with human preferences, leading to harmful or\nundesirable outputs. Preference learning, which trains models to distinguish\nbetween preferred and non-preferred responses based on human feedback, has\nbecome a crucial component for ensuring that LLMs align with human values.\nDespite the widespread adoption in real-world systems, a thorough theoretical\nunderstanding of the generalization guarantees for these models remain lacking.\nThis paper bridges that gap by introducing a new theoretical framework to\nanalyze the generalization guarantees of models trained with direct preference\noptimization (DPO). While existing generalization theory often focuses on\noverparameterized models achieving near-optimal loss or models independent of\nthe training process, our framework rigorously assesses how well models\ngeneralize after a finite number of gradient steps, reflecting real-world LLM\ntraining practices. By analyzing the reward margin associated with each sample\nand its trajectory throughout training, we can effectively bound the\ngeneralization error. We derive learning guarantees showing that, under\nspecific conditions, models trained with DPO can correctly discern preferred\nresponses on unseen data with high probability. These insights are empirically\nvalidated on contemporary LLMs, underscoring the practical relevance of our\ntheoretical findings.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2408.03459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.09753v2","updated":"2024-08-06T21:54:20Z","published":"2024-04-15T12:54:31Z","title":"Personalized Collaborative Fine-Tuning for On-Device Large Language\n  Models","summary":"  We explore on-device self-supervised collaborative fine-tuning of large\nlanguage models with limited local data availability. Taking inspiration from\nthe collaborative learning community, we introduce three distinct\ntrust-weighted gradient aggregation schemes: weight similarity-based,\nprediction similarity-based and validation performance-based. To minimize\ncommunication overhead, we integrate Low-Rank Adaptation (LoRA) and only\nexchange LoRA weight updates. Our protocols, driven by prediction and\nperformance metrics, surpass both FedAvg and local fine-tuning methods, which\nis particularly evident in realistic scenarios with more diverse local data\ndistributions. The results underscore the effectiveness of our approach in\naddressing heterogeneity and scarcity within local datasets.\n","authors":["Nicolas Wagner","Dongyang Fan","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2404.09753v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16266v2","updated":"2024-08-06T21:26:31Z","published":"2024-05-25T15:08:36Z","title":"Deep Reinforcement Learning with Enhanced PPO for Safe Mobile Robot\n  Navigation","summary":"  Collision-free motion is essential for mobile robots. Most approaches to\ncollision-free and efficient navigation with wheeled robots require parameter\ntuning by experts to obtain good navigation behavior. This study investigates\nthe application of deep reinforcement learning to train a mobile robot for\nautonomous navigation in a complex environment. The robot utilizes LiDAR sensor\ndata and a deep neural network to generate control signals guiding it toward a\nspecified target while avoiding obstacles. We employ two reinforcement learning\nalgorithms in the Gazebo simulation environment: Deep Deterministic Policy\nGradient and proximal policy optimization. The study introduces an enhanced\nneural network structure in the Proximal Policy Optimization algorithm to boost\nperformance, accompanied by a well-designed reward function to improve\nalgorithm efficacy. Experimental results conducted in both obstacle and\nobstacle-free environments underscore the effectiveness of the proposed\napproach. This research significantly contributes to the advancement of\nautonomous robotics in complex environments through the application of deep\nreinforcement learning.\n","authors":["Hamid Taheri","Seyed Rasoul Hosseini","Mohammad Ali Nekoui"],"pdf_url":"https://arxiv.org/pdf/2405.16266v2.pdf","comment":"This paper is under review by Int. J. of Intelligent Machines and\n  Robotics"},{"id":"http://arxiv.org/abs/2407.19943v2","updated":"2024-08-06T21:16:16Z","published":"2024-07-29T12:23:59Z","title":"Practical and Robust Safety Guarantees for Advanced Counterfactual\n  Learning to Rank","summary":"  Counterfactual learning to rank (CLTR) can be risky and, in various\ncircumstances, can produce sub-optimal models that hurt performance when\ndeployed. Safe CLTR was introduced to mitigate these risks when using inverse\npropensity scoring to correct for position bias. However, the existing safety\nmeasure for CLTR is not applicable to state-of-the-art CLTR methods, cannot\nhandle trust bias, and relies on specific assumptions about user behavior. Our\ncontributions are two-fold. First, we generalize the existing safe CLTR\napproach to make it applicable to state-of-the-art doubly robust CLTR and trust\nbias. Second, we propose a novel approach, proximal ranking policy optimization\n(PRPO), that provides safety in deployment without assumptions about user\nbehavior. PRPO removes incentives for learning ranking behavior that is too\ndissimilar to a safe ranking model. Thereby, PRPO imposes a limit on how much\nlearned models can degrade performance metrics, without relying on any specific\nuser assumptions. Our experiments show that both our novel safe doubly robust\nmethod and PRPO provide higher performance than the existing safe inverse\npropensity scoring approach. However, in unexpected circumstances, the safe\ndoubly robust approach can become unsafe and bring detrimental performance. In\ncontrast, PRPO always maintains safety, even in maximally adversarial\nsituations. By avoiding assumptions, PRPO is the first method with\nunconditional safety in deployment that translates to robust safety for\nreal-world applications.\n","authors":["Shashank Gupta","Harrie Oosterhuis","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2407.19943v2.pdf","comment":"Accepted as full paper at CIKM 2024"},{"id":"http://arxiv.org/abs/2403.10795v2","updated":"2024-08-06T21:14:23Z","published":"2024-03-16T03:54:38Z","title":"Can Large Language Models Solve Robot Routing?","summary":"  Routing problems are common in mobile robotics, encompassing tasks such as\ninspection, surveillance, and coverage. Depending on the objective and\nconstraints, these problems often reduce to variants of the Traveling Salesman\nProblem (TSP), with solutions traditionally derived by translating high-level\nobjectives into an optimization formulation and using modern solvers to arrive\nat a solution. Here, we explore the potential of Large Language Models (LLMs)\nto replace the entire pipeline from tasks described in natural language to the\ngeneration of robot routes. We systematically investigate the performance of\nLLMs in robot routing by constructing a dataset with 80 unique robot routing\nproblems across 8 variants in both single and multi-robot settings. We evaluate\nLLMs through three frameworks: single attempt, self-debugging, and\nself-debugging with self-verification and various contexts, including\nmathematical formulations, pseudo-code, and related research papers. Our\nfindings reveal that both self-debugging and self-verification enhance success\nrates without significantly lowering the optimality gap. We observe\ncontext-sensitive behavior - providing mathematical formulations as context\ndecreases the optimality gap but significantly decreases success rates and\nproviding pseudo-code and related research papers as context does not\nconsistently improve success rates or decrease the optimality gap. We identify\nkey challenges and propose future directions to enhance LLM performance in\nsolving robot routing problems. Our source code is available on the project\nwebsite: https://sites.google.com/view/words-to-routes/.\n","authors":["Zhehui Huang","Guangyao Shi","Gaurav S. Sukhatme"],"pdf_url":"https://arxiv.org/pdf/2403.10795v2.pdf","comment":"Submitted to International Symposium of Robotics Research (ISRR 2024)"},{"id":"http://arxiv.org/abs/2407.19305v2","updated":"2024-08-06T21:07:17Z","published":"2024-07-27T17:27:05Z","title":"GP-VLS: A general-purpose vision language model for surgery","summary":"  Surgery requires comprehensive medical knowledge, visual assessment skills,\nand procedural expertise. While recent surgical AI models have focused on\nsolving task-specific problems, there is a need for general-purpose systems\nthat can understand surgical scenes and interact through natural language. This\npaper introduces GP-VLS, a general-purpose vision language model for surgery\nthat integrates medical and surgical knowledge with visual scene understanding.\nFor comprehensively evaluating general-purpose surgical models, we propose\nSurgiQual, which evaluates across medical and surgical knowledge benchmarks as\nwell as surgical vision-language questions. To train GP-VLS, we develop six new\ndatasets spanning medical knowledge, surgical textbooks, and vision-language\npairs for tasks like phase recognition and tool identification. We show that\nGP-VLS significantly outperforms existing open- and closed-source models on\nsurgical vision-language tasks, with 8-21% improvements in accuracy across\nSurgiQual benchmarks. GP-VLS also demonstrates strong performance on medical\nand surgical knowledge tests compared to open-source alternatives. Overall,\nGP-VLS provides an open-source foundation for developing AI assistants to\nsupport surgeons across a wide range of tasks and scenarios. The code and data\nfor this work is publicly available at gpvls-surgery-vlm.github.io.\n","authors":["Samuel Schmidgall","Joseph Cho","Cyril Zakka","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2407.19305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03450v1","updated":"2024-08-06T21:03:16Z","published":"2024-08-06T21:03:16Z","title":"Probabilistic Surrogate Model for Accelerating the Design of Electric\n  Vehicle Battery Enclosures for Crash Performance","summary":"  This paper presents a probabilistic surrogate model for the accelerated\ndesign of electric vehicle battery enclosures with a focus on crash\nperformance. The study integrates high-throughput finite element simulations\nand Gaussian Process Regression to develop a surrogate model that predicts\ncrash parameters with high accuracy while providing uncertainty estimates. The\nmodel was trained using data generated from thermoforming and crash simulations\nover a range of material and process parameters. Validation against new\nsimulation data demonstrated the model's predictive accuracy with mean absolute\npercentage errors within 8.08% for all output variables. Additionally, a Monte\nCarlo uncertainty propagation study revealed the impact of input variability on\noutputs. The results highlight the efficacy of the Gaussian Process Regression\nmodel in capturing complex relationships within the dataset, offering a robust\nand efficient tool for the design optimization of composite battery enclosures.\n","authors":["Shadab Anwar Shaikh","Harish Cherukuri","Kranthi Balusu","Ram Devanathan","Ayoub Soulami"],"pdf_url":"https://arxiv.org/pdf/2408.03450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03449v1","updated":"2024-08-06T21:02:27Z","published":"2024-08-06T21:02:27Z","title":"EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction\n  with Advanced Mobile Architectures","summary":"  Electroencephalography (EEG) analysis is an important domain in the realm of\nBrain-Computer Interface (BCI) research. To ensure BCI devices are capable of\nproviding practical applications in the real world, brain signal processing\ntechniques must be fast, accurate, and resource-conscious to deliver\nlow-latency neural analytics. This study presents a model that leverages a\npre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression\ntasks. Our results showcase that this model is capable of performing at a level\ncomparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the\nEEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our\nresearch presents a cost-effective model applicable to resource-constrained\ndevices and contributes to expanding future research on lightweight,\nmobile-friendly models for EEG regression.\n","authors":["Teng Liang","Andrews Damoah"],"pdf_url":"https://arxiv.org/pdf/2408.03449v1.pdf","comment":"Accepted HCI International 2024 - Late Breaking Work"},{"id":"http://arxiv.org/abs/2408.03445v1","updated":"2024-08-06T20:53:02Z","published":"2024-08-06T20:53:02Z","title":"Spacecraft inertial parameters estimation using time series clustering\n  and reinforcement learning","summary":"  This paper presents a machine learning approach to estimate the inertial\nparameters of a spacecraft in cases when those change during operations, e.g.\nmultiple deployments of payloads, unfolding of appendages and booms, propellant\nconsumption as well as during in-orbit servicing and active debris removal\noperations. The machine learning approach uses time series clustering together\nwith an optimised actuation sequence generated by reinforcement learning to\nfacilitate distinguishing among different inertial parameter sets. The\nperformance of the proposed strategy is assessed against the case of a\nmulti-satellite deployment system showing that the algorithm is resilient\ntowards common disturbances in such kinds of operations.\n","authors":["Konstantinos Platanitis","Miguel Arana-Catania","Leonardo Capicchiano","Saurabh Upadhyay","Leonard Felicetti"],"pdf_url":"https://arxiv.org/pdf/2408.03445v1.pdf","comment":"6 pages, 3 figures, 1 table. To be presented in ESA - AI for Space\n  (SPAICE)"},{"id":"http://arxiv.org/abs/2408.03441v1","updated":"2024-08-06T20:40:20Z","published":"2024-08-06T20:40:20Z","title":"Simple Perturbations Subvert Ethereum Phishing Transactions Detection:\n  An Empirical Analysis","summary":"  This paper explores the vulnerability of machine learning models,\nspecifically Random Forest, Decision Tree, and K-Nearest Neighbors, to very\nsimple single-feature adversarial attacks in the context of Ethereum fraudulent\ntransaction detection. Through comprehensive experimentation, we investigate\nthe impact of various adversarial attack strategies on model performance\nmetrics, such as accuracy, precision, recall, and F1-score. Our findings,\nhighlighting how prone those techniques are to simple attacks, are alarming,\nand the inconsistency in the attacks' effect on different algorithms promises\nways for attack mitigation. We examine the effectiveness of different\nmitigation strategies, including adversarial training and enhanced feature\nselection, in enhancing model robustness.\n","authors":["Ahod Alghureid","David Mohaisen"],"pdf_url":"https://arxiv.org/pdf/2408.03441v1.pdf","comment":"12 pages, 1 figure, 5 tables, accepted for presentation at WISA 2024"},{"id":"http://arxiv.org/abs/2408.03433v1","updated":"2024-08-06T20:19:06Z","published":"2024-08-06T20:19:06Z","title":"Hybrid diffusion models: combining supervised and generative pretraining\n  for label-efficient fine-tuning of segmentation models","summary":"  We are considering in this paper the task of label-efficient fine-tuning of\nsegmentation models: We assume that a large labeled dataset is available and\nallows to train an accurate segmentation model in one domain, and that we have\nto adapt this model on a related domain where only a few samples are available.\nWe observe that this adaptation can be done using two distinct methods: The\nfirst method, supervised pretraining, is simply to take the model trained on\nthe first domain using classical supervised learning, and fine-tune it on the\nsecond domain with the available labeled samples. The second method is to\nperform self-supervised pretraining on the first domain using a generic pretext\ntask in order to get high-quality representations which can then be used to\ntrain a model on the second domain in a label-efficient way. We propose in this\npaper to fuse these two approaches by introducing a new pretext task, which is\nto perform simultaneously image denoising and mask prediction on the first\ndomain. We motivate this choice by showing that in the same way that an image\ndenoiser conditioned on the noise level can be considered as a generative model\nfor the unlabeled image distribution using the theory of diffusion models, a\nmodel trained using this new pretext task can be considered as a generative\nmodel for the joint distribution of images and segmentation masks under the\nassumption that the mapping from images to segmentation masks is deterministic.\nWe then empirically show on several datasets that fine-tuning a model\npretrained using this approach leads to better results than fine-tuning a\nsimilar model trained using either supervised or unsupervised pretraining only.\n","authors":["Bruno Sauvalle","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2408.03433v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2406.17885v2","updated":"2024-08-06T20:06:11Z","published":"2024-06-25T18:47:50Z","title":"Enabling Regional Explainability by Automatic and Model-agnostic Rule\n  Extraction","summary":"  In Explainable AI, rule extraction translates model knowledge into logical\nrules, such as IF-THEN statements, crucial for understanding patterns learned\nby black-box models. This could significantly aid in fields like disease\ndiagnosis, disease progression estimation, or drug discovery. However, such\napplication domains often contain imbalanced data, with the class of interest\nunderrepresented. Existing methods inevitably compromise the performance of\nrules for the minor class to maximise the overall performance. As the first\nattempt in this field, we propose a model-agnostic approach for extracting\nrules from specific subgroups of data, featuring automatic rule generation for\nnumerical features. This method enhances the regional explainability of machine\nlearning models and offers wider applicability compared to existing methods. We\nadditionally introduce a new method for selecting features to compose rules,\nreducing computational costs in high-dimensional spaces. Experiments across\nvarious datasets and models demonstrate the effectiveness of our methods.\n","authors":["Yu Chen","Tianyu Cui","Alexander Capstick","Nan Fletcher-Loyd","Payam Barnaghi"],"pdf_url":"https://arxiv.org/pdf/2406.17885v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2408.03425v1","updated":"2024-08-06T20:02:57Z","published":"2024-08-06T20:02:57Z","title":"Sequential Conditional Transport on Probabilistic Graphs for\n  Interpretable Counterfactual Fairness","summary":"  In this paper, we link two existing approaches to derive counterfactuals:\nadaptations based on a causal graph, as suggested in Ple\\v{c}ko and Meinshausen\n(2020) and optimal transport, as in De Lara et al. (2024). We extend \"Knothe's\nrearrangement\" Bonnotte (2013) and \"triangular transport\" Zech and Marzouk\n(2022a) to probabilistic graphical models, and use this counterfactual\napproach, referred to as sequential transport, to discuss individual fairness.\nAfter establishing the theoretical foundations of the proposed method, we\ndemonstrate its application through numerical experiments on both synthetic and\nreal datasets.\n","authors":["Agathe Fernandes Machado","Arthur Charpentier","Ewen Gallic"],"pdf_url":"https://arxiv.org/pdf/2408.03425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05707v4","updated":"2024-08-06T19:53:17Z","published":"2023-10-09T13:29:37Z","title":"Guiding Language Model Reasoning with Planning Tokens","summary":"  Large language models (LLMs) have recently attracted considerable interest\nfor their ability to perform complex reasoning tasks, such as chain-of-thought\n(CoT) reasoning. However, most of the existing approaches to enhance this\nability rely heavily on data-driven methods, while neglecting the structural\naspects of the model's reasoning capacity. To encourage a more structural\ngeneration of CoT steps, we propose a hierarchical generation scheme: we let\nthe LM generate a planning token at the start of each reasoning step,\nintuitively serving as a high-level plan of the current step, and add their\nembeddings to the model parameters. Our approach requires a negligible increase\nin trainable parameters (0.001%) and can be applied through either full\nfine-tuning or a more parameter-efficient scheme. We demonstrate our method's\neffectiveness by applying it to three different LLMs, showing notable accuracy\nimprovements across three math word problem datasets and one multihop QA\ndataset with respect to standard fine-tuning baselines.\n","authors":["Xinyi Wang","Lucas Caccia","Oleksiy Ostapenko","Xingdi Yuan","William Yang Wang","Alessandro Sordoni"],"pdf_url":"https://arxiv.org/pdf/2310.05707v4.pdf","comment":"Accepted to COLM 2024"},{"id":"http://arxiv.org/abs/2408.03421v1","updated":"2024-08-06T19:53:00Z","published":"2024-08-06T19:53:00Z","title":"Probabilistic Scores of Classifiers, Calibration is not Enough","summary":"  In binary classification tasks, accurate representation of probabilistic\npredictions is essential for various real-world applications such as predicting\npayment defaults or assessing medical risks. The model must then be\nwell-calibrated to ensure alignment between predicted probabilities and actual\noutcomes. However, when score heterogeneity deviates from the underlying data\nprobability distribution, traditional calibration metrics lose reliability,\nfailing to align score distribution with actual probabilities. In this study,\nwe highlight approaches that prioritize optimizing the alignment between\npredicted scores and true probability distributions over minimizing traditional\nperformance or calibration metrics. When employing tree-based models such as\nRandom Forest and XGBoost, our analysis emphasizes the flexibility these models\noffer in tuning hyperparameters to minimize the Kullback-Leibler (KL)\ndivergence between predicted and true distributions. Through extensive\nempirical analysis across 10 UCI datasets and simulations, we demonstrate that\noptimizing tree-based models based on KL divergence yields superior alignment\nbetween predicted scores and actual probabilities without significant\nperformance loss. In real-world scenarios, the reference probability is\ndetermined a priori as a Beta distribution estimated through maximum\nlikelihood. Conversely, minimizing traditional calibration metrics may lead to\nsuboptimal results, characterized by notable performance declines and inferior\nKL values. Our findings reveal limitations in traditional calibration metrics,\nwhich could undermine the reliability of predictive models for critical\ndecision-making.\n","authors":["Agathe Fernandes Machado","Arthur Charpentier","Emmanuel Flachaire","Ewen Gallic","François Hu"],"pdf_url":"https://arxiv.org/pdf/2408.03421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03414v1","updated":"2024-08-06T19:23:42Z","published":"2024-08-06T19:23:42Z","title":"Logistic Regression makes small LLMs strong and explainable\n  \"tens-of-shot\" classifiers","summary":"  For simple classification tasks, we show that users can benefit from the\nadvantages of using small, local, generative language models instead of large\ncommercial models without a trade-off in performance or introducing extra\nlabelling costs. These advantages, including those around privacy,\navailability, cost, and explainability, are important both in commercial\napplications and in the broader democratisation of AI. Through experiments on\n17 sentence classification tasks (2-4 classes), we show that penalised logistic\nregression on the embeddings from a small LLM equals (and usually betters) the\nperformance of a large LLM in the \"tens-of-shot\" regime. This requires no more\nlabelled instances than are needed to validate the performance of the large\nLLM. Finally, we extract stable and sensible explanations for classification\ndecisions.\n","authors":["Marcus Buckmann","Edward Hill"],"pdf_url":"https://arxiv.org/pdf/2408.03414v1.pdf","comment":"41 pages, 24 figures"},{"id":"http://arxiv.org/abs/2408.03413v1","updated":"2024-08-06T19:22:13Z","published":"2024-08-06T19:22:13Z","title":"A TVD neural network closure and application to turbulent combustion","summary":"  Trained neural networks (NN) have attractive features for closing governing\nequations, but in the absence of additional constraints, they can stray from\nphysical reality. A NN formulation is introduced to preclude spurious\noscillations that violate solution boundedness or positivity. It is embedded in\nthe discretized equations as a machine learning closure and strictly\nconstrained, inspired by total variation diminishing (TVD) methods for\nhyperbolic conservation laws. The constraint is exactly enforced during\ngradient-descent training by rescaling the NN parameters, which maps them onto\nan explicit feasible set. Demonstrations show that the constrained NN closure\nmodel usefully recovers linear and nonlinear hyperbolic phenomena and\nanti-diffusion while enforcing the non-oscillatory property. Finally, the model\nis applied to subgrid-scale (SGS) modeling of a turbulent reacting flow, for\nwhich it suppresses spurious oscillations in scalar fields that otherwise\nviolate the solution boundedness. It outperforms a simple penalization of\noscillations in the loss function.\n","authors":["Seung Won Suh","Jonathan F MacArt","Luke N Olson","Jonathan B Freund"],"pdf_url":"https://arxiv.org/pdf/2408.03413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03408v1","updated":"2024-08-06T19:10:25Z","published":"2024-08-06T19:10:25Z","title":"LLM-Aided Compilation for Tensor Accelerators","summary":"  Hardware accelerators, in particular accelerators for tensor processing, have\nmany potential application domains. However, they currently lack the software\ninfrastructure to support the majority of domains outside of deep learning.\nFurthermore, a compiler that can easily be updated to reflect changes at both\napplication and hardware levels would enable more agile development and design\nspace exploration of accelerators, allowing hardware designers to realize\ncloser-to-optimal performance. In this work, we discuss how large language\nmodels (LLMs) could be leveraged to build such a compiler. Specifically, we\ndemonstrate the ability of GPT-4 to achieve high pass rates in translating code\nto the Gemmini accelerator, and prototype a technique for decomposing\ntranslation into smaller, more LLM-friendly steps. Additionally, we propose a\n2-phase workflow for utilizing LLMs to generate hardware-optimized code.\n","authors":["Charles Hong","Sahil Bhatia","Altan Haan","Shengjun Kris Dong","Dima Nikiforov","Alvin Cheung","Yakun Sophia Shao"],"pdf_url":"https://arxiv.org/pdf/2408.03408v1.pdf","comment":"4 page workshop paper"},{"id":"http://arxiv.org/abs/2408.03407v1","updated":"2024-08-06T19:01:47Z","published":"2024-08-06T19:01:47Z","title":"Deep Clustering via Distribution Learning","summary":"  Distribution learning finds probability density functions from a set of data\nsamples, whereas clustering aims to group similar data points to form clusters.\nAlthough there are deep clustering methods that employ distribution learning\nmethods, past work still lacks theoretical analysis regarding the relationship\nbetween clustering and distribution learning. Thus, in this work, we provide a\ntheoretical analysis to guide the optimization of clustering via distribution\nlearning. To achieve better results, we embed deep clustering guided by a\ntheoretical analysis. Furthermore, the distribution learning method cannot\nalways be directly applied to data. To overcome this issue, we introduce a\nclustering-oriented distribution learning method called Monte-Carlo\nMarginalization for Clustering. We integrate Monte-Carlo Marginalization for\nClustering into Deep Clustering, resulting in Deep Clustering via Distribution\nLearning (DCDL). Eventually, the proposed DCDL achieves promising results\ncompared to state-of-the-art methods on popular datasets. Considering a\nclustering task, the new distribution learning method outperforms previous\nmethods as well.\n","authors":["Guanfang Dong","Zijie Tan","Chenqiu Zhao","Anup Basu"],"pdf_url":"https://arxiv.org/pdf/2408.03407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03405v1","updated":"2024-08-06T18:56:29Z","published":"2024-08-06T18:56:29Z","title":"Combining Diverse Information for Coordinated Action: Stochastic Bandit\n  Algorithms for Heterogeneous Agents","summary":"  Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.\n","authors":["Lucia Gordon","Esther Rolf","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2408.03405v1.pdf","comment":"19 pages, 6 figures, to be published in ECAI 2024"},{"id":"http://arxiv.org/abs/2408.03404v1","updated":"2024-08-06T18:55:31Z","published":"2024-08-06T18:55:31Z","title":"Set2Seq Transformer: Learning Permutation Aware Set Representations of\n  Artistic Sequences","summary":"  We propose Set2Seq Transformer, a novel sequential multiple instance\narchitecture, that learns to rank permutation aware set representations of\nsequences. First, we illustrate that learning temporal position-aware\nrepresentations of discrete timesteps can greatly improve static visual\nmultiple instance learning methods that do not regard temporality and\nconcentrate almost exclusively on visual content analysis. We further\ndemonstrate the significant advantages of end-to-end sequential multiple\ninstance learning, integrating visual content and temporal information in a\nmultimodal manner. As application we focus on fine art analysis related tasks.\nTo that end, we show that our Set2Seq Transformer can leverage visual set and\ntemporal position-aware representations for modelling visual artists' oeuvres\nfor predicting artistic success. Finally, through extensive quantitative and\nqualitative evaluation using a novel dataset, WikiArt-Seq2Rank, and a visual\nlearning-to-rank downstream task, we show that our Set2Seq Transformer captures\nessential temporal information improving the performance of strong static and\nsequential multiple instance learning methods for predicting artistic success.\n","authors":["Athanasios Efthymiou","Stevan Rudinac","Monika Kackovic","Nachoem Wijnberg","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2408.03404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03400v1","updated":"2024-08-06T18:52:17Z","published":"2024-08-06T18:52:17Z","title":"Attacks and Defenses for Generative Diffusion Models: A Comprehensive\n  Survey","summary":"  Diffusion models (DMs) have achieved state-of-the-art performance on various\ngenerative tasks such as image synthesis, text-to-image, and text-guided\nimage-to-image generation. However, the more powerful the DMs, the more harmful\nthey potentially are. Recent studies have shown that DMs are prone to a wide\nrange of attacks, including adversarial attacks, membership inference, backdoor\ninjection, and various multi-modal threats. Since numerous pre-trained DMs are\npublished widely on the Internet, potential threats from these attacks are\nespecially detrimental to the society, making DM-related security a worth\ninvestigating topic. Therefore, in this paper, we conduct a comprehensive\nsurvey on the security aspect of DMs, focusing on various attack and defense\nmethods for DMs. First, we present crucial knowledge of DMs with five main\ntypes of DMs, including denoising diffusion probabilistic models, denoising\ndiffusion implicit models, noise conditioned score networks, stochastic\ndifferential equations, and multi-modal conditional DMs. We further survey a\nvariety of recent studies investigating different types of attacks that exploit\nthe vulnerabilities of DMs. Then, we thoroughly review potential\ncountermeasures to mitigate each of the presented threats. Finally, we discuss\nopen challenges of DM-related security and envision certain research directions\nfor this topic.\n","authors":["Vu Tuan Truong","Luan Ba Dang","Long Bao Le"],"pdf_url":"https://arxiv.org/pdf/2408.03400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03399v1","updated":"2024-08-06T18:52:15Z","published":"2024-08-06T18:52:15Z","title":"RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting\n  Algorithms","summary":"  We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)\nframework, designed to assess the robustness of hierarchical time series\nforecasting models and algorithms on real-world datasets. Hierarchical time\nseries, where lower-level forecasts must sum to upper-level ones, are prevalent\nin various contexts, such as retail sales across countries. Current empirical\nevaluations of forecasting methods are often limited to a small set of\nbenchmark datasets, offering a narrow view of algorithm behavior. RHiOTS\naddresses this gap by systematically altering existing datasets and modifying\nthe characteristics of individual series and their interrelations. It uses a\nset of parameterizable transformations to simulate those changes in the data\ndistribution. Additionally, RHiOTS incorporates an innovative visualization\ncomponent, turning complex, multidimensional robustness evaluation results into\nintuitive, easily interpretable visuals. This approach allows an in-depth\nanalysis of algorithm and model behavior under diverse conditions. We\nillustrate the use of RHiOTS by analyzing the predictive performance of several\nalgorithms. Our findings show that traditional statistical methods are more\nrobust than state-of-the-art deep learning algorithms, except when the\ntransformation effect is highly disruptive. Furthermore, we found no\nsignificant differences in the robustness of the algorithms when applying\nspecific reconciliation methods, such as MinT. RHiOTS provides researchers with\na comprehensive tool for understanding the nuanced behavior of forecasting\nalgorithms, offering a more reliable basis for selecting the most appropriate\nmethod for a given problem.\n","authors":["Luis Roque","Carlos Soares","Luís Torgo"],"pdf_url":"https://arxiv.org/pdf/2408.03399v1.pdf","comment":"Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '24), August 25--29, 2024, Barcelona, Spain"},{"id":"http://arxiv.org/abs/2408.03397v1","updated":"2024-08-06T18:48:01Z","published":"2024-08-06T18:48:01Z","title":"HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for\n  Transformer Acceleration","summary":"  Transformers have revolutionized deep learning and generative modeling to\nenable unprecedented advancements in natural language processing tasks and\nbeyond. However, designing hardware accelerators for executing transformer\nmodels is challenging due to the wide variety of computing kernels involved in\nthe transformer architecture. Existing accelerators are either inadequate to\naccelerate end-to-end transformer models or suffer notable thermal limitations.\nIn this paper, we propose the design of a three-dimensional heterogeneous\narchitecture referred to as HeTraX specifically optimized to accelerate\nend-to-end transformer models. HeTraX employs hardware resources aligned with\nthe computational kernels of transformers and optimizes both performance and\nenergy. Experimental results show that HeTraX outperforms existing\nstate-of-the-art by up to 5.6x in speedup and improves EDP by 14.5x while\nensuring thermally feasibility.\n","authors":["Pratyush Dhingra","Janardhan Rao Doppa","Partha Pratim Pande"],"pdf_url":"https://arxiv.org/pdf/2408.03397v1.pdf","comment":"Presented at ACM/IEEE International Symposium on Low Power\n  Electronics and Design (ISLPED-24)"},{"id":"http://arxiv.org/abs/2408.03388v1","updated":"2024-08-06T18:18:37Z","published":"2024-08-06T18:18:37Z","title":"A Non-negative VAE:the Generalized Gamma Belief Network","summary":"  The gamma belief network (GBN), often regarded as a deep topic model, has\ndemonstrated its potential for uncovering multi-layer interpretable latent\nrepresentations in text data. Its notable capability to acquire interpretable\nlatent factors is partially attributed to sparse and non-negative\ngamma-distributed latent variables. However, the existing GBN and its\nvariations are constrained by the linear generative model, thereby limiting\ntheir expressiveness and applicability. To address this limitation, we\nintroduce the generalized gamma belief network (Generalized GBN) in this paper,\nwhich extends the original linear generative model to a more expressive\nnon-linear generative model. Since the parameters of the Generalized GBN no\nlonger possess an analytic conditional posterior, we further propose an\nupward-downward Weibull inference network to approximate the posterior\ndistribution of the latent variables. The parameters of both the generative\nmodel and the inference network are jointly trained within the variational\ninference framework. Finally, we conduct comprehensive experiments on both\nexpressivity and disentangled representation learning tasks to evaluate the\nperformance of the Generalized GBN against state-of-the-art Gaussian\nvariational autoencoders serving as baselines.\n","authors":["Zhibin Duan","Tiansheng Wen","Muyao Wang","Bo Chen","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.03388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07346v3","updated":"2024-08-06T18:14:17Z","published":"2024-07-10T03:52:53Z","title":"INSIGHT: Universal Neural Simulator for Analog Circuits Harnessing\n  Autoregressive Transformers","summary":"  Analog front-end design heavily relies on specialized human expertise and\ncostly trial-and-error simulations, which motivated many prior works on analog\ndesign automation. However, efficient and effective exploration of the vast and\ncomplex design space remains constrained by the time-consuming nature of SPICE\nsimulations, making effective design automation a challenging endeavor. In this\npaper, we introduce INSIGHT, a GPU-powered, technology-agnostic, effective\nuniversal neural simulator in the analog front-end design automation loop.\nINSIGHT accurately predicts the performance metrics of analog circuits across\nvarious technologies with just a few microseconds of inference time. Notably,\nits autoregressive capabilities enable INSIGHT to accurately predict\nsimulation-costly critical transient specifications leveraging less expensive\nperformance metric information. The low cost and high fidelity feature make\nINSIGHT a good substitute for standard simulators in analog front-end\noptimization frameworks. INSIGHT is compatible with any optimization framework,\nfacilitating enhanced design space exploration for sample efficiency through\nsophisticated offline learning and adaptation techniques. Our experiments\ndemonstrate that INSIGHT-M, a model-based batch reinforcement learning sizing\nframework with INSIGHT as the accurate surrogate, only requires < 20 real-time\nsimulations with 100-1000x lower simulation costs and significant speedup over\nexisting sizing methods.\n","authors":["Souradip Poddar","Youngmin Oh","Yao Lai","Hanqing Zhu","Bosun Hwang","David Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2407.07346v3.pdf","comment":null}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2408.03307v1","updated":"2024-08-06T17:16:10Z","published":"2024-08-06T17:16:10Z","title":"Pre-training and in-context learning IS Bayesian inference a la De\n  Finetti","summary":"  Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.\n","authors":["Naimeng Ye","Hanming Yang","Andrew Siah","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2408.03307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08871v3","updated":"2024-08-06T16:38:41Z","published":"2024-02-14T00:35:10Z","title":"Position: Topological Deep Learning is the New Frontier for Relational\n  Learning","summary":"  Topological deep learning (TDL) is a rapidly evolving field that uses\ntopological features to understand and design deep learning models. This paper\nposits that TDL is the new frontier for relational learning. TDL may complement\ngraph representation learning and geometric deep learning by incorporating\ntopological concepts, and can thus provide a natural choice for various machine\nlearning settings. To this end, this paper discusses open problems in TDL,\nranging from practical benefits to theoretical foundations. For each problem,\nit outlines potential solutions and future research opportunities. At the same\ntime, this paper serves as an invitation to the scientific community to\nactively participate in TDL research to unlock the potential of this emerging\nfield.\n","authors":["Theodore Papamarkou","Tolga Birdal","Michael Bronstein","Gunnar Carlsson","Justin Curry","Yue Gao","Mustafa Hajij","Roland Kwitt","Pietro Liò","Paolo Di Lorenzo","Vasileios Maroulas","Nina Miolane","Farzana Nasrin","Karthikeyan Natesan Ramamurthy","Bastian Rieck","Simone Scardapane","Michael T. Schaub","Petar Veličković","Bei Wang","Yusu Wang","Guo-Wei Wei","Ghada Zamzmi"],"pdf_url":"https://arxiv.org/pdf/2402.08871v3.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024"},{"id":"http://arxiv.org/abs/2402.00809v5","updated":"2024-08-06T16:32:38Z","published":"2024-02-01T17:45:26Z","title":"Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI","summary":"  In the current landscape of deep learning research, there is a predominant\nemphasis on achieving high predictive accuracy in supervised tasks involving\nlarge image and language datasets. However, a broader perspective reveals a\nmultitude of overlooked metrics, tasks, and data types, such as uncertainty,\nactive and continual learning, and scientific data, that demand attention.\nBayesian deep learning (BDL) constitutes a promising avenue, offering\nadvantages across these diverse settings. This paper posits that BDL can\nelevate the capabilities of deep learning. It revisits the strengths of BDL,\nacknowledges existing challenges, and highlights some exciting research avenues\naimed at addressing these obstacles. Looking ahead, the discussion focuses on\npossible ways to combine large-scale foundation models with BDL to unlock their\nfull potential.\n","authors":["Theodore Papamarkou","Maria Skoularidou","Konstantina Palla","Laurence Aitchison","Julyan Arbel","David Dunson","Maurizio Filippone","Vincent Fortuin","Philipp Hennig","José Miguel Hernández-Lobato","Aliaksandr Hubin","Alexander Immer","Theofanis Karaletsos","Mohammad Emtiyaz Khan","Agustinus Kristiadi","Yingzhen Li","Stephan Mandt","Christopher Nemeth","Michael A. Osborne","Tim G. J. Rudner","David Rügamer","Yee Whye Teh","Max Welling","Andrew Gordon Wilson","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.00809v5.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024"},{"id":"http://arxiv.org/abs/2312.07186v5","updated":"2024-08-06T13:47:50Z","published":"2023-12-12T11:48:56Z","title":"Towards Optimal Sobolev Norm Rates for the Vector-Valued Regularized\n  Least-Squares Algorithm","summary":"  We present the first optimal rates for infinite-dimensional vector-valued\nridge regression on a continuous scale of norms that interpolate between $L_2$\nand the hypothesis space, which we consider as a vector-valued reproducing\nkernel Hilbert space. These rates allow to treat the misspecified case in which\nthe true regression function is not contained in the hypothesis space. We\ncombine standard assumptions on the capacity of the hypothesis space with a\nnovel tensor product construction of vector-valued interpolation spaces in\norder to characterize the smoothness of the regression function. Our upper\nbound not only attains the same rate as real-valued kernel ridge regression,\nbut also removes the assumption that the target regression function is bounded.\nFor the lower bound, we reduce the problem to the scalar setting using a\nprojection argument. We show that these rates are optimal in most cases and\nindependent of the dimension of the output space. We illustrate our results for\nthe special case of vector-valued Sobolev spaces.\n","authors":["Zhu Li","Dimitri Meunier","Mattes Mollenhauer","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2312.07186v5.pdf","comment":"Published JMLR version. arXiv admin note: text overlap with\n  arXiv:2208.01711"},{"id":"http://arxiv.org/abs/2408.03144v1","updated":"2024-08-06T12:39:12Z","published":"2024-08-06T12:39:12Z","title":"Active Learning for Level Set Estimation Using Randomized Straddle\n  Algorithms","summary":"  Level set estimation (LSE), the problem of identifying the set of input\npoints where a function takes value above (or below) a given threshold, is\nimportant in practical applications. When the function is expensive-to-evaluate\nand black-box, the \\textit{straddle} algorithm, which is a representative\nheuristic for LSE based on Gaussian process models, and its extensions having\ntheoretical guarantees have been developed. However, many of existing methods\ninclude a confidence parameter $\\beta^{1/2}_t$ that must be specified by the\nuser, and methods that choose $\\beta^{1/2}_t$ heuristically do not provide\ntheoretical guarantees. In contrast, theoretically guaranteed values of\n$\\beta^{1/2}_t$ need to be increased depending on the number of iterations and\ncandidate points, and are conservative and not good for practical performance.\nIn this study, we propose a novel method, the \\textit{randomized straddle}\nalgorithm, in which $\\beta_t$ in the straddle algorithm is replaced by a random\nsample from the chi-squared distribution with two degrees of freedom. The\nconfidence parameter in the proposed method has the advantages of not needing\nadjustment, not depending on the number of iterations and candidate points, and\nnot being conservative. Furthermore, we show that the proposed method has\ntheoretical guarantees that depend on the sample complexity and the number of\niterations. Finally, we confirm the usefulness of the proposed method through\nnumerical experiments using synthetic and real data.\n","authors":["Yu Inatsu","Shion Takeno","Kentaro Kutsukake","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2408.03144v1.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.03138v1","updated":"2024-08-06T12:28:16Z","published":"2024-08-06T12:28:16Z","title":"Predictive Performance Test based on the Exhaustive Nested\n  Cross-Validation for High-dimensional data","summary":"  It is crucial to assess the predictive performance of a model in order to\nestablish its practicality and relevance in real-world scenarios, particularly\nfor high-dimensional data analysis. Among data splitting or resampling methods,\ncross-validation (CV) is extensively used for several tasks such as estimating\nthe prediction error, tuning the regularization parameter, and selecting the\nmost suitable predictive model among competing alternatives. The K-fold\ncross-validation is a popular CV method but its limitation is that the risk\nestimates are highly dependent on the partitioning of the data (for training\nand testing). Here, the issues regarding the reproducibility of the K-fold CV\nestimator is demonstrated in hypothesis testing wherein different partitions\nlead to notably disparate conclusions. This study presents an alternative novel\npredictive performance test and valid confidence intervals based on exhaustive\nnested cross-validation for determining the difference in prediction error\nbetween two model-fitting algorithms. A naive implementation of the exhaustive\nnested cross-validation is computationally costly. Here, we address concerns\nregarding computational complexity by devising a computationally tractable\nclosed-form expression for the proposed cross-validation estimator using ridge\nregularization. Our study also investigates strategies aimed at enhancing\nstatistical power within high-dimensional scenarios while controlling the Type\nI error rate. To illustrate the practical utility of our method, we apply it to\nan RNA sequencing study and demonstrate its effectiveness in the context of\nbiological data analysis.\n","authors":["Iris Ivy Gauran","Hernando Ombao","Zhaoxia Yu"],"pdf_url":"https://arxiv.org/pdf/2408.03138v1.pdf","comment":"49 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.17963v4","updated":"2024-08-06T06:28:57Z","published":"2023-03-31T11:06:09Z","title":"Learning-Based Optimal Control with Performance Guarantees for Unknown\n  Systems with Latent States","summary":"  As control engineering methods are applied to increasingly complex systems,\ndata-driven approaches for system identification appear as a promising\nalternative to physics-based modeling. While the Bayesian approaches prevalent\nfor safety-critical applications usually rely on the availability of state\nmeasurements, the states of a complex system are often not directly measurable.\nIt may then be necessary to jointly estimate the dynamics and the latent state,\nmaking the quantification of uncertainties and the design of controllers with\nformal performance guarantees considerably more challenging. This paper\nproposes a novel method for the computation of an optimal input trajectory for\nunknown nonlinear systems with latent states based on a combination of particle\nMarkov chain Monte Carlo methods and scenario theory. Probabilistic performance\nguarantees are derived for the resulting input trajectory, and an approach to\nvalidate the performance of arbitrary control laws is presented. The\neffectiveness of the proposed method is demonstrated in a numerical simulation.\n","authors":["Robert Lefringhausen","Supitsana Srithasan","Armin Lederer","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2303.17963v4.pdf","comment":"Accepted version submitted to the 2024 European Control Conference\n  (ECC)"},{"id":"http://arxiv.org/abs/2109.03445v6","updated":"2024-08-06T06:19:46Z","published":"2021-09-08T06:06:28Z","title":"Convergence of Batch Asynchronous Stochastic Approximation With\n  Applications to Reinforcement Learning","summary":"  We begin by briefly surveying some results on the convergence of the\nStochastic Gradient Descent (SGD) Method, proved in a companion paper by the\npresent authors. These results are based on viewing SGD as a version of\nStochastic Approximation (SA). Ever since its introduction in the classic paper\nof Robbins and Monro in 1951, SA has become a standard tool for finding a\nsolution of an equation of the form $f(\\theta) = 0$, when only noisy\nmeasurements of $f(\\cdot)$ are available. In most situations, \\textit{every\ncomponent} of the putative solution $\\theta_t$ is updated at each step $t$. In\nsome applications in Reinforcement Learning (RL), \\textit{only one component}\nof $\\theta_t$ is updated at each $t$. This is known as \\textbf{asynchronous}\nSA. In this paper, we study \\textbf{Block Asynchronous SA (BASA)}, in which, at\neach step $t$, \\textit{some but not necessarily all} components of $\\theta_t$\nare updated. The theory presented here embraces both conventional (synchronous)\nSA as well as asynchronous SA, and all in-between possibilities. We provide\nsufficient conditions for the convergence of BASA, and also prove bounds on the\n\\textit{rate} of convergence of $\\theta_t$ to the solution. For the case of\nconventional SGD, these results reduce to those proved in our companion paper.\nThen we apply these results to the problem of finding a fixed point of a map\nwith only noisy measurements. This problem arises frequently in RL. We prove\nsufficient conditions for convergence as well as estimates for the rate of\nconvergence.\n","authors":["Rajeeva L. Karandikar","M. Vidyasagar"],"pdf_url":"https://arxiv.org/pdf/2109.03445v6.pdf","comment":"34 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.00799v2","updated":"2024-08-06T03:03:16Z","published":"2024-07-22T02:27:57Z","title":"Deep Uncertainty-Based Explore for Index Construction and Retrieval in\n  Recommendation System","summary":"  In recommendation systems, the relevance and novelty of the final results are\nselected through a cascade system of Matching -> Ranking -> Strategy. The\nmatching model serves as the starting point of the pipeline and determines the\nupper bound of the subsequent stages. Balancing the relevance and novelty of\nmatching results is a crucial step in the design and optimization of\nrecommendation systems, contributing significantly to improving recommendation\nquality. However, the typical matching algorithms have not simultaneously\naddressed the relevance and novelty perfectly. One main reason is that deep\nmatching algorithms exhibit significant uncertainty when estimating items in\nthe long tail (e.g., due to insufficient training samples) items.The\nuncertainty not only affects the training of the models but also influences the\nconfidence in the index construction and beam search retrieval process of these\nmodels. This paper proposes the UICR (Uncertainty-based explore for Index\nConstruction and Retrieval) algorithm, which introduces the concept of\nuncertainty modeling in the matching stage and achieves multi-task modeling of\nmodel uncertainty and index uncertainty. The final matching results are\nobtained by combining the relevance score and uncertainty score infered by the\nmodel. Experimental results demonstrate that the UICR improves novelty without\nsacrificing relevance on realworld industrial productive environments and\nmultiple open-source datasets. Remarkably, online A/B test results of display\nadvertising in Shopee demonstrates the effectiveness of the proposed algorithm.\n","authors":["Xin Jiang","Kaiqiang Wang","Yinlong Wang","Fengchang Lv","Taiyang Peng","Shuai Yang","Xianteng Wu","Pengye Zhang","Shuo Yuan","Yifan Zeng"],"pdf_url":"https://arxiv.org/pdf/2408.00799v2.pdf","comment":"accepted by cikm2024"},{"id":"http://arxiv.org/abs/2310.12428v3","updated":"2024-08-06T01:45:44Z","published":"2023-10-19T02:42:20Z","title":"Enhanced Local Explainability and Trust Scores with Random Forest\n  Proximities","summary":"  We initiate a novel approach to explain the predictions and out of sample\nperformance of random forest (RF) regression and classification models by\nexploiting the fact that any RF can be mathematically formulated as an adaptive\nweighted K nearest-neighbors model. Specifically, we employ a recent result\nthat, for both regression and classification tasks, any RF prediction can be\nrewritten exactly as a weighted sum of the training targets, where the weights\nare RF proximities between the corresponding pairs of data points. We show that\nthis linearity facilitates a local notion of explainability of RF predictions\nthat generates attributions for any model prediction across observations in the\ntraining set, and thereby complements established feature-based methods like\nSHAP, which generate attributions for a model prediction across input features.\nWe show how this proximity-based approach to explainability can be used in\nconjunction with SHAP to explain not just the model predictions, but also\nout-of-sample performance, in the sense that proximities furnish a novel means\nof assessing when a given model prediction is more or less likely to be\ncorrect. We demonstrate this approach in the modeling of US corporate bond\nprices and returns in both regression and classification cases.\n","authors":["Joshua Rosaler","Dhruv Desai","Bhaskarjit Sarmah","Dimitrios Vamvourellis","Deran Onay","Dhagash Mehta","Stefano Pasquali"],"pdf_url":"https://arxiv.org/pdf/2310.12428v3.pdf","comment":"5 pages, 6 figures"},{"id":"http://arxiv.org/abs/1912.03573v2","updated":"2024-08-06T00:50:41Z","published":"2019-12-07T23:02:02Z","title":"Deep Variable-Block Chain with Adaptive Variable Selection","summary":"  The architectures of deep neural networks (DNN) rely heavily on the\nunderlying grid structure of variables, for instance, the lattice of pixels in\nan image. For general high dimensional data with variables not associated with\na grid, the multi-layer perceptron and deep belief network are often used.\nHowever, it is frequently observed that those networks do not perform\ncompetitively and they are not helpful for identifying important variables. In\nthis paper, we propose a framework that imposes on blocks of variables a chain\nstructure obtained by step-wise greedy search so that the DNN architecture can\nleverage the constructed grid. We call this new neural network Deep\nVariable-Block Chain (DVC). Because the variable blocks are used for\nclassification in a sequential manner, we further develop the capacity of\nselecting variables adaptively according to a number of regions trained by a\ndecision tree. Our experiments show that DVC outperforms other generic DNNs and\nother strong classifiers. Moreover, DVC can achieve high accuracy at much\nreduced dimensionality and sometimes reveals drastically different sets of\nrelevant variables for different regions.\n","authors":["Lixiang Zhang","Lin Lin","Jia Li"],"pdf_url":"https://arxiv.org/pdf/1912.03573v2.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2312.10330v2","updated":"2024-08-06T23:41:19Z","published":"2023-12-16T05:40:19Z","title":"Convergence and complexity of block majorization-minimization for\n  constrained block-Riemannian optimization","summary":"  Block majorization-minimization (BMM) is a simple iterative algorithm for\nnonconvex optimization that sequentially minimizes a majorizing surrogate of\nthe objective function in each block coordinate while the other block\ncoordinates are held fixed. We consider a family of BMM algorithms for\nminimizing smooth nonconvex objectives, where each parameter block is\nconstrained within a subset of a Riemannian manifold. We establish that this\nalgorithm converges asymptotically to the set of stationary points, and attains\nan $\\epsilon$-stationary point within $\\widetilde{O}(\\epsilon^{-2})$\niterations. In particular, the assumptions for our complexity results are\ncompletely Euclidean when the underlying manifold is a product of Euclidean or\nStiefel manifolds, although our analysis makes explicit use of the Riemannian\ngeometry. Our general analysis applies to a wide range of algorithms with\nRiemannian constraints: Riemannian MM, block projected gradient descent,\noptimistic likelihood estimation, geodesically constrained subspace tracking,\nrobust PCA, and Riemannian CP-dictionary-learning. We experimentally validate\nthat our algorithm converges faster than standard Euclidean algorithms applied\nto the Riemannian setting.\n","authors":["Yuchen Li","Laura Balzano","Deanna Needell","Hanbaek Lyu"],"pdf_url":"https://arxiv.org/pdf/2312.10330v2.pdf","comment":"54 pages, 8 figures. Related work updated"},{"id":"http://arxiv.org/abs/2408.03461v1","updated":"2024-08-06T22:14:54Z","published":"2024-08-06T22:14:54Z","title":"When does the mean network capture the topology of a sample of networks?","summary":"  The notion of Fr\\'echet mean (also known as \"barycenter\") network is the\nworkhorse of most machine learning algorithms that require the estimation of a\n\"location\" parameter to analyse network-valued data. In this context, it is\ncritical that the network barycenter inherits the topological structure of the\nnetworks in the training dataset. The metric - which measures the proximity\nbetween networks - controls the structural properties of the barycenter. This\nwork is significant because it provides for the first time analytical estimates\nof the sample Fr\\'echet mean for the stochastic blockmodel, which is at the\ncutting edge of rigorous probabilistic analysis of random networks. We show\nthat the mean network computed with the Hamming distance is unable to capture\nthe topology of the networks in the training sample, whereas the mean network\ncomputed using the effective resistance distance recovers the correct\npartitions and associated edge density. From a practical standpoint, our work\ninforms the choice of metrics in the context where the sample Fr\\'echet mean\nnetwork is used to characterise the topology of networks for network-valued\nmachine learning\n","authors":["François G Meyer"],"pdf_url":"https://arxiv.org/pdf/2408.03461v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2408.03421v1","updated":"2024-08-06T19:53:00Z","published":"2024-08-06T19:53:00Z","title":"Probabilistic Scores of Classifiers, Calibration is not Enough","summary":"  In binary classification tasks, accurate representation of probabilistic\npredictions is essential for various real-world applications such as predicting\npayment defaults or assessing medical risks. The model must then be\nwell-calibrated to ensure alignment between predicted probabilities and actual\noutcomes. However, when score heterogeneity deviates from the underlying data\nprobability distribution, traditional calibration metrics lose reliability,\nfailing to align score distribution with actual probabilities. In this study,\nwe highlight approaches that prioritize optimizing the alignment between\npredicted scores and true probability distributions over minimizing traditional\nperformance or calibration metrics. When employing tree-based models such as\nRandom Forest and XGBoost, our analysis emphasizes the flexibility these models\noffer in tuning hyperparameters to minimize the Kullback-Leibler (KL)\ndivergence between predicted and true distributions. Through extensive\nempirical analysis across 10 UCI datasets and simulations, we demonstrate that\noptimizing tree-based models based on KL divergence yields superior alignment\nbetween predicted scores and actual probabilities without significant\nperformance loss. In real-world scenarios, the reference probability is\ndetermined a priori as a Beta distribution estimated through maximum\nlikelihood. Conversely, minimizing traditional calibration metrics may lead to\nsuboptimal results, characterized by notable performance declines and inferior\nKL values. Our findings reveal limitations in traditional calibration metrics,\nwhich could undermine the reliability of predictive models for critical\ndecision-making.\n","authors":["Agathe Fernandes Machado","Arthur Charpentier","Emmanuel Flachaire","Ewen Gallic","François Hu"],"pdf_url":"https://arxiv.org/pdf/2408.03421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03414v1","updated":"2024-08-06T19:23:42Z","published":"2024-08-06T19:23:42Z","title":"Logistic Regression makes small LLMs strong and explainable\n  \"tens-of-shot\" classifiers","summary":"  For simple classification tasks, we show that users can benefit from the\nadvantages of using small, local, generative language models instead of large\ncommercial models without a trade-off in performance or introducing extra\nlabelling costs. These advantages, including those around privacy,\navailability, cost, and explainability, are important both in commercial\napplications and in the broader democratisation of AI. Through experiments on\n17 sentence classification tasks (2-4 classes), we show that penalised logistic\nregression on the embeddings from a small LLM equals (and usually betters) the\nperformance of a large LLM in the \"tens-of-shot\" regime. This requires no more\nlabelled instances than are needed to validate the performance of the large\nLLM. Finally, we extract stable and sensible explanations for classification\ndecisions.\n","authors":["Marcus Buckmann","Edward Hill"],"pdf_url":"https://arxiv.org/pdf/2408.03414v1.pdf","comment":"41 pages, 24 figures"}]},"2024-08-07T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.03940v1","updated":"2024-08-07T17:59:40Z","published":"2024-08-07T17:59:40Z","title":"How Well Can Vision Language Models See Image Details?","summary":"  Large Language Model-based Vision-Language Models (LLM-based VLMs) have\ndemonstrated impressive results in various vision-language understanding tasks.\nHowever, how well these VLMs can see image detail beyond the semantic level\nremains unclear. In our study, we introduce a pixel value prediction task (PVP)\nto explore \"How Well Can Vision Language Models See Image Details?\" and to\nassist VLMs in perceiving more details. Typically, these models comprise a\nfrozen CLIP visual encoder, a large language model, and a connecting module.\nAfter fine-tuning VLMs on the PVP task, we find: 1) existing VLMs struggle to\npredict precise pixel values by only fine-tuning the connection module and LLM;\nand 2) prediction precision is significantly improved when the vision encoder\nis also adapted. Additionally, our research reveals that incorporating pixel\nvalue prediction as one of the VLM pre-training tasks and vision encoder\nadaptation markedly boosts VLM performance on downstream image-language\nunderstanding tasks requiring detailed image perception, such as referring\nimage segmentation (with an average +10.19 cIoU improvement) and video game\ndecision making (with average score improvements of +80.34 and +70.54 on two\ngames, respectively).\n","authors":["Chenhui Gou","Abdulwahab Felemban","Faizan Farooq Khan","Deyao Zhu","Jianfei Cai","Hamid Rezatofighi","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2408.03940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19674v3","updated":"2024-08-07T17:45:05Z","published":"2024-07-29T03:30:09Z","title":"Advancing Prompt Learning through an External Layer","summary":"  Prompt learning represents a promising method for adapting pre-trained\nvision-language models (VLMs) to various downstream tasks by learning a set of\ntext embeddings. One challenge inherent to these methods is the poor\ngeneralization performance due to the invalidity of the learned text embeddings\nfor unseen tasks. A straightforward approach to bridge this gap is to freeze\nthe text embeddings in prompts, which results in a lack of capacity to adapt\nVLMs for downstream tasks. To address this dilemma, we propose a paradigm\ncalled EnPrompt with a novel External Layer (EnLa). Specifically, we propose a\ntextual external layer and learnable visual embeddings for adapting VLMs to\ndownstream tasks. The learnable external layer is built upon valid embeddings\nof pre-trained CLIP. This design considers the balance of learning capabilities\nbetween the two branches. To align the textual and visual features, we propose\na novel two-pronged approach: i) we introduce the optimal transport as the\ndiscrepancy metric to align the vision and text modalities, and ii) we\nintroduce a novel strengthening feature to enhance the interaction between\nthese two modalities. Four representative experiments (i.e., base-to-novel\ngeneralization, few-shot learning, cross-dataset generalization, domain shifts\ngeneralization) across 15 datasets demonstrate that our method outperforms the\nexisting prompt learning method.\n","authors":["Fangming Cui","Xun Yang","Chao Wu","Liang Xiao","Xinmei Tian"],"pdf_url":"https://arxiv.org/pdf/2407.19674v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03923v1","updated":"2024-08-07T17:30:59Z","published":"2024-08-07T17:30:59Z","title":"Fast Sprite Decomposition from Animated Graphics","summary":"  This paper presents an approach to decomposing animated graphics into\nsprites, a set of basic elements or layers. Our approach builds on the\noptimization of sprite parameters to fit the raster video. For efficiency, we\nassume static textures for sprites to reduce the search space while preventing\nartifacts using a texture prior model. To further speed up the optimization, we\nintroduce the initialization of the sprite parameters utilizing a pre-trained\nvideo object segmentation model and user input of single frame annotations. For\nour study, we construct the Crello Animation dataset from an online design\nservice and define quantitative metrics to measure the quality of the extracted\nsprites. Experiments show that our method significantly outperforms baselines\nfor similar decomposition tasks in terms of the quality/efficiency tradeoff.\n","authors":["Tomoyuki Suzuki","Kotaro Kikuchi","Kota Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2408.03923v1.pdf","comment":"To be published ECCV 2024, project page:\n  https://cyberagentailab.github.io/sprite-decompose/"},{"id":"http://arxiv.org/abs/2405.19450v2","updated":"2024-08-07T17:30:16Z","published":"2024-05-29T18:58:59Z","title":"FourierMamba: Fourier Learning Integration with State Space Models for\n  Image Deraining","summary":"  Image deraining aims to remove rain streaks from rainy images and restore\nclear backgrounds. Currently, some research that employs the Fourier transform\nhas proved to be effective for image deraining, due to it acting as an\neffective frequency prior for capturing rain streaks. However, despite there\nexists dependency of low frequency and high frequency in images, these\nFourier-based methods rarely exploit the correlation of different frequencies\nfor conjuncting their learning procedures, limiting the full utilization of\nfrequency information for image deraining. Alternatively, the recently emerged\nMamba technique depicts its effectiveness and efficiency for modeling\ncorrelation in various domains (e.g., spatial, temporal), and we argue that\nintroducing Mamba into its unexplored Fourier spaces to correlate different\nfrequencies would help improve image deraining. This motivates us to propose a\nnew framework termed FourierMamba, which performs image deraining with Mamba in\nthe Fourier space. Owning to the unique arrangement of frequency orders in\nFourier space, the core of FourierMamba lies in the scanning encoding of\ndifferent frequencies, where the low-high frequency order formats exhibit\ndifferently in the spatial dimension (unarranged in axis) and channel dimension\n(arranged in axis). Therefore, we design FourierMamba that correlates Fourier\nspace information in the spatial and channel dimensions with distinct designs.\nSpecifically, in the spatial dimension Fourier space, we introduce the zigzag\ncoding to scan the frequencies to rearrange the orders from low to high\nfrequencies, thereby orderly correlating the connections between frequencies;\nin the channel dimension Fourier space with arranged orders of frequencies in\naxis, we can directly use Mamba to perform frequency correlation and improve\nthe channel information representation.\n","authors":["Dong Li","Yidi Liu","Xueyang Fu","Senyan Xu","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2405.19450v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03922v1","updated":"2024-08-07T17:29:19Z","published":"2024-08-07T17:29:19Z","title":"FMiFood: Multi-modal Contrastive Learning for Food Image Classification","summary":"  Food image classification is the fundamental step in image-based dietary\nassessment, which aims to estimate participants' nutrient intake from eating\noccasion images. A common challenge of food images is the intra-class diversity\nand inter-class similarity, which can significantly hinder classification\nperformance. To address this issue, we introduce a novel multi-modal\ncontrastive learning framework called FMiFood, which learns more discriminative\nfeatures by integrating additional contextual information, such as food\ncategory text descriptions, to enhance classification accuracy. Specifically,\nwe propose a flexible matching technique that improves the similarity matching\nbetween text and image embeddings to focus on multiple key information.\nFurthermore, we incorporate the classification objectives into the framework\nand explore the use of GPT-4 to enrich the text descriptions and provide more\ndetailed context. Our method demonstrates improved performance on both the\nUPMC-101 and VFN datasets compared to existing methods.\n","authors":["Xinyue Pan","Jiangpeng He","Fengqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.03922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03913v1","updated":"2024-08-07T17:19:15Z","published":"2024-08-07T17:19:15Z","title":"AdapMTL: Adaptive Pruning Framework for Multitask Learning Model","summary":"  In the domain of multimedia and multimodal processing, the efficient handling\nof diverse data streams such as images, video, and sensor data is paramount.\nModel compression and multitask learning (MTL) are crucial in this field,\noffering the potential to address the resource-intensive demands of processing\nand interpreting multiple forms of media simultaneously. However, effectively\ncompressing a multitask model presents significant challenges due to the\ncomplexities of balancing sparsity allocation and accuracy performance across\nmultiple tasks. To tackle these challenges, we propose AdapMTL, an adaptive\npruning framework for MTL models. AdapMTL leverages multiple learnable soft\nthresholds independently assigned to the shared backbone and the task-specific\nheads to capture the nuances in different components' sensitivity to pruning.\nDuring training, it co-optimizes the soft thresholds and MTL model weights to\nautomatically determine the suitable sparsity level at each component to\nachieve both high task accuracy and high overall sparsity. It further\nincorporates an adaptive weighting mechanism that dynamically adjusts the\nimportance of task-specific losses based on each task's robustness to pruning.\nWe demonstrate the effectiveness of AdapMTL through comprehensive experiments\non popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with different\narchitectures, showcasing superior performance compared to state-of-the-art\npruning methods.\n","authors":["Mingcan Xiang","Steven Jiaxun Tang","Qizheng Yang","Hui Guan","Tongping Liu"],"pdf_url":"https://arxiv.org/pdf/2408.03913v1.pdf","comment":"13 pages, 9 figures, Published at ACM Multimedia (ACM MM) 2024"},{"id":"http://arxiv.org/abs/2408.03904v1","updated":"2024-08-07T17:08:46Z","published":"2024-08-07T17:08:46Z","title":"Lightweight Video Denoising Using a Classic Bayesian Backbone","summary":"  In recent years, state-of-the-art image and video denoising networks have\nbecome increasingly large, requiring millions of trainable parameters to\nachieve best-in-class performance. Improved denoising quality has come at the\ncost of denoising speed, where modern transformer networks are far slower to\nrun than smaller denoising networks such as FastDVDnet and classic Bayesian\ndenoisers such as the Wiener filter.\n  In this paper, we implement a hybrid Wiener filter which leverages small\nancillary networks to increase the original denoiser performance, while\nretaining fast denoising speeds. These networks are used to refine the Wiener\ncoring estimate, optimise windowing functions and estimate the unknown noise\nprofile. Using these methods, we outperform several popular denoisers and\nremain within 0.2 dB, on average, of the popular VRT transformer. Our method\nwas found to be over x10 faster than the transformer method, with a far lower\nparameter cost.\n","authors":["Clément Bled","François Pitié"],"pdf_url":"https://arxiv.org/pdf/2408.03904v1.pdf","comment":"Paper accepted to ICME 2024"},{"id":"http://arxiv.org/abs/2407.14153v2","updated":"2024-08-07T17:04:53Z","published":"2024-07-19T09:32:30Z","title":"ESP-MedSAM: Efficient Self-Prompting SAM for Universal Image\n  Segmentation","summary":"  The Segment Anything Model (SAM) has demonstrated outstanding adaptation to\nmedical image segmentation but still faces three major challenges. Firstly, the\nhuge computational costs of SAM limit its real-world applicability. Secondly,\nSAM depends on manual annotations (e.g., points, boxes) as prompts, which are\nlaborious and impractical in clinical scenarios. Thirdly, SAM handles all\nsegmentation targets equally, which is suboptimal for diverse medical\nmodalities with inherent heterogeneity. To address these issues, we propose an\nEfficient Self-Prompting SAM for universal medical image segmentation, named\nESP-MedSAM. We devise a Multi-Modal Decoupled Knowledge Distillation (MMDKD)\nstrategy to distil common image knowledge and domain-specific medical knowledge\nfrom the foundation model to train a lightweight image encoder and a modality\ncontroller. Further, they combine with the additionally introduced Self-Patch\nPrompt Generator (SPPG) and Query-Decoupled Modality Decoder (QDMD) to\nconstruct ESP-MedSAM. Specifically, SPPG aims to generate a set of patch\nprompts automatically and QDMD leverages a one-to-one strategy to provide an\nindependent decoding channel for every modality. Extensive experiments indicate\nthat ESP-MedSAM outperforms state-of-the-arts in diverse medical imaging\nsegmentation takes, displaying superior zero-shot learning and modality\ntransfer ability. Especially, our framework uses only 31.4% parameters compared\nto SAM-Base.\n","authors":["Qing Xu","Jiaxuan Li","Xiangjian He","Ziyu Liu","Zhen Chen","Wenting Duan","Chenxin Li","Maggie M. He","Fiseha B. Tesema","Wooi P. Cheah","Yi Wang","Rong Qu","Jonathan M. Garibaldi"],"pdf_url":"https://arxiv.org/pdf/2407.14153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15098v3","updated":"2024-08-07T17:03:30Z","published":"2024-03-22T10:36:50Z","title":"UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction","summary":"  Vehicle trajectory prediction has increasingly relied on data-driven\nsolutions, but their ability to scale to different data domains and the impact\nof larger dataset sizes on their generalization remain under-explored. While\nthese questions can be studied by employing multiple datasets, it is\nchallenging due to several discrepancies, e.g., in data formats, map\nresolution, and semantic annotation types. To address these challenges, we\nintroduce UniTraj, a comprehensive framework that unifies various datasets,\nmodels, and evaluation criteria, presenting new opportunities for the vehicle\ntrajectory prediction field. In particular, using UniTraj, we conduct extensive\nexperiments and find that model performance significantly drops when\ntransferred to other datasets. However, enlarging data size and diversity can\nsubstantially improve performance, leading to a new state-of-the-art result for\nthe nuScenes dataset. We provide insights into dataset characteristics to\nexplain these findings. The code can be found here:\nhttps://github.com/vita-epfl/UniTraj\n","authors":["Lan Feng","Mohammadhossein Bahari","Kaouther Messaoud Ben Amor","Éloi Zablocki","Matthieu Cord","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2403.15098v3.pdf","comment":"Accepted in ECCV 2024"},{"id":"http://arxiv.org/abs/2403.11956v5","updated":"2024-08-07T17:02:00Z","published":"2024-03-18T16:52:49Z","title":"Subjective-Aligned Dataset and Metric for Text-to-Video Quality\n  Assessment","summary":"  With the rapid development of generative models, Artificial\nIntelligence-Generated Contents (AIGC) have exponentially increased in daily\nlives. Among them, Text-to-Video (T2V) generation has received widespread\nattention. Though many T2V models have been released for generating high\nperceptual quality videos, there is still lack of a method to evaluate the\nquality of these videos quantitatively. To solve this issue, we establish the\nlargest-scale Text-to-Video Quality Assessment DataBase (T2VQA-DB) to date. The\ndataset is composed of 10,000 videos generated by 9 different T2V models. We\nalso conduct a subjective study to obtain each video's corresponding mean\nopinion score. Based on T2VQA-DB, we propose a novel transformer-based model\nfor subjective-aligned Text-to-Video Quality Assessment (T2VQA). The model\nextracts features from text-video alignment and video fidelity perspectives,\nthen it leverages the ability of a large language model to give the prediction\nscore. Experimental results show that T2VQA outperforms existing T2V metrics\nand SOTA video quality assessment models. Quantitative analysis indicates that\nT2VQA is capable of giving subjective-align predictions, validating its\neffectiveness. The dataset and code will be released at\nhttps://github.com/QMME/T2VQA.\n","authors":["Tengchuan Kou","Xiaohong Liu","Zicheng Zhang","Chunyi Li","Haoning Wu","Xiongkuo Min","Guangtao Zhai","Ning Liu"],"pdf_url":"https://arxiv.org/pdf/2403.11956v5.pdf","comment":"Accepted by ACMMM 24"},{"id":"http://arxiv.org/abs/2408.03888v1","updated":"2024-08-07T16:39:16Z","published":"2024-08-07T16:39:16Z","title":"Dual-Modeling Decouple Distillation for Unsupervised Anomaly Detection","summary":"  Knowledge distillation based on student-teacher network is one of the\nmainstream solution paradigms for the challenging unsupervised Anomaly\nDetection task, utilizing the difference in representation capabilities of the\nteacher and student networks to implement anomaly localization. However,\nover-generalization of the student network to the teacher network may lead to\nnegligible differences in representation capabilities of anomaly, thus\naffecting the detection effectiveness. Existing methods address the possible\nover-generalization by using differentiated students and teachers from the\nstructural perspective or explicitly expanding distilled information from the\ncontent perspective, which inevitably result in an increased likelihood of\nunderfitting of the student network and poor anomaly detection capabilities in\nanomaly center or edge. In this paper, we propose Dual-Modeling Decouple\nDistillation (DMDD) for the unsupervised anomaly detection. In DMDD, a Decouple\nStudent-Teacher Network is proposed to decouple the initial student features\ninto normality and abnormality features. We further introduce Dual-Modeling\nDistillation based on normal-anomaly image pairs, fitting normality features of\nanomalous image and the teacher features of the corresponding normal image,\nwidening the distance between abnormality features and the teacher features in\nanomalous regions. Synthesizing these two distillation ideas, we achieve\nanomaly detection which focuses on both edge and center of anomaly. Finally, a\nMulti-perception Segmentation Network is proposed to achieve focused anomaly\nmap fusion based on multiple attention. Experimental results on MVTec AD show\nthat DMDD surpasses SOTA localization performance of previous knowledge\ndistillation-based methods, reaching 98.85% on pixel-level AUC and 96.13% on\nPRO.\n","authors":["Xinyue Liu","Jianyuan Wang","Biao Leng","Shuo Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.03888v1.pdf","comment":"10 pages, 8 figures, Accepted to ACM MM '24"},{"id":"http://arxiv.org/abs/2408.03885v1","updated":"2024-08-07T16:34:32Z","published":"2024-08-07T16:34:32Z","title":"Global-Local Progressive Integration Network for Blind Image Quality\n  Assessment","summary":"  Vision transformers (ViTs) excel in computer vision for modeling long-term\ndependencies, yet face two key challenges for image quality assessment (IQA):\ndiscarding fine details during patch embedding, and requiring extensive\ntraining data due to lack of inductive biases. In this study, we propose a\nGlobal-Local progressive INTegration network for IQA, called GlintIQA, to\naddress these issues through three key components: 1) Hybrid feature extraction\ncombines ViT-based global feature extractor (VGFE) and convolutional neural\nnetworks (CNNs)-based local feature extractor (CLFE) to capture global\ncoarse-grained features and local fine-grained features, respectively. The\nincorporation of CNNs mitigates the patch-level information loss and inductive\nbias constraints inherent to ViT architectures. 2) Progressive feature\nintegration leverages diverse kernel sizes in embedding to spatially align\ncoarse- and fine-grained features, and progressively aggregate these features\nby interactively stacking channel-wise attention and spatial enhancement\nmodules to build effective quality-aware representations. 3) Content\nsimilarity-based labeling approach is proposed that automatically assigns\nquality labels to images with diverse content based on subjective quality\nscores. This addresses the scarcity of labeled training data in synthetic\ndatasets and bolsters model generalization. The experimental results\ndemonstrate the efficacy of our approach, yielding 5.04% average SROCC gains on\ncross-authentic dataset evaluations. Moreover, our model and its counterpart\npre-trained on the proposed dataset respectively exhibited 5.40% and 13.23%\nimprovements on across-synthetic datasets evaluation. The codes and proposed\ndataset will be released at https://github.com/XiaoqiWang/GlintIQA.\n","authors":["Xiaoqi Wang","Yun Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.03885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00920v3","updated":"2024-08-07T16:30:56Z","published":"2023-10-02T06:17:24Z","title":"Every Dataset Counts: Scaling up Monocular 3D Object Detection with\n  Joint Datasets Training","summary":"  Monocular 3D object detection plays a crucial role in autonomous driving.\nHowever, existing monocular 3D detection algorithms depend on 3D labels derived\nfrom LiDAR measurements, which are costly to acquire for new datasets and\nchallenging to deploy in novel environments. Specifically, this study\ninvestigates the pipeline for training a monocular 3D object detection model on\na diverse collection of 3D and 2D datasets. The proposed framework comprises\nthree components: (1) a robust monocular 3D model capable of functioning across\nvarious camera settings, (2) a selective-training strategy to accommodate\ndatasets with differing class annotations, and (3) a pseudo 3D training\napproach using 2D labels to enhance detection performance in scenes containing\nonly 2D labels. With this framework, we could train models on a joint set of\nvarious open 3D/2D datasets to obtain models with significantly stronger\ngeneralization capability and enhanced performance on new dataset with only 2D\nlabels. We conduct extensive experiments on\nKITTI/nuScenes/ONCE/Cityscapes/BDD100K datasets to demonstrate the scaling\nability of the proposed method.\n","authors":["Fulong Ma","Xiaoyang Yan","Guoyang Zhao","Xiaojie Xu","Yuxuan Liu","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2310.00920v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03867v1","updated":"2024-08-07T16:16:31Z","published":"2024-08-07T16:16:31Z","title":"Surgformer: Surgical Transformer with Hierarchical Temporal Attention\n  for Surgical Phase Recognition","summary":"  Existing state-of-the-art methods for surgical phase recognition either rely\non the extraction of spatial-temporal features at a short-range temporal\nresolution or adopt the sequential extraction of the spatial and temporal\nfeatures across the entire temporal resolution. However, these methods have\nlimitations in modeling spatial-temporal dependency and addressing\nspatial-temporal redundancy: 1) These methods fail to effectively model\nspatial-temporal dependency, due to the lack of long-range information or joint\nspatial-temporal modeling. 2) These methods utilize dense spatial features\nacross the entire temporal resolution, resulting in significant\nspatial-temporal redundancy. In this paper, we propose the Surgical Transformer\n(Surgformer) to address the issues of spatial-temporal modeling and redundancy\nin an end-to-end manner, which employs divided spatial-temporal attention and\ntakes a limited set of sparse frames as input. Moreover, we propose a novel\nHierarchical Temporal Attention (HTA) to capture both global and local\ninformation within varied temporal resolutions from a target frame-centric\nperspective. Distinct from conventional temporal attention that primarily\nemphasizes dense long-range similarity, HTA not only captures long-term\ninformation but also considers local latent consistency among informative\nframes. HTA then employs pyramid feature aggregation to effectively utilize\ntemporal information across diverse temporal resolutions, thereby enhancing the\noverall temporal representation. Extensive experiments on two challenging\nbenchmark datasets verify that our proposed Surgformer performs favorably\nagainst the state-of-the-art methods. The code is released at\nhttps://github.com/isyangshu/Surgformer.\n","authors":["Shu Yang","Luyang Luo","Qiong Wang","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2408.03867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15636v3","updated":"2024-08-07T16:07:05Z","published":"2024-05-24T15:22:58Z","title":"Visualize and Paint GAN Activations","summary":"  We investigate how generated structures of GANs correlate with their\nactivations in hidden layers, with the purpose of better understanding the\ninner workings of those models and being able to paint structures with\nunconditionally trained GANs. This gives us more control over the generated\nimages, allowing to generate them from a semantic segmentation map while not\nrequiring such a segmentation in the training data. To this end we introduce\nthe concept of tileable features, allowing us to identify activations that work\nwell for painting.\n","authors":["Rudolf Herdt","Peter Maass"],"pdf_url":"https://arxiv.org/pdf/2405.15636v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03842v1","updated":"2024-08-07T15:35:25Z","published":"2024-08-07T15:35:25Z","title":"Bi-Level Spatial and Channel-aware Transformer for Learned Image\n  Compression","summary":"  Recent advancements in learned image compression (LIC) methods have\ndemonstrated superior performance over traditional hand-crafted codecs. These\nlearning-based methods often employ convolutional neural networks (CNNs) or\nTransformer-based architectures. However, these nonlinear approaches frequently\noverlook the frequency characteristics of images, which limits their\ncompression efficiency. To address this issue, we propose a novel\nTransformer-based image compression method that enhances the transformation\nstage by considering frequency components within the feature map. Our method\nintegrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB),\nwhere a spatial-based branch independently handles high and low frequencies at\nthe attention layer, and a Channel-aware Self-Attention (CaSA) module captures\ninformation across channels, significantly improving compression performance.\nAdditionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN)\nwithin the Transformer block to enhance the extraction of diverse and rich\ninformation, which is crucial for effective compression. These innovations\ncollectively improve the transformation's ability to project data into a more\ndecorrelated latent space, thereby boosting overall compression efficiency.\nExperimental results demonstrate that our framework surpasses state-of-the-art\nLIC methods in rate-distortion performance.\n","authors":["Hamidreza Soltani","Erfan Ghasemi"],"pdf_url":"https://arxiv.org/pdf/2408.03842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03838v1","updated":"2024-08-07T15:24:25Z","published":"2024-08-07T15:24:25Z","title":"Using a Distance Sensor to Detect Deviations in a Planar Surface","summary":"  We investigate methods for determining if a planar surface contains geometric\ndeviations (e.g., protrusions, objects, divots, or cliffs) using only an\ninstantaneous measurement from a miniature optical time-of-flight sensor. The\nkey to our method is to utilize the entirety of information encoded in raw\ntime-of-flight data captured by off-the-shelf distance sensors. We provide an\nanalysis of the problem in which we identify the key ambiguity between geometry\nand surface photometrics. To overcome this challenging ambiguity, we fit a\nGaussian mixture model to a small dataset of planar surface measurements. This\nmodel implicitly captures the expected geometry and distribution of\nphotometrics of the planar surface and is used to identify measurements that\nare likely to contain deviations. We characterize our method on a variety of\nsurfaces and planar deviations across a range of scenarios. We find that our\nmethod utilizing raw time-of-flight data outperforms baselines which use only\nderived distance estimates. We build an example application in which our method\nenables mobile robot obstacle and cliff avoidance over a wide field-of-view.\n","authors":["Carter Sifferman","William Sun","Mohit Gupta","Michael Gleicher"],"pdf_url":"https://arxiv.org/pdf/2408.03838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03834v1","updated":"2024-08-07T15:17:51Z","published":"2024-08-07T15:17:51Z","title":"Target Prompting for Information Extraction with Vision Language Model","summary":"  The recent trend in the Large Vision and Language model has brought a new\nchange in how information extraction systems are built. VLMs have set a new\nbenchmark with their State-of-the-art techniques in understanding documents and\nbuilding question-answering systems across various industries. They are\nsignificantly better at generating text from document images and providing\naccurate answers to questions. However, there are still some challenges in\neffectively utilizing these models to build a precise conversational system.\nGeneral prompting techniques used with large language models are often not\nsuitable for these specially designed vision language models. The output\ngenerated by such generic input prompts is ordinary and may contain information\ngaps when compared with the actual content of the document. To obtain more\naccurate and specific answers, a well-targeted prompt is required by the vision\nlanguage model, along with the document image. In this paper, a technique is\ndiscussed called Target prompting, which focuses on explicitly targeting parts\nof document images and generating related answers from those specific regions\nonly. The paper also covers the evaluation of response for each prompting\ntechnique using different user queries and input prompts.\n","authors":["Dipankar Medhi"],"pdf_url":"https://arxiv.org/pdf/2408.03834v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.19588v2","updated":"2024-08-07T15:11:01Z","published":"2024-03-28T17:12:39Z","title":"DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs","summary":"  This paper revives Densely Connected Convolutional Networks (DenseNets) and\nreveals the underrated effectiveness over predominant ResNet-style\narchitectures. We believe DenseNets' potential was overlooked due to untouched\ntraining methods and traditional design elements not fully revealing their\ncapabilities. Our pilot study shows dense connections through concatenation are\nstrong, demonstrating that DenseNets can be revitalized to compete with modern\narchitectures. We methodically refine suboptimal components - architectural\nadjustments, block redesign, and improved training recipes towards widening\nDenseNets and boosting memory efficiency while keeping concatenation shortcuts.\nOur models, employing simple architectural elements, ultimately surpass Swin\nTransformer, ConvNeXt, and DeiT-III - key architectures in the residual\nlearning lineage. Furthermore, our models exhibit near state-of-the-art\nperformance on ImageNet-1K, competing with the very recent models and\ndownstream tasks, ADE20k semantic segmentation, and COCO object\ndetection/instance segmentation. Finally, we provide empirical analyses that\nuncover the merits of the concatenation over additive shortcuts, steering a\nrenewed preference towards DenseNet-style designs. Our code is available at\nhttps://github.com/naver-ai/rdnet.\n","authors":["Donghyun Kim","Byeongho Heo","Dongyoon Han"],"pdf_url":"https://arxiv.org/pdf/2403.19588v2.pdf","comment":"ECCV 2024. Code at https://github.com/naver-ai/rdnet"},{"id":"http://arxiv.org/abs/2401.00763v2","updated":"2024-08-07T15:10:15Z","published":"2024-01-01T14:06:55Z","title":"New Job, New Gender? Measuring the Social Bias in Image Generation\n  Models","summary":"  Image generation models can generate or edit images from a given text. Recent\nadvancements in image generation technology, exemplified by DALL-E and\nMidjourney, have been groundbreaking. These advanced models, despite their\nimpressive capabilities, are often trained on massive Internet datasets, making\nthem susceptible to generating content that perpetuates social stereotypes and\nbiases, which can lead to severe consequences. Prior research on assessing bias\nwithin image generation models suffers from several shortcomings, including\nlimited accuracy, reliance on extensive human labor, and lack of comprehensive\nanalysis. In this paper, we propose BiasPainter, a novel evaluation framework\nthat can accurately, automatically and comprehensively trigger social bias in\nimage generation models. BiasPainter uses a diverse range of seed images of\nindividuals and prompts the image generation models to edit these images using\ngender, race, and age-neutral queries. These queries span 62 professions, 39\nactivities, 57 types of objects, and 70 personality traits. The framework then\ncompares the edited images to the original seed images, focusing on the\nsignificant changes related to gender, race, and age. BiasPainter adopts a key\ninsight that these characteristics should not be modified when subjected to\nneutral prompts. Built upon this design, BiasPainter can trigger the social\nbias and evaluate the fairness of image generation models. We use BiasPainter\nto evaluate six widely-used image generation models, such as stable diffusion\nand Midjourney. Experimental results show that BiasPainter can successfully\ntrigger social bias in image generation models. According to our human\nevaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection,\nwhich is significantly higher than the results reported in previous work.\n","authors":["Wenxuan Wang","Haonan Bai","Jen-tse Huang","Yuxuan Wan","Youliang Yuan","Haoyi Qiu","Nanyun Peng","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2401.00763v2.pdf","comment":"ACM MM 2024 Oral"},{"id":"http://arxiv.org/abs/2408.03825v1","updated":"2024-08-07T15:01:08Z","published":"2024-08-07T15:01:08Z","title":"Towards Real-Time Gaussian Splatting: Accelerating 3DGS through\n  Photometric SLAM","summary":"  Initial applications of 3D Gaussian Splatting (3DGS) in Visual Simultaneous\nLocalization and Mapping (VSLAM) demonstrate the generation of high-quality\nvolumetric reconstructions from monocular video streams. However, despite these\npromising advancements, current 3DGS integrations have reduced tracking\nperformance and lower operating speeds compared to traditional VSLAM. To\naddress these issues, we propose integrating 3DGS with Direct Sparse Odometry,\na monocular photometric SLAM system. We have done preliminary experiments\nshowing that using Direct Sparse Odometry point cloud outputs, as opposed to\nstandard structure-from-motion methods, significantly shortens the training\ntime needed to achieve high-quality renders. Reducing 3DGS training time\nenables the development of 3DGS-integrated SLAM systems that operate in\nreal-time on mobile hardware. These promising initial findings suggest further\nexploration is warranted in combining traditional VSLAM systems with 3DGS.\n","authors":["Yan Song Hu","Dayou Mao","Yuhao Chen","John Zelek"],"pdf_url":"https://arxiv.org/pdf/2408.03825v1.pdf","comment":"This extended abstract has been submitted to be presented at an IEEE\n  conference. It will be made available online by IEEE but will not be\n  published in IEEE Xplore. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2408.03822v1","updated":"2024-08-07T14:56:34Z","published":"2024-08-07T14:56:34Z","title":"Compact 3D Gaussian Splatting for Static and Dynamic Radiance Fields","summary":"  3D Gaussian splatting (3DGS) has recently emerged as an alternative\nrepresentation that leverages a 3D Gaussian-based representation and introduces\nan approximated volumetric rendering, achieving very fast rendering speed and\npromising image quality. Furthermore, subsequent studies have successfully\nextended 3DGS to dynamic 3D scenes, demonstrating its wide range of\napplications. However, a significant drawback arises as 3DGS and its following\nmethods entail a substantial number of Gaussians to maintain the high fidelity\nof the rendered images, which requires a large amount of memory and storage. To\naddress this critical issue, we place a specific emphasis on two key\nobjectives: reducing the number of Gaussian points without sacrificing\nperformance and compressing the Gaussian attributes, such as view-dependent\ncolor and covariance. To this end, we propose a learnable mask strategy that\nsignificantly reduces the number of Gaussians while preserving high\nperformance. In addition, we propose a compact but effective representation of\nview-dependent color by employing a grid-based neural field rather than relying\non spherical harmonics. Finally, we learn codebooks to compactly represent the\ngeometric and temporal attributes by residual vector quantization. With model\ncompression techniques such as quantization and entropy coding, we consistently\nshow over 25x reduced storage and enhanced rendering speed compared to 3DGS for\nstatic scenes, while maintaining the quality of the scene representation. For\ndynamic scenes, our approach achieves more than 12x storage efficiency and\nretains a high-quality reconstruction compared to the existing state-of-the-art\nmethods. Our work provides a comprehensive framework for 3D scene\nrepresentation, achieving high performance, fast training, compactness, and\nreal-time rendering. Our project page is available at\nhttps://maincold2.github.io/c3dgs/.\n","authors":["Joo Chan Lee","Daniel Rho","Xiangyu Sun","Jong Hwan Ko","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2408.03822v1.pdf","comment":"Project page: https://maincold2.github.io/c3dgs/"},{"id":"http://arxiv.org/abs/2405.06342v2","updated":"2024-08-07T14:33:42Z","published":"2024-05-10T09:18:17Z","title":"Compression-Realized Deep Structural Network for Video Quality\n  Enhancement","summary":"  This paper focuses on the task of quality enhancement for compressed videos.\nAlthough deep network-based video restorers achieve impressive progress, most\nof the existing methods lack a structured design to optimally leverage the\npriors within compression codecs. Since the quality degradation of the video is\nprimarily induced by the compression algorithm, a new paradigm is urgently\nneeded for a more ``conscious'' process of quality enhancement. As a result, we\npropose the Compression-Realized Deep Structural Network (CRDS), introducing\nthree inductive biases aligned with the three primary processes in the classic\ncompression codec, merging the strengths of classical encoder architecture with\ndeep network capabilities. Inspired by the residual extraction and domain\ntransformation process in the codec, a pre-trained Latent Degradation Residual\nAuto-Encoder is proposed to transform video frames into a latent feature space,\nand the mutual neighborhood attention mechanism is integrated for precise\nmotion estimation and residual extraction. Furthermore, drawing inspiration\nfrom the quantization noise distribution of the codec, CRDS proposes a novel\nProgressive Denoising framework with intermediate supervision that decomposes\nthe quality enhancement into a series of simpler denoising sub-tasks.\nExperimental results on datasets like LDV 2.0 and MFQE 2.0 indicate our\napproach surpasses state-of-the-art models. Codes are available at\nhttps://github.com/shc15522/CRDS.\n","authors":["Hanchi Sun","Xiaohong Liu","Xinyang Jiang","Yifei Shen","Dongsheng Li","Xiongkuo Min","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2405.06342v2.pdf","comment":"Accepted by ACM MM'24"},{"id":"http://arxiv.org/abs/2407.18520v2","updated":"2024-08-07T14:33:14Z","published":"2024-07-26T05:29:24Z","title":"Text-Region Matching for Multi-Label Image Recognition with Missing\n  Labels","summary":"  Recently, large-scale visual language pre-trained (VLP) models have\ndemonstrated impressive performance across various downstream tasks. Motivated\nby these advancements, pioneering efforts have emerged in multi-label image\nrecognition with missing labels, leveraging VLP prompt-tuning technology.\nHowever, they usually cannot match text and vision features well, due to\ncomplicated semantics gaps and missing labels in a multi-label image. To tackle\nthis challenge, we propose \\textbf{T}ext-\\textbf{R}egion \\textbf{M}atching for\noptimizing \\textbf{M}ulti-\\textbf{L}abel prompt tuning, namely TRM-ML, a novel\nmethod for enhancing meaningful cross-modal matching. Compared to existing\nmethods, we advocate exploring the information of category-aware regions rather\nthan the entire image or pixels, which contributes to bridging the semantic gap\nbetween textual and visual representations in a one-to-one matching manner.\nConcurrently, we further introduce multimodal contrastive learning to narrow\nthe semantic gap between textual and visual modalities and establish\nintra-class and inter-class relationships. Additionally, to deal with missing\nlabels, we propose a multimodal category prototype that leverages intra- and\ninter-category semantic relationships to estimate unknown labels, facilitating\npseudo-label generation. Extensive experiments on the MS-COCO, PASCAL VOC,\nVisual Genome, NUS-WIDE, and CUB-200-211 benchmark datasets demonstrate that\nour proposed framework outperforms the state-of-the-art methods by a\nsignificant margin. Our code is available\nhere\\href{https://github.com/yu-gi-oh-leilei/TRM-ML}{\\raisebox{-1pt}{\\faGithub}}.\n","authors":["Leilei Ma","Hongxing Xie","Lei Wang","Yanping Fu","Dengdi Sun","Haifeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2407.18520v2.pdf","comment":"Accepted to ACM International Conference on Multimedia (ACM MM) 2024"},{"id":"http://arxiv.org/abs/2408.03790v1","updated":"2024-08-07T14:14:53Z","published":"2024-08-07T14:14:53Z","title":"Vision-Language Guidance for LiDAR-based Unsupervised 3D Object\n  Detection","summary":"  Accurate 3D object detection in LiDAR point clouds is crucial for autonomous\ndriving systems. To achieve state-of-the-art performance, the supervised\ntraining of detectors requires large amounts of human-annotated data, which is\nexpensive to obtain and restricted to predefined object categories. To mitigate\nmanual labeling efforts, recent unsupervised object detection approaches\ngenerate class-agnostic pseudo-labels for moving objects, subsequently serving\nas supervision signal to bootstrap a detector. Despite promising results, these\napproaches do not provide class labels or generalize well to static objects.\nFurthermore, they are mostly restricted to data containing multiple drives from\nthe same scene or images from a precisely calibrated and synchronized camera\nsetup. To overcome these limitations, we propose a vision-language-guided\nunsupervised 3D detection approach that operates exclusively on LiDAR point\nclouds. We transfer CLIP knowledge to classify point clusters of static and\nmoving objects, which we discover by exploiting the inherent spatio-temporal\ninformation of LiDAR point clouds for clustering, tracking, as well as box and\nlabel refinement. Our approach outperforms state-of-the-art unsupervised 3D\nobject detectors on the Waymo Open Dataset ($+23~\\text{AP}_{3D}$) and Argoverse\n2 ($+7.9~\\text{AP}_{3D}$) and provides class labels not solely based on object\nsize assumptions, marking a significant advancement in the field.\n","authors":["Christian Fruhwirth-Reisinger","Wei Lin","Dušan Malić","Horst Bischof","Horst Possegger"],"pdf_url":"https://arxiv.org/pdf/2408.03790v1.pdf","comment":"Accepted to BMVC 2024"},{"id":"http://arxiv.org/abs/2408.03789v1","updated":"2024-08-07T14:14:05Z","published":"2024-08-07T14:14:05Z","title":"Counterfactuals and Uncertainty-Based Explainable Paradigm for the\n  Automated Detection and Segmentation of Renal Cysts in Computed Tomography\n  Images: A Multi-Center Study","summary":"  Routine computed tomography (CT) scans often detect a wide range of renal\ncysts, some of which may be malignant. Early and precise localization of these\ncysts can significantly aid quantitative image analysis. Current segmentation\nmethods, however, do not offer sufficient interpretability at the feature and\npixel levels, emphasizing the necessity for an explainable framework that can\ndetect and rectify model inaccuracies. We developed an interpretable\nsegmentation framework and validated it on a multi-centric dataset. A\nVariational Autoencoder Generative Adversarial Network (VAE-GAN) was employed\nto learn the latent representation of 3D input patches and reconstruct input\nimages. Modifications in the latent representation using the gradient of the\nsegmentation model generated counterfactual explanations for varying dice\nsimilarity coefficients (DSC). Radiomics features extracted from these\ncounterfactual images, using a ground truth cyst mask, were analyzed to\ndetermine their correlation with segmentation performance. The DSCs for the\noriginal and VAE-GAN reconstructed images for counterfactual image generation\nshowed no significant differences. Counterfactual explanations highlighted how\nvariations in cyst image features influence segmentation outcomes and showed\nmodel discrepancies. Radiomics features correlating positively and negatively\nwith dice scores were identified. The uncertainty of the predicted segmentation\nmasks was estimated using posterior sampling of the weight space. The\ncombination of counterfactual explanations and uncertainty maps provided a\ndeeper understanding of the image features within the segmented renal cysts\nthat lead to high uncertainty. The proposed segmentation framework not only\nachieved high segmentation accuracy but also increased interpretability\nregarding how image features impact segmentation performance.\n","authors":["Zohaib Salahuddin","Abdalla Ibrahim","Sheng Kuang","Yousif Widaatalla","Razvan L. Miclea","Oliver Morin","Spencer Behr","Marnix P. M. Kop","Tom Marcelissen","Patricia Zondervan","Auke Jager","Philippe Lambin","Henry C Woodruff"],"pdf_url":"https://arxiv.org/pdf/2408.03789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06646v2","updated":"2024-08-07T14:06:30Z","published":"2024-03-20T05:52:11Z","title":"Diffusion-based Human Motion Style Transfer with Semantic Guidance","summary":"  3D Human motion style transfer is a fundamental problem in computer graphic\nand animation processing. Existing AdaIN- based methods necessitate datasets\nwith balanced style distribution and content/style labels to train the\nclustered latent space. However, we may encounter a single unseen style example\nin practical scenarios, but not in sufficient quantity to constitute a style\ncluster for AdaIN-based methods. Therefore, in this paper, we propose a novel\ntwo-stage framework for few-shot style transfer learning based on the diffusion\nmodel. Specifically, in the first stage, we pre-train a diffusion-based\ntext-to-motion model as a generative prior so that it can cope with various\ncontent motion inputs. In the second stage, based on the single style example,\nwe fine-tune the pre-trained diffusion model in a few-shot manner to make it\ncapable of style transfer. The key idea is regarding the reverse process of\ndiffusion as a motion-style translation process since the motion styles can be\nviewed as special motion variations. During the fine-tuning for style transfer,\na simple yet effective semantic-guided style transfer loss coordinated with\nstyle example reconstruction loss is introduced to supervise the style transfer\nin CLIP semantic space. The qualitative and quantitative evaluations\ndemonstrate that our method can achieve state-of-the-art performance and has\npractical applications.\n","authors":["Lei Hu","Zihao Zhang","Yongjing Ye","Yiwen Xu","Shihong Xia"],"pdf_url":"https://arxiv.org/pdf/2405.06646v2.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.05771v2","updated":"2024-08-07T14:01:34Z","published":"2024-07-08T09:27:34Z","title":"Multi-times Monte Carlo Rendering for Inter-reflection Reconstruction","summary":"  Inverse rendering methods have achieved remarkable performance in\nreconstructing high-fidelity 3D objects with disentangled geometries,\nmaterials, and environmental light. However, they still face huge challenges in\nreflective surface reconstruction. Although recent methods model the light\ntrace to learn specularity, the ignorance of indirect illumination makes it\nhard to handle inter-reflections among multiple smooth objects. In this work,\nwe propose Ref-MC2 that introduces the multi-time Monte Carlo sampling which\ncomprehensively computes the environmental illumination and meanwhile considers\nthe reflective light from object surfaces. To address the computation challenge\nas the times of Monte Carlo sampling grow, we propose a specularity-adaptive\nsampling strategy, significantly reducing the computational complexity. Besides\nthe computational resource, higher geometry accuracy is also required because\ngeometric errors accumulate multiple times. Therefore, we further introduce a\nreflection-aware surface model to initialize the geometry and refine it during\ninverse rendering. We construct a challenging dataset containing scenes with\nmultiple objects and inter-reflections. Experiments show that our method\noutperforms other inverse rendering methods on various object groups. We also\nshow downstream applications, e.g., relighting and material editing, to\nillustrate the disentanglement ability of our method.\n","authors":["Tengjie Zhu","Zhuo Chen","Jingnan Gao","Yichao Yan","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2407.05771v2.pdf","comment":"10 pages,6 figures,NeurIPS 2024 Submitted"},{"id":"http://arxiv.org/abs/2407.15793v2","updated":"2024-08-07T13:59:46Z","published":"2024-07-22T16:51:28Z","title":"CLIP with Generative Latent Replay: a Strong Baseline for Incremental\n  Learning","summary":"  With the emergence of Transformers and Vision-Language Models (VLMs) such as\nCLIP, large pre-trained models have become a common strategy to enhance\nperformance in Continual Learning scenarios. This led to the development of\nnumerous prompting strategies to effectively fine-tune transformer-based models\nwithout succumbing to catastrophic forgetting. However, these methods struggle\nto specialize the model on domains significantly deviating from the\npre-training and preserving its zero-shot capabilities. In this work, we\npropose Continual Generative training for Incremental prompt-Learning, a novel\napproach to mitigate forgetting while adapting a VLM, which exploits generative\nreplay to align prompts to tasks. We also introduce a new metric to evaluate\nzero-shot capabilities within CL benchmarks. Through extensive experiments on\ndifferent domains, we demonstrate the effectiveness of our framework in\nadapting to new tasks while improving zero-shot capabilities. Further analysis\nreveals that our approach can bridge the gap with joint prompt tuning. The\ncodebase is available at https://github.com/aimagelab/mammoth.\n","authors":["Emanuele Frascaroli","Aniello Panariello","Pietro Buzzega","Lorenzo Bonicelli","Angelo Porrello","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2407.15793v2.pdf","comment":"15 pages, 1 figure. Accepted at the The 35th British Machine Vision\n  Conference 2024 (BMVC 2024), Glasgow, UK"},{"id":"http://arxiv.org/abs/2408.03771v1","updated":"2024-08-07T13:47:32Z","published":"2024-08-07T13:47:32Z","title":"Methodological Explainability Evaluation of an Interpretable Deep\n  Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating\n  Counterfactual Explanations and Layerwise Relevance Propagation: A\n  Prospective In Silico Trial","summary":"  Artificial intelligence (AI)-based decision support systems have demonstrated\nvalue in predicting post-hepatectomy liver failure (PHLF) in hepatocellular\ncarcinoma (HCC). However, they often lack transparency, and the impact of model\nexplanations on clinicians' decisions has not been thoroughly evaluated.\nBuilding on prior research, we developed a variational autoencoder-multilayer\nperceptron (VAE-MLP) model for preoperative PHLF prediction. This model\nintegrated counterfactuals and layerwise relevance propagation (LRP) to provide\ninsights into its decision-making mechanism. Additionally, we proposed a\nmethodological framework for evaluating the explainability of AI systems. This\nframework includes qualitative and quantitative assessments of explanations\nagainst recognized biomarkers, usability evaluations, and an in silico clinical\ntrial. Our evaluations demonstrated that the model's explanation correlated\nwith established biomarkers and exhibited high usability at both the case and\nsystem levels. Furthermore, results from the three-track in silico clinical\ntrial showed that clinicians' prediction accuracy and confidence increased when\nAI explanations were provided.\n","authors":["Xian Zhong","Zohaib Salahuddin","Yi Chen","Henry C Woodruff","Haiyi Long","Jianyun Peng","Nuwan Udawatte","Roberto Casale","Ayoub Mokhtari","Xiaoer Zhang","Jiayao Huang","Qingyu Wu","Li Tan","Lili Chen","Dongming Li","Xiaoyan Xie","Manxia Lin","Philippe Lambin"],"pdf_url":"https://arxiv.org/pdf/2408.03771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10428v5","updated":"2024-08-07T13:44:06Z","published":"2023-03-18T14:46:44Z","title":"RCA: Region Conditioned Adaptation for Visual Abductive Reasoning","summary":"  Visual abductive reasoning aims to make likely explanations for visual\nobservations. We propose a simple yet effective Region Conditioned Adaptation,\na hybrid parameter-efficient fine-tuning method that equips the frozen CLIP\nwith the ability to infer explanations from local visual cues. We encode\n``local hints'' and ``global contexts'' into visual prompts of the CLIP model\nseparately at fine and coarse-grained levels. Adapters are used for fine-tuning\nCLIP models for downstream tasks and we design a new attention adapter, that\ndirectly steers the focus of the attention map with trainable query and key\nprojections of a frozen CLIP model. Finally, we train our new model with a\nmodified contrastive loss to regress the visual feature simultaneously toward\nfeatures of literal description and plausible explanations. The loss enables\nCLIP to maintain both perception and reasoning abilities. Experiments on the\nSherlock visual abductive reasoning benchmark show that the RCA significantly\noutstands previous SOTAs, ranking the \\nth{1} on the leaderboards (e.g., Human\nAcc: RCA 31.74 \\textit{vs} CPT-CLIP 29.58, higher =better). We also validate\nthe RCA is generalizable to local perception benchmarks like RefCOCO. We\nopen-source our project at\n\\textit{\\color{magenta}{\\url{https://github.com/LUNAProject22/RPA}}}.\n","authors":["Hao Zhang","Yeo Keat Ee","Basura Fernando"],"pdf_url":"https://arxiv.org/pdf/2303.10428v5.pdf","comment":"13 pages, 11 figures, ACM Multimedia 2024"},{"id":"http://arxiv.org/abs/2406.18944v3","updated":"2024-08-07T13:37:41Z","published":"2024-06-27T07:14:14Z","title":"Investigating and Defending Shortcut Learning in Personalized Diffusion\n  Models","summary":"  Personalized diffusion models have gained popularity for adapting pre-trained\ntext-to-image models to generate images of specific topics with minimal\ntraining data. However, these models are vulnerable to minor adversarial\nperturbations, leading to degraded performance on corrupted datasets. Such\nvulnerabilities are further exploited to craft protective perturbations on\nsensitive images like portraits that prevent unauthorized generation. In\nresponse, diffusion-based purification methods have been proposed to remove\nthese perturbations and retain generation performance. However, existing works\nturn to over-purifying the images, which causes information loss. In this\npaper, we take a closer look at the fine-tuning process of personalized\ndiffusion models through the lens of shortcut learning. And we propose a\nhypothesis explaining the manipulation mechanisms of existing perturbation\nmethods, demonstrating that perturbed images significantly deviate from their\noriginal prompts in the CLIP-based latent space. This misalignment during\nfine-tuning causes models to associate noisy patterns with identifiers,\nresulting in performance degradation. Based on these insights, we introduce a\nsystematic approach to maintain training performance through purification. Our\nmethod first purifies the images to realign them with their original semantic\nmeanings in latent space. Then, we introduce contrastive learning with negative\ntokens to decouple the learning of clean identities from noisy patterns, which\nshows a strong potential capacity against adaptive perturbation. Our study\nuncovers shortcut learning vulnerabilities in personalized diffusion models and\nprovides a firm evaluation framework for future protective perturbation\nresearch. Code is available at https://github.com/liuyixin-louis/DiffShortcut.\n","authors":["Yixin Liu","Ruoxi Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2406.18944v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2408.03761v1","updated":"2024-08-07T13:30:58Z","published":"2024-08-07T13:30:58Z","title":"MMSummary: Multimodal Summary Generation for Fetal Ultrasound Video","summary":"  We present the first automated multimodal summary generation system,\nMMSummary, for medical imaging video, particularly with a focus on fetal\nultrasound analysis. Imitating the examination process performed by a human\nsonographer, MMSummary is designed as a three-stage pipeline, progressing from\nkeyframe detection to keyframe captioning and finally anatomy segmentation and\nmeasurement. In the keyframe detection stage, an innovative automated workflow\nis proposed to progressively select a concise set of keyframes, preserving\nsufficient video information without redundancy. Subsequently, we adapt a large\nlanguage model to generate meaningful captions for fetal ultrasound keyframes\nin the keyframe captioning stage. If a keyframe is captioned as fetal biometry,\nthe segmentation and measurement stage estimates biometric parameters by\nsegmenting the region of interest according to the textual prior. The MMSummary\nsystem provides comprehensive summaries for fetal ultrasound examinations and\nbased on reported experiments is estimated to reduce scanning time by\napproximately 31.5%, thereby suggesting the potential to enhance clinical\nworkflow efficiency.\n","authors":["Xiaoqing Guo","Qianhui Men","J. Alison Noble"],"pdf_url":"https://arxiv.org/pdf/2408.03761v1.pdf","comment":"MICCAI 2024"},{"id":"http://arxiv.org/abs/2408.01953v2","updated":"2024-08-07T13:24:38Z","published":"2024-08-04T07:59:17Z","title":"EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning","summary":"  Humans perceive and interact with the world with the awareness of\nequivariance, facilitating us in manipulating different objects in diverse\nposes. For robotic manipulation, such equivariance also exists in many\nscenarios. For example, no matter what the pose of a drawer is (translation,\nrotation and tilt), the manipulation strategy is consistent (grasp the handle\nand pull in a line). While traditional models usually do not have the awareness\nof equivariance for robotic manipulation, which might result in more data for\ntraining and poor performance in novel object poses, we propose our EqvAfford\nframework, with novel designs to guarantee the equivariance in point-level\naffordance learning for downstream robotic manipulation, with great performance\nand generalization ability on representative tasks on objects in diverse poses.\n","authors":["Yue Chen","Chenrui Tie","Ruihai Wu","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2408.01953v2.pdf","comment":"Accept to CVPRWorkshop on Equivariant Vision: From Theory to Practice\n  2024"},{"id":"http://arxiv.org/abs/2404.11317v2","updated":"2024-08-07T13:20:30Z","published":"2024-04-17T12:30:54Z","title":"Improving Composed Image Retrieval via Contrastive Learning with Scaling\n  Positives and Negatives","summary":"  The Composed Image Retrieval (CIR) task aims to retrieve target images using\na composed query consisting of a reference image and a modified text. Advanced\nmethods often utilize contrastive learning as the optimization objective, which\nbenefits from adequate positive and negative examples. However, the triplet for\nCIR incurs high manual annotation costs, resulting in limited positive\nexamples. Furthermore, existing methods commonly use in-batch negative\nsampling, which reduces the negative number available for the model. To address\nthe problem of lack of positives, we propose a data generation method by\nleveraging a multi-modal large language model to construct triplets for CIR. To\nintroduce more negatives during fine-tuning, we design a two-stage fine-tuning\nframework for CIR, whose second stage introduces plenty of static\nrepresentations of negatives to optimize the representation space rapidly. The\nabove two improvements can be effectively stacked and designed to be\nplug-and-play, easily applied to existing CIR models without changing their\noriginal architectures. Extensive experiments and ablation analysis demonstrate\nthat our method effectively scales positives and negatives and achieves\nstate-of-the-art results on both FashionIQ and CIRR datasets. In addition, our\nmethod also performs well in zero-shot composed image retrieval, providing a\nnew CIR solution for the low-resources scenario. Our code and data are released\nat https://github.com/BUAADreamer/SPN4CIR.\n","authors":["Zhangchi Feng","Richong Zhang","Zhijie Nie"],"pdf_url":"https://arxiv.org/pdf/2404.11317v2.pdf","comment":"Accepted to ACM MM 2024 Regular Papers"},{"id":"http://arxiv.org/abs/2408.03753v1","updated":"2024-08-07T13:06:29Z","published":"2024-08-07T13:06:29Z","title":"3iGS: Factorised Tensorial Illumination for 3D Gaussian Splatting","summary":"  The use of 3D Gaussians as representation of radiance fields has enabled high\nquality novel view synthesis at real-time rendering speed. However, the choice\nof optimising the outgoing radiance of each Gaussian independently as spherical\nharmonics results in unsatisfactory view dependent effects. In response to\nthese limitations, our work, Factorised Tensorial Illumination for 3D Gaussian\nSplatting, or 3iGS, improves upon 3D Gaussian Splatting (3DGS) rendering\nquality. Instead of optimising a single outgoing radiance parameter, 3iGS\nenhances 3DGS view-dependent effects by expressing the outgoing radiance as a\nfunction of a local illumination field and Bidirectional Reflectance\nDistribution Function (BRDF) features. We optimise a continuous incident\nillumination field through a Tensorial Factorisation representation, while\nseparately fine-tuning the BRDF features of each 3D Gaussian relative to this\nillumination field. Our methodology significantly enhances the rendering\nquality of specular view-dependent effects of 3DGS, while maintaining rapid\ntraining and rendering speeds.\n","authors":["Zhe Jun Tang","Tat-Jen Cham"],"pdf_url":"https://arxiv.org/pdf/2408.03753v1.pdf","comment":"The 18th European Conference on Computer Vision ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03748v1","updated":"2024-08-07T13:01:10Z","published":"2024-08-07T13:01:10Z","title":"Data Generation Scheme for Thermal Modality with Edge-Guided Adversarial\n  Conditional Diffusion Model","summary":"  In challenging low light and adverse weather conditions,thermal vision\nalgorithms,especially object detection,have exhibited remarkable\npotential,contrasting with the frequent struggles encountered by visible vision\nalgorithms. Nevertheless,the efficacy of thermal vision algorithms driven by\ndeep learning models remains constrained by the paucity of available training\ndata samples. To this end,this paper introduces a novel approach termed the\nedge guided conditional diffusion model. This framework aims to produce\nmeticulously aligned pseudo thermal images at the pixel level,leveraging edge\ninformation extracted from visible images. By utilizing edges as contextual\ncues from the visible domain,the diffusion model achieves meticulous control\nover the delineation of objects within the generated images. To alleviate the\nimpacts of those visible-specific edge information that should not appear in\nthe thermal domain,a two-stage modality adversarial training strategy is\nproposed to filter them out from the generated images by differentiating the\nvisible and thermal modality. Extensive experiments on LLVIP demonstrate ECDM s\nsuperiority over existing state-of-the-art approaches in terms of image\ngeneration quality.\n","authors":["Guoqing Zhu","Honghu Pan","Qiang Wang","Chao Tian","Chao Yang","Zhenyu He"],"pdf_url":"https://arxiv.org/pdf/2408.03748v1.pdf","comment":"accepted by ACM MM 2024/ACM MM24"},{"id":"http://arxiv.org/abs/2305.18381v4","updated":"2024-08-07T12:59:31Z","published":"2023-05-28T06:53:41Z","title":"Distill Gold from Massive Ores: Bi-level Data Pruning towards Efficient\n  Dataset Distillation","summary":"  Data-efficient learning has garnered significant attention, especially given\nthe current trend of large multi-modal models. Recently, dataset distillation\nhas become an effective approach by synthesizing data samples that are\nessential for network training. However, it remains to be explored which\nsamples are essential for the dataset distillation process itself. In this\nwork, we study the data efficiency and selection for the dataset distillation\ntask. By re-formulating the dynamics of distillation, we provide insight into\nthe inherent redundancy in the real dataset, both theoretically and\nempirically. We propose to use the empirical loss value as a static data\npruning criterion. To further compensate for the variation of the data value in\ntraining, we find the most contributing samples based on their causal effects\non the distillation. The proposed selection strategy can efficiently exploit\nthe training dataset, outperform the previous SOTA distillation algorithms, and\nconsistently enhance the distillation algorithms, even on much larger-scale and\nmore heterogeneous datasets, e.g., full ImageNet-1K and Kinetics-400. We\nbelieve this paradigm will open up new avenues in the dynamics of distillation\nand pave the way for efficient dataset distillation. Our code is available on\nhttps://github.com/silicx/GoldFromOres-BiLP.\n","authors":["Yue Xu","Yong-Lu Li","Kaitong Cui","Ziyu Wang","Cewu Lu","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2305.18381v4.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03745v1","updated":"2024-08-07T12:58:39Z","published":"2024-08-07T12:58:39Z","title":"Intuitionistic Fuzzy Cognitive Maps for Interpretable Image\n  Classification","summary":"  The interpretability of machine learning models is critical, as users may be\nreluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been\nproposed as an extension of FCMs offering a natural mechanism to assess the\nquality of their output through the estimation of hesitancy, a concept\nresembling to human hesitation in decision making. To address the challenge of\ninterpretable image classification, this paper introduces a novel framework,\nnamed Interpretable Intuitionistic FCM (I2FCM) which is domain-independent,\nsimple to implement, and can be applied on Convolutional Neural Network (CNN)\nmodels, rendering them interpretable. To the best of our knowledge this is the\nfirst time iFCMs are applied for image classification. Further novel\ncontributions include: a feature extraction process focusing on the most\ninformative image regions; a learning algorithm for data-driven determination\nof the intuitionistic fuzzy interconnections of the iFCM; an inherently\ninterpretable classification approach based on image contents. In the context\nof image classification, hesitancy is considered as a degree of inconfidence\nwith which an image is categorized to a class. The constructed iFCM model\ndistinguishes the most representative image semantics and analyses them\nutilizing cause-and-effect relations. The effectiveness of the introduced\nframework is evaluated on publicly available datasets, and the experimental\nresults confirm that it can provide enhanced classification performance, while\nproviding interpretable inferences.\n","authors":["Georgia Sovatzidi","Michael D. Vasilakakis","Dimitris K. Iakovidis"],"pdf_url":"https://arxiv.org/pdf/2408.03745v1.pdf","comment":"This work has been submitted for possible journal publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.03735v1","updated":"2024-08-07T12:42:09Z","published":"2024-08-07T12:42:09Z","title":"Advancing Multimodal Large Language Models with Quantization-Aware Scale\n  Learning for Efficient Adaptation","summary":"  This paper presents the first study to explore the potential of parameter\nquantization for multimodal large language models to alleviate the significant\nresource constraint encountered during vision-language instruction tuning. We\nintroduce a Quantization-aware Scale LeArning method based on multimodal\nWarmup, termed QSLAW. This method is grounded in two key innovations: (1) The\nlearning of group-wise scale factors for quantized LLM weights to mitigate the\nquantization error arising from activation outliers and achieve more effective\nvision-language instruction tuning; (2) The implementation of a multimodal\nwarmup that progressively integrates linguistic and multimodal training\nsamples, thereby preventing overfitting of the quantized model to multimodal\ndata while ensuring stable adaptation of multimodal large language models to\ndownstream vision-language tasks. Extensive experiments demonstrate that models\nquantized by QSLAW perform on par with, or even surpass, their full-precision\ncounterparts, while facilitating up to 1.4 times reduction in VL tuning time\nand GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.\n","authors":["Jingjing Xie","Yuxin Zhang","Mingbao Lin","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2408.03735v1.pdf","comment":"Accepted by ACMMM2024"},{"id":"http://arxiv.org/abs/2408.03734v1","updated":"2024-08-07T12:42:06Z","published":"2024-08-07T12:42:06Z","title":"Soft-Hard Attention U-Net Model and Benchmark Dataset for Multiscale\n  Image Shadow Removal","summary":"  Effective shadow removal is pivotal in enhancing the visual quality of images\nin various applications, ranging from computer vision to digital photography.\nDuring the last decades physics and machine learning -based methodologies have\nbeen proposed; however, most of them have limited capacity in capturing complex\nshadow patterns due to restrictive model assumptions, neglecting the fact that\nshadows usually appear at different scales. Also, current datasets used for\nbenchmarking shadow removal are composed of a limited number of images with\nsimple scenes containing mainly uniform shadows cast by single objects, whereas\nonly a few of them include both manual shadow annotations and paired\nshadow-free images. Aiming to address all these limitations in the context of\nnatural scene imaging, including urban environments with complex scenes, the\ncontribution of this study is twofold: a) it proposes a novel deep learning\narchitecture, named Soft-Hard Attention U-net (SHAU), focusing on multiscale\nshadow removal; b) it provides a novel synthetic dataset, named Multiscale\nShadow Removal Dataset (MSRD), containing complex shadow patterns of multiple\nscales, aiming to serve as a privacy-preserving dataset for a more\ncomprehensive benchmarking of future shadow removal methodologies. Key\narchitectural components of SHAU are the soft and hard attention modules, which\nalong with multiscale feature extraction blocks enable effective shadow removal\nof different scales and intensities. The results demonstrate the effectiveness\nof SHAU over the relevant state-of-the-art shadow removal methods across\nvarious benchmark datasets, improving the Peak Signal-to-Noise Ratio and Root\nMean Square Error for the shadow area by 25.1% and 61.3%, respectively.\n","authors":["Eirini Cholopoulou","Dimitrios E. Diamantis","Dimitra-Christina C. Koutsiou","Dimitris K. Iakovidis"],"pdf_url":"https://arxiv.org/pdf/2408.03734v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.03717v1","updated":"2024-08-07T12:10:32Z","published":"2024-08-07T12:10:32Z","title":"Pick of the Bunch: Detecting Infrared Small Targets Beyond Hit-Miss\n  Trade-Offs via Selective Rank-Aware Attention","summary":"  Infrared small target detection faces the inherent challenge of precisely\nlocalizing dim targets amidst complex background clutter. Traditional\napproaches struggle to balance detection precision and false alarm rates. To\nbreak this dilemma, we propose SeRankDet, a deep network that achieves high\naccuracy beyond the conventional hit-miss trade-off, by following the ``Pick of\nthe Bunch'' principle. At its core lies our Selective Rank-Aware Attention\n(SeRank) module, employing a non-linear Top-K selection process that preserves\nthe most salient responses, preventing target signal dilution while maintaining\nconstant complexity. Furthermore, we replace the static concatenation typical\nin U-Net structures with our Large Selective Feature Fusion (LSFF) module, a\ndynamic fusion strategy that empowers SeRankDet with adaptive feature\nintegration, enhancing its ability to discriminate true targets from false\nalarms. The network's discernment is further refined by our Dilated Difference\nConvolution (DDC) module, which merges differential convolution aimed at\namplifying subtle target characteristics with dilated convolution to expand the\nreceptive field, thereby substantially improving target-background separation.\nDespite its lightweight architecture, the proposed SeRankDet sets new\nbenchmarks in state-of-the-art performance across multiple public datasets. The\ncode is available at https://github.com/GrokCV/SeRankDet.\n","authors":["Yimian Dai","Peiwen Pan","Yulei Qian","Yuxuan Li","Xiang Li","Jian Yang","Huan Wan"],"pdf_url":"https://arxiv.org/pdf/2408.03717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01669v2","updated":"2024-08-07T12:06:18Z","published":"2024-08-03T05:35:13Z","title":"SynopGround: A Large-Scale Dataset for Multi-Paragraph Video Grounding\n  from TV Dramas and Synopses","summary":"  Video grounding is a fundamental problem in multimodal content understanding,\naiming to localize specific natural language queries in an untrimmed video.\nHowever, current video grounding datasets merely focus on simple events and are\neither limited to shorter videos or brief sentences, which hinders the model\nfrom evolving toward stronger multimodal understanding capabilities. To address\nthese limitations, we present a large-scale video grounding dataset named\nSynopGround, in which more than 2800 hours of videos are sourced from popular\nTV dramas and are paired with accurately localized human-written synopses. Each\nparagraph in the synopsis serves as a language query and is manually annotated\nwith precise temporal boundaries in the long video. These paragraph queries are\ntightly correlated to each other and contain a wealth of abstract expressions\nsummarizing video storylines and specific descriptions portraying event\ndetails, which enables the model to learn multimodal perception on more\nintricate concepts over longer context dependencies. Based on the dataset, we\nfurther introduce a more complex setting of video grounding dubbed\nMulti-Paragraph Video Grounding (MPVG), which takes as input multiple\nparagraphs and a long video for grounding each paragraph query to its temporal\ninterval. In addition, we propose a novel Local-Global Multimodal Reasoner\n(LGMR) to explicitly model the local-global structures of long-term multimodal\ninputs for MPVG. Our method provides an effective baseline solution to the\nmulti-paragraph video grounding problem. Extensive experiments verify the\nproposed model's effectiveness as well as its superiority in long-term\nmulti-paragraph video grounding over prior state-of-the-arts. Dataset and code\nare publicly available. Project page: https://synopground.github.io/.\n","authors":["Chaolei Tan","Zihang Lin","Junfu Pu","Zhongang Qi","Wei-Yi Pei","Zhi Qu","Yexin Wang","Ying Shan","Wei-Shi Zheng","Jian-Fang Hu"],"pdf_url":"https://arxiv.org/pdf/2408.01669v2.pdf","comment":"Accepted to ACM MM 2024. Project page: https://synopground.github.io/"},{"id":"http://arxiv.org/abs/2408.01334v2","updated":"2024-08-07T12:01:58Z","published":"2024-08-02T15:32:42Z","title":"A Backbone for Long-Horizon Robot Task Understanding","summary":"  End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot\ntask understanding and transferability. This framework uses therbligs (basic\naction elements) as the backbone to decompose high-level robot tasks into\nelemental robot configurations, which are then integrated with current\nfoundation models to improve task understanding. The approach consists of two\nstages: offline training and online testing. During the offline training stage,\nwe developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, the Large Language Model\n(LLM)-Alignment Policy for Visual Correction (LAP-VC) is employed to ensure\nprecise action execution, facilitating trajectory transfer in novel robot\nscenarios. Experimental results validate these methods, achieving 94.37% recall\nin therblig segmentation and success rates of 94.4% and 80% in real-world\nonline robot testing for simple and complex scenarios, respectively.\nSupplementary material is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home\n","authors":["Xiaoshuai Chen","Wei Chen","Dongmyoung Lee","Yukun Ge","Nicolas Rojas","Petar Kormushev"],"pdf_url":"https://arxiv.org/pdf/2408.01334v2.pdf","comment":"8 pages, 8 figures. This work is intended to be submitted to IEEE\n  Robotics and Automation Letters (RA-L) for possible publication"},{"id":"http://arxiv.org/abs/2305.12661v4","updated":"2024-08-07T11:37:02Z","published":"2023-05-22T03:04:22Z","title":"Semantic-guided modeling of spatial relation and object co-occurrence\n  for indoor scene recognition","summary":"  Exploring the semantic context in scene images is essential for indoor scene\nrecognition. However, due to the diverse intra-class spatial layouts and the\ncoexisting inter-class objects, modeling contextual relationships to adapt\nvarious image characteristics is a great challenge. Existing contextual\nmodeling methods for scene recognition exhibit two limitations: 1) They\ntypically model only one type of spatial relationship (order or metric) among\nobjects within scenes, with limited exploration of diverse spatial layouts. 2)\nThey often overlook the differences in coexisting objects across different\nscenes, suppressing scene recognition performance. To overcome these\nlimitations, we propose SpaCoNet, which simultaneously models Spatial relation\nand Co-occurrence of objects guided by semantic segmentation. Firstly, the\nSemantic Spatial Relation Module (SSRM) is constructed to model scene spatial\nfeatures. With the help of semantic segmentation, this module decouples spatial\ninformation from the scene image and thoroughly explores all spatial\nrelationships among objects in an end-to-end manner, thereby obtaining\nsemantic-based spatial features. Secondly, both spatial features from the SSRM\nand deep features from the Image Feature Extraction Module are allocated to\neach object, so as to distinguish the coexisting object across different\nscenes. Finally, utilizing the discriminative features above, we design a\nGlobal-Local Dependency Module to explore the long-range co-occurrence among\nobjects, and further generate a semantic-guided feature representation for\nindoor scene recognition. Experimental results on three widely used scene\ndatasets demonstrate the effectiveness and generality of the proposed method.\n","authors":["Chuanxin Song","Hanbo Wu","Xin Ma"],"pdf_url":"https://arxiv.org/pdf/2305.12661v4.pdf","comment":"Under second review at Expert Systems with Applications"},{"id":"http://arxiv.org/abs/2408.03703v1","updated":"2024-08-07T11:33:46Z","published":"2024-08-07T11:33:46Z","title":"CAS-ViT: Convolutional Additive Self-attention Vision Transformers for\n  Efficient Mobile Applications","summary":"  Vision Transformers (ViTs) mark a revolutionary advance in neural networks\nwith their token mixer's powerful global context capability. However, the\npairwise token affinity and complex matrix operations limit its deployment on\nresource-constrained scenarios and real-time applications, such as mobile\ndevices, although considerable efforts have been made in previous works. In\nthis paper, we introduce CAS-ViT: Convolutional Additive Self-attention Vision\nTransformers, to achieve a balance between efficiency and performance in mobile\napplications. Firstly, we argue that the capability of token mixers to obtain\nglobal contextual information hinges on multiple information interactions, such\nas spatial and channel domains. Subsequently, we construct a novel additive\nsimilarity function following this paradigm and present an efficient\nimplementation named Convolutional Additive Token Mixer (CATM). This\nsimplification leads to a significant reduction in computational overhead. We\nevaluate CAS-ViT across a variety of vision tasks, including image\nclassification, object detection, instance segmentation, and semantic\nsegmentation. Our experiments, conducted on GPUs, ONNX, and iPhones,\ndemonstrate that CAS-ViT achieves a competitive performance when compared to\nother state-of-the-art backbones, establishing it as a viable option for\nefficient mobile vision applications. Our code and model are available at:\n\\url{https://github.com/Tianfang-Zhang/CAS-ViT}\n","authors":["Tianfang Zhang","Lei Li","Yang Zhou","Wentao Liu","Chen Qian","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2408.03703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05278v2","updated":"2024-08-07T11:33:21Z","published":"2024-07-07T06:36:09Z","title":"HyperKAN: Kolmogorov-Arnold Networks make Hyperspectral Image\n  Classificators Smarter","summary":"  In traditional neural network architectures, a multilayer perceptron (MLP) is\ntypically employed as a classification block following the feature extraction\nstage. However, the Kolmogorov-Arnold Network (KAN) presents a promising\nalternative to MLP, offering the potential to enhance prediction accuracy. In\nthis paper, we propose the replacement of linear and convolutional layers of\ntraditional networks with KAN-based counterparts. These modifications allowed\nus to significantly increase the per-pixel classification accuracy for\nhyperspectral remote-sensing images. We modified seven different neural network\narchitectures for hyperspectral image classification and observed a substantial\nimprovement in the classification accuracy across all the networks. The\narchitectures considered in the paper include baseline MLP, state-of-the-art 1D\n(1DCNN) and 3D convolutional (two different 3DCNN, NM3DCNN), and transformer\n(SSFTT) architectures, as well as newly proposed M1DCNN. The greatest effect\nwas achieved for convolutional networks working exclusively on spectral data,\nand the best classification quality was achieved using a KAN-based transformer\narchitecture. All the experiments were conducted using seven openly available\nhyperspectral datasets. Our code is available at\nhttps://github.com/f-neumann77/HyperKAN.\n","authors":["Valeriy Lobanov","Nikita Firsov","Evgeny Myasnikov","Roman Khabibullin","Artem Nikonorov"],"pdf_url":"https://arxiv.org/pdf/2407.05278v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10271v2","updated":"2024-08-07T11:32:19Z","published":"2023-12-16T00:23:21Z","title":"Robustness of Deep Learning for Accelerated MRI: Benefits of Diverse\n  Training Data","summary":"  Deep learning based methods for image reconstruction are state-of-the-art for\na variety of imaging tasks. However, neural networks often perform worse if the\ntraining data differs significantly from the data they are applied to. For\nexample, a model trained for accelerated magnetic resonance imaging (MRI) on\none scanner performs worse on another scanner. In this work, we investigate the\nimpact of the training data on a model's performance and robustness for\naccelerated MRI. We find that models trained on the combination of various data\ndistributions, such as those obtained from different MRI scanners and\nanatomies, exhibit robustness equal or superior to models trained on the best\nsingle distribution for a specific target distribution. Thus training on such\ndiverse data tends to improve robustness. Furthermore, training on such a\ndiverse dataset does not compromise in-distribution performance, i.e., a model\ntrained on diverse data yields in-distribution performance at least as good as\nmodels trained on the more narrow individual distributions. Our results suggest\nthat training a model for imaging on a variety of distributions tends to yield\na more effective and robust model than maintaining separate models for\nindividual distributions.\n","authors":["Kang Lin","Reinhard Heckel"],"pdf_url":"https://arxiv.org/pdf/2312.10271v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2408.03695v1","updated":"2024-08-07T11:20:37Z","published":"2024-08-07T11:20:37Z","title":"Openstory++: A Large-scale Dataset and Benchmark for Instance-aware\n  Open-domain Visual Storytelling","summary":"  Recent image generation models excel at creating high-quality images from\nbrief captions. However, they fail to maintain consistency of multiple\ninstances across images when encountering lengthy contexts. This inconsistency\nis largely due to in existing training datasets the absence of granular\ninstance feature labeling in existing training datasets. To tackle these\nissues, we introduce Openstory++, a large-scale dataset combining additional\ninstance-level annotations with both images and text. Furthermore, we develop a\ntraining methodology that emphasizes entity-centric image-text generation,\nensuring that the models learn to effectively interweave visual and textual\ninformation. Specifically, Openstory++ streamlines the process of keyframe\nextraction from open-domain videos, employing vision-language models to\ngenerate captions that are then polished by a large language model for\nnarrative continuity. It surpasses previous datasets by offering a more\nexpansive open-domain resource, which incorporates automated captioning,\nhigh-resolution imagery tailored for instance count, and extensive frame\nsequences for temporal consistency. Additionally, we present Cohere-Bench, a\npioneering benchmark framework for evaluating the image generation tasks when\nlong multimodal context is provided, including the ability to keep the\nbackground, style, instances in the given context coherent. Compared to\nexisting benchmarks, our work fills critical gaps in multi-modal generation,\npropelling the development of models that can adeptly generate and interpret\ncomplex narratives in open-domain environments. Experiments conducted within\nCohere-Bench confirm the superiority of Openstory++ in nurturing high-quality\nvisual storytelling models, enhancing their ability to address open-domain\ngeneration tasks. More details can be found at https://openstorypp.github.io/\n","authors":["Zilyu Ye","Jinxiu Liu","Ruotian Peng","Jinjin Cao","Zhiyang Chen","Yiyang Zhang","Ziwei Xuan","Mingyuan Zhou","Xiaoqian Shen","Mohamed Elhoseiny","Qi Liu","Guo-Jun Qi"],"pdf_url":"https://arxiv.org/pdf/2408.03695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12670v3","updated":"2024-08-07T10:45:03Z","published":"2024-03-19T12:11:57Z","title":"Driving Animatronic Robot Facial Expression From Speech","summary":"  Animatronic robots hold the promise of enabling natural human-robot\ninteraction through lifelike facial expressions. However, generating realistic,\nspeech-synchronized robot expressions poses significant challenges due to the\ncomplexities of facial biomechanics and the need for responsive motion\nsynthesis. This paper introduces a novel, skinning-centric approach to drive\nanimatronic robot facial expressions from speech input. At its core, the\nproposed approach employs linear blend skinning (LBS) as a unifying\nrepresentation, guiding innovations in both embodiment design and motion\nsynthesis. LBS informs the actuation topology, facilitates human expression\nretargeting, and enables efficient speech-driven facial motion generation. This\napproach demonstrates the capability to produce highly realistic facial\nexpressions on an animatronic face in real-time at over 4000 fps on a single\nNvidia RTX 4090, significantly advancing robots' ability to replicate nuanced\nhuman expressions for natural interaction. To foster further research and\ndevelopment in this field, the code has been made publicly available at:\n\\url{https://github.com/library87/OpenRoboExp}.\n","authors":["Boren Li","Hang Li","Hangxin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.12670v3.pdf","comment":"8 pages, 6 figures, accepted to IROS 2024. For associated project\n  page, see https://library87.github.io/animatronic-face-iros24"},{"id":"http://arxiv.org/abs/2408.03677v1","updated":"2024-08-07T10:36:26Z","published":"2024-08-07T10:36:26Z","title":"L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection","summary":"  LiDAR-based vision systems are integral for 3D object detection, which is\ncrucial for autonomous navigation. However, they suffer from performance\ndegradation in adverse weather conditions due to the quality deterioration of\nLiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor is\nexpected to solve this problem. However, the fusion of LiDAR and 4D radar is\nchallenging because they differ significantly in terms of data quality and the\ndegree of degradation in adverse weather. To address these issues, we introduce\nL4DR, a weather-robust 3D object detection method that effectively achieves\nLiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) and\nForeground-Aware Denoising (FAD) technique to reconcile sensor gaps, which is\nthe first exploration of the complementarity of early fusion between LiDAR and\n4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 )\nparallel feature extraction backbone coupled with a Multi-Scale Gated Fusion\n(MSGF) module to counteract the varying degrees of sensor degradation under\nadverse weather conditions. Experimental evaluation on a VoD dataset with\nsimulated fog proves that L4DR is more adaptable to changing weather\nconditions. It delivers a significant performance increase under different fog\nlevels, improving the 3D mAP by up to 18.17% over the traditional LiDAR-only\napproach. Moreover, the results on the K-Radar dataset validate the consistent\nperformance improvement of L4DR in real-world adverse weather conditions.\n","authors":["Xun Huang","Ziyu Xu","Hai Wu","Jinlong Wang","Qiming Xia","Yan Xia","Jonathan Li","Kyle Gao","Chenglu Wen","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14068v2","updated":"2024-08-07T10:28:18Z","published":"2024-06-20T07:44:56Z","title":"Classifying Dry Eye Disease Patients from Healthy Controls Using Machine\n  Learning and Metabolomics Data","summary":"  Dry eye disease is a common disorder of the ocular surface, leading patients\nto seek eye care. Clinical signs and symptoms are currently used to diagnose\ndry eye disease. Metabolomics, a method for analyzing biological systems, has\nbeen found helpful in identifying distinct metabolites in patients and in\ndetecting metabolic profiles that may indicate dry eye disease at early stages.\nIn this study, we explored using machine learning and metabolomics information\nto identify which cataract patients suffered from dry eye disease. As there is\nno one-size-fits-all machine learning model for metabolomics data, choosing the\nmost suitable model can significantly affect the quality of predictions and\nsubsequent metabolomics analyses. To address this challenge, we conducted a\ncomparative analysis of nine machine learning models on three metabolomics data\nsets from cataract patients with and without dry eye disease. The models were\nevaluated and optimized using nested k-fold cross-validation. To assess the\nperformance of these models, we selected a set of suitable evaluation metrics\ntailored to the data set's challenges. The logistic regression model overall\nperformed the best, achieving the highest area under the curve score of 0.8378,\nbalanced accuracy of 0.735, Matthew's correlation coefficient of 0.5147, an\nF1-score of 0.8513, and a specificity of 0.5667. Additionally, following the\nlogistic regression, the XGBoost and Random Forest models also demonstrated\ngood performance.\n","authors":["Sajad Amouei Sheshkal","Morten Gundersen","Michael Alexander Riegler","Øygunn Aass Utheim","Kjell Gunnar Gundersen","Hugo Lewi Hammer"],"pdf_url":"https://arxiv.org/pdf/2406.14068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01126v2","updated":"2024-08-07T10:25:08Z","published":"2024-08-02T09:07:31Z","title":"IG-SLAM: Instant Gaussian SLAM","summary":"  3D Gaussian Splatting has recently shown promising results as an alternative\nscene representation in SLAM systems to neural implicit representations.\nHowever, current methods either lack dense depth maps to supervise the mapping\nprocess or detailed training designs that consider the scale of the\nenvironment. To address these drawbacks, we present IG-SLAM, a dense RGB-only\nSLAM system that employs robust Dense-SLAM methods for tracking and combines\nthem with Gaussian Splatting. A 3D map of the environment is constructed using\naccurate pose and dense depth provided by tracking. Additionally, we utilize\ndepth uncertainty in map optimization to improve 3D reconstruction. Our decay\nstrategy in map optimization enhances convergence and allows the system to run\nat 10 fps in a single process. We demonstrate competitive performance with\nstate-of-the-art RGB-only SLAM systems while achieving faster operation speeds.\nWe present our experiments on the Replica, TUM-RGBD, ScanNet, and EuRoC\ndatasets. The system achieves photo-realistic 3D reconstruction in large-scale\nsequences, particularly in the EuRoC dataset.\n","authors":["F. Aykut Sarikamis","A. Aydin Alatan"],"pdf_url":"https://arxiv.org/pdf/2408.01126v2.pdf","comment":"8 pages, 3 page ref, 5 figures"},{"id":"http://arxiv.org/abs/2408.03663v1","updated":"2024-08-07T10:04:04Z","published":"2024-08-07T10:04:04Z","title":"Designing Extremely Memory-Efficient CNNs for On-device Vision Tasks","summary":"  In this paper, we introduce a memory-efficient CNN (convolutional neural\nnetwork), which enables resource-constrained low-end embedded and IoT devices\nto perform on-device vision tasks, such as image classification and object\ndetection, using extremely low memory, i.e., only 63 KB on ImageNet\nclassification. Based on the bottleneck block of MobileNet, we propose three\ndesign principles that significantly curtail the peak memory usage of a CNN so\nthat it can fit the limited KB memory of the low-end device. First, 'input\nsegmentation' divides an input image into a set of patches, including the\ncentral patch overlapped with the others, reducing the size (and memory\nrequirement) of a large input image. Second, 'patch tunneling' builds\nindependent tunnel-like paths consisting of multiple bottleneck blocks per\npatch, penetrating through the entire model from an input patch to the last\nlayer of the network, maintaining lightweight memory usage throughout the whole\nnetwork. Lastly, 'bottleneck reordering' rearranges the execution order of\nconvolution operations inside the bottleneck block such that the memory usage\nremains constant regardless of the size of the convolution output channels. The\nexperiment result shows that the proposed network classifies ImageNet with\nextremely low memory (i.e., 63 KB) while achieving competitive top-1 accuracy\n(i.e., 61.58\\%). To the best of our knowledge, the memory usage of the proposed\nnetwork is far smaller than state-of-the-art memory-efficient networks, i.e.,\nup to 89x and 3.1x smaller than MobileNet (i.e., 5.6 MB) and MCUNet (i.e., 196\nKB), respectively.\n","authors":["Jaewook Lee","Yoel Park","Seulki Lee"],"pdf_url":"https://arxiv.org/pdf/2408.03663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03657v1","updated":"2024-08-07T09:52:30Z","published":"2024-08-07T09:52:30Z","title":"PHOCUS: Physics-Based Deconvolution for Ultrasound Resolution\n  Enhancement","summary":"  Ultrasound is widely used in medical diagnostics allowing for accessible and\npowerful imaging but suffers from resolution limitations due to diffraction and\nthe finite aperture of the imaging system, which restricts diagnostic use. The\nimpulse function of an ultrasound imaging system is called the point spread\nfunction (PSF), which is convolved with the spatial distribution of reflectors\nin the image formation process. Recovering high-resolution reflector\ndistributions by removing image distortions induced by the convolution process\nimproves image clarity and detail. Conventionally, deconvolution techniques\nattempt to rectify the imaging system's dependent PSF, working directly on the\nradio-frequency (RF) data. However, RF data is often not readily accessible.\nTherefore, we introduce a physics-based deconvolution process using a modeled\nPSF, working directly on the more commonly available B-mode images. By\nleveraging Implicit Neural Representations (INRs), we learn a continuous\nmapping from spatial locations to their respective echogenicity values,\neffectively compensating for the discretized image space. Our contribution\nconsists of a novel methodology for retrieving a continuous echogenicity map\ndirectly from a B-mode image through a differentiable physics-based rendering\npipeline for ultrasound resolution enhancement. We qualitatively and\nquantitatively evaluate our approach on synthetic data, demonstrating\nimprovements over traditional methods in metrics such as PSNR and SSIM.\nFurthermore, we show qualitative enhancements on an ultrasound phantom and an\nin-vivo acquisition of a carotid artery.\n","authors":["Felix Duelmer","Walter Simson","Mohammad Farid Azampour","Magdalena Wysocki","Angelos Karlas","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2408.03657v1.pdf","comment":"Accepted at the Workshop of Advances in Simplifying Medical\n  Ultrasound at MICCAI 2024"},{"id":"http://arxiv.org/abs/2408.03654v1","updated":"2024-08-07T09:40:26Z","published":"2024-08-07T09:40:26Z","title":"Unsupervised Detection of Fetal Brain Anomalies using Denoising\n  Diffusion Models","summary":"  Congenital malformations of the brain are among the most common fetal\nabnormalities that impact fetal development. Previous anomaly detection methods\non ultrasound images are based on supervised learning, rely on manual\nannotations, and risk missing underrepresented categories. In this work, we\nframe fetal brain anomaly detection as an unsupervised task using diffusion\nmodels. To this end, we employ an inpainting-based Noise Agnostic Anomaly\nDetection approach that identifies the abnormality using\ndiffusion-reconstructed fetal brain images from multiple noise levels. Our\napproach only requires normal fetal brain ultrasound images for training,\naddressing the limited availability of abnormal data. Our experiments on a\nreal-world clinical dataset show the potential of using unsupervised methods\nfor fetal brain anomaly detection. Additionally, we comprehensively evaluate\nhow different noise types affect diffusion models in the fetal anomaly\ndetection domain.\n","authors":["Markus Ditlev Sjøgren Olsen","Jakob Ambsdorf","Manxi Lin","Caroline Taksøe-Vester","Morten Bo Søndergaard Svendsen","Anders Nymark Christensen","Mads Nielsen","Martin Grønnebæk Tolsgaard","Aasa Feragen","Paraskevas Pegios"],"pdf_url":"https://arxiv.org/pdf/2408.03654v1.pdf","comment":"Accepted at ASMUS@MICCAI 2024"},{"id":"http://arxiv.org/abs/2405.00354v2","updated":"2024-08-07T09:36:55Z","published":"2024-05-01T07:16:03Z","title":"CrossMatch: Enhance Semi-Supervised Medical Image Segmentation with\n  Perturbation Strategies and Knowledge Distillation","summary":"  Semi-supervised learning for medical image segmentation presents a unique\nchallenge of efficiently using limited labeled data while leveraging abundant\nunlabeled data. Despite advancements, existing methods often do not fully\nexploit the potential of the unlabeled data for enhancing model robustness and\naccuracy. In this paper, we introduce CrossMatch, a novel framework that\nintegrates knowledge distillation with dual perturbation strategies-image-level\nand feature-level-to improve the model's learning from both labeled and\nunlabeled data. CrossMatch employs multiple encoders and decoders to generate\ndiverse data streams, which undergo self-knowledge distillation to enhance\nconsistency and reliability of predictions across varied perturbations. Our\nmethod significantly surpasses other state-of-the-art techniques in standard\nbenchmarks by effectively minimizing the gap between training on labeled and\nunlabeled data and improving edge accuracy and generalization in medical image\nsegmentation. The efficacy of CrossMatch is demonstrated through extensive\nexperimental validations, showing remarkable performance improvements without\nincreasing computational costs. Code for this implementation is made available\nat https://github.com/AiEson/CrossMatch.git.\n","authors":["Bin Zhao","Chunshi Wang","Shuxue Ding"],"pdf_url":"https://arxiv.org/pdf/2405.00354v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15838v2","updated":"2024-08-07T09:34:25Z","published":"2024-07-22T17:55:22Z","title":"MMInstruct: A High-Quality Multi-Modal Instruction Tuning Dataset with\n  Extensive Diversity","summary":"  Despite the effectiveness of vision-language supervised fine-tuning in\nenhancing the performance of Vision Large Language Models (VLLMs). However,\nexisting visual instruction tuning datasets include the following limitations:\n(1) Instruction annotation quality: despite existing VLLMs exhibiting strong\nperformance, instructions generated by those advanced VLLMs may still suffer\nfrom inaccuracies, such as hallucinations. (2) Instructions and image\ndiversity: the limited range of instruction types and the lack of diversity in\nimage data may impact the model's ability to generate diversified and closer to\nreal-world scenarios outputs. To address these challenges, we construct a\nhigh-quality, diverse visual instruction tuning dataset MMInstruct, which\nconsists of 973K instructions from 24 domains. There are four instruction\ntypes: Judgement, Multiple-Choice, Long Visual Question Answering and Short\nVisual Question Answering. To construct MMInstruct, we propose an instruction\ngeneration data engine that leverages GPT-4V, GPT-3.5, and manual correction.\nOur instruction generation engine enables semi-automatic, low-cost, and\nmulti-domain instruction generation at 1/6 the cost of manual construction.\nThrough extensive experiment validation and ablation experiments, we\ndemonstrate that MMInstruct could significantly improve the performance of\nVLLMs, e.g., the model fine-tuning on MMInstruct achieves new state-of-the-art\nperformance on 10 out of 12 benchmarks. The code and data shall be available at\nhttps://github.com/yuecao0119/MMInstruct.\n","authors":["Yangzhou Liu","Yue Cao","Zhangwei Gao","Weiyun Wang","Zhe Chen","Wenhai Wang","Hao Tian","Lewei Lu","Xizhou Zhu","Tong Lu","Yu Qiao","Jifeng Dai"],"pdf_url":"https://arxiv.org/pdf/2407.15838v2.pdf","comment":"18 pages, 8 figures, technical report"},{"id":"http://arxiv.org/abs/2408.03651v1","updated":"2024-08-07T09:30:51Z","published":"2024-08-07T09:30:51Z","title":"SAM2-PATH: A better segment anything model for semantic segmentation in\n  digital pathology","summary":"  The semantic segmentation task in pathology plays an indispensable role in\nassisting physicians in determining the condition of tissue lesions. Foundation\nmodels, such as the SAM (Segment Anything Model) and SAM2, exhibit exceptional\nperformance in instance segmentation within everyday natural scenes. SAM-PATH\nhas also achieved impressive results in semantic segmentation within the field\nof pathology. However, in computational pathology, the models mentioned above\nstill have the following limitations. The pre-trained encoder models suffer\nfrom a scarcity of pathology image data; SAM and SAM2 are not suitable for\nsemantic segmentation. In this paper, we have designed a trainable\nKolmogorov-Arnold Networks(KAN) classification module within the SAM2 workflow,\nand we have introduced the largest pretrained vision encoder for histopathology\n(UNI) to date. Our proposed framework, SAM2-PATH, augments SAM2's capability to\nperform semantic segmentation in digital pathology autonomously, eliminating\nthe need for human provided input prompts. The experimental results demonstrate\nthat, after fine-tuning the KAN classification module and decoder, Our dataset\nhas achieved competitive results on publicly available pathology data. The code\nhas been open-sourced and can be found at the following address:\nhttps://github.com/simzhangbest/SAM2PATH.\n","authors":["Mingya Zhang","Liang Wang","Limei Gu","Zhao Li","Yaohui Wang","Tingshen Ling","Xianping Tao"],"pdf_url":"https://arxiv.org/pdf/2408.03651v1.pdf","comment":"6 pages , 3 figures"},{"id":"http://arxiv.org/abs/2408.02164v2","updated":"2024-08-07T09:23:36Z","published":"2024-08-04T23:21:46Z","title":"Rethinking Affect Analysis: A Protocol for Ensuring Fairness and\n  Consistency","summary":"  Evaluating affect analysis methods presents challenges due to inconsistencies\nin database partitioning and evaluation protocols, leading to unfair and biased\nresults. Previous studies claim continuous performance improvements, but our\nfindings challenge such assertions. Using these insights, we propose a unified\nprotocol for database partitioning that ensures fairness and comparability. We\nprovide detailed demographic annotations (in terms of race, gender and age),\nevaluation metrics, and a common framework for expression recognition, action\nunit detection and valence-arousal estimation. We also rerun the methods with\nthe new protocol and introduce a new leaderboards to encourage future research\nin affect recognition with a fairer comparison. Our annotations, code, and\npre-trained models are available on\n\\hyperlink{https://github.com/dkollias/Fair-Consistent-Affect-Analysis}{Github}.\n","authors":["Guanyu Hu","Dimitrios Kollias","Eleni Papadopoulou","Paraskevi Tzouveli","Jie Wei","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.02164v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2405.06841"},{"id":"http://arxiv.org/abs/2405.10885v2","updated":"2024-08-07T09:11:38Z","published":"2024-05-17T16:22:52Z","title":"FA-Depth: Toward Fast and Accurate Self-supervised Monocular Depth\n  Estimation","summary":"  Most existing methods often rely on complex models to predict scene depth\nwith high accuracy, resulting in slow inference that is not conducive to\ndeployment. To better balance precision and speed, we first designed SmallDepth\nbased on sparsity. Second, to enhance the feature representation ability of\nSmallDepth during training under the condition of equal complexity during\ninference, we propose an equivalent transformation module(ETM). Third, to\nimprove the ability of each layer in the case of a fixed SmallDepth to perceive\ndifferent context information and improve the robustness of SmallDepth to the\nleft-right direction and illumination changes, we propose pyramid loss. Fourth,\nto further improve the accuracy of SmallDepth, we utilized the proposed\nfunction approximation loss (APX) to transfer knowledge in the pretrained\nHQDecv2, obtained by optimizing the previous HQDec to address grid artifacts in\nsome regions, to SmallDepth. Extensive experiments demonstrate that each\nproposed component improves the precision of SmallDepth without changing the\ncomplexity of SmallDepth during inference, and the developed approach achieves\nstate-of-the-art results on KITTI at an inference speed of more than 500 frames\nper second and with approximately 2 M parameters. The code and models will be\npublicly available at https://github.com/fwucas/FA-Depth.\n","authors":["Fei Wang","Jun Cheng"],"pdf_url":"https://arxiv.org/pdf/2405.10885v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14973v2","updated":"2024-08-07T08:53:25Z","published":"2024-03-22T06:04:11Z","title":"Pose-Aware Self-Supervised Learning with Viewpoint Trajectory\n  Regularization","summary":"  Learning visual features from unlabeled images has proven successful for\nsemantic categorization, often by mapping different $views$ of the same object\nto the same feature to achieve recognition invariance. However, visual\nrecognition involves not only identifying $what$ an object is but also\nunderstanding $how$ it is presented. For example, seeing a car from the side\nversus head-on is crucial for deciding whether to stay put or jump out of the\nway. While unsupervised feature learning for downstream viewpoint reasoning is\nimportant, it remains under-explored, partly due to the lack of a standardized\nevaluation method and benchmarks.\n  We introduce a new dataset of adjacent image triplets obtained from a\nviewpoint trajectory, without any semantic or pose labels. We benchmark both\nsemantic classification and pose estimation accuracies on the same visual\nfeature. Additionally, we propose a viewpoint trajectory regularization loss\nfor learning features from unlabeled image triplets. Our experiments\ndemonstrate that this approach helps develop a visual representation that\nencodes object identity and organizes objects by their poses, retaining\nsemantic classification accuracy while achieving emergent global pose awareness\nand better generalization to novel objects. Our dataset and code are available\nat http://pwang.pw/trajSSL/.\n","authors":["Jiayun Wang","Yubei Chen","Stella X. Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14973v2.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03637v1","updated":"2024-08-07T08:52:21Z","published":"2024-08-07T08:52:21Z","title":"TALE: Training-free Cross-domain Image Composition via Adaptive Latent\n  Manipulation and Energy-guided Optimization","summary":"  We present TALE, a novel training-free framework harnessing the generative\ncapabilities of text-to-image diffusion models to address the cross-domain\nimage composition task that focuses on flawlessly incorporating user-specified\nobjects into a designated visual contexts regardless of domain disparity.\nPrevious methods often involve either training auxiliary networks or finetuning\ndiffusion models on customized datasets, which are expensive and may undermine\nthe robust textual and visual priors of pre-trained diffusion models. Some\nrecent works attempt to break the barrier by proposing training-free\nworkarounds that rely on manipulating attention maps to tame the denoising\nprocess implicitly. However, composing via attention maps does not necessarily\nyield desired compositional outcomes. These approaches could only retain some\nsemantic information and usually fall short in preserving identity\ncharacteristics of input objects or exhibit limited background-object style\nadaptation in generated images. In contrast, TALE is a novel method that\noperates directly on latent space to provide explicit and effective guidance\nfor the composition process to resolve these problems. Specifically, we equip\nTALE with two mechanisms dubbed Adaptive Latent Manipulation and Energy-guided\nLatent Optimization. The former formulates noisy latents conducive to\ninitiating and steering the composition process by directly leveraging\nbackground and foreground latents at corresponding timesteps, and the latter\nexploits designated energy functions to further optimize intermediate latents\nconforming to specific conditions that complement the former to generate\ndesired final results. Our experiments demonstrate that TALE surpasses prior\nbaselines and attains state-of-the-art performance in image-guided composition\nacross various photorealistic and artistic domains.\n","authors":["Kien T. Pham","Jingye Chen","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2408.03637v1.pdf","comment":"The 32nd ACM Multimedia Conference (MM '24)"},{"id":"http://arxiv.org/abs/2408.03632v1","updated":"2024-08-07T08:43:58Z","published":"2024-08-07T08:43:58Z","title":"Concept Conductor: Orchestrating Multiple Personalized Concepts in\n  Text-to-Image Synthesis","summary":"  The customization of text-to-image models has seen significant advancements,\nyet generating multiple personalized concepts remains a challenging task.\nCurrent methods struggle with attribute leakage and layout confusion when\nhandling multiple concepts, leading to reduced concept fidelity and semantic\nconsistency. In this work, we introduce a novel training-free framework,\nConcept Conductor, designed to ensure visual fidelity and correct layout in\nmulti-concept customization. Concept Conductor isolates the sampling processes\nof multiple custom models to prevent attribute leakage between different\nconcepts and corrects erroneous layouts through self-attention-based spatial\nguidance. Additionally, we present a concept injection technique that employs\nshape-aware masks to specify the generation area for each concept. This\ntechnique injects the structure and appearance of personalized concepts through\nfeature fusion in the attention layers, ensuring harmony in the final image.\nExtensive qualitative and quantitative experiments demonstrate that Concept\nConductor can consistently generate composite images with accurate layouts\nwhile preserving the visual details of each concept. Compared to existing\nbaselines, Concept Conductor shows significant performance improvements. Our\nmethod supports the combination of any number of concepts and maintains high\nfidelity even when dealing with visually similar concepts. The code and models\nare available at https://github.com/Nihukat/Concept-Conductor.\n","authors":["Zebin Yao","Fangxiang Feng","Ruifan Li","Xiaojie Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03632v1.pdf","comment":"Github Page: https://github.com/Nihukat/Concept-Conductor"},{"id":"http://arxiv.org/abs/2408.03627v1","updated":"2024-08-07T08:39:33Z","published":"2024-08-07T08:39:33Z","title":"Weakly Contrastive Learning via Batch Instance Discrimination and\n  Feature Clustering for Small Sample SAR ATR","summary":"  In recent years, impressive performance of deep learning technology has been\nrecognized in Synthetic Aperture Radar (SAR) Automatic Target Recognition\n(ATR). Since a large amount of annotated data is required in this technique, it\nposes a trenchant challenge to the issue of obtaining a high recognition rate\nthrough less labeled data. To overcome this problem, inspired by the\ncontrastive learning, we proposed a novel framework named Batch Instance\nDiscrimination and Feature Clustering (BIDFC). In this framework, different\nfrom that of the objective of general contrastive learning methods, embedding\ndistance between samples should be moderate because of the high similarity\nbetween samples in the SAR images. Consequently, our flexible framework is\nequipped with adjustable distance between embedding, which we term as weakly\ncontrastive learning. Technically, instance labels are assigned to the\nunlabeled data in per batch and random augmentation and training are performed\nfew times on these augmented data. Meanwhile, a novel Dynamic-Weighted Variance\nloss (DWV loss) function is also posed to cluster the embedding of enhanced\nversions for each sample. Experimental results on the moving and stationary\ntarget acquisition and recognition (MSTAR) database indicate a 91.25%\nclassification accuracy of our method fine-tuned on only 3.13% training data.\nEven though a linear evaluation is performed on the same training data, the\naccuracy can still reach 90.13%. We also verified the effectiveness of BIDFC in\nOpenSarShip database, indicating that our method can be generalized to other\ndatasets. Our code is avaliable at:\nhttps://github.com/Wenlve-Zhou/BIDFC-master.\n","authors":["Yikui Zhai","Wenlve Zhou","Bing Sun","Jingwen Li","Qirui Ke","Zilu Ying","Junying Gan","Chaoyun Mai","Ruggero Donida Labati","Vincenzo Piuri","Fabio Scotti"],"pdf_url":"https://arxiv.org/pdf/2408.03627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03624v1","updated":"2024-08-07T08:34:48Z","published":"2024-08-07T08:34:48Z","title":"AgentsCoMerge: Large Language Model Empowered Collaborative Decision\n  Making for Ramp Merging","summary":"  Ramp merging is one of the bottlenecks in traffic systems, which commonly\ncause traffic congestion, accidents, and severe carbon emissions. In order to\naddress this essential issue and enhance the safety and efficiency of connected\nand autonomous vehicles (CAVs) at multi-lane merging zones, we propose a novel\ncollaborative decision-making framework, named AgentsCoMerge, to leverage large\nlanguage models (LLMs). Specifically, we first design a scene observation and\nunderstanding module to allow an agent to capture the traffic environment. Then\nwe propose a hierarchical planning module to enable the agent to make decisions\nand plan trajectories based on the observation and the agent's own state. In\naddition, in order to facilitate collaboration among multiple agents, we\nintroduce a communication module to enable the surrounding agents to exchange\nnecessary information and coordinate their actions. Finally, we develop a\nreinforcement reflection guided training paradigm to further enhance the\ndecision-making capability of the framework. Extensive experiments are\nconducted to evaluate the performance of our proposed method, demonstrating its\nsuperior efficiency and effectiveness for multi-agent collaborative\ndecision-making under various ramp merging scenarios.\n","authors":["Senkang Hu","Zhengru Fang","Zihan Fang","Yiqin Deng","Xianhao Chen","Yuguang Fang","Sam Kwong"],"pdf_url":"https://arxiv.org/pdf/2408.03624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09914v4","updated":"2024-08-07T08:20:43Z","published":"2023-04-19T18:32:49Z","title":"The Face of Populism: Examining Differences in Facial Emotional\n  Expressions of Political Leaders Using Machine Learning","summary":"  Populist rhetoric employed on online media is characterized as deeply\nimpassioned and often imbued with strong emotions. The aim of this paper is to\nempirically investigate the differences in affective nonverbal communication of\npolitical leaders. We use a deep-learning approach to process a sample of 220\nYouTube videos of political leaders from 15 different countries, analyze their\nfacial expressions of emotion and then examine differences in average emotion\nscores representing the relative presence of 6 emotional states (anger,\ndisgust, fear, happiness, sadness, and surprise) and a neutral expression for\neach frame of the YouTube video. Based on a sample of manually coded images, we\nfind that this deep-learning approach has 53-60\\% agreement with human labels.\nWe observe statistically significant differences in the average score of\nnegative emotions between groups of leaders with varying degrees of populist\nrhetoric.\n","authors":["Sara Major","Aleksandar Tomašević"],"pdf_url":"https://arxiv.org/pdf/2304.09914v4.pdf","comment":"Version 4.0: Annotation study added, supplementary information\n  extended"},{"id":"http://arxiv.org/abs/2408.03616v1","updated":"2024-08-07T08:17:34Z","published":"2024-08-07T08:17:34Z","title":"Distillation Learning Guided by Image Reconstruction for One-Shot\n  Medical Image Segmentation","summary":"  Traditional one-shot medical image segmentation (MIS) methods use\nregistration networks to propagate labels from a reference atlas or rely on\ncomprehensive sampling strategies to generate synthetic labeled data for\ntraining. However, these methods often struggle with registration errors and\nlow-quality synthetic images, leading to poor performance and generalization.\nTo overcome this, we introduce a novel one-shot MIS framework based on\nknowledge distillation, which allows the network to directly 'see' real images\nthrough a distillation process guided by image reconstruction. It focuses on\nanatomical structures in a single labeled image and a few unlabeled ones. A\nregistration-based data augmentation network creates realistic, labeled\nsamples, while a feature distillation module helps the student network learn\nsegmentation from these samples, guided by the teacher network. During\ninference, the streamlined student network accurately segments new images.\nEvaluations on three public datasets (OASIS for T1 brain MRI, BCV for abdomen\nCT, and VerSe for vertebrae CT) show superior segmentation performance and\ngeneralization across different medical image datasets and modalities compared\nto leading methods. Our code is available at\nhttps://github.com/NoviceFodder/OS-MedSeg.\n","authors":["Feng Zhou","Yanjie Zhou","Longjie Wang","Yun Peng","David E. Carlson","Liyun Tu"],"pdf_url":"https://arxiv.org/pdf/2408.03616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03612v1","updated":"2024-08-07T08:08:08Z","published":"2024-08-07T08:08:08Z","title":"JARViS: Detecting Actions in Video Using Unified Actor-Scene Context\n  Relation Modeling","summary":"  Video action detection (VAD) is a formidable vision task that involves the\nlocalization and classification of actions within the spatial and temporal\ndimensions of a video clip. Among the myriad VAD architectures, two-stage VAD\nmethods utilize a pre-trained person detector to extract the region of interest\nfeatures, subsequently employing these features for action detection. However,\nthe performance of two-stage VAD methods has been limited as they depend solely\non localized actor features to infer action semantics. In this study, we\npropose a new two-stage VAD framework called Joint Actor-scene context Relation\nmodeling based on Visual Semantics (JARViS), which effectively consolidates\ncross-modal action semantics distributed globally across spatial and temporal\ndimensions using Transformer attention. JARViS employs a person detector to\nproduce densely sampled actor features from a keyframe. Concurrently, it uses a\nvideo backbone to create spatio-temporal scene features from a video clip.\nFinally, the fine-grained interactions between actors and scenes are modeled\nthrough a Unified Action-Scene Context Transformer to directly output the final\nset of actions in parallel. Our experimental results demonstrate that JARViS\noutperforms existing methods by significant margins and achieves\nstate-of-the-art performance on three popular VAD datasets, including AVA,\nUCF101-24, and JHMDB51-21.\n","authors":["Seok Hwan Lee","Taein Son","Soo Won Seo","Jisong Kim","Jun Won Choi"],"pdf_url":"https://arxiv.org/pdf/2408.03612v1.pdf","comment":"31 pages, 10 figures"},{"id":"http://arxiv.org/abs/2408.03608v1","updated":"2024-08-07T07:54:19Z","published":"2024-08-07T07:54:19Z","title":"InPer: Whole-Process Domain Generalization via Causal Intervention and\n  Perturbation","summary":"  Despite the considerable advancements achieved by deep neural networks, their\nperformance tends to degenerate when the test environment diverges from the\ntraining ones. Domain generalization (DG) solves this issue by learning\nrepresentations independent of domain-related information, thus facilitating\nextrapolation to unseen environments. Existing approaches typically focus on\nformulating tailored training objectives to extract shared features from the\nsource data. However, the disjointed training and testing procedures may\ncompromise robustness, particularly in the face of unforeseen variations during\ndeployment. In this paper, we propose a novel and holistic framework based on\ncausality, named InPer, designed to enhance model generalization by\nincorporating causal intervention during training and causal perturbation\nduring testing. Specifically, during the training phase, we employ\nentropy-based causal intervention (EnIn) to refine the selection of causal\nvariables. To identify samples with anti-interference causal variables from the\ntarget domain, we propose a novel metric, homeostatic score, through causal\nperturbation (HoPer) to construct a prototype classifier in test time.\nExperimental results across multiple cross-domain tasks confirm the efficacy of\nInPer.\n","authors":["Luyao Tang","Yuxuan Yuan","Chaoqi Chen","Xinghao Ding","Yue Huang"],"pdf_url":"https://arxiv.org/pdf/2408.03608v1.pdf","comment":"Accepted by BMVC2024"},{"id":"http://arxiv.org/abs/2408.03598v1","updated":"2024-08-07T07:35:17Z","published":"2024-08-07T07:35:17Z","title":"PRISM: PRogressive dependency maxImization for Scale-invariant image\n  Matching","summary":"  Image matching aims at identifying corresponding points between a pair of\nimages. Currently, detector-free methods have shown impressive performance in\nchallenging scenarios, thanks to their capability of generating dense matches\nand global receptive field. However, performing feature interaction and\nproposing matches across the entire image is unnecessary, because not all image\nregions contribute to the matching process. Interacting and matching in\nunmatchable areas can introduce errors, reducing matching accuracy and\nefficiency. Meanwhile, the scale discrepancy issue still troubles existing\nmethods. To address above issues, we propose PRogressive dependency\nmaxImization for Scale-invariant image Matching (PRISM), which jointly prunes\nirrelevant patch features and tackles the scale discrepancy. To do this, we\nfirstly present a Multi-scale Pruning Module (MPM) to adaptively prune\nirrelevant features by maximizing the dependency between the two feature sets.\nMoreover, we design the Scale-Aware Dynamic Pruning Attention (SADPA) to\naggregate information from different scales via a hierarchical design. Our\nmethod's superior matching performance and generalization capability are\nconfirmed by leading accuracy across various evaluation benchmarks and\ndownstream tasks. The code is publicly available at\nhttps://github.com/Master-cai/PRISM.\n","authors":["Xudong Cai","Yongcai Wang","Lun Luo","Minhang Wang","Deying Li","Jintao Xu","Weihao Gu","Rui Ai"],"pdf_url":"https://arxiv.org/pdf/2408.03598v1.pdf","comment":"15 pages, 8 figures, ACM MM 2024. Supplementary materials are\n  included"},{"id":"http://arxiv.org/abs/2405.19722v2","updated":"2024-08-07T07:28:02Z","published":"2024-05-30T06:07:57Z","title":"QClusformer: A Quantum Transformer-based Framework for Unsupervised\n  Visual Clustering","summary":"  Unsupervised vision clustering, a cornerstone in computer vision, has been\nstudied for decades, yielding significant outcomes across numerous vision\ntasks. However, these algorithms involve substantial computational demands when\nconfronted with vast amounts of unlabeled data. Conversely, quantum computing\nholds promise in expediting unsupervised algorithms when handling large-scale\ndatabases. In this study, we introduce QClusformer, a pioneering\nTransformer-based framework leveraging quantum machines to tackle unsupervised\nvision clustering challenges. Specifically, we design the Transformer\narchitecture, including the self-attention module and transformer blocks, from\na quantum perspective to enable execution on quantum hardware. In addition, we\npresent QClusformer, a variant based on the Transformer architecture, tailored\nfor unsupervised vision clustering tasks. By integrating these elements into an\nend-to-end framework, QClusformer consistently outperforms previous methods\nrunning on classical computers. Empirical evaluations across diverse\nbenchmarks, including MS-Celeb-1M and DeepFashion, underscore the superior\nperformance of QClusformer compared to state-of-the-art methods.\n","authors":["Xuan-Bac Nguyen","Hoang-Quan Nguyen","Samuel Yen-Chi Chen","Samee U. Khan","Hugh Churchill","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2405.19722v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03596v1","updated":"2024-08-07T07:24:15Z","published":"2024-08-07T07:24:15Z","title":"Hierarchical Quantum Control Gates for Functional MRI Understanding","summary":"  Quantum computing has emerged as a powerful tool for solving complex problems\nintractable for classical computers, particularly in popular fields such as\ncryptography, optimization, and neurocomputing. In this paper, we present a new\nquantum-based approach named the Hierarchical Quantum Control Gates (HQCG)\nmethod for efficient understanding of Functional Magnetic Resonance Imaging\n(fMRI) data. This approach includes two novel modules: the Local Quantum\nControl Gate (LQCG) and the Global Quantum Control Gate (GQCG), which are\ndesigned to extract local and global features of fMRI signals, respectively.\nOur method operates end-to-end on a quantum machine, leveraging quantum\nmechanics to learn patterns within extremely high-dimensional fMRI signals,\nsuch as 30,000 samples which is a challenge for classical computers. Empirical\nresults demonstrate that our approach significantly outperforms classical\nmethods. Additionally, we found that the proposed quantum model is more stable\nand less prone to overfitting than the classical methods.\n","authors":["Xuan-Bac Nguyen","Hoang-Quan Nguyen","Hugh Churchill","Samee U. Khan","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2408.03596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03592v1","updated":"2024-08-07T07:12:52Z","published":"2024-08-07T07:12:52Z","title":"HistoSPACE: Histology-Inspired Spatial Transcriptome Prediction And\n  Characterization Engine","summary":"  Spatial transcriptomics (ST) enables the visualization of gene expression\nwithin the context of tissue morphology. This emerging discipline has the\npotential to serve as a foundation for developing tools to design precision\nmedicines. However, due to the higher costs and expertise required for such\nexperiments, its translation into a regular clinical practice might be\nchallenging. Despite the implementation of modern deep learning to enhance\ninformation obtained from histological images using AI, efforts have been\nconstrained by limitations in the diversity of information. In this paper, we\ndeveloped a model, HistoSPACE that explore the diversity of histological images\navailable with ST data to extract molecular insights from tissue image. Our\nproposed study built an image encoder derived from universal image autoencoder.\nThis image encoder was connected to convolution blocks to built the final\nmodel. It was further fine tuned with the help of ST-Data. This model is\nnotably lightweight in compared to traditional histological models. Our\ndeveloped model demonstrates significant efficiency compared to contemporary\nalgorithms, revealing a correlation of 0.56 in leave-one-out cross-validation.\nFinally, its robustness was validated through an independent dataset, showing a\nwell matched preditction with predefined disease pathology.\n","authors":["Shivam Kumar","Samrat Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2408.03592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03591v1","updated":"2024-08-07T07:09:14Z","published":"2024-08-07T07:09:14Z","title":"Focal Depth Estimation: A Calibration-Free, Subject- and Daytime\n  Invariant Approach","summary":"  In an era where personalized technology is increasingly intertwined with\ndaily life, traditional eye-tracking systems and autofocal glasses face a\nsignificant challenge: the need for frequent, user-specific calibration, which\nimpedes their practicality. This study introduces a groundbreaking\ncalibration-free method for estimating focal depth, leveraging machine learning\ntechniques to analyze eye movement features within short sequences. Our\napproach, distinguished by its innovative use of LSTM networks and\ndomain-specific feature engineering, achieves a mean absolute error (MAE) of\nless than 10 cm, setting a new focal depth estimation accuracy standard. This\nadvancement promises to enhance the usability of autofocal glasses and pave the\nway for their seamless integration into extended reality environments, marking\na significant leap forward in personalized visual technology.\n","authors":["Benedikt W. Hosp","Björn Severitt","Rajat Agarwala","Evgenia Rusak","Yannick Sauer","Siegfried Wahl"],"pdf_url":"https://arxiv.org/pdf/2408.03591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02922v2","updated":"2024-08-07T06:44:24Z","published":"2024-08-06T03:15:18Z","title":"Pose Magic: Efficient and Temporally Consistent Human Pose Estimation\n  with a Hybrid Mamba-GCN Network","summary":"  Current state-of-the-art (SOTA) methods in 3D Human Pose Estimation (HPE) are\nprimarily based on Transformers. However, existing Transformer-based 3D HPE\nbackbones often encounter a trade-off between accuracy and computational\nefficiency. To resolve the above dilemma, in this work, we leverage recent\nadvances in state space models and utilize Mamba for high-quality and efficient\nlong-range modeling. Nonetheless, Mamba still faces challenges in precisely\nexploiting local dependencies between joints. To address these issues, we\npropose a new attention-free hybrid spatiotemporal architecture named Hybrid\nMamba-GCN (Pose Magic). This architecture introduces local enhancement with GCN\nby capturing relationships between neighboring joints, thus producing new\nrepresentations to complement Mamba's outputs. By adaptively fusing\nrepresentations from Mamba and GCN, Pose Magic demonstrates superior capability\nin learning the underlying 3D structure. To meet the requirements of real-time\ninference, we also provide a fully causal version. Extensive experiments show\nthat Pose Magic achieves new SOTA results ($\\downarrow 0.9 mm$) while saving\n$74.1\\%$ FLOPs. In addition, Pose Magic exhibits optimal motion consistency and\nthe ability to generalize to unseen sequence lengths.\n","authors":["Xinyi Zhang","Qiqi Bao","Qinpeng Cui","Wenming Yang","Qingmin Liao"],"pdf_url":"https://arxiv.org/pdf/2408.02922v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11936v2","updated":"2024-08-07T06:43:51Z","published":"2024-07-16T17:26:50Z","title":"Thermal Imaging and Radar for Remote Sleep Monitoring of Breathing and\n  Apnea","summary":"  Polysomnography (PSG), the current gold standard method for monitoring and\ndetecting sleep disorders, is cumbersome and costly. At-home testing solutions,\nknown as home sleep apnea testing (HSAT), exist. However, they are\ncontact-based, a feature which limits the ability of some patient populations\nto tolerate testing and discourages widespread deployment. Previous work on\nnon-contact sleep monitoring for sleep apnea detection either estimates\nrespiratory effort using radar or nasal airflow using a thermal camera, but has\nnot compared the two or used them together. We conducted a study on 10\nparticipants, ages 34 - 78, with suspected sleep disorders using a hardware\nsetup with a synchronized radar and thermal camera. We show the first\ncomparison of radar and thermal imaging for sleep monitoring, and find that our\nthermal imaging method outperforms radar significantly. Our thermal imaging\nmethod detects apneas with an accuracy of 0.99, a precision of 0.68, a recall\nof 0.74, an F1 score of 0.71, and an intra-class correlation of 0.70; our radar\nmethod detects apneas with an accuracy of 0.83, a precision of 0.13, a recall\nof 0.86, an F1 score of 0.22, and an intra-class correlation of 0.13. We also\npresent a novel proposal for classifying obstructive and central sleep apnea by\nleveraging a multimodal setup. This method could be used accurately detect and\nclassify apneas during sleep with non-contact sensors, thereby improving\ndiagnostic capacities in patient populations unable to tolerate current\ntechnology.\n","authors":["Kai Del Regno","Alexander Vilesov","Adnan Armouti","Anirudh Bindiganavale Harish","Selim Emir Can","Ashley Kita","Achuta Kadambi"],"pdf_url":"https://arxiv.org/pdf/2407.11936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03574v1","updated":"2024-08-07T06:26:04Z","published":"2024-08-07T06:26:04Z","title":"Teach CLIP to Develop a Number Sense for Ordinal Regression","summary":"  Ordinal regression is a fundamental problem within the field of computer\nvision, with customised well-trained models on specific tasks. While\npre-trained vision-language models (VLMs) have exhibited impressive performance\non various vision tasks, their potential for ordinal regression has received\nless exploration. In this study, we first investigate CLIP's potential for\nordinal regression, from which we expect the model could generalise to\ndifferent ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP\nfails on this task, since current VLMs have a well-documented limitation of\nencapsulating compositional concepts such as number sense. We propose a simple\nyet effective method called NumCLIP to improve the quantitative understanding\nof VLMs. We disassemble the exact image to number-specific text matching\nproblem into coarse classification and fine prediction stages. We discretize\nand phrase each numerical bin with common language concept to better leverage\nthe available pre-trained alignment in CLIP. To consider the inherent\ncontinuous property of ordinal regression, we propose a novel fine-grained\ncross-modal ranking-based regularisation loss specifically designed to keep\nboth semantic and ordinal alignment in CLIP's feature space. Experimental\nresults on three general ordinal regression tasks demonstrate the effectiveness\nof NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating\nand image aesthetics assessment task, respectively. Code is publicly available\nat https://github.com/xmed-lab/NumCLIP.\n","authors":["Yao Du","Qiang Zhai","Weihang Dai","Xiaomeng Li"],"pdf_url":"https://arxiv.org/pdf/2408.03574v1.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03568v1","updated":"2024-08-07T06:11:25Z","published":"2024-08-07T06:11:25Z","title":"A comparative study of generative adversarial networks for image\n  recognition algorithms based on deep learning and traditional methods","summary":"  In this paper, an image recognition algorithm based on the combination of\ndeep learning and generative adversarial network (GAN) is studied, and compared\nwith traditional image recognition methods. The purpose of this study is to\nevaluate the advantages and application prospects of deep learning technology,\nespecially GAN, in the field of image recognition. Firstly, this paper reviews\nthe basic principles and techniques of traditional image recognition methods,\nincluding the classical algorithms based on feature extraction such as SIFT,\nHOG and their combination with support vector machine (SVM), random forest, and\nother classifiers. Then, the working principle, network structure, and unique\nadvantages of GAN in image generation and recognition are introduced. In order\nto verify the effectiveness of GAN in image recognition, a series of\nexperiments are designed and carried out using multiple public image data sets\nfor training and testing. The experimental results show that compared with\ntraditional methods, GAN has excellent performance in processing complex\nimages, recognition accuracy, and anti-noise ability. Specifically, Gans are\nbetter able to capture high-dimensional features and details of images,\nsignificantly improving recognition performance. In addition, Gans shows unique\nadvantages in dealing with image noise, partial missing information, and\ngenerating high-quality images.\n","authors":["Yihao Zhong","Yijing Wei","Yingbin Liang","Xiqing Liu","Rongwei Ji","Yiru Cang"],"pdf_url":"https://arxiv.org/pdf/2408.03568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03567v1","updated":"2024-08-07T06:10:45Z","published":"2024-08-07T06:10:45Z","title":"Unlocking Exocentric Video-Language Data for Egocentric Video\n  Representation Learning","summary":"  We present EMBED (Egocentric Models Built with Exocentric Data), a method\ndesigned to transform exocentric video-language data for egocentric video\nrepresentation learning. Large-scale exocentric data covers diverse activities\nwith significant potential for egocentric learning, but inherent disparities\nbetween egocentric and exocentric data pose challenges in utilizing one view\nfor the other seamlessly. Egocentric videos predominantly feature close-up\nhand-object interactions, whereas exocentric videos offer a broader perspective\non human activities. Additionally, narratives in egocentric datasets are\ntypically more action-centric and closely linked with the visual content, in\ncontrast to the narrative styles found in exocentric datasets. To address these\nchallenges, we employ a data transformation framework to adapt exocentric data\nfor egocentric training, focusing on identifying specific video clips that\nemphasize hand-object interactions and transforming narration styles to align\nwith egocentric perspectives. By applying both vision and language style\ntransfer, our framework creates a new egocentric dataset derived from\nexocentric video-language data. Through extensive evaluations, we demonstrate\nthe effectiveness of EMBED, achieving state-of-the-art results across various\negocentric downstream tasks, including an absolute improvement of 4.7% on the\nEpic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification\nbenchmarks in zero-shot settings. Furthermore, EMBED enables egocentric\nvideo-language models to perform competitively in exocentric tasks. Finally, we\nshowcase EMBED's application across various exocentric datasets, exhibiting\nstrong generalization capabilities when applied to different exocentric\ndatasets.\n","authors":["Zi-Yi Dou","Xitong Yang","Tushar Nagarajan","Huiyu Wang","Jing Huang","Nanyun Peng","Kris Kitani","Fu-Jen Chu"],"pdf_url":"https://arxiv.org/pdf/2408.03567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11755v3","updated":"2024-08-07T06:05:42Z","published":"2024-03-18T13:03:24Z","title":"Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs","summary":"  Prompt ensembling of Large Language Model (LLM) generated category-specific\nprompts has emerged as an effective method to enhance zero-shot recognition\nability of Vision-Language Models (VLMs). To obtain these category-specific\nprompts, the present methods rely on hand-crafting the prompts to the LLMs for\ngenerating VLM prompts for the downstream tasks. However, this requires\nmanually composing these task-specific prompts and still, they might not cover\nthe diverse set of visual concepts and task-specific styles associated with the\ncategories of interest. To effectively take humans out of the loop and\ncompletely automate the prompt generation process for zero-shot recognition, we\npropose Meta-Prompting for Visual Recognition (MPVR). Taking as input only\nminimal information about the target task, in the form of its short natural\nlanguage description, and a list of associated class labels, MPVR automatically\nproduces a diverse set of category-specific prompts resulting in a strong\nzero-shot classifier. MPVR generalizes effectively across various popular\nzero-shot image recognition benchmarks belonging to widely different domains\nwhen tested with multiple LLMs and VLMs. For example, MPVR obtains a zero-shot\nrecognition improvement over CLIP by up to 19.8% and 18.2% (5.0% and 4.5% on\naverage over 20 datasets) leveraging GPT and Mixtral LLMs, respectively\n","authors":["M. Jehanzeb Mirza","Leonid Karlinsky","Wei Lin","Sivan Doveh","Jakub Micorek","Mateusz Kozinski","Hilde Kuehne","Horst Possegger"],"pdf_url":"https://arxiv.org/pdf/2403.11755v3.pdf","comment":"ECCV Camera Ready. Code & Data:\n  https://jmiemirza.github.io/Meta-Prompting/"},{"id":"http://arxiv.org/abs/2408.02085v3","updated":"2024-08-07T06:04:31Z","published":"2024-08-04T16:50:07Z","title":"Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data\n  Assessment and Selection for Instruction Tuning of Language Models","summary":"  Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering.\n","authors":["Yulei Qin","Yuncheng Yang","Pengcheng Guo","Gang Li","Hang Shao","Yuchen Shi","Zihan Xu","Yun Gu","Ke Li","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02085v3.pdf","comment":"review, survey, 28 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2402.14461v2","updated":"2024-08-07T06:01:18Z","published":"2024-02-22T11:40:49Z","title":"S^2Former-OR: Single-Stage Bi-Modal Transformer for Scene Graph\n  Generation in OR","summary":"  Scene graph generation (SGG) of surgical procedures is crucial in enhancing\nholistically cognitive intelligence in the operating room (OR). However,\nprevious works have primarily relied on multi-stage learning, where the\ngenerated semantic scene graphs depend on intermediate processes with pose\nestimation and object detection. This pipeline may potentially compromise the\nflexibility of learning multimodal representations, consequently constraining\nthe overall effectiveness. In this study, we introduce a novel single-stage\nbi-modal transformer framework for SGG in the OR, termed S^2Former-OR, aimed to\ncomplementally leverage multi-view 2D scenes and 3D point clouds for SGG in an\nend-to-end manner. Concretely, our model embraces a View-Sync Transfusion\nscheme to encourage multi-view visual information interaction. Concurrently, a\nGeometry-Visual Cohesion operation is designed to integrate the synergic 2D\nsemantic features into 3D point cloud features. Moreover, based on the\naugmented feature, we propose a novel relation-sensitive transformer decoder\nthat embeds dynamic entity-pair queries and relational trait priors, which\nenables the direct prediction of entity-pair relations for graph generation\nwithout intermediate steps. Extensive experiments have validated the superior\nSGG performance and lower computational cost of S^2Former-OR on 4D-OR\nbenchmark, compared with current OR-SGG methods, e.g., 3 percentage points\nPrecision increase and 24.2M reduction in model parameters. We further compared\nour method with generic single-stage SGG methods with broader metrics for a\ncomprehensive evaluation, with consistently better performance achieved.\n","authors":["Jialun Pei","Diandian Guo","Jingyang Zhang","Manxi Lin","Yueming Jin","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2402.14461v2.pdf","comment":"This work has been accepted by TMI2024"},{"id":"http://arxiv.org/abs/2408.03564v1","updated":"2024-08-07T05:56:05Z","published":"2024-08-07T05:56:05Z","title":"Underwater litter monitoring using consumer-grade aerial-aquatic speedy\n  scanner (AASS) and deep learning based super-resolution reconstruction and\n  detection network","summary":"  Underwater litter is widely spread across aquatic environments such as lakes,\nrivers, and oceans, significantly impacting natural ecosystems. Current\nmonitoring technologies for detecting underwater litter face limitations in\nsurvey efficiency, cost, and environmental conditions, highlighting the need\nfor efficient, consumer-grade technologies for automatic detection. This\nresearch introduces the Aerial-Aquatic Speedy Scanner (AASS) combined with\nSuper-Resolution Reconstruction (SRR) and an improved YOLOv8 detection network.\nAASS enhances data acquisition efficiency over traditional methods, capturing\nhigh-quality images that accurately identify underwater waste. SRR improves\nimage-resolution by mitigating motion blur and insufficient resolution, thereby\nenhancing detection tasks. Specifically, the RCAN model achieved the highest\nmean average precision (mAP) of 78.6% for detection accuracy on reconstructed\nimages among the tested SRR models. With a magnification factor of 4, the SRR\ntest set shows an improved mAP compared to the conventional bicubic set. These\nresults demonstrate the effectiveness of the proposed method in detecting\nunderwater litter.\n","authors":["Fan Zhao","Yongying Liu","Jiaqi Wang","Yijia Chen","Dianhan Xi","Xinlei Shao","Shigeru Tabeta","Katsunori Mizuno"],"pdf_url":"https://arxiv.org/pdf/2408.03564v1.pdf","comment":"The earlier version of this conference paper was accepted at OCEANS\n  2024-Halifax, Canada and was selected for inclusion in the Student Poster\n  Competition (SPC) Program"},{"id":"http://arxiv.org/abs/2403.19026v3","updated":"2024-08-07T05:54:04Z","published":"2024-03-27T21:43:12Z","title":"EgoNav: Egocentric Scene-aware Human Trajectory Prediction","summary":"  Wearable collaborative robots stand to assist human wearers who need fall\nprevention assistance or wear exoskeletons. Such a robot needs to be able to\nconstantly adapt to the surrounding scene based on egocentric vision, and\npredict the ego motion of the wearer. In this work, we leveraged body-mounted\ncameras and sensors to anticipate the trajectory of human wearers through\ncomplex surroundings. To facilitate research in ego-motion prediction, we have\ncollected a comprehensive walking scene navigation dataset centered on the\nuser's perspective. We then present a method to predict human motion\nconditioning on the surrounding static scene. Our method leverages a diffusion\nmodel to produce a distribution of potential future trajectories, taking into\naccount the user's observation of the environment. To that end, we introduce a\ncompact representation to encode the user's visual memory of the surroundings,\nas well as an efficient sample-generating technique to speed up real-time\ninference of a diffusion model. We ablate our model and compare it to\nbaselines, and results show that our model outperforms existing methods on key\nmetrics of collision avoidance and trajectory mode coverage.\n","authors":["Weizhuo Wang","C. Karen Liu","Monroe Kennedy III"],"pdf_url":"https://arxiv.org/pdf/2403.19026v3.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2408.03559v1","updated":"2024-08-07T05:47:15Z","published":"2024-08-07T05:47:15Z","title":"Monitoring of Hermit Crabs Using drone-captured imagery and Deep\n  Learning based Super-Resolution Reconstruction and Improved YOLOv8","summary":"  Hermit crabs play a crucial role in coastal ecosystems by dispersing seeds,\ncleaning up debris, and disturbing soil. They serve as vital indicators of\nmarine environmental health, responding to climate change and pollution.\nTraditional survey methods, like quadrat sampling, are labor-intensive,\ntime-consuming, and environmentally dependent. This study presents an\ninnovative approach combining UAV-based remote sensing with Super-Resolution\nReconstruction (SRR) and the CRAB-YOLO detection network, a modification of\nYOLOv8s, to monitor hermit crabs. SRR enhances image quality by addressing\nissues such as motion blur and insufficient resolution, significantly improving\ndetection accuracy over conventional low-resolution fuzzy images. The CRAB-YOLO\nnetwork integrates three improvements for detection accuracy, hermit crab\ncharacteristics, and computational efficiency, achieving state-of-the-art\n(SOTA) performance compared to other mainstream detection models. The RDN\nnetworks demonstrated the best image reconstruction performance, and CRAB-YOLO\nachieved a mean average precision (mAP) of 69.5% on the SRR test set, a 40%\nimprovement over the conventional Bicubic method with a magnification factor of\n4. These results indicate that the proposed method is effective in detecting\nhermit crabs, offering a cost-effective and automated solution for extensive\nhermit crab monitoring, thereby aiding coastal benthos conservation.\n","authors":["Fan Zhao","Yijia Chen","Dianhan Xi","Yongying Liu","Jiaqi Wang","Shigeru Tabeta","Katsunori Mizuno"],"pdf_url":"https://arxiv.org/pdf/2408.03559v1.pdf","comment":"The earlier version of this conference paper was presented at OCEANS\n  2024-Singapore and was selected for inclusion in the Student Poster\n  Competition (SPC) Program"},{"id":"http://arxiv.org/abs/2408.03558v1","updated":"2024-08-07T05:47:06Z","published":"2024-08-07T05:47:06Z","title":"D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion\n  Methods","summary":"  In image processing, one of the most challenging tasks is to render an\nimage's semantic meaning using a variety of artistic approaches. Existing\ntechniques for arbitrary style transfer (AST) frequently experience\nmode-collapse, over-stylization, or under-stylization due to a disparity\nbetween the style and content images. We propose a novel framework called\nD$^2$Styler (Discrete Diffusion Styler) that leverages the discrete\nrepresentational capability of VQ-GANs and the advantages of discrete\ndiffusion, including stable training and avoidance of mode collapse. Our method\nuses Adaptive Instance Normalization (AdaIN) features as a context guide for\nthe reverse diffusion process. This makes it easy to move features from the\nstyle image to the content image without bias. The proposed method\nsubstantially enhances the visual quality of style-transferred images, allowing\nthe combination of content and style in a visually appealing manner. We take\nstyle images from the WikiArt dataset and content images from the COCO dataset.\nExperimental results demonstrate that D$^2$Styler produces high-quality\nstyle-transferred images and outperforms twelve existing methods on nearly all\nthe metrics. The qualitative results and ablation studies provide further\ninsights into the efficacy of our technique. The code is available at\nhttps://github.com/Onkarsus13/D2Styler.\n","authors":["Onkar Susladkar","Gayatri Deshmukh","Sparsh Mittal","Parth Shastri"],"pdf_url":"https://arxiv.org/pdf/2408.03558v1.pdf","comment":"Paper accepted at 27th International Conference on Pattern\n  Recognition (ICPR), 2024"},{"id":"http://arxiv.org/abs/2106.11760v5","updated":"2024-08-07T05:28:30Z","published":"2021-06-19T06:25:10Z","title":"Fingerprinting Image-to-Image Generative Adversarial Networks","summary":"  Generative Adversarial Networks (GANs) have been widely used in various\napplication scenarios. Since the production of a commercial GAN requires\nsubstantial computational and human resources, the copyright protection of GANs\nis urgently needed. This paper presents a novel fingerprinting scheme for the\nIntellectual Property (IP) protection of image-to-image GANs based on a trusted\nthird party. We break through the stealthiness and robustness bottlenecks\nsuffered by previous fingerprinting methods for classification models being\nnaively transferred to GANs. Specifically, we innovatively construct a\ncomposite deep learning model from the target GAN and a classifier. Then we\ngenerate fingerprint samples from this composite model, and embed them in the\nclassifier for effective ownership verification. This scheme inspires some\nconcrete methodologies to practically protect the modern image-to-image\ntranslation GANs. Theoretical analysis proves that these methods can satisfy\ndifferent security requirements necessary for IP protection. We also conduct\nextensive experiments to show that our solutions outperform existing\nstrategies.\n","authors":["Guanlin Li","Guowen Xu","Han Qiu","Shangwei Guo","Run Wang","Jiwei Li","Tianwei Zhang","Rongxing Lu"],"pdf_url":"https://arxiv.org/pdf/2106.11760v5.pdf","comment":"Accepted by EuroS&P 2024"},{"id":"http://arxiv.org/abs/2408.03551v1","updated":"2024-08-07T05:23:52Z","published":"2024-08-07T05:23:52Z","title":"VPOcc: Exploiting Vanishing Point for Monocular 3D Semantic Occupancy\n  Prediction","summary":"  Monocular 3D semantic occupancy prediction is becoming important in robot\nvision due to the compactness of using a single RGB camera. However, existing\nmethods often do not adequately account for camera perspective geometry,\nresulting in information imbalance along the depth range of the image. To\naddress this issue, we propose a vanishing point (VP) guided monocular 3D\nsemantic occupancy prediction framework named VPOcc. Our framework consists of\nthree novel modules utilizing VP. First, in the VPZoomer module, we initially\nutilize VP in feature extraction to achieve information balanced feature\nextraction across the scene by generating a zoom-in image based on VP. Second,\nwe perform perspective geometry-aware feature aggregation by sampling points\ntowards VP using a VP-guided cross-attention (VPCA) module. Finally, we create\nan information-balanced feature volume by effectively fusing original and\nzoom-in voxel feature volumes with a balanced feature volume fusion (BVFV)\nmodule. Experiments demonstrate that our method achieves state-of-the-art\nperformance for both IoU and mIoU on SemanticKITTI and SSCBench-KITTI360. These\nresults are obtained by effectively addressing the information imbalance in\nimages through the utilization of VP. Our code will be available at\nwww.github.com/anonymous.\n","authors":["Junsu Kim","Junhee Lee","Ukcheol Shin","Jean Oh","Kyungdon Joo"],"pdf_url":"https://arxiv.org/pdf/2408.03551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01089v4","updated":"2024-08-07T05:22:57Z","published":"2023-02-02T13:22:18Z","title":"Curriculum Learning for ab initio Deep Learned Refractive Optics","summary":"  Deep optical optimization has recently emerged as a new paradigm for\ndesigning computational imaging systems using only the output image as the\nobjective. However, it has been limited to either simple optical systems\nconsisting of a single element such as a diffractive optical element (DOE) or\nmetalens, or the fine-tuning of compound lenses from good initial designs. Here\nwe present a DeepLens design method based on curriculum learning, which is able\nto learn optical designs of compound lenses ab initio from randomly initialized\nsurfaces without human intervention, therefore overcoming the need for a good\ninitial design. We demonstrate the effectiveness of our approach by fully\nautomatically designing both classical imaging lenses and a large field-of-view\nextended depth-of-field computational lens in a cellphone-style form factor,\nwith highly aspheric surfaces and a short back focal length.\n","authors":["Xinge Yang","Qiang Fu","Wolfgang Heidrich"],"pdf_url":"https://arxiv.org/pdf/2302.01089v4.pdf","comment":"Automatically design computational lenses from scratch with\n  differentiable ray tracing"},{"id":"http://arxiv.org/abs/2407.11652v5","updated":"2024-08-07T05:14:24Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v5.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2404.06605v3","updated":"2024-08-07T05:10:43Z","published":"2024-04-09T20:24:29Z","title":"RoadBEV: Road Surface Reconstruction in Bird's Eye View","summary":"  Road surface conditions, especially geometry profiles, enormously affect\ndriving performance of autonomous vehicles. Vision-based online road\nreconstruction promisingly captures road information in advance. Existing\nsolutions like monocular depth estimation and stereo matching suffer from\nmodest performance. The recent technique of Bird's-Eye-View (BEV) perception\nprovides immense potential to more reliable and accurate reconstruction. This\npaper uniformly proposes two simple yet effective models for road elevation\nreconstruction in BEV named RoadBEV-mono and RoadBEV-stereo, which estimate\nroad elevation with monocular and stereo images, respectively. The former\ndirectly fits elevation values based on voxel features queried from image view,\nwhile the latter efficiently recognizes road elevation patterns based on BEV\nvolume representing correlation between left and right voxel features.\nInsightful analyses reveal their consistence and difference with the\nperspective view. Experiments on real-world dataset verify the models'\neffectiveness and superiority. Elevation errors of RoadBEV-mono and\nRoadBEV-stereo achieve 1.83 cm and 0.50 cm, respectively. Our models are\npromising for practical road preview, providing essential information for\npromoting safety and comfort of autonomous vehicles. The code is released at\nhttps://github.com/ztsrxh/RoadBEV\n","authors":["Tong Zhao","Lei Yang","Yichen Xie","Mingyu Ding","Masayoshi Tomizuka","Yintao Wei"],"pdf_url":"https://arxiv.org/pdf/2404.06605v3.pdf","comment":"Accepted by IEEE TITS https://ieeexplore.ieee.org/document/10618926"},{"id":"http://arxiv.org/abs/2305.10856v3","updated":"2024-08-07T04:59:01Z","published":"2023-05-18T10:18:59Z","title":"Spatial-Frequency Discriminability for Revealing Adversarial\n  Perturbations","summary":"  The vulnerability of deep neural networks to adversarial perturbations has\nbeen widely perceived in the computer vision community. From a security\nperspective, it poses a critical risk for modern vision systems, e.g., the\npopular Deep Learning as a Service (DLaaS) frameworks. For protecting deep\nmodels while not modifying them, current algorithms typically detect\nadversarial patterns through discriminative decomposition for natural and\nadversarial data. However, these decompositions are either biased towards\nfrequency resolution or spatial resolution, thus failing to capture adversarial\npatterns comprehensively. Also, when the detector relies on few fixed features,\nit is practical for an adversary to fool the model while evading the detector\n(i.e., defense-aware attack). Motivated by such facts, we propose a\ndiscriminative detector relying on a spatial-frequency Krawtchouk\ndecomposition. It expands the above works from two aspects: 1) the introduced\nKrawtchouk basis provides better spatial-frequency discriminability, capturing\nthe differences between natural and adversarial data comprehensively in both\nspatial and frequency distributions, w.r.t. the common trigonometric or wavelet\nbasis; 2) the extensive features formed by the Krawtchouk decomposition allows\nfor adaptive feature selection and secrecy mechanism, significantly increasing\nthe difficulty of the defense-aware attack, w.r.t. the detector with few fixed\nfeatures. Theoretical and numerical analyses demonstrate the uniqueness and\nusefulness of our detector, exhibiting competitive scores on several deep\nmodels and image sets against a variety of adversarial attacks.\n","authors":["Chao Wang","Shuren Qi","Zhiqiu Huang","Yushu Zhang","Rushi Lan","Xiaochun Cao","Feng-Lei Fan"],"pdf_url":"https://arxiv.org/pdf/2305.10856v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03545v1","updated":"2024-08-07T04:50:05Z","published":"2024-08-07T04:50:05Z","title":"CLIP-based Point Cloud Classification via Point Cloud to Image\n  Translation","summary":"  Point cloud understanding is an inherently challenging problem because of the\nsparse and unordered structure of the point cloud in the 3D space. Recently,\nContrastive Vision-Language Pre-training (CLIP) based point cloud\nclassification model i.e. PointCLIP has added a new direction in the point\ncloud classification research domain. In this method, at first multi-view depth\nmaps are extracted from the point cloud and passed through the CLIP visual\nencoder. To transfer the 3D knowledge to the network, a small network called an\nadapter is fine-tuned on top of the CLIP visual encoder. PointCLIP has two\nlimitations. Firstly, the point cloud depth maps lack image information which\nis essential for tasks like classification and recognition. Secondly, the\nadapter only relies on the global representation of the multi-view features.\nMotivated by this observation, we propose a Pretrained Point Cloud to Image\nTranslation Network (PPCITNet) that produces generalized colored images along\nwith additional salient visual cues to the point cloud depth maps so that it\ncan achieve promising performance on point cloud classification and\nunderstanding. In addition, we propose a novel viewpoint adapter that combines\nthe view feature processed by each viewpoint as well as the global intertwined\nknowledge that exists across the multi-view features. The experimental results\ndemonstrate the superior performance of the proposed model over existing\nstate-of-the-art CLIP-based models on ModelNet10, ModelNet40, and ScanobjectNN\ndatasets.\n","authors":["Shuvozit Ghose","Manyi Li","Yiming Qian","Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03545v1.pdf","comment":"Accepted by ICPR2024"},{"id":"http://arxiv.org/abs/2408.03542v1","updated":"2024-08-07T04:42:10Z","published":"2024-08-07T04:42:10Z","title":"Automatic identification of the area covered by acorn trees in the\n  dehesa (pastureland) Extremadura of Spain","summary":"  The acorn is the fruit of the oak and is an important crop in the Spanish\ndehesa extreme\\~na, especially for the value it provides in the Iberian pig\nfood to obtain the \"acorn\" certification. For this reason, we want to maximise\nthe production of Iberian pigs with the appropriate weight. Hence the need to\nknow the area covered by the crowns of the acorn trees, to determine the\ncovered wooded area (CWA, from the Spanish Superficie Arbolada Cubierta SAC)\nand thereby estimate the number of Iberian pigs that can be released per\nhectare, as indicated by the royal decree 4/2014. In this work, we propose the\nautomatic estimation of the CWA, through aerial digital images (orthophotos) of\nthe pastureland of Extremadura, and with this, to offer the possibility of\ndetermining the number of Iberian pigs to be released in a specific plot of\nland. Among the main issues for automatic detection are, first, the correct\nidentification of acorn trees, secondly, correctly discriminating the shades of\nthe acorn trees and, finally, detect the arbuscles (young acorn trees not yet\nproductive, or shrubs that are not oaks). These difficulties represent a real\nchallenge, both for the automatic segmentation process and for manual\nsegmentation. In this work, the proposed method for automatic segmentation is\nbased on the clustering algorithm proposed by Gustafson-Kessel (GK) but the\nmodified version of Babuska (GK-B) and on the use of real orthophotos. The\nobtained results are promising both in their comparison with the real images\nand when compared with the images segmented by hand. The whole set of\northophotos used in this work correspond to an approximate area of 142\nhectares, and the results are of great interest to producers of certified\n\"acorn\" pork.\n","authors":["Ojeda-Magaña Benjamin","Ruelas Ruben","Quintanilla-Dominguez Joel","Gomez-Barba Leopoldo","Lopez de Herrera Juan","Robledo-Hernandez Jose","Tarquis Ana"],"pdf_url":"https://arxiv.org/pdf/2408.03542v1.pdf","comment":"22 pages, 15 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2408.03540v1","updated":"2024-08-07T04:38:03Z","published":"2024-08-07T04:38:03Z","title":"PoseMamba: Monocular 3D Human Pose Estimation with Bidirectional\n  Global-Local Spatio-Temporal State Space Model","summary":"  Transformers have significantly advanced the field of 3D human pose\nestimation (HPE). However, existing transformer-based methods primarily use\nself-attention mechanisms for spatio-temporal modeling, leading to a quadratic\ncomplexity, unidirectional modeling of spatio-temporal relationships, and\ninsufficient learning of spatial-temporal correlations. Recently, the Mamba\narchitecture, utilizing the state space model (SSM), has exhibited superior\nlong-range modeling capabilities in a variety of vision tasks with linear\ncomplexity. In this paper, we propose PoseMamba, a novel purely SSM-based\napproach with linear complexity for 3D human pose estimation in monocular\nvideo. Specifically, we propose a bidirectional global-local spatio-temporal\nSSM block that comprehensively models human joint relations within individual\nframes as well as temporal correlations across frames. Within this\nbidirectional global-local spatio-temporal SSM block, we introduce a reordering\nstrategy to enhance the local modeling capability of the SSM. This strategy\nprovides a more logical geometric scanning order and integrates it with the\nglobal SSM, resulting in a combined global-local spatial scan. We have\nquantitatively and qualitatively evaluated our approach using two benchmark\ndatasets: Human3.6M and MPI-INF-3DHP. Extensive experiments demonstrate that\nPoseMamba achieves state-of-the-art performance on both datasets while\nmaintaining a smaller model size and reducing computational costs. The code and\nmodels will be released.\n","authors":["Yunlong Huang","Junshuo Liu","Ke Xian","Robert Caiming Qiu"],"pdf_url":"https://arxiv.org/pdf/2408.03540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03538v1","updated":"2024-08-07T04:35:06Z","published":"2024-08-07T04:35:06Z","title":"PRTGS: Precomputed Radiance Transfer of Gaussian Splats for Real-Time\n  High-Quality Relighting","summary":"  We proposed Precomputed RadianceTransfer of GaussianSplats (PRTGS), a\nreal-time high-quality relighting method for Gaussian splats in low-frequency\nlighting environments that captures soft shadows and interreflections by\nprecomputing 3D Gaussian splats' radiance transfer. Existing studies have\ndemonstrated that 3D Gaussian splatting (3DGS) outperforms neural fields'\nefficiency for dynamic lighting scenarios. However, the current relighting\nmethod based on 3DGS still struggles to compute high-quality shadow and\nindirect illumination in real time for dynamic light, leading to unrealistic\nrendering results. We solve this problem by precomputing the expensive\ntransport simulations required for complex transfer functions like shadowing,\nthe resulting transfer functions are represented as dense sets of vectors or\nmatrices for every Gaussian splat. We introduce distinct precomputing methods\ntailored for training and rendering stages, along with unique ray tracing and\nindirect lighting precomputation techniques for 3D Gaussian splats to\naccelerate training speed and compute accurate indirect lighting related to\nenvironment light. Experimental analyses demonstrate that our approach achieves\nstate-of-the-art visual quality while maintaining competitive training times\nand allows high-quality real-time (30+ fps) relighting for dynamic light and\nrelatively complex scenes at 1080p resolution.\n","authors":["Yijia Guo","Yuanxi Bai","Liwen Hu","Ziyi Guo","Mianzhi Liu","Yu Cai","Tiejun Huang","Lei Ma"],"pdf_url":"https://arxiv.org/pdf/2408.03538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04346v2","updated":"2024-08-07T04:00:57Z","published":"2024-07-05T08:37:10Z","title":"MobileFlow: A Multimodal LLM For Mobile GUI Agent","summary":"  Currently, the integration of mobile Graphical User Interfaces (GUIs) is\nubiquitous in most people's daily lives. And the ongoing evolution of\nmultimodal large-scale models, such as GPT-4v, Qwen-VL-Max, has significantly\nbolstered the capabilities of GUI comprehension and user action analysis,\nshowcasing the potentiality of intelligent GUI assistants. However, current GUI\nAgents often need to access page layout information through calling system\nAPIs, which may pose privacy risks. Fixing GUI (such as mobile interfaces) to a\ncertain low resolution might result in the loss of fine-grained image details.\nAt the same time, the multimodal large models built for GUI Agents currently\nhave poor understanding and decision-making abilities for Chinese GUI\ninterfaces, making them difficult to apply to a large number of Chinese apps.\nThis paper introduces MobileFlow, a multimodal large language model\nmeticulously crafted for mobile GUI agents. Transforming from the open-source\nmodel Qwen-VL-Chat into GUI domain, MobileFlow contains approximately 21\nbillion parameters and is equipped with novel hybrid visual encoders, making it\npossible for variable resolutions of image inputs and good support for\nmultilingual GUI. By incorporating Mixture of Experts (MoE) expansions and\npioneering alignment training strategies, MobileFlow has the capacity to fully\ninterpret image data and comprehend user instructions for GUI interaction\ntasks. Finally, MobileFlow outperforms Qwen-VL-Max and GPT-4v in terms of task\nexecution by GUI agents on both public and our proposed evaluation metrics, and\nhas been successfully deployed in real-world business contexts, proving its\neffectiveness for practical applications.\n","authors":["Songqin Nong","Jiali Zhu","Rui Wu","Jiongchao Jin","Shuo Shan","Xiutian Huang","Wenhao Xu"],"pdf_url":"https://arxiv.org/pdf/2407.04346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18403v5","updated":"2024-08-07T03:30:30Z","published":"2023-05-28T15:15:48Z","title":"LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient\n  Fine-Tuning","summary":"  Large Language Models (LLMs), such as LLaMA and T5, have shown exceptional\nperformance across various tasks through fine-tuning. Although low-rank\nadaption (LoRA) has emerged to cheaply fine-tune these LLMs on downstream\ntasks, their deployment is still hindered by the vast model scale and\ncomputational costs. Post-training model pruning offers a way to compress LLMs.\nHowever, the current pruning methods designed for LLMs are not compatible with\nLoRA. This is due to their utilization of unstructured pruning on LLMs,\nimpeding the merging of LoRA weights, or their dependence on the gradients of\npre-trained weights to guide pruning, which can impose significant memory\noverhead. To this end, we propose LoRAPrune, a new framework that delivers an\naccurate structured pruned model in a highly memory-efficient manner.\nSpecifically, we first design a LoRA-guided pruning criterion, which uses the\nweights and gradients of LoRA, rather than the gradients of pre-trained weights\nfor importance estimation. We subsequently integrate this criterion into an\niterative pruning process, effectively removing redundant channels and heads.\nExtensive experimental results demonstrate the superior performance of our\nLoRAPrune over existing approaches on the LLaMA series models. At a 50\\%\ncompression rate, LoRAPrune demonstrates superior performance over LLM-Pruner,\nachieving a reduction in perplexity by 4.81 on WikiText2 and 3.46 on PTB, while\nalso decreasing memory usage by 52.6%. Besides, LoRAPrune also matches\nsemi-structural pruning across multiple LLMs, proving its wide applicability.\nThe code is available at https://github.com/aim-uofa/LoRAPrune.\n","authors":["Mingyang Zhang","Hao Chen","Chunhua Shen","Zhen Yang","Linlin Ou","Xinyi Yu","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2305.18403v5.pdf","comment":"accepted by acl 2024 findings"},{"id":"http://arxiv.org/abs/2408.03521v1","updated":"2024-08-07T03:16:33Z","published":"2024-08-07T03:16:33Z","title":"SwinShadow: Shifted Window for Ambiguous Adjacent Shadow Detection","summary":"  Shadow detection is a fundamental and challenging task in many computer\nvision applications. Intuitively, most shadows come from the occlusion of light\nby the object itself, resulting in the object and its shadow being contiguous\n(referred to as the adjacent shadow in this paper). In this case, when the\ncolor of the object is similar to that of the shadow, existing methods struggle\nto achieve accurate detection. To address this problem, we present SwinShadow,\na transformer-based architecture that fully utilizes the powerful shifted\nwindow mechanism for detecting adjacent shadows. The mechanism operates in two\nsteps. Initially, it applies local self-attention within a single window,\nenabling the network to focus on local details. Subsequently, it shifts the\nattention windows to facilitate inter-window attention, enabling the capture of\na broader range of adjacent information. These combined steps significantly\nimprove the network's capacity to distinguish shadows from nearby objects. And\nthe whole process can be divided into three parts: encoder, decoder, and\nfeature integration. During encoding, we adopt Swin Transformer to acquire\nhierarchical features. Then during decoding, for shallow layers, we propose a\ndeep supervision (DS) module to suppress the false positives and boost the\nrepresentation capability of shadow features for subsequent processing, while\nfor deep layers, we leverage a double attention (DA) module to integrate local\nand shifted window in one stage to achieve a larger receptive field and enhance\nthe continuity of information. Ultimately, a new multi-level aggregation (MLA)\nmechanism is applied to fuse the decoded features for mask prediction.\nExtensive experiments on three shadow detection benchmark datasets, SBU, UCF,\nand ISTD, demonstrate that our network achieves good performance in terms of\nbalance error rate (BER).\n","authors":["Yonghui Wang","Shaokai Liu","Li Li","Wengang Zhou","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2408.03521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03516v1","updated":"2024-08-07T02:54:43Z","published":"2024-08-07T02:54:43Z","title":"Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in\n  Autonomous Driving","summary":"  This paper introduces a novel method for open-vocabulary 3D scene\nunderstanding in autonomous driving by combining Language Embedded 3D Gaussians\nwith Large Language Models (LLMs) for enhanced inference. We propose utilizing\nLLMs to generate contextually relevant canonical phrases for segmentation and\nscene interpretation. Our method leverages the contextual and semantic\ncapabilities of LLMs to produce a set of canonical phrases, which are then\ncompared with the language features embedded in the 3D Gaussians. This\nLLM-guided approach significantly improves zero-shot scene understanding and\ndetection of objects of interest, even in the most challenging or unfamiliar\nenvironments. Experimental results on the WayveScenes101 dataset demonstrate\nthat our approach surpasses state-of-the-art methods in terms of accuracy and\nflexibility for open-vocabulary object detection and segmentation. This work\nrepresents a significant advancement towards more intelligent, context-aware\nautonomous driving systems, effectively bridging 3D scene representation with\nhigh-level semantic understanding.\n","authors":["Amirhosein Chahe","Lifeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.03516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12223v2","updated":"2024-08-07T02:51:50Z","published":"2024-04-06T03:02:47Z","title":"Cascaded Multi-path Shortcut Diffusion Model for Medical Image\n  Translation","summary":"  Image-to-image translation is a vital component in medical imaging\nprocessing, with many uses in a wide range of imaging modalities and clinical\nscenarios. Previous methods include Generative Adversarial Networks (GANs) and\nDiffusion Models (DMs), which offer realism but suffer from instability and\nlack uncertainty estimation. Even though both GAN and DM methods have\nindividually exhibited their capability in medical image translation tasks, the\npotential of combining a GAN and DM to further improve translation performance\nand to enable uncertainty estimation remains largely unexplored. In this work,\nwe address these challenges by proposing a Cascade Multi-path Shortcut\nDiffusion Model (CMDM) for high-quality medical image translation and\nuncertainty estimation. To reduce the required number of iterations and ensure\nrobust performance, our method first obtains a conditional GAN-generated prior\nimage that will be used for the efficient reverse translation with a DM in the\nsubsequent step. Additionally, a multi-path shortcut diffusion strategy is\nemployed to refine translation results and estimate uncertainty. A cascaded\npipeline further enhances translation quality, incorporating residual averaging\nbetween cascades. We collected three different medical image datasets with two\nsub-tasks for each dataset to test the generalizability of our approach. Our\nexperimental results found that CMDM can produce high-quality translations\ncomparable to state-of-the-art methods while providing reasonable uncertainty\nestimations that correlate well with the translation error.\n","authors":["Yinchi Zhou","Tianqi Chen","Jun Hou","Huidong Xie","Nicha C. Dvornek","S. Kevin Zhou","David L. Wilson","James S. Duncan","Chi Liu","Bo Zhou"],"pdf_url":"https://arxiv.org/pdf/2405.12223v2.pdf","comment":"Accepted at Medical Image Analysis Journal"},{"id":"http://arxiv.org/abs/2304.06345v3","updated":"2024-08-07T02:46:46Z","published":"2023-04-13T08:52:34Z","title":"ASR: Attention-alike Structural Re-parameterization","summary":"  The structural re-parameterization (SRP) technique is a novel deep learning\ntechnique that achieves interconversion between different network architectures\nthrough equivalent parameter transformations. This technique enables the\nmitigation of the extra costs for performance improvement during training, such\nas parameter size and inference time, through these transformations during\ninference, and therefore SRP has great potential for industrial and practical\napplications. The existing SRP methods have successfully considered many\ncommonly used architectures, such as normalizations, pooling methods, and\nmulti-branch convolution. However, the widely used attention modules which\ndrastically slow inference speed cannot be directly implemented by SRP due to\nthese modules usually act on the backbone network in a multiplicative manner\nand the modules' output is input-dependent during inference, which limits the\napplication scenarios of SRP. In this paper, we conduct extensive experiments\nfrom a statistical perspective and discover an interesting phenomenon Stripe\nObservation, which reveals that channel attention values quickly approach some\nconstant vectors during training. This observation inspires us to propose a\nsimple-yet-effective attention-alike structural re-parameterization (ASR) that\nallows us to achieve SRP for a given network while enjoying the effectiveness\nof the attention mechanism. Extensive experiments conducted on several standard\nbenchmarks demonstrate the effectiveness of ASR in generally improving the\nperformance of existing backbone networks, attention modules, and SRP methods\nwithout any elaborated model crafting. We also analyze the limitations and\nprovide experimental and theoretical evidence for the strong robustness of the\nproposed ASR.\n","authors":["Shanshan Zhong","Zhongzhan Huang","Wushao Wen","Jinghui Qin","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2304.06345v3.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2406.16087v4","updated":"2024-08-07T02:36:19Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neural-Symbolic Learning\n  Framework for Robot Autonomy","summary":"  Data-driven methods such as reinforcement and imitation learning have\nachieved remarkable success in robot autonomy. However, their data-centric\nnature still hinders them from generalizing well to ever-changing environments.\nMoreover, collecting large datasets for robotic tasks is often impractical and\nexpensive. To overcome these challenges, we introduce a new self-supervised\nneural-symbolic (NeSy) computational framework, imperative learning (IL), for\nrobot autonomy, leveraging the generalization abilities of symbolic reasoning.\nThe framework of IL consists of three primary components: a neural module, a\nreasoning engine, and a memory system. We formulate IL as a special bilevel\noptimization (BLO), which enables reciprocal learning over the three modules.\nThis overcomes the label-intensive obstacles associated with data-driven\napproaches and takes advantage of symbolic reasoning concerning logical\nreasoning, physical principles, geometric analysis, etc. We discuss several\noptimization techniques for IL and verify their effectiveness in five distinct\nrobot autonomy tasks including path planning, rule induction, optimal control,\nvisual odometry, and multi-robot routing. Through various experiments, we show\nthat IL can significantly enhance robot autonomy capabilities and we anticipate\nthat it will catalyze further research across diverse domains.\n","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.16087v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03867v2","updated":"2024-08-07T02:32:40Z","published":"2023-11-07T10:31:41Z","title":"Supervised domain adaptation for building extraction from off-nadir\n  aerial images","summary":"  Building extraction $-$ needed for inventory management and planning of urban\nenvironment $-$ is affected by the misalignment between labels and off-nadir\nsource imagery in training data. Teacher-Student learning of noise-tolerant\nconvolutional neural networks (CNNs) is the existing solution, but the Student\nnetworks typically have lower accuracy and cannot surpass the Teacher's\nperformance. This paper proposes a supervised domain adaptation (SDA) of\nencoder-decoder networks (EDNs) between noisy and clean datasets to tackle the\nproblem. EDNs are configured with high-performing lightweight encoders such as\nEfficientNet, ResNeSt, and MobileViT. The proposed method is compared against\nthe existing Teacher-Student learning methods like knowledge distillation (KD)\nand deep mutual learning (DML) with three newly developed datasets. The methods\nare evaluated for different urban buildings (low-rise, mid-rise, high-rise, and\nskyscrapers), where misalignment increases with the increase in building height\nand spatial resolution. For a robust experimental design, 43 lightweight CNNs,\nfive optimisers, nine loss functions, and seven EDNs are benchmarked to obtain\nthe best-performing EDN for SDA. The SDA of the best-performing EDN from our\nstudy significantly outperformed KD and DML with up to 0.943, 0.868, 0.912, and\n0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers\nrespectively. The proposed method and the experimental findings will be\nbeneficial in training robust CNNs for building extraction.\n","authors":["Bipul Neupane","Jagannath Aryal","Abbas Rajabifard"],"pdf_url":"https://arxiv.org/pdf/2311.03867v2.pdf","comment":"This work has been submitted to Elsevier for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.03511v1","updated":"2024-08-07T02:28:37Z","published":"2024-08-07T02:28:37Z","title":"MoExtend: Tuning New Experts for Modality and Task Extension","summary":"  Large language models (LLMs) excel in various tasks but are primarily trained\non text data, limiting their application scope. Expanding LLM capabilities to\ninclude vision-language understanding is vital, yet training them on multimodal\ndata from scratch is challenging and costly. Existing instruction tuning\nmethods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs\nvia fully fine-tuning LLMs to bridge the modality gap. However, full\nfine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous\nknowledge, and high training costs particularly in the era of increasing tasks\nand modalities. To solve this issue, we introduce MoExtend, an effective\nframework designed to streamline the modality adaptation and extension of\nMixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts\ninto pre-trained MoE models, endowing them with novel knowledge without the\nneed to tune pretrained models such as MoE and vision encoders. This approach\nenables rapid adaptation and extension to new modal data or tasks, effectively\naddressing the challenge of accommodating new modalities within LLMs.\nFurthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk\nof catastrophic forgetting. Experimental results demonstrate the efficacy and\nefficiency of MoExtend in enhancing the multimodal capabilities of LLMs,\ncontributing to advancements in multimodal AI research. Code:\nhttps://github.com/zhongshsh/MoExtend.\n","authors":["Shanshan Zhong","Shanghua Gao","Zhongzhan Huang","Wushao Wen","Marinka Zitnik","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.03511v1.pdf","comment":"ACL 2024 - SRW"},{"id":"http://arxiv.org/abs/2408.03507v1","updated":"2024-08-07T02:18:39Z","published":"2024-08-07T02:18:39Z","title":"GUI Element Detection Using SOTA YOLO Deep Learning Models","summary":"  Detection of Graphical User Interface (GUI) elements is a crucial task for\nautomatic code generation from images and sketches, GUI testing, and GUI\nsearch. Recent studies have leveraged both old-fashioned and modern computer\nvision (CV) techniques. Oldfashioned methods utilize classic image processing\nalgorithms (e.g. edge detection and contour detection) and modern methods use\nmature deep learning solutions for general object detection tasks. GUI element\ndetection, however, is a domain-specific case of object detection, in which\nobjects overlap more often, and are located very close to each other, plus the\nnumber of object classes is considerably lower, yet there are more objects in\nthe images compared to natural images. Hence, the studies that have been\ncarried out on comparing various object detection models, might not apply to\nGUI element detection. In this study, we evaluate the performance of the four\nmost recent successful YOLO models for general object detection tasks on GUI\nelement detection and investigate their accuracy performance in detecting\nvarious GUI elements.\n","authors":["Seyed Shayan Daneshvar","Shaowei Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03503v1","updated":"2024-08-07T02:03:32Z","published":"2024-08-07T02:03:32Z","title":"Opening the Black Box of 3D Reconstruction Error Analysis with VECTOR","summary":"  Reconstruction of 3D scenes from 2D images is a technical challenge that\nimpacts domains from Earth and planetary sciences and space exploration to\naugmented and virtual reality. Typically, reconstruction algorithms first\nidentify common features across images and then minimize reconstruction errors\nafter estimating the shape of the terrain. This bundle adjustment (BA) step\noptimizes around a single, simplifying scalar value that obfuscates many\npossible causes of reconstruction errors (e.g., initial estimate of the\nposition and orientation of the camera, lighting conditions, ease of feature\ndetection in the terrain). Reconstruction errors can lead to inaccurate\nscientific inferences or endanger a spacecraft exploring a remote environment.\nTo address this challenge, we present VECTOR, a visual analysis tool that\nimproves error inspection for stereo reconstruction BA. VECTOR provides\nanalysts with previously unavailable visibility into feature locations, camera\npose, and computed 3D points. VECTOR was developed in partnership with the\nPerseverance Mars Rover and Ingenuity Mars Helicopter terrain reconstruction\nteam at the NASA Jet Propulsion Laboratory. We report on how this tool was used\nto debug and improve terrain reconstruction for the Mars 2020 mission.\n","authors":["Racquel Fygenson","Kazi Jawad","Isabel Li","Francois Ayoub","Robert G. Deen","Scott Davidoff","Dominik Moritz","Mauricio Hess-Flores"],"pdf_url":"https://arxiv.org/pdf/2408.03503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03500v1","updated":"2024-08-07T01:59:25Z","published":"2024-08-07T01:59:25Z","title":"e-Health CSIRO at RRG24: Entropy-Augmented Self-Critical Sequence\n  Training for Radiology Report Generation","summary":"  The Shared Task on Large-Scale Radiology Report Generation (RRG24) aims to\nexpedite the development of assistive systems for interpreting and reporting on\nchest X-ray (CXR) images. This task challenges participants to develop models\nthat generate the findings and impression sections of radiology reports from\nCXRs from a patient's study, using five different datasets. This paper outlines\nthe e-Health CSIRO team's approach, which achieved multiple first-place\nfinishes in RRG24. The core novelty of our approach lies in the addition of\nentropy regularisation to self-critical sequence training, to maintain a higher\nentropy in the token distribution. This prevents overfitting to common phrases\nand ensures a broader exploration of the vocabulary during training, essential\nfor handling the diversity of the radiology reports in the RRG24 datasets. Our\nmodel is available on Hugging Face https://huggingface.co/aehrc/cxrmate-rrg24.\n","authors":["Aaron Nicolson","Jinghui Liu","Jason Dowling","Anthony Nguyen","Bevan Koopman"],"pdf_url":"https://arxiv.org/pdf/2408.03500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03499v1","updated":"2024-08-07T01:50:34Z","published":"2024-08-07T01:50:34Z","title":"FacialPulse: An Efficient RNN-based Depression Detection via Temporal\n  Facial Landmarks","summary":"  Depression is a prevalent mental health disorder that significantly impacts\nindividuals' lives and well-being. Early detection and intervention are crucial\nfor effective treatment and management of depression. Recently, there are many\nend-to-end deep learning methods leveraging the facial expression features for\nautomatic depression detection. However, most current methods overlook the\ntemporal dynamics of facial expressions. Although very recent 3DCNN methods\nremedy this gap, they introduce more computational cost due to the selection of\nCNN-based backbones and redundant facial features.\n  To address the above limitations, by considering the timing correlation of\nfacial expressions, we propose a novel framework called FacialPulse, which\nrecognizes depression with high accuracy and speed. By harnessing the\nbidirectional nature and proficiently addressing long-term dependencies, the\nFacial Motion Modeling Module (FMMM) is designed in FacialPulse to fully\ncapture temporal features. Since the proposed FMMM has parallel processing\ncapabilities and has the gate mechanism to mitigate gradient vanishing, this\nmodule can also significantly boost the training speed.\n  Besides, to effectively use facial landmarks to replace original images to\ndecrease information redundancy, a Facial Landmark Calibration Module (FLCM) is\ndesigned to eliminate facial landmark errors to further improve recognition\naccuracy. Extensive experiments on the AVEC2014 dataset and MMDA dataset (a\ndepression dataset) demonstrate the superiority of FacialPulse on recognition\naccuracy and speed, with the average MAE (Mean Absolute Error) decreased by 21%\ncompared to baselines, and the recognition speed increased by 100% compared to\nstate-of-the-art methods. Codes are released at\nhttps://github.com/volatileee/FacialPulse.\n","authors":["Ruiqi Wang","Jinyang Huang","Jie Zhang","Xin Liu","Xiang Zhang","Zhi Liu","Peng Zhao","Sigui Chen","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2408.03499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00875v3","updated":"2024-08-07T01:50:29Z","published":"2024-04-01T03:10:36Z","title":"DPA-Net: Structured 3D Abstraction from Sparse Views via Differentiable\n  Primitive Assembly","summary":"  We present a differentiable rendering framework to learn structured 3D\nabstractions in the form of primitive assemblies from sparse RGB images\ncapturing a 3D object. By leveraging differentiable volume rendering, our\nmethod does not require 3D supervision. Architecturally, our network follows\nthe general pipeline of an image-conditioned neural radiance field (NeRF)\nexemplified by pixelNeRF for color prediction. As our core contribution, we\nintroduce differential primitive assembly (DPA) into NeRF to output a 3D\noccupancy field in place of density prediction, where the predicted occupancies\nserve as opacity values for volume rendering. Our network, coined DPA-Net,\nproduces a union of convexes, each as an intersection of convex quadric\nprimitives, to approximate the target 3D object, subject to an abstraction loss\nand a masking loss, both defined in the image space upon volume rendering. With\ntest-time adaptation and additional sampling and loss designs aimed at\nimproving the accuracy and compactness of the obtained assemblies, our method\ndemonstrates superior performance over state-of-the-art alternatives for 3D\nprimitive abstraction from sparse views.\n","authors":["Fenggen Yu","Yiming Qian","Xu Zhang","Francisca Gil-Ureta","Brian Jackson","Eric Bennett","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.00875v3.pdf","comment":"14 pages, accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2308.15068v4","updated":"2024-08-07T01:04:29Z","published":"2023-08-29T07:00:35Z","title":"A Comprehensive Augmentation Framework for Anomaly Detection","summary":"  Data augmentation methods are commonly integrated into the training of\nanomaly detection models. Previous approaches have primarily focused on\nreplicating real-world anomalies or enhancing diversity, without considering\nthat the standard of anomaly varies across different classes, potentially\nleading to a biased training distribution.This paper analyzes crucial traits of\nsimulated anomalies that contribute to the training of reconstructive networks\nand condenses them into several methods, thus creating a comprehensive\nframework by selectively utilizing appropriate combinations.Furthermore, we\nintegrate this framework with a reconstruction-based approach and concurrently\npropose a split training strategy that alleviates the issue of overfitting\nwhile avoiding introducing interference to the reconstruction process. The\nevaluations conducted on the MVTec anomaly detection dataset demonstrate that\nour method outperforms the previous state-of-the-art approach, particularly in\nterms of object classes. To evaluate generalizability, we generate a simulated\ndataset comprising anomalies with diverse characteristics since the original\ntest samples only include specific types of anomalies and may lead to biased\nevaluations. Experimental results demonstrate that our approach exhibits\npromising potential for generalizing effectively to various unforeseen\nanomalies encountered in real-world scenarios.\n","authors":["Jiang Lin","Yaping Yan"],"pdf_url":"https://arxiv.org/pdf/2308.15068v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09305v2","updated":"2024-08-07T23:45:13Z","published":"2024-06-13T16:40:39Z","title":"Toffee: Efficient Million-Scale Dataset Construction for Subject-Driven\n  Text-to-Image Generation","summary":"  In subject-driven text-to-image generation, recent works have achieved\nsuperior performance by training the model on synthetic datasets containing\nnumerous image pairs. Trained on these datasets, generative models can produce\ntext-aligned images for specific subject from arbitrary testing image in a\nzero-shot manner. They even outperform methods which require additional\nfine-tuning on testing images. However, the cost of creating such datasets is\nprohibitive for most researchers. To generate a single training pair, current\nmethods fine-tune a pre-trained text-to-image model on the subject image to\ncapture fine-grained details, then use the fine-tuned model to create images\nfor the same subject based on creative text prompts. Consequently, constructing\na large-scale dataset with millions of subjects can require hundreds of\nthousands of GPU hours. To tackle this problem, we propose Toffee, an efficient\nmethod to construct datasets for subject-driven editing and generation.\nSpecifically, our dataset construction does not need any subject-level\nfine-tuning. After pre-training two generative models, we are able to generate\ninfinite number of high-quality samples. We construct the first large-scale\ndataset for subject-driven image editing and generation, which contains 5\nmillion image pairs, text prompts, and masks. Our dataset is 5 times the size\nof previous largest dataset, yet our cost is tens of thousands of GPU hours\nlower. To test the proposed dataset, we also propose a model which is capable\nof both subject-driven image editing and generation. By simply training the\nmodel on our proposed dataset, it obtains competitive results, illustrating the\neffectiveness of the proposed dataset construction framework.\n","authors":["Yufan Zhou","Ruiyi Zhang","Kaizhi Zheng","Nanxuan Zhao","Jiuxiang Gu","Zichao Wang","Xin Eric Wang","Tong Sun"],"pdf_url":"https://arxiv.org/pdf/2406.09305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04121v1","updated":"2024-08-07T23:09:23Z","published":"2024-08-07T23:09:23Z","title":"Can Rule-Based Insights Enhance LLMs for Radiology Report\n  Classification? Introducing the RadPrompt Methodology","summary":"  Developing imaging models capable of detecting pathologies from chest X-rays\ncan be cost and time-prohibitive for large datasets as it requires supervision\nto attain state-of-the-art performance. Instead, labels extracted from\nradiology reports may serve as distant supervision since these are routinely\ngenerated as part of clinical practice. Despite their widespread use, current\nrule-based methods for label extraction rely on extensive rule sets that are\nlimited in their robustness to syntactic variability. To alleviate these\nlimitations, we introduce RadPert, a rule-based system that integrates an\nuncertainty-aware information schema with a streamlined set of rules, enhancing\nperformance. Additionally, we have developed RadPrompt, a multi-turn prompting\nstrategy that leverages RadPert to bolster the zero-shot predictive\ncapabilities of large language models, achieving a statistically significant\nimprovement in weighted average F1 score over GPT-4 Turbo. Most notably,\nRadPrompt surpasses both its underlying models, showcasing the synergistic\npotential of LLMs with rule-based models. We have evaluated our methods on two\nEnglish Corpora: the MIMIC-CXR gold-standard test set and a gold-standard\ndataset collected from the Cambridge University Hospitals.\n","authors":["Panagiotis Fytas","Anna Breger","Ian Selby","Simon Baker","Shahab Shahipasand","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2408.04121v1.pdf","comment":"Accepted at BioNLP, ACL 2024"},{"id":"http://arxiv.org/abs/2403.00816v2","updated":"2024-08-07T22:40:27Z","published":"2024-02-26T01:17:50Z","title":"Read and Think: An Efficient Step-wise Multimodal Language Model for\n  Document Understanding and Reasoning","summary":"  Understanding the contents of multimodal documents is essential to accurately\nextract relevant evidence and use it for reasoning. Existing document\nunderstanding models tend to generate answers with a single word or phrase\ndirectly, ignoring the source document's evidence and lacking interpretability.\nIn this work, we address the lack of step-wise capabilities through data\naugmentation and extension. Specifically, We use Multi-modal Large Language\nModels (MLLMs), which have strong visual understanding and reasoning abilities,\nas data generators to generate step-wise question-and-answer pairs for document\nimages and use a high-performance LLM as the error detector to filter out noisy\ndata. This step-wise data generation pipeline is implemented using both\ntemplate-based and few-shot methods. We then use the generated high-quality\ndata to train a humanized document understanding and reasoning model,\nspecifically designed to solve complex questions that require reasoning or\nmulti-hop question answering, dubbed DocAssistant. Experimental results\ndemonstrate the effectiveness and application value of step-wise generation,\nshowing a 5 improvement on InfoVQA with complex layouts and a 7 improvement on\nChartQA with complex reasoning, compared to directly generated answers. We hope\nour work highlights the potential of synthetic data and encourages further\nexploration of multi-modal document reasoning capabilities.\n","authors":["Jinxu Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.00816v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04110v1","updated":"2024-08-07T22:23:13Z","published":"2024-08-07T22:23:13Z","title":"PaveCap: The First Multimodal Framework for Comprehensive Pavement\n  Condition Assessment with Dense Captioning and PCI Estimation","summary":"  This research introduces the first multimodal approach for pavement condition\nassessment, providing both quantitative Pavement Condition Index (PCI)\npredictions and qualitative descriptions. We introduce PaveCap, a novel\nframework for automated pavement condition assessment. The framework consists\nof two main parts: a Single-Shot PCI Estimation Network and a Dense Captioning\nNetwork. The PCI Estimation Network uses YOLOv8 for object detection, the\nSegment Anything Model (SAM) for zero-shot segmentation, and a four-layer\nconvolutional neural network to predict PCI. The Dense Captioning Network uses\na YOLOv8 backbone, a Transformer encoder-decoder architecture, and a\nconvolutional feed-forward module to generate detailed descriptions of pavement\nconditions. To train and evaluate these networks, we developed a pavement\ndataset with bounding box annotations, textual annotations, and PCI values. The\nresults of our PCI Estimation Network showed a strong positive correlation\n(0.70) between predicted and actual PCIs, demonstrating its effectiveness in\nautomating condition assessment. Also, the Dense Captioning Network produced\naccurate pavement condition descriptions, evidenced by high BLEU (0.7445), GLEU\n(0.5893), and METEOR (0.7252) scores. Additionally, the dense captioning model\nhandled complex scenarios well, even correcting some errors in the ground truth\ndata. The framework developed here can greatly improve infrastructure\nmanagement and decision18 making in pavement maintenance.\n","authors":["Blessing Agyei Kyem","Eugene Kofi Okrah Denteh","Joshua Kofi Asamoah","Armstrong Aboah"],"pdf_url":"https://arxiv.org/pdf/2408.04110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05285v2","updated":"2024-08-07T21:47:41Z","published":"2024-06-07T22:41:39Z","title":"VISTA3D: Versatile Imaging SegmenTation and Annotation model for 3D\n  Computed Tomography","summary":"  Medical image segmentation is a core component of precision medicine, and 3D\ncomputed tomography (CT) is one of the most important imaging techniques. A\nhighly accurate and clinically applicable segmentation foundation model will\ngreatly facilitate clinicians and researchers using CT images. Although\nexisting foundation models have attracted great interest, none are adequate for\n3D CT, either because they lack accurate automatic segmentation for large\ncohort analysis or the ability to segment novel classes. An ideal segmentation\nsolution should possess two features: accurate out-of-the-box performance\ncovering major organ classes, and effective adaptation or zero-shot ability to\nnovel structures. To achieve this goal, we introduce Versatile Imaging\nSegmenTation and Annotation model (VISTA3D). VISTA3D is trained systematically\non 11454 volumes and provides accurate out-of-the-box segmentation for 127\ncommon types of human anatomical structures and various lesions. Additionally,\nVISTA3D supports 3D interactive segmentation, allowing convenient editing of\nautomatic results and achieving state-of-the-art annotation results on unseen\nclasses. The novel model design and training recipe represent a promising step\ntoward developing a versatile medical image foundation model and will serve as\na valuable foundation for CT image analysis. Code and model weights are\navailable at https://github.com/Project-MONAI/VISTA\n","authors":["Yufan He","Pengfei Guo","Yucheng Tang","Andriy Myronenko","Vishwesh Nath","Ziyue Xu","Dong Yang","Can Zhao","Benjamin Simon","Mason Belue","Stephanie Harmon","Baris Turkbey","Daguang Xu","Wenqi Li"],"pdf_url":"https://arxiv.org/pdf/2406.05285v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04103v1","updated":"2024-08-07T21:44:56Z","published":"2024-08-07T21:44:56Z","title":"Decoding Visual Sentiment of Political Imagery","summary":"  How can we define visual sentiment when viewers systematically disagree on\ntheir perspectives? This study introduces a novel approach to visual sentiment\nanalysis by integrating attitudinal differences into visual sentiment\nclassification. Recognizing that societal divides, such as partisan\ndifferences, heavily influence sentiment labeling, we developed a dataset that\nreflects these divides. We then trained a deep learning multi-task multi-class\nmodel to predict visual sentiment from different ideological viewpoints.\nApplied to immigration-related images, our approach captures perspectives from\nboth Democrats and Republicans. By incorporating diverse perspectives into the\nlabeling and model training process, our strategy addresses the limitation of\nlabel ambiguity and demonstrates improved accuracy in visual sentiment\npredictions. Overall, our study advocates for a paradigm shift in decoding\nvisual sentiment toward creating classifiers that more accurately reflect the\nsentiments generated by humans.\n","authors":["Olga Gasparyan","Elena Sirotkina"],"pdf_url":"https://arxiv.org/pdf/2408.04103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04102v1","updated":"2024-08-07T21:44:29Z","published":"2024-08-07T21:44:29Z","title":"ArtVLM: Attribute Recognition Through Vision-Based Prefix Language\n  Modeling","summary":"  Recognizing and disentangling visual attributes from objects is a foundation\nto many computer vision applications. While large vision language\nrepresentations like CLIP had largely resolved the task of zero-shot object\nrecognition, zero-shot visual attribute recognition remains a challenge because\nCLIP's contrastively-learned vision-language representation cannot effectively\ncapture object-attribute dependencies. In this paper, we target this weakness\nand propose a sentence generation-based retrieval formulation for attribute\nrecognition that is novel in 1) explicitly modeling a to-be-measured and\nretrieved object-attribute relation as a conditional probability graph, which\nconverts the recognition problem into a dependency-sensitive language-modeling\nproblem, and 2) applying a large pretrained Vision-Language Model (VLM) on this\nreformulation and naturally distilling its knowledge of image-object-attribute\nrelations to use towards attribute recognition. Specifically, for each\nattribute to be recognized on an image, we measure the visual-conditioned\nprobability of generating a short sentence encoding the attribute's relation to\nobjects on the image. Unlike contrastive retrieval, which measures likelihood\nby globally aligning elements of the sentence to the image, generative\nretrieval is sensitive to the order and dependency of objects and attributes in\nthe sentence. We demonstrate through experiments that generative retrieval\nconsistently outperforms contrastive retrieval on two visual reasoning\ndatasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual\nGenome Attribute Ranking (VGARank).\n","authors":["William Y. Zhu","Keren Ye","Junjie Ke","Jiahui Yu","Leonidas Guibas","Peyman Milanfar","Feng Yang"],"pdf_url":"https://arxiv.org/pdf/2408.04102v1.pdf","comment":"Accepted at ECCV 2024"},{"id":"http://arxiv.org/abs/2408.04091v1","updated":"2024-08-07T21:13:49Z","published":"2024-08-07T21:13:49Z","title":"The Quest for Early Detection of Retinal Disease: 3D CycleGAN-based\n  Translation of Optical Coherence Tomography into Confocal Microscopy","summary":"  Optical coherence tomography (OCT) and confocal microscopy are pivotal in\nretinal imaging, offering distinct advantages and limitations. In vivo OCT\noffers rapid, non-invasive imaging but can suffer from clarity issues and\nmotion artifacts, while ex vivo confocal microscopy, providing high-resolution,\ncellular-detailed color images, is invasive and raises ethical concerns. To\nbridge the benefits of both modalities, we propose a novel framework based on\nunsupervised 3D CycleGAN for translating unpaired in vivo OCT to ex vivo\nconfocal microscopy images. This marks the first attempt to exploit the\ninherent 3D information of OCT and translate it into the rich, detailed color\ndomain of confocal microscopy. We also introduce a unique dataset,\nOCT2Confocal, comprising mouse OCT and confocal retinal images, facilitating\nthe development of and establishing a benchmark for cross-modal image\ntranslation research. Our model has been evaluated both quantitatively and\nqualitatively, achieving Fr\\'echet Inception Distance (FID) scores of 0.766 and\nKernel Inception Distance (KID) scores as low as 0.153, and leading subjective\nMean Opinion Scores (MOS). Our model demonstrated superior image fidelity and\nquality with limited data over existing methods. Our approach effectively\nsynthesizes color information from 3D confocal images, closely approximating\ntarget outcomes and suggesting enhanced potential for diagnostic and monitoring\napplications in ophthalmology.\n","authors":["Xin Tian","Nantheera Anantrasirichai","Lindsay Nicholson","Alin Achim"],"pdf_url":"https://arxiv.org/pdf/2408.04091v1.pdf","comment":"30 pages, 11 figures, 5 tables"},{"id":"http://arxiv.org/abs/2407.19547v2","updated":"2024-08-07T20:43:10Z","published":"2024-07-28T17:46:15Z","title":"Temporal Feature Matters: A Framework for Diffusion Model Quantization","summary":"  The Diffusion models, widely used for image generation, face significant\nchallenges related to their broad applicability due to prolonged inference\ntimes and high memory demands. Efficient Post-Training Quantization (PTQ) is\ncrucial to address these issues. However, unlike traditional models, diffusion\nmodels critically rely on the time-step for the multi-round denoising.\nTypically, each time-step is encoded into a hypersensitive temporal feature by\nseveral modules. Despite this, existing PTQ methods do not optimize these\nmodules individually. Instead, they employ unsuitable reconstruction objectives\nand complex calibration methods, leading to significant disturbances in the\ntemporal feature and denoising trajectory, as well as reduced compression\nefficiency. To address these challenges, we introduce a novel quantization\nframework that includes three strategies: 1) TIB-based Maintenance: Based on\nour innovative Temporal Information Block (TIB) definition, Temporal\nInformation-aware Reconstruction (TIAR) and Finite Set Calibration (FSC) are\ndeveloped to efficiently align original temporal features. 2) Cache-based\nMaintenance: Instead of indirect and complex optimization for the related\nmodules, pre-computing and caching quantized counterparts of temporal features\nare developed to minimize errors. 3) Disturbance-aware Selection: Employ\ntemporal feature errors to guide a fine-grained selection between the two\nmaintenance strategies for further disturbance reduction. This framework\npreserves most of the temporal information and ensures high-quality end-to-end\ngeneration. Extensive testing on various datasets, diffusion models and\nhardware confirms our superior performance and acceleration..\n","authors":["Yushi Huang","Ruihao Gong","Xianglong Liu","Jing Liu","Yuhang Li","Jiwen Lu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2407.19547v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2311.16503"},{"id":"http://arxiv.org/abs/2408.04077v1","updated":"2024-08-07T20:36:20Z","published":"2024-08-07T20:36:20Z","title":"PushPull-Net: Inhibition-driven ResNet robust to image corruptions","summary":"  We introduce a novel computational unit, termed PushPull-Conv, in the first\nlayer of a ResNet architecture, inspired by the anti-phase inhibition\nphenomenon observed in the primary visual cortex. This unit redefines the\ntraditional convolutional layer by implementing a pair of complementary\nfilters: a trainable push kernel and its counterpart, the pull kernel. The push\nkernel (analogous to traditional convolution) learns to respond to specific\nstimuli, while the pull kernel reacts to the same stimuli but of opposite\ncontrast. This configuration enhances stimulus selectivity and effectively\ninhibits response in regions lacking preferred stimuli. This effect is\nattributed to the push and pull kernels, which produce responses of comparable\nmagnitude in such regions, thereby neutralizing each other. The incorporation\nof the PushPull-Conv into ResNets significantly increases their robustness to\nimage corruption. Our experiments with benchmark corruption datasets show that\nthe PushPull-Conv can be combined with other data augmentation techniques to\nfurther improve model robustness. We set a new robustness benchmark on ResNet50\nachieving an $mCE$ of 49.95$\\%$ on ImageNet-C when combining PRIME augmentation\nwith PushPull inhibition.\n","authors":["Guru Swaroop Bennabhaktula","Enrique Alegre","Nicola Strisciuglio","George Azzopardi"],"pdf_url":"https://arxiv.org/pdf/2408.04077v1.pdf","comment":"Accepted at ICPR 2024, code available at\n  https://github.com/bgswaroop/pushpull-conv"},{"id":"http://arxiv.org/abs/2403.05466v2","updated":"2024-08-07T20:33:27Z","published":"2024-03-08T17:29:51Z","title":"Grasping Trajectory Optimization with Point Clouds","summary":"  We introduce a new trajectory optimization method for robotic grasping based\non a point-cloud representation of robots and task spaces. In our method,\nrobots are represented by 3D points on their link surfaces. The task space of a\nrobot is represented by a point cloud that can be obtained from depth sensors.\nUsing the point-cloud representation, goal reaching in grasping can be\nformulated as point matching, while collision avoidance can be efficiently\nachieved by querying the signed distance values of the robot points in the\nsigned distance field of the scene points. Consequently, a constrained\nnonlinear optimization problem is formulated to solve the joint motion and\ngrasp planning problem. The advantage of our method is that the point-cloud\nrepresentation is general to be used with any robot in any environment. We\ndemonstrate the effectiveness of our method by performing experiments on a\ntabletop scene and a shelf scene for grasping with a Fetch mobile manipulator\nand a Franka Panda arm. The project page is available at\n\\url{https://irvlutd.github.io/GraspTrajOpt}\n","authors":["Yu Xiang","Sai Haneesh Allu","Rohith Peddi","Tyler Summers","Vibhav Gogate"],"pdf_url":"https://arxiv.org/pdf/2403.05466v2.pdf","comment":"Published in IROS 2024"},{"id":"http://arxiv.org/abs/2405.06786v2","updated":"2024-08-07T20:27:41Z","published":"2024-05-10T19:26:17Z","title":"SAM3D: Zero-Shot Semi-Automatic Segmentation in 3D Medical Images with\n  the Segment Anything Model","summary":"  We introduce SAM3D, a new approach to semi-automatic zero-shot segmentation\nof 3D images building on the existing Segment Anything Model. We achieve fast\nand accurate segmentations in 3D images with a four-step strategy involving:\nuser prompting with 3D polylines, volume slicing along multiple axes,\nslice-wide inference with a pretrained model, and recomposition and refinement\nin 3D. We evaluated SAM3D performance qualitatively on an array of imaging\nmodalities and anatomical structures and quantify performance for specific\nstructures in abdominal pelvic CT and brain MRI. Notably, our method achieves\ngood performance with zero model training or finetuning, making it particularly\nuseful for tasks with a scarcity of preexisting labeled data. By enabling users\nto create 3D segmentations of unseen data quickly and with dramatically reduced\nmanual input, these methods have the potential to aid surgical planning and\neducation, diagnostic imaging, and scientific research.\n","authors":["Trevor J. Chan","Aarush Sahni","Yijin Fang","Jie Li","Alisha Luthra","Alison Pouch","Chamith S. Rajapakse"],"pdf_url":"https://arxiv.org/pdf/2405.06786v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04076v1","updated":"2024-08-07T20:26:35Z","published":"2024-08-07T20:26:35Z","title":"Multi-scale structural complexity as a quantitative measure of visual\n  complexity","summary":"  While intuitive for humans, the concept of visual complexity is hard to\ndefine and quantify formally. We suggest adopting the multi-scale structural\ncomplexity (MSSC) measure, an approach that defines structural complexity of an\nobject as the amount of dissimilarities between distinct scales in its\nhierarchical organization. In this work, we apply MSSC to the case of visual\nstimuli, using an open dataset of images with subjective complexity scores\nobtained from human participants (SAVOIAS). We demonstrate that MSSC correlates\nwith subjective complexity on par with other computational complexity measures,\nwhile being more intuitive by definition, consistent across categories of\nimages, and easier to compute. We discuss objective and subjective elements\ninherently present in human perception of complexity and the domains where the\ntwo are more likely to diverge. We show how the multi-scale nature of MSSC\nallows further investigation of complexity as it is perceived by humans.\n","authors":["Anna Kravchenko","Andrey A. Bagrov","Mikhail I. Katsnelson","Veronica Dudarev"],"pdf_url":"https://arxiv.org/pdf/2408.04076v1.pdf","comment":"16 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2408.04072v1","updated":"2024-08-07T20:19:20Z","published":"2024-08-07T20:19:20Z","title":"AEye: A Visualization Tool for Image Datasets","summary":"  Image datasets serve as the foundation for machine learning models in\ncomputer vision, significantly influencing model capabilities, performance, and\nbiases alongside architectural considerations. Therefore, understanding the\ncomposition and distribution of these datasets has become increasingly crucial.\nTo address the need for intuitive exploration of these datasets, we propose\nAEye, an extensible and scalable visualization tool tailored to image datasets.\nAEye utilizes a contrastively trained model to embed images into semantically\nmeaningful high-dimensional representations, facilitating data clustering and\norganization. To visualize the high-dimensional representations, we project\nthem onto a two-dimensional plane and arrange images in layers so users can\nseamlessly navigate and explore them interactively. AEye facilitates semantic\nsearch functionalities for both text and image queries, enabling users to\nsearch for content. We open-source the codebase for AEye, and provide a simple\nconfiguration to add datasets.\n","authors":["Florian Grötschla","Luca A. Lanzendörfer","Marco Calzavara","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2408.04072v1.pdf","comment":"Accepted at IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2408.04065v1","updated":"2024-08-07T20:07:25Z","published":"2024-08-07T20:07:25Z","title":"Do Sharpness-based Optimizers Improve Generalization in Medical Image\n  Analysis?","summary":"  Effective clinical deployment of deep learning models in healthcare demands\nhigh generalization performance to ensure accurate diagnosis and treatment\nplanning. In recent years, significant research has focused on improving the\ngeneralization of deep learning models by regularizing the sharpness of the\nloss landscape. Among the optimization approaches that explicitly minimize\nsharpness, Sharpness-Aware Minimization (SAM) has shown potential in enhancing\ngeneralization performance on general domain image datasets. This success has\nled to the development of several advanced sharpness-based algorithms aimed at\naddressing the limitations of SAM, such as Adaptive SAM, surrogate-Gap SAM,\nWeighted SAM, and Curvature Regularized SAM. These sharpness-based optimizers\nhave shown improvements in model generalization compared to conventional\nstochastic gradient descent optimizers and their variants on general domain\nimage datasets, but they have not been thoroughly evaluated on medical images.\nThis work provides a review of recent sharpness-based methods for improving the\ngeneralization of deep learning networks and evaluates the methods performance\non medical breast ultrasound images. Our findings indicate that the initial SAM\nmethod successfully enhances the generalization of various deep learning\nmodels. While Adaptive SAM improves generalization of convolutional neural\nnetworks, it fails to do so for vision transformers. Other sharpness-based\noptimizers, however, do not demonstrate consistent results. The results reveal\nthat, contrary to findings in the non-medical domain, SAM is the only\nrecommended sharpness-based optimizer that consistently improves generalization\nin medical image analysis, and further research is necessary to refine the\nvariants of SAM to enhance generalization performance in this field\n","authors":["Mohamed Hassan","Aleksander Vakanski","Min Xian"],"pdf_url":"https://arxiv.org/pdf/2408.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13717v4","updated":"2024-08-07T19:31:30Z","published":"2023-11-22T22:21:26Z","title":"Feature Extraction for Generative Medical Imaging Evaluation: New\n  Evidence Against an Evolving Trend","summary":"  Fr\\'echet Inception Distance (FID) is a widely used metric for assessing\nsynthetic image quality. It relies on an ImageNet-based feature extractor,\nmaking its applicability to medical imaging unclear. A recent trend is to adapt\nFID to medical imaging through feature extractors trained on medical images.\nOur study challenges this practice by demonstrating that ImageNet-based\nextractors are more consistent and aligned with human judgment than their\nRadImageNet counterparts. We evaluated sixteen StyleGAN2 networks across four\nmedical imaging modalities and four data augmentation techniques with Fr\\'echet\ndistances (FDs) computed using eleven ImageNet or RadImageNet-trained feature\nextractors. Comparison with human judgment via visual Turing tests revealed\nthat ImageNet-based extractors produced rankings consistent with human\njudgment, with the FD derived from the ImageNet-trained SwAV extractor\nsignificantly correlating with expert evaluations. In contrast,\nRadImageNet-based rankings were volatile and inconsistent with human judgment.\nOur findings challenge prevailing assumptions, providing novel evidence that\nmedical image-trained feature extractors do not inherently improve FDs and can\neven compromise their reliability. Our code is available at\nhttps://github.com/mckellwoodland/fid-med-eval.\n","authors":["McKell Woodland","Austin Castelo","Mais Al Taie","Jessica Albuquerque Marques Silva","Mohamed Eltaher","Frank Mohn","Alexander Shieh","Suprateek Kundu","Joshua P. Yung","Ankit B. Patel","Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2311.13717v4.pdf","comment":"Preprint of manuscript early accepted to MICCAI 2024"},{"id":"http://arxiv.org/abs/2402.09611v2","updated":"2024-08-07T19:27:53Z","published":"2024-02-14T22:57:03Z","title":"Towards Privacy-Aware Sign Language Translation at Scale","summary":"  A major impediment to the advancement of sign language translation (SLT) is\ndata scarcity. Much of the sign language data currently available on the web\ncannot be used for training supervised models due to the lack of aligned\ncaptions. Furthermore, scaling SLT using large-scale web-scraped datasets bears\nprivacy risks due to the presence of biometric information, which the\nresponsible development of SLT technologies should account for. In this work,\nwe propose a two-stage framework for privacy-aware SLT at scale that addresses\nboth of these issues. We introduce SSVP-SLT, which leverages self-supervised\nvideo pretraining on anonymized and unannotated videos, followed by supervised\nSLT finetuning on a curated parallel dataset. SSVP-SLT achieves\nstate-of-the-art finetuned and zero-shot gloss-free SLT performance on the\nHow2Sign dataset, outperforming the strongest respective baselines by over 3\nBLEU-4. Based on controlled experiments, we further discuss the advantages and\nlimitations of self-supervised pretraining and anonymization via facial\nobfuscation for SLT.\n","authors":["Phillip Rust","Bowen Shi","Skyler Wang","Necati Cihan Camgöz","Jean Maillard"],"pdf_url":"https://arxiv.org/pdf/2402.09611v2.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2307.07176v3","updated":"2024-08-07T19:08:36Z","published":"2023-07-14T06:00:08Z","title":"SafeDreamer: Safe Reinforcement Learning with World Models","summary":"  The deployment of Reinforcement Learning (RL) in real-world applications is\nconstrained by its failure to satisfy safety criteria. Existing Safe\nReinforcement Learning (SafeRL) methods, which rely on cost functions to\nenforce safety, often fail to achieve zero-cost performance in complex\nscenarios, especially vision-only tasks. These limitations are primarily due to\nmodel inaccuracies and inadequate sample efficiency. The integration of the\nworld model has proven effective in mitigating these shortcomings. In this\nwork, we introduce SafeDreamer, a novel algorithm incorporating\nLagrangian-based methods into world model planning processes within the\nsuperior Dreamer framework. Our method achieves nearly zero-cost performance on\nvarious tasks, spanning low-dimensional and vision-only input, within the\nSafety-Gymnasium benchmark, showcasing its efficacy in balancing performance\nand safety in RL tasks. Further details can be found in the code repository:\n\\url{https://github.com/PKU-Alignment/SafeDreamer}.\n","authors":["Weidong Huang","Jiaming Ji","Chunhe Xia","Borong Zhang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2307.07176v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2408.04034v1","updated":"2024-08-07T18:30:18Z","published":"2024-08-07T18:30:18Z","title":"Task-oriented Sequential Grounding in 3D Scenes","summary":"  Grounding natural language in physical 3D environments is essential for the\nadvancement of embodied artificial intelligence. Current datasets and models\nfor 3D visual grounding predominantly focus on identifying and localizing\nobjects from static, object-centric descriptions. These approaches do not\nadequately address the dynamic and sequential nature of task-oriented grounding\nnecessary for practical applications. In this work, we propose a new task:\nTask-oriented Sequential Grounding in 3D scenes, wherein an agent must follow\ndetailed step-by-step instructions to complete daily activities by locating a\nsequence of target objects in indoor scenes. To facilitate this task, we\nintroduce SG3D, a large-scale dataset containing 22,346 tasks with 112,236\nsteps across 4,895 real-world 3D scenes. The dataset is constructed using a\ncombination of RGB-D scans from various 3D scene datasets and an automated task\ngeneration pipeline, followed by human verification for quality assurance. We\nadapted three state-of-the-art 3D visual grounding models to the sequential\ngrounding task and evaluated their performance on SG3D. Our results reveal that\nwhile these models perform well on traditional benchmarks, they face\nsignificant challenges with task-oriented sequential grounding, underscoring\nthe need for further research in this area.\n","authors":["Zhuofan Zhang","Ziyu Zhu","Pengxiang Li","Tengyu Liu","Xiaojian Ma","Yixin Chen","Baoxiong Jia","Siyuan Huang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.04034v1.pdf","comment":"website: https://sg-3d.github.io/"},{"id":"http://arxiv.org/abs/2312.02976v2","updated":"2024-08-07T18:11:51Z","published":"2023-12-05T18:59:45Z","title":"SPOC: Imitating Shortest Paths in Simulation Enables Effective\n  Navigation and Manipulation in the Real World","summary":"  Reinforcement learning (RL) with dense rewards and imitation learning (IL)\nwith human-generated trajectories are the most widely used approaches for\ntraining modern embodied agents. RL requires extensive reward shaping and\nauxiliary losses and is often too slow and ineffective for long-horizon tasks.\nWhile IL with human supervision is effective, collecting human trajectories at\nscale is extremely expensive. In this work, we show that imitating\nshortest-path planners in simulation produces agents that, given a language\ninstruction, can proficiently navigate, explore, and manipulate objects in both\nsimulation and in the real world using only RGB sensors (no depth map or GPS\ncoordinates). This surprising result is enabled by our end-to-end,\ntransformer-based, SPOC architecture, powerful visual encoders paired with\nextensive image augmentation, and the dramatic scale and diversity of our\ntraining data: millions of frames of shortest-path-expert trajectories\ncollected inside approximately 200,000 procedurally generated houses containing\n40,000 unique 3D assets. Our models, data, training code, and newly proposed\n10-task benchmarking suite CHORES are available in\nhttps://spoc-robot.github.io.\n","authors":["Kiana Ehsani","Tanmay Gupta","Rose Hendrix","Jordi Salvador","Luca Weihs","Kuo-Hao Zeng","Kunal Pratap Singh","Yejin Kim","Winson Han","Alvaro Herrasti","Ranjay Krishna","Dustin Schwenk","Eli VanderBilt","Aniruddha Kembhavi"],"pdf_url":"https://arxiv.org/pdf/2312.02976v2.pdf","comment":"First six authors contributed equally. Project page:\n  https://spoc-robot.github.io/"},{"id":"http://arxiv.org/abs/2408.04015v1","updated":"2024-08-07T18:04:01Z","published":"2024-08-07T18:04:01Z","title":"Image-to-LaTeX Converter for Mathematical Formulas and Text","summary":"  In this project, we train a vision encoder-decoder model to generate LaTeX\ncode from images of mathematical formulas and text. Utilizing a diverse\ncollection of image-to-LaTeX data, we build two models: a base model with a\nSwin Transformer encoder and a GPT-2 decoder, trained on machine-generated\nimages, and a fine-tuned version enhanced with Low-Rank Adaptation (LoRA)\ntrained on handwritten formulas. We then compare the BLEU performance of our\nspecialized model on a handwritten test set with other similar models, such as\nPix2Text, TexTeller, and Sumen. Through this project, we contribute open-source\nmodels for converting images to LaTeX and provide from-scratch code for\nbuilding these models with distributed training and GPU optimizations.\n","authors":["Daniil Gurgurov","Aleksey Morshnev"],"pdf_url":"https://arxiv.org/pdf/2408.04015v1.pdf","comment":"4 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2408.03936v1","updated":"2024-08-07T17:54:21Z","published":"2024-08-07T17:54:21Z","title":"SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic\n  Performance for Mercosur Common Nomenclature","summary":"  Natural language processing (NLP) has seen significant advancements with the\nadvent of large language models (LLMs). However, substantial improvements are\nstill needed for languages other than English, especially for specific domains\nlike the applications of Mercosur Common Nomenclature (NCM), a Brazilian\nHarmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a\nfoundational Portuguese LLM, as an LLM source to implement the NCM application\nprocessing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)\ntechnique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.\nThis approach retains the chain-of-thought (CoT) methodology for prompt\ndevelopment in a more concise and streamlined manner, utilizing brief and\nfocused documents for training. The proposed model demonstrates an efficient\nand cost-effective alternative for fine-tuning smaller LLMs, significantly\noutperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the\nresearch focuses on NCM applications, the methodology can be easily adapted for\nHS applications worldwide.\n","authors":["Vinícius Di Oliveira","Yuri Façanha Bezerra","Li Weigang","Pedro Carvalho Brom","Victor Rafael R. Celestino"],"pdf_url":"https://arxiv.org/pdf/2408.03936v1.pdf","comment":"13 pages, 1 figure, to be publish in International Conference on Web\n  Information Systems and Technologies - WEBIST 2024 proceedings"},{"id":"http://arxiv.org/abs/2310.12294v3","updated":"2024-08-07T17:46:32Z","published":"2023-10-18T19:55:11Z","title":"Open-Set Multivariate Time-Series Anomaly Detection","summary":"  Numerous methods for time-series anomaly detection (TSAD) have emerged in\nrecent years, most of which are unsupervised and assume that only normal\nsamples are available during the training phase, due to the challenge of\nobtaining abnormal data in real-world scenarios. Still, limited samples of\nabnormal data are often available, albeit they are far from representative of\nall possible anomalies. Supervised methods can be utilized to classify normal\nand seen anomalies, but they tend to overfit to the seen anomalies present\nduring training, hence, they fail to generalize to unseen anomalies. We propose\nthe first algorithm to address the open-set TSAD problem, called Multivariate\nOpen-Set Time-Series Anomaly Detector (MOSAD), that leverages only a few shots\nof labeled anomalies during the training phase in order to achieve superior\nanomaly detection performance compared to both supervised and unsupervised TSAD\nalgorithms. MOSAD is a novel multi-head TSAD framework with a shared\nrepresentation space and specialized heads, including the Generative head, the\nDiscriminative head, and the Anomaly-Aware Contrastive head. The latter\nproduces a superior representation space for anomaly detection compared to\nconventional supervised contrastive learning. Extensive experiments on three\nreal-world datasets establish MOSAD as a new state-of-the-art in the TSAD\nfield.\n","authors":["Thomas Lai","Thi Kieu Khanh Ho","Narges Armanfard"],"pdf_url":"https://arxiv.org/pdf/2310.12294v3.pdf","comment":"Accepted to ECAI-2024"},{"id":"http://arxiv.org/abs/2408.03915v1","updated":"2024-08-07T17:20:52Z","published":"2024-08-07T17:20:52Z","title":"Hard to Explain: On the Computational Hardness of In-Distribution Model\n  Interpretation","summary":"  The ability to interpret Machine Learning (ML) models is becoming\nincreasingly essential. However, despite significant progress in the field,\nthere remains a lack of rigorous characterization regarding the innate\ninterpretability of different models. In an attempt to bridge this gap, recent\nwork has demonstrated that it is possible to formally assess interpretability\nby studying the computational complexity of explaining the decisions of various\nmodels. In this setting, if explanations for a particular model can be obtained\nefficiently, the model is considered interpretable (since it can be explained\n``easily''). However, if generating explanations over an ML model is\ncomputationally intractable, it is considered uninterpretable. Prior research\nidentified two key factors that influence the complexity of interpreting an ML\nmodel: (i) the type of the model (e.g., neural networks, decision trees, etc.);\nand (ii) the form of explanation (e.g., contrastive explanations, Shapley\nvalues, etc.). In this work, we claim that a third, important factor must also\nbe considered for this analysis -- the underlying distribution over which the\nexplanation is obtained. Considering the underlying distribution is key in\navoiding explanations that are socially misaligned, i.e., convey information\nthat is biased and unhelpful to users. We demonstrate the significant influence\nof the underlying distribution on the resulting overall interpretation\ncomplexity, in two settings: (i) prediction models paired with an external\nout-of-distribution (OOD) detector; and (ii) prediction models designed to\ninherently generate socially aligned explanations. Our findings prove that the\nexpressiveness of the distribution can significantly influence the overall\ncomplexity of interpretation, and identify essential prerequisites that a model\nmust possess to generate socially aligned explanations.\n","authors":["Guy Amir","Shahaf Bassan","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2408.03915v1.pdf","comment":"To appear in ECAI 2024"},{"id":"http://arxiv.org/abs/2408.03913v1","updated":"2024-08-07T17:19:15Z","published":"2024-08-07T17:19:15Z","title":"AdapMTL: Adaptive Pruning Framework for Multitask Learning Model","summary":"  In the domain of multimedia and multimodal processing, the efficient handling\nof diverse data streams such as images, video, and sensor data is paramount.\nModel compression and multitask learning (MTL) are crucial in this field,\noffering the potential to address the resource-intensive demands of processing\nand interpreting multiple forms of media simultaneously. However, effectively\ncompressing a multitask model presents significant challenges due to the\ncomplexities of balancing sparsity allocation and accuracy performance across\nmultiple tasks. To tackle these challenges, we propose AdapMTL, an adaptive\npruning framework for MTL models. AdapMTL leverages multiple learnable soft\nthresholds independently assigned to the shared backbone and the task-specific\nheads to capture the nuances in different components' sensitivity to pruning.\nDuring training, it co-optimizes the soft thresholds and MTL model weights to\nautomatically determine the suitable sparsity level at each component to\nachieve both high task accuracy and high overall sparsity. It further\nincorporates an adaptive weighting mechanism that dynamically adjusts the\nimportance of task-specific losses based on each task's robustness to pruning.\nWe demonstrate the effectiveness of AdapMTL through comprehensive experiments\non popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with different\narchitectures, showcasing superior performance compared to state-of-the-art\npruning methods.\n","authors":["Mingcan Xiang","Steven Jiaxun Tang","Qizheng Yang","Hui Guan","Tongping Liu"],"pdf_url":"https://arxiv.org/pdf/2408.03913v1.pdf","comment":"13 pages, 9 figures, Published at ACM Multimedia (ACM MM) 2024"},{"id":"http://arxiv.org/abs/2408.03909v1","updated":"2024-08-07T17:13:46Z","published":"2024-08-07T17:13:46Z","title":"LaFA: Latent Feature Attacks on Non-negative Matrix Factorization","summary":"  As Machine Learning (ML) applications rapidly grow, concerns about\nadversarial attacks compromising their reliability have gained significant\nattention. One unsupervised ML method known for its resilience to such attacks\nis Non-negative Matrix Factorization (NMF), an algorithm that decomposes input\ndata into lower-dimensional latent features. However, the introduction of\npowerful computational tools such as Pytorch enables the computation of\ngradients of the latent features with respect to the original data, raising\nconcerns about NMF's reliability. Interestingly, naively deriving the\nadversarial loss for NMF as in the case of ML would result in the\nreconstruction loss, which can be shown theoretically to be an ineffective\nattacking objective. In this work, we introduce a novel class of attacks in NMF\ntermed Latent Feature Attacks (LaFA), which aim to manipulate the latent\nfeatures produced by the NMF process. Our method utilizes the Feature Error\n(FE) loss directly on the latent features. By employing FE loss, we generate\nperturbations in the original data that significantly affect the extracted\nlatent features, revealing vulnerabilities akin to those found in other ML\ntechniques. To handle large peak-memory overhead from gradient back-propagation\nin FE attacks, we develop a method based on implicit differentiation which\nenables their scaling to larger datasets. We validate NMF vulnerabilities and\nFE attacks effectiveness through extensive experiments on synthetic and\nreal-world data.\n","authors":["Minh Vu","Ben Nebgen","Erik Skau","Geigh Zollicoffer","Juan Castorena","Kim Rasmussen","Boian Alexandrov","Manish Bhattarai"],"pdf_url":"https://arxiv.org/pdf/2408.03909v1.pdf","comment":"LA-UR-24-26951"},{"id":"http://arxiv.org/abs/2402.14049v2","updated":"2024-08-07T17:09:10Z","published":"2024-02-21T18:25:04Z","title":"Generative Adversarial Models for Extreme Geospatial Downscaling","summary":"  Addressing the challenges of climate change requires accurate and\nhigh-resolution mapping of geospatial data, especially climate and weather\nvariables. However, many existing geospatial datasets, such as the gridded\noutputs of the state-of-the-art numerical climate models (e.g., general\ncirculation models), are only available at very coarse spatial resolutions due\nto the model complexity and extremely high computational demand.\nDeep-learning-based methods, particularly generative adversarial networks\n(GANs) and their variants, have proved effective for refining natural images\nand have shown great promise in improving geospatial datasets. This paper\ndescribes a conditional GAN-based stochastic geospatial downscaling method that\ncan accommodates very high scaling factors. Compared to most existing methods,\nthe method can generate high-resolution accurate climate datasets from very\nlow-resolution inputs. More importantly, the method explicitly considers the\nuncertainty inherent to the downscaling process that tends to be ignored in\nexisting methods. Given an input, the method can produce a multitude of\nplausible high-resolution samples instead of one single deterministic result.\nThese samples allow for an empirical exploration and inferences of model\nuncertainty and robustness. With a case study of gridded climate datasets (wind\nvelocity and solar irradiance), we demonstrate the performances of the\nframework in downscaling tasks with large scaling factors (up to $64\\times$)\nand highlight the advantages of the framework with a comprehensive comparison\nwith commonly used and most recent downscaling methods, including area-to-point\n(ATP) kriging, deep image prior (DIP), enhanced super-resolution generative\nadversarial networks (ESRGAN), physics-informed resolution-enhancing GAN (PhIRE\nGAN), and an efficient diffusion model for remote sensing image\nsuper-resolution (EDiffSR).\n","authors":["Guiye Li","Guofeng Cao"],"pdf_url":"https://arxiv.org/pdf/2402.14049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13218v3","updated":"2024-08-07T16:57:06Z","published":"2024-07-18T07:04:33Z","title":"LiNR: Model Based Neural Retrieval on GPUs at LinkedIn","summary":"  This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.\n","authors":["Fedor Borisyuk","Qingquan Song","Mingzhou Zhou","Ganesh Parameswaran","Madhu Arun","Siva Popuri","Tugrul Bingol","Zhuotao Pei","Kuang-Hsuan Lee","Lu Zheng","Qizhan Shao","Ali Naqvi","Sen Zhou","Aman Gupta"],"pdf_url":"https://arxiv.org/pdf/2407.13218v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04262v3","updated":"2024-08-07T16:54:40Z","published":"2023-02-08T18:55:49Z","title":"Algorithmic Collective Action in Machine Learning","summary":"  We initiate a principled study of algorithmic collective action on digital\nplatforms that deploy machine learning algorithms. We propose a simple\ntheoretical model of a collective interacting with a firm's learning algorithm.\nThe collective pools the data of participating individuals and executes an\nalgorithmic strategy by instructing participants how to modify their own data\nto achieve a collective goal. We investigate the consequences of this model in\nthree fundamental learning-theoretic settings: the case of a nonparametric\noptimal learning algorithm, a parametric risk minimizer, and gradient-based\noptimization. In each setting, we come up with coordinated algorithmic\nstrategies and characterize natural success criteria as a function of the\ncollective's size. Complementing our theory, we conduct systematic experiments\non a skill classification task involving tens of thousands of resumes from a\ngig platform for freelancers. Through more than two thousand model training\nruns of a BERT-like language model, we see a striking correspondence emerge\nbetween our empirical observations and the predictions made by our theory.\nTaken together, our theory and experiments broadly support the conclusion that\nalgorithmic collectives of exceedingly small fractional size can exert\nsignificant control over a platform's learning algorithm.\n","authors":["Moritz Hardt","Eric Mazumdar","Celestine Mendler-Dünner","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2302.04262v3.pdf","comment":"Published at ICML 2023; Revision corrects epsilon-dependence in the\n  analysis"},{"id":"http://arxiv.org/abs/2402.06859v2","updated":"2024-08-07T16:54:23Z","published":"2024-02-10T01:47:10Z","title":"LiRank: Industrial Large Scale Ranking Models at LinkedIn","summary":"  We present LiRank, a large-scale ranking framework at LinkedIn that brings to\nproduction state-of-the-art modeling architectures and optimization methods. We\nunveil several modeling improvements, including Residual DCN, which adds\nattention and residual connections to the famous DCNv2 architecture. We share\ninsights into combining and tuning SOTA architectures to create a unified\nmodel, including Dense Gating, Transformers and Residual DCN. We also propose\nnovel techniques for calibration and describe how we productionalized deep\nlearning based explore/exploit methods. To enable effective, production-grade\nserving of large ranking models, we detail how to train and compress models\nusing quantization and vocabulary compression. We provide details about the\ndeployment setup for large-scale use cases of Feed ranking, Jobs\nRecommendations, and Ads click-through rate (CTR) prediction. We summarize our\nlearnings from various A/B tests by elucidating the most effective technical\napproaches. These ideas have contributed to relative metrics improvements\nacross the board at LinkedIn: +0.5% member sessions in the Feed, +1.76%\nqualified job applications for Jobs search and recommendations, and +4.3% for\nAds CTR. We hope this work can provide practical insights and solutions for\npractitioners interested in leveraging large-scale deep ranking systems.\n","authors":["Fedor Borisyuk","Mingzhou Zhou","Qingquan Song","Siyu Zhu","Birjodh Tiwana","Ganesh Parameswaran","Siddharth Dangi","Lars Hertel","Qiang Xiao","Xiaochen Hou","Yunbo Ouyang","Aman Gupta","Sheallika Singh","Dan Liu","Hailing Cheng","Lei Le","Jonathan Hung","Sathiya Keerthi","Ruoyan Wang","Fengyu Zhang","Mohit Kothari","Chen Zhu","Daqi Sun","Yun Dai","Xun Luan","Sirou Zhu","Zhiwei Wang","Neil Daftary","Qianqi Shen","Chengming Jiang","Haichao Wei","Maneesh Varshney","Amol Ghoting","Souvik Ghosh"],"pdf_url":"https://arxiv.org/pdf/2402.06859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03877v1","updated":"2024-08-07T16:27:45Z","published":"2024-08-07T16:27:45Z","title":"Knowledge Probing for Graph Representation Learning","summary":"  Graph learning methods have been extensively applied in diverse application\nareas. However, what kind of inherent graph properties e.g. graph proximity,\ngraph structural information has been encoded into graph representation\nlearning for downstream tasks is still under-explored. In this paper, we\npropose a novel graph probing framework (GraphProbe) to investigate and\ninterpret whether the family of graph learning methods has encoded different\nlevels of knowledge in graph representation learning. Based on the intrinsic\nproperties of graphs, we design three probes to systematically investigate the\ngraph representation learning process from different perspectives, respectively\nthe node-wise level, the path-wise level, and the structural level. We\nconstruct a thorough evaluation benchmark with nine representative graph\nlearning methods from random walk based approaches, basic graph neural networks\nand self-supervised graph methods, and probe them on six benchmark datasets for\nnode classification, link prediction and graph classification. The experimental\nevaluation verify that GraphProbe can estimate the capability of graph\nrepresentation learning. Remaking results have been concluded: GCN and\nWeightedGCN methods are relatively versatile methods achieving better results\nwith respect to different tasks.\n","authors":["Mingyu Zhao","Xingyu Huang","Ziyu Lyu","Yanlin Wang","Lixin Cui","Lu Bai"],"pdf_url":"https://arxiv.org/pdf/2408.03877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03872v1","updated":"2024-08-07T16:22:21Z","published":"2024-08-07T16:22:21Z","title":"Inter-Series Transformer: Attending to Products in Time Series\n  Forecasting","summary":"  Time series forecasting is an important task in many fields ranging from\nsupply chain management to weather forecasting. Recently, Transformer neural\nnetwork architectures have shown promising results in forecasting on common\ntime series benchmark datasets. However, application to supply chain demand\nforecasting, which can have challenging characteristics such as sparsity and\ncross-series effects, has been limited.\n  In this work, we explore the application of Transformer-based models to\nsupply chain demand forecasting. In particular, we develop a new\nTransformer-based forecasting approach using a shared, multi-task per-time\nseries network with an initial component applying attention across time series,\nto capture interactions and help address sparsity. We provide a case study\napplying our approach to successfully improve demand prediction for a medical\ndevice manufacturing company. To further validate our approach, we also apply\nit to public demand forecasting datasets as well and demonstrate competitive to\nsuperior performance compared to a variety of baseline and state-of-the-art\nforecast methods across the private and public datasets.\n","authors":["Rares Cristian","Pavithra Harsha","Clemente Ocejo","Georgia Perakis","Brian Quanz","Ioannis Spantidakis","Hamza Zerhouni"],"pdf_url":"https://arxiv.org/pdf/2408.03872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08973v2","updated":"2024-08-07T16:21:25Z","published":"2024-04-13T11:40:05Z","title":"PraFFL: A Preference-Aware Scheme in Fair Federated Learning","summary":"  Fairness in federated learning has emerged as a critical concern, aiming to\ndevelop an unbiased model for any special group (e.g., male or female) of\nsensitive features. However, there is a trade-off between model performance and\nfairness, i.e., improving model fairness will decrease model performance.\nExisting approaches have characterized such a trade-off by introducing\nhyperparameters to quantify client's preferences for model fairness and model\nperformance. Nevertheless, these approaches are limited to scenarios where each\nclient has only a single pre-defined preference, and fail to work in practical\nsystems where each client generally have multiple preferences. The key\nchallenge is to design a method that allows the model to adapt to diverse\npreferences of each client in real time. To this end, we propose a\nPreference-aware scheme in Fair Federated Learning paradigm (called PraFFL) to\ngenerate preference-wise model in real time. PraFFL can adaptively adjust the\nmodel based on each client's preferences to meet their needs. We theoretically\nprove that PraFFL can offer the optimal model tailored to an arbitrary\npreference of each client, and show its linear convergence. Experimental\nresults show that our proposed PraFFL outperforms five fair federated learning\nalgorithms in terms of the model's capability of adapting to clients' different\npreferences.\n","authors":["Rongguang Ye","Wei-Bin Kou","Ming Tang"],"pdf_url":"https://arxiv.org/pdf/2404.08973v2.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.02426v2","updated":"2024-08-07T16:20:56Z","published":"2024-03-04T19:18:53Z","title":"Digital Twins and Civil Engineering Phases: Reorienting Adoption\n  Strategies","summary":"  Digital twin (DT) technology has received immense attention over the years\ndue to the promises it presents to various stakeholders in science and\nengineering. As a result, different thematic areas of DT have been explored.\nThis is no different in specific fields such as manufacturing, automation, oil\nand gas, and civil engineering, leading to fragmented approaches for\nfield-specific applications. The civil engineering industry is further\ndisadvantaged in this regard as it relies on external techniques by other\nengineering fields for its DT adoption. A rising consequence of these\nextensions is a concentrated application of DT to the operations and\nmaintenance phase. On another spectrum, Building Information Modeling (BIM) is\npervasively utilized in the planning/design phase, and the transient nature of\nthe construction phase remains a challenge for its DT adoption. In this paper,\nwe present a phase-based development of DT in the Architecture, Engineering,\nand Construction industry. We commence by presenting succinct expositions on DT\nas a concept and as a service, and establish a five-level scale system.\nFurthermore, we present separately a systematic literature review of the\nconventional techniques employed at each civil engineering phase. In this\nregard, we identified enabling technologies such as computer vision for\nextended sensing and the Internet of Things for reliable integration.\nUltimately, we attempt to reveal DT as an important tool across the entire life\ncycle of civil engineering projects, and nudge researchers to think more\nholistically in their quest for the integration of DT for civil engineering\napplications.\n","authors":["Taiwo A. Adebiyi","Nafeezat A. Ajenifuja","Ruda Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.02426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03865v1","updated":"2024-08-07T16:13:43Z","published":"2024-08-07T16:13:43Z","title":"PackMamba: Efficient Processing of Variable-Length Sequences in Mamba\n  training","summary":"  With the evolution of large language models, traditional Transformer models\nbecome computationally demanding for lengthy sequences due to the quadratic\ngrowth in computation with respect to the sequence length. Mamba, emerging as a\ngroundbreaking architecture in the field of generative AI, demonstrates\nremarkable proficiency in handling elongated sequences with reduced\ncomputational and memory complexity. Nevertheless, the existing training\nframework of Mamba presents inefficiency with variable-length sequence inputs.\nEither single-sequence training results in low GPU utilization, or batched\nprocessing of variable-length sequences to a maximum length incurs considerable\nmemory and computational overhead. To address this problem, we analyze the\nperformance of bottleneck operators in Mamba under diverse tensor shapes and\nproposed PackMamba, a high-throughput Mamba that efficiently handles\nvariable-length sequences. Diving deep into state-space models (SSMs), we\nmodify the parallel operators to avoid passing information between individual\nsequences while maintaining high performance. Experimental results on an NVIDIA\nA100 GPU demonstrate throughput exceeding the baseline single-sequence\nprocessing scheme: 3.06x speedup on the 1.4B model and 2.62x on the 2.8B model.\n","authors":["Haoran Xu","Ziqian Liu","Rong Fu","Zhongling Su","Zerui Wang","Zheng Cai","Zhilin Pei","Xingcheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.03865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15636v3","updated":"2024-08-07T16:07:05Z","published":"2024-05-24T15:22:58Z","title":"Visualize and Paint GAN Activations","summary":"  We investigate how generated structures of GANs correlate with their\nactivations in hidden layers, with the purpose of better understanding the\ninner workings of those models and being able to paint structures with\nunconditionally trained GANs. This gives us more control over the generated\nimages, allowing to generate them from a semantic segmentation map while not\nrequiring such a segmentation in the training data. To this end we introduce\nthe concept of tileable features, allowing us to identify activations that work\nwell for painting.\n","authors":["Rudolf Herdt","Peter Maass"],"pdf_url":"https://arxiv.org/pdf/2405.15636v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05941v3","updated":"2024-08-07T15:58:17Z","published":"2023-11-10T08:54:51Z","title":"Out-of-Distribution-Aware Electric Vehicle Charging","summary":"  We tackle the challenge of learning to charge Electric Vehicles (EVs) with\nOut-of-Distribution (OOD) data. Traditional scheduling algorithms typically\nfail to balance near-optimal average performance with worst-case guarantees,\nparticularly with OOD data. Model Predictive Control (MPC) is often too\nconservative and data-independent, whereas Reinforcement Learning (RL) tends to\nbe overly aggressive and fully trusts the data, hindering their ability to\nconsistently achieve the best-of-both-worlds. To bridge this gap, we introduce\na novel OOD-aware scheduling algorithm, denoted OOD-Charging. This algorithm\nemploys a dynamic \"awareness radius\", which updates in real-time based on the\nTemporal Difference (TD)-error that reflects the severity of OOD. The\nOOD-Charging algorithm allows for a more effective balance between consistency\nand robustness in EV charging schedules, thereby significantly enhancing\nadaptability and efficiency in real-world charging environments. Our results\ndemonstrate that this approach improves the scheduling reward reliably under\nreal OOD scenarios with remarkable shifts of EV charging behaviors caused by\nCOVID-19 in the Caltech ACN-Data.\n","authors":["Tongxin Li","Chenxi Sun"],"pdf_url":"https://arxiv.org/pdf/2311.05941v3.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2408.03849v1","updated":"2024-08-07T15:46:45Z","published":"2024-08-07T15:46:45Z","title":"Hate Speech Detection and Classification in Amharic Text with Deep\n  Learning","summary":"  Hate speech is a growing problem on social media. It can seriously impact\nsociety, especially in countries like Ethiopia, where it can trigger conflicts\namong diverse ethnic and religious groups. While hate speech detection in\nresource rich languages are progressing, for low resource languages such as\nAmharic are lacking. To address this gap, we develop Amharic hate speech data\nand SBi-LSTM deep learning model that can detect and classify text into four\ncategories of hate speech: racial, religious, gender, and non-hate speech. We\nhave annotated 5k Amharic social media post and comment data into four\ncategories. The data is annotated using a custom annotation tool by a total of\n100 native Amharic speakers. The model achieves a 94.8 F1-score performance.\nFuture improvements will include expanding the dataset and develop state-of-the\nart models.\n  Keywords: Amharic hate speech detection, classification, Amharic dataset,\nDeep Learning, SBi-LSTM\n","authors":["Samuel Minale Gashe","Seid Muhie Yimam","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2408.03849v1.pdf","comment":"Dataset: https://data.mendeley.com/datasets/p74pfhz3yx/1"},{"id":"http://arxiv.org/abs/2306.07350v3","updated":"2024-08-07T15:36:15Z","published":"2023-06-12T18:16:33Z","title":"G-invariant diffusion maps","summary":"  The diffusion maps embedding of data lying on a manifold has shown success in\ntasks such as dimensionality reduction, clustering, and data visualization. In\nthis work, we consider embedding data sets that were sampled from a manifold\nwhich is closed under the action of a continuous matrix group. An example of\nsuch a data set is images whose planar rotations are arbitrary. The G-invariant\ngraph Laplacian, introduced in Part I of this work, admits eigenfunctions in\nthe form of tensor products between the elements of the irreducible unitary\nrepresentations of the group and eigenvectors of certain matrices. We employ\nthese eigenfunctions to derive diffusion maps that intrinsically account for\nthe group action on the data. In particular, we construct both equivariant and\ninvariant embeddings, which can be used to cluster and align the data points.\nWe demonstrate the utility of our construction in the problem of random\ncomputerized tomography.\n","authors":["Eitan Rosen","Xiuyuan Cheng","Yoel Shkolnisky"],"pdf_url":"https://arxiv.org/pdf/2306.07350v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03842v1","updated":"2024-08-07T15:35:25Z","published":"2024-08-07T15:35:25Z","title":"Bi-Level Spatial and Channel-aware Transformer for Learned Image\n  Compression","summary":"  Recent advancements in learned image compression (LIC) methods have\ndemonstrated superior performance over traditional hand-crafted codecs. These\nlearning-based methods often employ convolutional neural networks (CNNs) or\nTransformer-based architectures. However, these nonlinear approaches frequently\noverlook the frequency characteristics of images, which limits their\ncompression efficiency. To address this issue, we propose a novel\nTransformer-based image compression method that enhances the transformation\nstage by considering frequency components within the feature map. Our method\nintegrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB),\nwhere a spatial-based branch independently handles high and low frequencies at\nthe attention layer, and a Channel-aware Self-Attention (CaSA) module captures\ninformation across channels, significantly improving compression performance.\nAdditionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN)\nwithin the Transformer block to enhance the extraction of diverse and rich\ninformation, which is crucial for effective compression. These innovations\ncollectively improve the transformation's ability to project data into a more\ndecorrelated latent space, thereby boosting overall compression efficiency.\nExperimental results demonstrate that our framework surpasses state-of-the-art\nLIC methods in rate-distortion performance.\n","authors":["Hamidreza Soltani","Erfan Ghasemi"],"pdf_url":"https://arxiv.org/pdf/2408.03842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19588v2","updated":"2024-08-07T15:11:01Z","published":"2024-03-28T17:12:39Z","title":"DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs","summary":"  This paper revives Densely Connected Convolutional Networks (DenseNets) and\nreveals the underrated effectiveness over predominant ResNet-style\narchitectures. We believe DenseNets' potential was overlooked due to untouched\ntraining methods and traditional design elements not fully revealing their\ncapabilities. Our pilot study shows dense connections through concatenation are\nstrong, demonstrating that DenseNets can be revitalized to compete with modern\narchitectures. We methodically refine suboptimal components - architectural\nadjustments, block redesign, and improved training recipes towards widening\nDenseNets and boosting memory efficiency while keeping concatenation shortcuts.\nOur models, employing simple architectural elements, ultimately surpass Swin\nTransformer, ConvNeXt, and DeiT-III - key architectures in the residual\nlearning lineage. Furthermore, our models exhibit near state-of-the-art\nperformance on ImageNet-1K, competing with the very recent models and\ndownstream tasks, ADE20k semantic segmentation, and COCO object\ndetection/instance segmentation. Finally, we provide empirical analyses that\nuncover the merits of the concatenation over additive shortcuts, steering a\nrenewed preference towards DenseNet-style designs. Our code is available at\nhttps://github.com/naver-ai/rdnet.\n","authors":["Donghyun Kim","Byeongho Heo","Dongyoon Han"],"pdf_url":"https://arxiv.org/pdf/2403.19588v2.pdf","comment":"ECCV 2024. Code at https://github.com/naver-ai/rdnet"},{"id":"http://arxiv.org/abs/2301.04660v2","updated":"2024-08-07T15:07:41Z","published":"2023-01-11T19:00:00Z","title":"Anomalies, Representations, and Self-Supervision","summary":"  We develop a self-supervised method for density-based anomaly detection using\ncontrastive learning, and test it using event-level anomaly data from CMS\nADC2021. The AnomalyCLR technique is data-driven and uses augmentations of the\nbackground data to mimic non-Standard-Model events in a model-agnostic way. It\nuses a permutation-invariant Transformer Encoder architecture to map the\nobjects measured in a collider event to the representation space, where the\ndata augmentations define a representation space which is sensitive to\npotential anomalous features. An AutoEncoder trained on background\nrepresentations then computes anomaly scores for a variety of signals in the\nrepresentation space. With AnomalyCLR we find significant improvements on\nperformance metrics for all signals when compared to the raw data baseline.\n","authors":["Barry M. Dillon","Luigi Favaro","Friedrich Feiden","Tanmoy Modak","Tilman Plehn"],"pdf_url":"https://arxiv.org/pdf/2301.04660v2.pdf","comment":"19 pages, 3 figures, journal version"},{"id":"http://arxiv.org/abs/2408.03819v1","updated":"2024-08-07T14:55:04Z","published":"2024-08-07T14:55:04Z","title":"Leveraging Variation Theory in Counterfactual Data Augmentation for\n  Optimized Active Learning","summary":"  Active Learning (AL) allows models to learn interactively from user feedback.\nThis paper introduces a counterfactual data augmentation approach to AL,\nparticularly addressing the selection of datapoints for user querying, a\npivotal concern in enhancing data efficiency. Our approach is inspired by\nVariation Theory, a theory of human concept learning that emphasizes the\nessential features of a concept by focusing on what stays the same and what\nchanges. Instead of just querying with existing datapoints, our approach\nsynthesizes artificial datapoints that highlight potential key similarities and\ndifferences among labels using a neuro-symbolic pipeline combining large\nlanguage models (LLMs) and rule-based models. Through an experiment in the\nexample domain of text classification, we show that our approach achieves\nsignificantly higher performance when there are fewer annotated data. As the\nannotated training data gets larger the impact of the generated data starts to\ndiminish showing its capability to address the cold start problem in AL. This\nresearch sheds light on integrating theories of human learning into the\noptimization of AL.\n","authors":["Simret Araya Gebreegziabher","Kuangshi Ai","Zheng Zhang","Elena L. Glassman","Toby Jia-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2408.03819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03816v1","updated":"2024-08-07T14:52:06Z","published":"2024-08-07T14:52:06Z","title":"Early Prediction of Causes (not Effects) in Healthcare by Long-Term\n  Clinical Time Series Forecasting","summary":"  Machine learning for early syndrome diagnosis aims to solve the intricate\ntask of predicting a ground truth label that most often is the outcome (effect)\nof a medical consensus definition applied to observed clinical measurements\n(causes), given clinical measurements observed several hours before. Instead of\nfocusing on the prediction of the future effect, we propose to directly predict\nthe causes via time series forecasting (TSF) of clinical variables and\ndetermine the effect by applying the gold standard consensus definition to the\nforecasted values. This method has the invaluable advantage of being\nstraightforwardly interpretable to clinical practitioners, and because model\ntraining does not rely on a particular label anymore, the forecasted data can\nbe used to predict any consensus-based label. We exemplify our method by means\nof long-term TSF with Transformer models, with a focus on accurate prediction\nof sparse clinical variables involved in the SOFA-based Sepsis-3 definition and\nthe new Simplified Acute Physiology Score (SAPS-II) definition. Our experiments\nare conducted on two datasets and show that contrary to recent proposals which\nadvocate set function encoders for time series and direct multi-step decoders,\nbest results are achieved by a combination of standard dense encoders with\niterative multi-step decoders. The key for success of iterative multi-step\ndecoding can be attributed to its ability to capture cross-variate dependencies\nand to a student forcing training strategy that teaches the model to rely on\nits own previous time step predictions for the next time step prediction.\n","authors":["Michael Staniek","Marius Fracarolli","Michael Hagmann","Stefan Riezler"],"pdf_url":"https://arxiv.org/pdf/2408.03816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03806v1","updated":"2024-08-07T14:32:36Z","published":"2024-08-07T14:32:36Z","title":"Trustworthy Image Semantic Communication with GenAI: Explainablity,\n  Controllability, and Efficiency","summary":"  Image semantic communication (ISC) has garnered significant attention for its\npotential to achieve high efficiency in visual content transmission. However,\nexisting ISC systems based on joint source-channel coding face challenges in\ninterpretability, operability, and compatibility. To address these limitations,\nwe propose a novel trustworthy ISC framework. This approach leverages text\nextraction and segmentation mapping techniques to convert images into\nexplainable semantics, while employing Generative Artificial Intelligence\n(GenAI) for multiple downstream inference tasks. We also introduce a multi-rate\nISC transmission protocol that dynamically adapts to both the received\nexplainable semantic content and specific task requirements at the receiver.\nSimulation results demonstrate that our framework achieves explainable\nlearning, decoupled training, and compatible transmission in various\napplication scenarios. Finally, some intriguing research directions and\napplication scenarios are identified.\n","authors":["Xijun Wang","Dongshan Ye","Chenyuan Feng","Howard H. Yang","Xiang Chen","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2408.03806v1.pdf","comment":"8 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2407.11075v2","updated":"2024-08-07T14:05:28Z","published":"2024-07-13T04:29:36Z","title":"A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)","summary":"  Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have\ngained a thorough understanding of its theoretical foundation, architectural\ndesign, application scenarios, and current research progress. KAN, with its\nunique architecture and flexible activation functions, excels in handling\ncomplex data patterns and nonlinear relationships, demonstrating wide-ranging\napplication potential. While challenges remain, KAN is poised to pave the way\nfor innovative solutions in various fields, potentially revolutionizing how we\napproach complex computational problems.\n","authors":["Yuntian Hou","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.11075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15793v2","updated":"2024-08-07T13:59:46Z","published":"2024-07-22T16:51:28Z","title":"CLIP with Generative Latent Replay: a Strong Baseline for Incremental\n  Learning","summary":"  With the emergence of Transformers and Vision-Language Models (VLMs) such as\nCLIP, large pre-trained models have become a common strategy to enhance\nperformance in Continual Learning scenarios. This led to the development of\nnumerous prompting strategies to effectively fine-tune transformer-based models\nwithout succumbing to catastrophic forgetting. However, these methods struggle\nto specialize the model on domains significantly deviating from the\npre-training and preserving its zero-shot capabilities. In this work, we\npropose Continual Generative training for Incremental prompt-Learning, a novel\napproach to mitigate forgetting while adapting a VLM, which exploits generative\nreplay to align prompts to tasks. We also introduce a new metric to evaluate\nzero-shot capabilities within CL benchmarks. Through extensive experiments on\ndifferent domains, we demonstrate the effectiveness of our framework in\nadapting to new tasks while improving zero-shot capabilities. Further analysis\nreveals that our approach can bridge the gap with joint prompt tuning. The\ncodebase is available at https://github.com/aimagelab/mammoth.\n","authors":["Emanuele Frascaroli","Aniello Panariello","Pietro Buzzega","Lorenzo Bonicelli","Angelo Porrello","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2407.15793v2.pdf","comment":"15 pages, 1 figure. Accepted at the The 35th British Machine Vision\n  Conference 2024 (BMVC 2024), Glasgow, UK"},{"id":"http://arxiv.org/abs/2404.09657v3","updated":"2024-08-07T13:44:01Z","published":"2024-04-15T10:45:12Z","title":"Sampling for Model Predictive Trajectory Planning in Autonomous Driving\n  using Normalizing Flows","summary":"  Alongside optimization-based planners, sampling-based approaches are often\nused in trajectory planning for autonomous driving due to their simplicity.\nModel predictive path integral control is a framework that builds upon\noptimization principles while incorporating stochastic sampling of input\ntrajectories. This paper investigates several sampling approaches for\ntrajectory generation. In this context, normalizing flows originating from the\nfield of variational inference are considered for the generation of sampling\ndistributions, as they model transformations of simple to more complex\ndistributions. Accordingly, learning-based normalizing flow models are trained\nfor a more efficient exploration of the input domain for the task at hand. The\ndeveloped algorithm and the proposed sampling distributions are evaluated in\ntwo simulation scenarios.\n","authors":["Georg Rabenstein","Lars Ullrich","Knut Graichen"],"pdf_url":"https://arxiv.org/pdf/2404.09657v3.pdf","comment":"Accepted to be published as part of the 2024 IEEE Intelligent\n  Vehicles Symposium (IV), Jeju Shinhwa World, Jeju Island, Korea, June 2-5,\n  2024"},{"id":"http://arxiv.org/abs/2408.03765v1","updated":"2024-08-07T13:36:03Z","published":"2024-08-07T13:36:03Z","title":"Reliable Node Similarity Matrix Guided Contrastive Graph Clustering","summary":"  Graph clustering, which involves the partitioning of nodes within a graph\ninto disjoint clusters, holds significant importance for numerous subsequent\napplications. Recently, contrastive learning, known for utilizing supervisory\ninformation, has demonstrated encouraging results in deep graph clustering.\nThis methodology facilitates the learning of favorable node representations for\nclustering by attracting positively correlated node pairs and distancing\nnegatively correlated pairs within the representation space. Nevertheless, a\nsignificant limitation of existing methods is their inadequacy in thoroughly\nexploring node-wise similarity. For instance, some hypothesize that the node\nsimilarity matrix within the representation space is identical, ignoring the\ninherent semantic relationships among nodes. Given the fundamental role of\ninstance similarity in clustering, our research investigates contrastive graph\nclustering from the perspective of the node similarity matrix. We argue that an\nideal node similarity matrix within the representation space should accurately\nreflect the inherent semantic relationships among nodes, ensuring the\npreservation of semantic similarities in the learned representations. In\nresponse to this, we introduce a new framework, Reliable Node Similarity Matrix\nGuided Contrastive Graph Clustering (NS4GC), which estimates an approximately\nideal node similarity matrix within the representation space to guide\nrepresentation learning. Our method introduces node-neighbor alignment and\nsemantic-aware sparsification, ensuring the node similarity matrix is both\naccurate and efficiently sparse. Comprehensive experiments conducted on $8$\nreal-world datasets affirm the efficacy of learning the node similarity matrix\nand the superior performance of NS4GC.\n","authors":["Yunhui Liu","Xinyi Gao","Tieke He","Tao Zheng","Jianhua Zhao","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2408.03765v1.pdf","comment":"Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)"},{"id":"http://arxiv.org/abs/2408.01953v2","updated":"2024-08-07T13:24:38Z","published":"2024-08-04T07:59:17Z","title":"EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning","summary":"  Humans perceive and interact with the world with the awareness of\nequivariance, facilitating us in manipulating different objects in diverse\nposes. For robotic manipulation, such equivariance also exists in many\nscenarios. For example, no matter what the pose of a drawer is (translation,\nrotation and tilt), the manipulation strategy is consistent (grasp the handle\nand pull in a line). While traditional models usually do not have the awareness\nof equivariance for robotic manipulation, which might result in more data for\ntraining and poor performance in novel object poses, we propose our EqvAfford\nframework, with novel designs to guarantee the equivariance in point-level\naffordance learning for downstream robotic manipulation, with great performance\nand generalization ability on representative tasks on objects in diverse poses.\n","authors":["Yue Chen","Chenrui Tie","Ruihai Wu","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2408.01953v2.pdf","comment":"Accept to CVPRWorkshop on Equivariant Vision: From Theory to Practice\n  2024"},{"id":"http://arxiv.org/abs/2207.03927v2","updated":"2024-08-07T13:15:55Z","published":"2022-07-08T14:27:52Z","title":"BAST: Binaural Audio Spectrogram Transformer for Binaural Sound\n  Localization","summary":"  Accurate sound localization in a reverberation environment is essential for\nhuman auditory perception. Recently, Convolutional Neural Networks (CNNs) have\nbeen utilized to model the binaural human auditory pathway. However, CNN shows\nbarriers in capturing the global acoustic features. To address this issue, we\npropose a novel end-to-end Binaural Audio Spectrogram Transformer (BAST) model\nto predict the sound azimuth in both anechoic and reverberation environments.\nTwo modes of implementation, i.e. BAST-SP and BAST-NSP corresponding to BAST\nmodel with shared and non-shared parameters respectively, are explored. Our\nmodel with subtraction interaural integration and hybrid loss achieves an\nangular distance of 1.29 degrees and a Mean Square Error of 1e-3 at all\nazimuths, significantly surpassing CNN based model. The exploratory analysis of\nthe BAST's performance on the left-right hemifields and anechoic and\nreverberation environments shows its generalization ability as well as the\nfeasibility of binaural Transformers in sound localization. Furthermore, the\nanalysis of the attention maps is provided to give additional insights on the\ninterpretation of the localization process in a natural reverberant\nenvironment.\n","authors":["Sheng Kuang","Jie Shi","Kiki van der Heijden","Siamak Mehrkanoon"],"pdf_url":"https://arxiv.org/pdf/2207.03927v2.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.07118v2","updated":"2024-08-07T13:14:00Z","published":"2024-02-11T07:27:01Z","title":"Next-Generation Teleophthalmology: AI-enabled Quality Assessment Aiding\n  Remote Smartphone-based Consultation","summary":"  Blindness and other eye diseases are a global health concern, particularly in\nlow- and middle-income countries like India. In this regard, during the\nCOVID-19 pandemic, teleophthalmology became a lifeline, and the Grabi\nattachment for smartphone-based eye imaging gained in use. However, quality of\nuser-captured image often remained inadequate, requiring clinician vetting and\ndelays. In this backdrop, we propose an AI-based quality assessment system with\ninstant feedback mimicking clinicians' judgments and tested on patient-captured\nimages. Dividing the complex problem hierarchically, here we tackle a\nnontrivial part, and demonstrate a proof of the concept.\n","authors":["Dhruv Srikanth","Jayang Gurung","N Satya Deepika","Vineet Joshi","Lopamudra Giri","Pravin Vaddavalli","Soumya Jana"],"pdf_url":"https://arxiv.org/pdf/2402.07118v2.pdf","comment":"4 pages, Presented at IEEE EMBC 2024"},{"id":"http://arxiv.org/abs/2404.15213v2","updated":"2024-08-07T13:11:14Z","published":"2024-03-28T10:15:10Z","title":"Automatic Classification of Subjective Time Perception Using Multi-modal\n  Physiological Data of Air Traffic Controllers","summary":"  In high-pressure environments where human individuals must simultaneously\nmonitor multiple entities, communicate effectively, and maintain intense focus,\nthe perception of time becomes a critical factor influencing performance and\nwell-being. One indicator of well-being can be the person's subjective time\nperception. In our project $ChronoPilot$, we aim to develop a device that\nmodulates human subjective time perception. In this study, we present a method\nto automatically assess the subjective time perception of air traffic\ncontrollers, a group often faced with demanding conditions, using their\nphysiological data and eleven state-of-the-art machine learning classifiers.\nThe physiological data consist of photoplethysmogram, electrodermal activity,\nand temperature data. We find that the support vector classifier works best\nwith an accuracy of 79 % and electrodermal activity provides the most\ndescriptive biomarker. These findings are an important step towards closing the\nfeedback loop of our $ChronoPilot$-device to automatically modulate the user's\nsubjective time perception. This technological advancement may promise\nimprovements in task management, stress reduction, and overall productivity in\nhigh-stakes professions.\n","authors":["Till Aust","Eirini Balta","Argiro Vatakis","Heiko Hamann"],"pdf_url":"https://arxiv.org/pdf/2404.15213v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.03747v1","updated":"2024-08-07T13:01:10Z","published":"2024-08-07T13:01:10Z","title":"Online Model-based Anomaly Detection in Multivariate Time Series:\n  Taxonomy, Survey, Research Challenges and Future Directions","summary":"  Time-series anomaly detection plays an important role in engineering\nprocesses, like development, manufacturing and other operations involving\ndynamic systems. These processes can greatly benefit from advances in the\nfield, as state-of-the-art approaches may aid in cases involving, for example,\nhighly dimensional data. To provide the reader with understanding of the\nterminology, this survey introduces a novel taxonomy where a distinction\nbetween online and offline, and training and inference is made. Additionally,\nit presents the most popular data sets and evaluation metrics used in the\nliterature, as well as a detailed analysis. Furthermore, this survey provides\nan extensive overview of the state-of-the-art model-based online semi- and\nunsupervised anomaly detection approaches for multivariate time-series data,\ncategorising them into different model families and other properties. The\nbiggest research challenge revolves around benchmarking, as currently there is\nno reliable way to compare different approaches against one another. This\nproblem is two-fold: on the one hand, public data sets suffers from at least\none fundamental flaw, while on the other hand, there is a lack of intuitive and\nrepresentative evaluation metrics in the field. Moreover, the way most\npublications choose a detection threshold disregards real-world conditions,\nwhich hinders the application in the real world. To allow for tangible advances\nin the field, these issues must be addressed in future work.\n","authors":["Lucas Correia","Jan-Christoph Goos","Philipp Klein","Thomas Bäck","Anna V. Kononova"],"pdf_url":"https://arxiv.org/pdf/2408.03747v1.pdf","comment":"Submitted to Engineering Applications of Artificial Intelligence\n  journal"},{"id":"http://arxiv.org/abs/2408.03746v1","updated":"2024-08-07T12:59:58Z","published":"2024-08-07T12:59:58Z","title":"Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion\n  Posterior Sampling","summary":"  Bayesian Last Layer (BLL) models focus solely on uncertainty in the output\nlayer of neural networks, demonstrating comparable performance to more complex\nBayesian models. However, the use of Gaussian priors for last layer weights in\nBayesian Last Layer (BLL) models limits their expressive capacity when faced\nwith non-Gaussian, outlier-rich, or high-dimensional datasets. To address this\nshortfall, we introduce a novel approach that combines diffusion techniques and\nimplicit priors for variational learning of Bayesian last layer weights. This\nmethod leverages implicit distributions for modeling weight priors in BLL,\ncoupled with diffusion samplers for approximating true posterior predictions,\nthereby establishing a comprehensive Bayesian prior and posterior estimation\nstrategy. By delivering an explicit and computationally efficient variational\nlower bound, our method aims to augment the expressive abilities of BLL models,\nenhancing model accuracy, calibration, and out-of-distribution detection\nproficiency. Through detailed exploration and experimental validation, We\nshowcase the method's potential for improving predictive accuracy and\nuncertainty quantification while ensuring computational efficiency.\n","authors":["Jian Xu","Zhiqi Lin","Shigui Li","Min Chen","Junmei Yang","Delu Zeng","John Paisley"],"pdf_url":"https://arxiv.org/pdf/2408.03746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18381v4","updated":"2024-08-07T12:59:31Z","published":"2023-05-28T06:53:41Z","title":"Distill Gold from Massive Ores: Bi-level Data Pruning towards Efficient\n  Dataset Distillation","summary":"  Data-efficient learning has garnered significant attention, especially given\nthe current trend of large multi-modal models. Recently, dataset distillation\nhas become an effective approach by synthesizing data samples that are\nessential for network training. However, it remains to be explored which\nsamples are essential for the dataset distillation process itself. In this\nwork, we study the data efficiency and selection for the dataset distillation\ntask. By re-formulating the dynamics of distillation, we provide insight into\nthe inherent redundancy in the real dataset, both theoretically and\nempirically. We propose to use the empirical loss value as a static data\npruning criterion. To further compensate for the variation of the data value in\ntraining, we find the most contributing samples based on their causal effects\non the distillation. The proposed selection strategy can efficiently exploit\nthe training dataset, outperform the previous SOTA distillation algorithms, and\nconsistently enhance the distillation algorithms, even on much larger-scale and\nmore heterogeneous datasets, e.g., full ImageNet-1K and Kinetics-400. We\nbelieve this paradigm will open up new avenues in the dynamics of distillation\nand pave the way for efficient dataset distillation. Our code is available on\nhttps://github.com/silicx/GoldFromOres-BiLP.\n","authors":["Yue Xu","Yong-Lu Li","Kaitong Cui","Ziyu Wang","Cewu Lu","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2305.18381v4.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2307.12754v4","updated":"2024-08-07T12:51:46Z","published":"2023-07-24T12:52:55Z","title":"Nonparametric Linear Feature Learning in Regression Through\n  Regularisation","summary":"  Representation learning plays a crucial role in automated feature selection,\nparticularly in the context of high-dimensional data, where non-parametric\nmethods often struggle. In this study, we focus on supervised learning\nscenarios where the pertinent information resides within a lower-dimensional\nlinear subspace of the data, namely the multi-index model. If this subspace\nwere known, it would greatly enhance prediction, computation, and\ninterpretation. To address this challenge, we propose a novel method for joint\nlinear feature learning and non-parametric function estimation, aimed at more\neffectively leveraging hidden features for learning. Our approach employs\nempirical risk minimisation, augmented with a penalty on function derivatives,\nensuring versatility. Leveraging the orthogonality and rotation invariance\nproperties of Hermite polynomials, we introduce our estimator, named RegFeaL.\nBy using alternative minimisation, we iteratively rotate the data to improve\nalignment with leading directions. We establish that the expected risk of our\nmethod converges in high-probability to the minimal risk under minimal\nassumptions and with explicit rates. Additionally, we provide empirical results\ndemonstrating the performance of RegFeaL in various experiments.\n","authors":["Bertille Follain","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2307.12754v4.pdf","comment":"45 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.03735v1","updated":"2024-08-07T12:42:09Z","published":"2024-08-07T12:42:09Z","title":"Advancing Multimodal Large Language Models with Quantization-Aware Scale\n  Learning for Efficient Adaptation","summary":"  This paper presents the first study to explore the potential of parameter\nquantization for multimodal large language models to alleviate the significant\nresource constraint encountered during vision-language instruction tuning. We\nintroduce a Quantization-aware Scale LeArning method based on multimodal\nWarmup, termed QSLAW. This method is grounded in two key innovations: (1) The\nlearning of group-wise scale factors for quantized LLM weights to mitigate the\nquantization error arising from activation outliers and achieve more effective\nvision-language instruction tuning; (2) The implementation of a multimodal\nwarmup that progressively integrates linguistic and multimodal training\nsamples, thereby preventing overfitting of the quantized model to multimodal\ndata while ensuring stable adaptation of multimodal large language models to\ndownstream vision-language tasks. Extensive experiments demonstrate that models\nquantized by QSLAW perform on par with, or even surpass, their full-precision\ncounterparts, while facilitating up to 1.4 times reduction in VL tuning time\nand GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.\n","authors":["Jingjing Xie","Yuxin Zhang","Mingbao Lin","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2408.03735v1.pdf","comment":"Accepted by ACMMM2024"},{"id":"http://arxiv.org/abs/2408.03733v1","updated":"2024-08-07T12:41:56Z","published":"2024-08-07T12:41:56Z","title":"Bayes-optimal learning of an extensive-width neural network from\n  quadratically many samples","summary":"  We consider the problem of learning a target function corresponding to a\nsingle hidden layer neural network, with a quadratic activation function after\nthe first layer, and random weights. We consider the asymptotic limit where the\ninput dimension and the network width are proportionally large. Recent work\n[Cui & al '23] established that linear regression provides Bayes-optimal test\nerror to learn such a function when the number of available samples is only\nlinear in the dimension. That work stressed the open challenge of theoretically\nanalyzing the optimal test error in the more interesting regime where the\nnumber of samples is quadratic in the dimension. In this paper, we solve this\nchallenge for quadratic activations and derive a closed-form expression for the\nBayes-optimal test error. We also provide an algorithm, that we call GAMP-RIE,\nwhich combines approximate message passing with rotationally invariant matrix\ndenoising, and that asymptotically achieves the optimal performance.\nTechnically, our result is enabled by establishing a link with recent works on\noptimal denoising of extensive-rank matrices and on the ellipsoid fitting\nproblem. We further show empirically that, in the absence of noise,\nrandomly-initialized gradient descent seems to sample the space of weights,\nleading to zero training loss, and averaging over initialization leads to a\ntest error equal to the Bayes-optimal one.\n","authors":["Antoine Maillard","Emanuele Troiani","Simon Martin","Florent Krzakala","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2408.03733v1.pdf","comment":"47 pages"},{"id":"http://arxiv.org/abs/2408.03732v1","updated":"2024-08-07T12:38:23Z","published":"2024-08-07T12:38:23Z","title":"Question Rephrasing for Quantifying Uncertainty in Large Language\n  Models: Applications in Molecular Chemistry Tasks","summary":"  Uncertainty quantification enables users to assess the reliability of\nresponses generated by large language models (LLMs). We present a novel\nQuestion Rephrasing technique to evaluate the input uncertainty of LLMs, which\nrefers to the uncertainty arising from equivalent variations of the inputs\nprovided to LLMs. This technique is integrated with sampling methods that\nmeasure the output uncertainty of LLMs, thereby offering a more comprehensive\nuncertainty assessment. We validated our approach on property prediction and\nreaction prediction for molecular chemistry tasks.\n","authors":["Zizhang Chen","Pengyu Hong","Sandeep Madireddy"],"pdf_url":"https://arxiv.org/pdf/2408.03732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03728v1","updated":"2024-08-07T12:33:46Z","published":"2024-08-07T12:33:46Z","title":"A Convex-optimization-based Layer-wise Post-training Pruner for Large\n  Language Models","summary":"  Pruning is a critical strategy for compressing trained large language models\n(LLMs), aiming at substantial memory conservation and computational\nacceleration without compromising performance. However, existing pruning\nmethods often necessitate inefficient retraining for billion-scale LLMs or rely\non heuristic methods such as the optimal brain surgeon framework, which degrade\nperformance. In this paper, we introduce FISTAPruner, the first post-training\npruner based on convex optimization models and algorithms. Specifically, we\npropose a convex optimization model incorporating $\\ell_1$ norm to induce\nsparsity and utilize the FISTA solver for optimization. FISTAPruner\nincorporates an intra-layer cumulative error correction mechanism and supports\nparallel pruning. We comprehensively evaluate FISTAPruner on models such as\nOPT, LLaMA, LLaMA-2, and LLaMA-3 with 125M to 70B parameters under unstructured\nand 2:4 semi-structured sparsity, demonstrating superior performance over\nexisting state-of-the-art methods across various language benchmarks.\n","authors":["Pengxiang Zhao","Hanyu Hu","Ping Li","Yi Zheng","Zhefeng Wang","Xiaoming Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.03728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03706v1","updated":"2024-08-07T11:44:32Z","published":"2024-08-07T11:44:32Z","title":"Local Topology Measures of Contextual Language Model Latent Spaces With\n  Applications to Dialogue Term Extraction","summary":"  A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties.\n","authors":["Benjamin Matthias Ruppik","Michael Heck","Carel van Niekerk","Renato Vukovic","Hsien-chin Lin","Shutong Feng","Marcus Zibrowius","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2408.03706v1.pdf","comment":"Accepted as a long paper to SIGDIAL 2024. 9 pages, 2 figures, 3\n  tables"},{"id":"http://arxiv.org/abs/2312.10271v2","updated":"2024-08-07T11:32:19Z","published":"2023-12-16T00:23:21Z","title":"Robustness of Deep Learning for Accelerated MRI: Benefits of Diverse\n  Training Data","summary":"  Deep learning based methods for image reconstruction are state-of-the-art for\na variety of imaging tasks. However, neural networks often perform worse if the\ntraining data differs significantly from the data they are applied to. For\nexample, a model trained for accelerated magnetic resonance imaging (MRI) on\none scanner performs worse on another scanner. In this work, we investigate the\nimpact of the training data on a model's performance and robustness for\naccelerated MRI. We find that models trained on the combination of various data\ndistributions, such as those obtained from different MRI scanners and\nanatomies, exhibit robustness equal or superior to models trained on the best\nsingle distribution for a specific target distribution. Thus training on such\ndiverse data tends to improve robustness. Furthermore, training on such a\ndiverse dataset does not compromise in-distribution performance, i.e., a model\ntrained on diverse data yields in-distribution performance at least as good as\nmodels trained on the more narrow individual distributions. Our results suggest\nthat training a model for imaging on a variety of distributions tends to yield\na more effective and robust model than maintaining separate models for\nindividual distributions.\n","authors":["Kang Lin","Reinhard Heckel"],"pdf_url":"https://arxiv.org/pdf/2312.10271v2.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2408.03694v1","updated":"2024-08-07T11:14:18Z","published":"2024-08-07T11:14:18Z","title":"A Blockchain-based Reliable Federated Meta-learning for Metaverse: A\n  Dual Game Framework","summary":"  The metaverse, envisioned as the next digital frontier for avatar-based\nvirtual interaction, involves high-performance models. In this dynamic\nenvironment, users' tasks frequently shift, requiring fast model\npersonalization despite limited data. This evolution consumes extensive\nresources and requires vast data volumes. To address this, meta-learning\nemerges as an invaluable tool for metaverse users, with federated meta-learning\n(FML), offering even more tailored solutions owing to its adaptive\ncapabilities. However, the metaverse is characterized by users heterogeneity\nwith diverse data structures, varied tasks, and uneven sample sizes,\npotentially undermining global training outcomes due to statistical difference.\nGiven this, an urgent need arises for smart coalition formation that accounts\nfor these disparities. This paper introduces a dual game-theoretic framework\nfor metaverse services involving meta-learners as workers to manage FML. A\nblockchain-based cooperative coalition formation game is crafted, grounded on a\nreputation metric, user similarity, and incentives. We also introduce a novel\nreputation system based on users' historical contributions and potential\ncontributions to present tasks, leveraging correlations between past and new\ntasks. Finally, a Stackelberg game-based incentive mechanism is presented to\nattract reliable workers to participate in meta-learning, minimizing users'\nenergy costs, increasing payoffs, boosting FML efficacy, and improving\nmetaverse utility. Results show that our dual game framework outperforms\nbest-effort, random, and non-uniform clustering schemes - improving training\nperformance by up to 10%, cutting completion times by as much as 30%, enhancing\nmetaverse utility by more than 25%, and offering up to 5% boost in training\nefficiency over non-blockchain systems, effectively countering misbehaving\nusers.\n","authors":["Emna Baccour","Aiman Erbad","Amr Mohamed","Mounir Hamdi","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2408.03694v1.pdf","comment":"Accepted in IEEE Internet of Things Journal"},{"id":"http://arxiv.org/abs/2408.03691v1","updated":"2024-08-07T11:13:19Z","published":"2024-08-07T11:13:19Z","title":"Generative Design of Periodic Orbits in the Restricted Three-Body\n  Problem","summary":"  The Three-Body Problem has fascinated scientists for centuries and it has\nbeen crucial in the design of modern space missions. Recent developments in\nGenerative Artificial Intelligence hold transformative promise for addressing\nthis longstanding problem. This work investigates the use of Variational\nAutoencoder (VAE) and its internal representation to generate periodic orbits.\nWe utilize a comprehensive dataset of periodic orbits in the Circular\nRestricted Three-Body Problem (CR3BP) to train deep-learning architectures that\ncapture key orbital characteristics, and we set up physical evaluation metrics\nfor the generated trajectories. Through this investigation, we seek to enhance\nthe understanding of how Generative AI can improve space mission planning and\nastrodynamics research, leading to novel, data-driven approaches in the field.\n","authors":["Alvaro Francisco Gil","Walther Litteri","Victor Rodriguez-Fernandez","David Camacho","Massimiliano Vasile"],"pdf_url":"https://arxiv.org/pdf/2408.03691v1.pdf","comment":"SPAICE Conference 2024 (7 pages)"},{"id":"http://arxiv.org/abs/2408.03685v1","updated":"2024-08-07T10:53:07Z","published":"2024-08-07T10:53:07Z","title":"RL-ADN: A High-Performance Deep Reinforcement Learning Environment for\n  Optimal Energy Storage Systems Dispatch in Active Distribution Networks","summary":"  Deep Reinforcement Learning (DRL) presents a promising avenue for optimizing\nEnergy Storage Systems (ESSs) dispatch in distribution networks. This paper\nintroduces RL-ADN, an innovative open-source library specifically designed for\nsolving the optimal ESSs dispatch in active distribution networks. RL-ADN\noffers unparalleled flexibility in modeling distribution networks, and ESSs,\naccommodating a wide range of research goals. A standout feature of RL-ADN is\nits data augmentation module, based on Gaussian Mixture Model and Copula (GMC)\nfunctions, which elevates the performance ceiling of DRL agents. Additionally,\nRL-ADN incorporates the Laurent power flow solver, significantly reducing the\ncomputational burden of power flow calculations during training without\nsacrificing accuracy. The effectiveness of RL-ADN is demonstrated using in\ndifferent sizes of distribution networks, showing marked performance\nimprovements in the adaptability of DRL algorithms for ESS dispatch tasks. This\nenhancement is particularly beneficial from the increased diversity of training\nscenarios. Furthermore, RL-ADN achieves a tenfold increase in computational\nefficiency during training, making it highly suitable for large-scale network\napplications. The library sets a new benchmark in DRL-based ESSs dispatch in\ndistribution networks and it is poised to advance DRL applications in\ndistribution network operations significantly. RL-ADN is available at:\nhttps://github.com/ShengrenHou/RL-ADN.\n","authors":["Shengren Hou","Shuyi Gao","Weijie Xia","Edgar Mauricio Salazar Duque","Peter Palensky","Pedro P. Vergara"],"pdf_url":"https://arxiv.org/pdf/2408.03685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03669v1","updated":"2024-08-07T10:24:59Z","published":"2024-08-07T10:24:59Z","title":"Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep\n  Graph Neural Networks","summary":"  The drastic performance degradation of Graph Neural Networks (GNNs) as the\ndepth of the graph propagation layers exceeds 8-10 is widely attributed to a\nphenomenon of Over-smoothing. Although recent research suggests that\nOver-smoothing may not be the dominant reason for such a performance\ndegradation, they have not provided rigorous analysis from a theoretical view,\nwhich warrants further investigation. In this paper, we systematically analyze\nthe real dominant problem in deep GNNs and identify the issues that these GNNs\ntowards addressing Over-smoothing essentially work on via empirical experiments\nand theoretical gradient analysis. We theoretically prove that the difficult\ntraining problem of deep MLPs is actually the main challenge, and various\nexisting methods that supposedly tackle Over-smoothing actually improve the\ntrainability of MLPs, which is the main reason for their performance gains. Our\nfurther investigation into trainability issues reveals that properly\nconstrained smaller upper bounds of gradient flow notably enhance the\ntrainability of GNNs. Experimental results on diverse datasets demonstrate\nconsistency between our theoretical findings and empirical evidence. Our\nanalysis provides new insights in constructing deep graph models.\n","authors":["Jie Peng","Runlin Lei","Zhewei Wei"],"pdf_url":"https://arxiv.org/pdf/2408.03669v1.pdf","comment":"CIKM2024"},{"id":"http://arxiv.org/abs/2403.04202v5","updated":"2024-08-07T10:10:34Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v5.pdf","comment":"Accepted at AIES 2024 (7th AAAI/ACM Conference on AI, Ethics, and\n  Society - San Jose, CA, USA)"},{"id":"http://arxiv.org/abs/2408.03664v1","updated":"2024-08-07T10:06:04Z","published":"2024-08-07T10:06:04Z","title":"AI-Driven approach for sustainable extraction of earth's subsurface\n  renewable energy while minimizing seismic activity","summary":"  Deep Geothermal Energy, Carbon Capture and Storage, and Hydrogen Storage hold\nconsiderable promise for meeting the energy sector's large-scale requirements\nand reducing CO$_2$ emissions. However, the injection of fluids into the\nEarth's crust, essential for these activities, can induce or trigger\nearthquakes. In this paper, we highlight a new approach based on Reinforcement\nLearning for the control of human-induced seismicity in the highly complex\nenvironment of an underground reservoir. This complex system poses significant\nchallenges in the control design due to parameter uncertainties and unmodeled\ndynamics. We show that the reinforcement learning algorithm can interact\nefficiently with a robust controller, by choosing the controller parameters in\nreal-time, reducing human-induced seismicity and allowing the consideration of\nfurther production objectives, \\textit{e.g.}, minimal control power.\nSimulations are presented for a simplified underground reservoir under various\nenergy demand scenarios, demonstrating the reliability and effectiveness of the\nproposed control-reinforcement learning approach.\n","authors":["Diego Gutierrez-Oribio","Alexandros Stathas","Ioannis Stefanou"],"pdf_url":"https://arxiv.org/pdf/2408.03664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18613v2","updated":"2024-08-07T09:46:49Z","published":"2024-03-27T14:28:44Z","title":"Scalable Lipschitz Estimation for CNNs","summary":"  Estimating the Lipschitz constant of deep neural networks is of growing\ninterest as it is useful for informing on generalisability and adversarial\nrobustness. Convolutional neural networks (CNNs) in particular, underpin much\nof the recent success in computer vision related applications. However,\nalthough existing methods for estimating the Lipschitz constant can be tight,\nthey have limited scalability when applied to CNNs. To tackle this, we propose\na novel method to accelerate Lipschitz constant estimation for CNNs. The core\nidea is to divide a large convolutional block via a joint layer and width-wise\npartition, into a collection of smaller blocks. We prove an upper-bound on the\nLipschitz constant of the larger block in terms of the Lipschitz constants of\nthe smaller blocks. Through varying the partition factor, the resulting method\ncan be adjusted to prioritise either accuracy or scalability and permits\nparallelisation. We demonstrate an enhanced scalability and comparable accuracy\nto existing baselines through a range of experiments.\n","authors":["Yusuf Sulehman","Tingting Mu"],"pdf_url":"https://arxiv.org/pdf/2403.18613v2.pdf","comment":"An inconsistency between the input of the flattened convolutional\n  block and the flattened, partitioned input impacts the validity of the\n  proposed Lipschitz bound"},{"id":"http://arxiv.org/abs/2408.03655v1","updated":"2024-08-07T09:45:24Z","published":"2024-08-07T09:45:24Z","title":"Consumer Transactions Simulation through Generative Adversarial Networks","summary":"  In the rapidly evolving domain of large-scale retail data systems,\nenvisioning and simulating future consumer transactions has become a crucial\narea of interest. It offers significant potential to fortify demand forecasting\nand fine-tune inventory management. This paper presents an innovative\napplication of Generative Adversarial Networks (GANs) to generate synthetic\nretail transaction data, specifically focusing on a novel system architecture\nthat combines consumer behavior modeling with stock-keeping unit (SKU)\navailability constraints to address real-world assortment optimization\nchallenges. We diverge from conventional methodologies by integrating SKU data\ninto our GAN architecture and using more sophisticated embedding methods (e.g.,\nhyper-graphs). This design choice enables our system to generate not only\nsimulated consumer purchase behaviors but also reflects the dynamic interplay\nbetween consumer behavior and SKU availability -- an aspect often overlooked,\namong others, because of data scarcity in legacy retail simulation models. Our\nGAN model generates transactions under stock constraints, pioneering a\nresourceful experimental system with practical implications for real-world\nretail operation and strategy. Preliminary results demonstrate enhanced realism\nin simulated transactions measured by comparing generated items with real ones\nusing methods employed earlier in related studies. This underscores the\npotential for more accurate predictive modeling.\n","authors":["Sergiy Tkachuk","Szymon Łukasik","Anna Wróblewska"],"pdf_url":"https://arxiv.org/pdf/2408.03655v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2408.03652v1","updated":"2024-08-07T09:34:55Z","published":"2024-08-07T09:34:55Z","title":"mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest\n  Neighbor Search","summary":"  Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)\nthat aims to identify and classify entities in text into predefined categories.\nHowever, when applied to Arabic data, NER encounters unique challenges stemming\nfrom the language's rich morphological inflections, absence of capitalization\ncues, and spelling variants, where a single word can comprise multiple\nmorphemes. In this paper, we introduce Arabic KNN-NER, our submission to the\nWojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the\nshared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained\nflat-entity recognition for Arabic text, where we identify a single main entity\nand possibly zero or multiple sub-entities for each word. Arabic KNN-NER\naugments the probability distribution of a fine-tuned model with another label\nprobability distribution derived from performing a KNN search over the cached\ntraining data. Our submission achieved 91% on the test set on the WojoodFine\ndataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.\n","authors":["Ahmed Abdou","Tasneem Mohsen"],"pdf_url":"https://arxiv.org/pdf/2408.03652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.03703v2","updated":"2024-08-07T09:18:40Z","published":"2022-08-07T12:02:48Z","title":"Granger Causality using Neural Networks","summary":"  Dependence between nodes in a network is an important concept that pervades\nmany areas including finance, politics, sociology, genomics and the brain\nsciences. One way to characterize dependence between components of a\nmultivariate time series data is via Granger Causality (GC). Standard\ntraditional approaches to GC estimation / inference commonly assume linear\ndynamics, however such simplification does not hold in many real-world\napplications where signals are inherently non-linear. In such cases, imposing\nlinear models such as vector autoregressive (VAR) models can lead to\nmis-characterization of true Granger Causal interactions. To overcome this\nlimitation, Tank et al (IEEE Transactions on Pattern Analysis and Machine\nLearning, 2022) proposed a solution that uses neural networks with sparse\nregularization penalties. The regularization encourages learnable weights to be\nsparse, which enables inference on GC. This paper overcomes the limitations of\ncurrent methods by leveraging advances in machine learning and deep learning\nwhich have been demonstrated to learn hidden patterns in the data. We propose\nnovel classes of models that can handle underlying non-linearity in a\ncomputationally efficient manner, simultaneously providing GC and lag order\nselection. Firstly, we present the Learned Kernel VAR (LeKVAR) model that\nlearns kernel parameterized by a shared neural net followed by penalization on\nlearnable weights to discover GC structure. Secondly, we show one can directly\ndecouple lags and individual time series importance via decoupled penalties.\nThis is important as we want to select the lag order during the process of GC\nestimation. This decoupling acts as a filtering and can be extended to any DL\nmodel including Multi-Layer Perceptrons (MLP), Recurrent Neural Networks (RNN),\nLong Short Term Memory Networks (LSTM), Transformers etc, for simultaneous GC\nestimation and lag selection.\n","authors":["Malik Shahid Sultan","Samuel Horvath","Hernando Ombao"],"pdf_url":"https://arxiv.org/pdf/2208.03703v2.pdf","comment":"To be Submitted to a Journal work Presented at JSM. arXiv admin note:\n  text overlap with arXiv:1802.05842 by other authors"},{"id":"http://arxiv.org/abs/2407.19265v2","updated":"2024-08-07T09:16:12Z","published":"2024-07-27T14:16:25Z","title":"Towards Robust Few-shot Class Incremental Learning in Audio\n  Classification using Contrastive Representation","summary":"  In machine learning applications, gradual data ingress is common, especially\nin audio processing where incremental learning is vital for real-time\nanalytics. Few-shot class-incremental learning addresses challenges arising\nfrom limited incoming data. Existing methods often integrate additional\ntrainable components or rely on a fixed embedding extractor post-training on\nbase sessions to mitigate concerns related to catastrophic forgetting and the\ndangers of model overfitting. However, using cross-entropy loss alone during\nbase session training is suboptimal for audio data. To address this, we propose\nincorporating supervised contrastive learning to refine the representation\nspace, enhancing discriminative power and leading to better generalization\nsince it facilitates seamless integration of incremental classes, upon arrival.\nExperimental results on NSynth and LibriSpeech datasets with 100 classes, as\nwell as ESC dataset with 50 and 10 classes, demonstrate state-of-the-art\nperformance.\n","authors":["Riyansha Singh","Parinita Nema","Vinod K Kurmi"],"pdf_url":"https://arxiv.org/pdf/2407.19265v2.pdf","comment":"INTERSPEECH 2024 accepted"},{"id":"http://arxiv.org/abs/2408.03287v2","updated":"2024-08-07T09:07:01Z","published":"2024-08-06T16:35:25Z","title":"Malicious Internet Entity Detection Using Local Graph Inference","summary":"  Detection of malicious behavior in a large network is a challenging problem\nfor machine learning in computer security, since it requires a model with high\nexpressive power and scalable inference. Existing solutions struggle to achieve\nthis feat -- current cybersec-tailored approaches are still limited in\nexpressivity, and methods successful in other domains do not scale well for\nlarge volumes of data, rendering frequent retraining impossible. This work\nproposes a new perspective for learning from graph data that is modeling\nnetwork entity interactions as a large heterogeneous graph. High expressivity\nof the method is achieved with neural network architecture HMILnet that\nnaturally models this type of data and provides theoretical guarantees. The\nscalability is achieved by pursuing local graph inference, i.e., classifying\nindividual vertices and their neighborhood as independent samples. Our\nexperiments exhibit improvement over the state-of-the-art Probabilistic Threat\nPropagation (PTP) algorithm, show a further threefold accuracy improvement when\nadditional data is used, which is not possible with the PTP algorithm, and\ndemonstrate the generalization capabilities of the method to new, previously\nunseen entities.\n","authors":["Simon Mandlik","Tomas Pevny","Vaclav Smidl","Lukas Bajer"],"pdf_url":"https://arxiv.org/pdf/2408.03287v2.pdf","comment":"A preprint. Full publication:\n  https://ieeexplore.ieee.org/document/10418120"},{"id":"http://arxiv.org/abs/2403.14973v2","updated":"2024-08-07T08:53:25Z","published":"2024-03-22T06:04:11Z","title":"Pose-Aware Self-Supervised Learning with Viewpoint Trajectory\n  Regularization","summary":"  Learning visual features from unlabeled images has proven successful for\nsemantic categorization, often by mapping different $views$ of the same object\nto the same feature to achieve recognition invariance. However, visual\nrecognition involves not only identifying $what$ an object is but also\nunderstanding $how$ it is presented. For example, seeing a car from the side\nversus head-on is crucial for deciding whether to stay put or jump out of the\nway. While unsupervised feature learning for downstream viewpoint reasoning is\nimportant, it remains under-explored, partly due to the lack of a standardized\nevaluation method and benchmarks.\n  We introduce a new dataset of adjacent image triplets obtained from a\nviewpoint trajectory, without any semantic or pose labels. We benchmark both\nsemantic classification and pose estimation accuracies on the same visual\nfeature. Additionally, we propose a viewpoint trajectory regularization loss\nfor learning features from unlabeled image triplets. Our experiments\ndemonstrate that this approach helps develop a visual representation that\nencodes object identity and organizes objects by their poses, retaining\nsemantic classification accuracy while achieving emergent global pose awareness\nand better generalization to novel objects. Our dataset and code are available\nat http://pwang.pw/trajSSL/.\n","authors":["Jiayun Wang","Yubei Chen","Stella X. Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14973v2.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03636v1","updated":"2024-08-07T08:51:10Z","published":"2024-08-07T08:51:10Z","title":"Time is Not Enough: Time-Frequency based Explanation for Time-Series\n  Black-Box Models","summary":"  Despite the massive attention given to time-series explanations due to their\nextensive applications, a notable limitation in existing approaches is their\nprimary reliance on the time-domain. This overlooks the inherent characteristic\nof time-series data containing both time and frequency features. In this work,\nwe present Spectral eXplanation (SpectralX), an XAI framework that provides\ntime-frequency explanations for time-series black-box classifiers. This easily\nadaptable framework enables users to \"plug-in\" various perturbation-based XAI\nmethods for any pre-trained time-series classification models to assess their\nimpact on the explanation quality without having to modify the framework\narchitecture. Additionally, we introduce Feature Importance Approximations\n(FIA), a new perturbation-based XAI method. These methods consist of feature\ninsertion, deletion, and combination techniques to enhance computational\nefficiency and class-specific explanations in time-series classification tasks.\nWe conduct extensive experiments in the generated synthetic dataset and various\nUCR Time-Series datasets to first compare the explanation performance of FIA\nand other existing perturbation-based XAI methods in both time-domain and\ntime-frequency domain, and then show the superiority of our FIA in the\ntime-frequency domain with the SpectralX framework. Finally, we conduct a user\nstudy to confirm the practicality of our FIA in SpectralX framework for\nclass-specific time-frequency based time-series explanations. The source code\nis available in https://github.com/gustmd0121/Time_is_not_Enough\n","authors":["Hyunseung Chung","Sumin Jo","Yeonsu Kwon","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2408.03636v1.pdf","comment":"Accepted to CIKM 2024 (10 pages, 4 figures, 6 tables)"},{"id":"http://arxiv.org/abs/2408.03626v1","updated":"2024-08-07T08:37:23Z","published":"2024-08-07T08:37:23Z","title":"On the choice of the non-trainable internal weights in random feature\n  maps","summary":"  The computationally cheap machine learning architecture of random feature\nmaps can be viewed as a single-layer feedforward network in which the weights\nof the hidden layer are random but fixed and only the outer weights are learned\nvia linear regression. The internal weights are typically chosen from a\nprescribed distribution. The choice of the internal weights significantly\nimpacts the accuracy of random feature maps. We address here the task of how to\nbest select the internal weights. In particular, we consider the forecasting\nproblem whereby random feature maps are used to learn a one-step propagator map\nfor a dynamical system. We provide a computationally cheap hit-and-run\nalgorithm to select good internal weights which lead to good forecasting skill.\nWe show that the number of good features is the main factor controlling the\nforecasting skill of random feature maps and acts as an effective feature\ndimension. Lastly, we compare random feature maps with single-layer feedforward\nneural networks in which the internal weights are now learned using gradient\ndescent. We find that random feature maps have superior forecasting\ncapabilities whilst having several orders of magnitude lower computational\ncost.\n","authors":["Pinak Mandal","Georg A. Gottwald"],"pdf_url":"https://arxiv.org/pdf/2408.03626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01185v5","updated":"2024-08-07T08:31:05Z","published":"2023-12-02T17:24:17Z","title":"A ripple in time: a discontinuity in American history","summary":"  In this technical note we suggest a novel approach to discover temporal\n(related and unrelated to language dilation) and personality (authorship\nattribution) in historical datasets. We exemplify our approach on the State of\nthe Union speeches given by the past 42 US presidents: this dataset is known\nfor its relatively small amount of data, and high variability of the amount and\nstyle of texts. Nevertheless we manage to achieve about 95\\% accuracy on the\nauthorship attribution task, and pin down the date of writing to a single\npresidential term.\n","authors":["Alexander Kolpakov","Igor Rivin"],"pdf_url":"https://arxiv.org/pdf/2312.01185v5.pdf","comment":"6 pages, 8 figures; GitHub repository\n  (https://github.com/sashakolpakov/ripple_in_time); restructured manuscript"},{"id":"http://arxiv.org/abs/2408.03619v1","updated":"2024-08-07T08:23:42Z","published":"2024-08-07T08:23:42Z","title":"Making Robust Generalizers Less Rigid with Soft Ascent-Descent","summary":"  While the traditional formulation of machine learning tasks is in terms of\nperformance on average, in practice we are often interested in how well a\ntrained model performs on rare or difficult data points at test time. To\nachieve more robust and balanced generalization, methods applying\nsharpness-aware minimization to a subset of worst-case examples have proven\nsuccessful for image classification tasks, but only using deep neural networks\nin a scenario where the most difficult points are also the least common. In\nthis work, we show how such a strategy can dramatically break down under more\ndiverse models, and as a more robust alternative, instead of typical sharpness\nwe propose and evaluate a training criterion which penalizes poor loss\nconcentration, which can be easily combined with loss transformations such as\nCVaR or DRO that control tail emphasis.\n","authors":["Matthew J. Holland","Toma Hamada"],"pdf_url":"https://arxiv.org/pdf/2408.03619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14573v2","updated":"2024-08-07T08:22:35Z","published":"2024-07-21T06:27:45Z","title":"Trading Devil Final: Backdoor attack via Stock market and Bayesian\n  Optimization","summary":"  Since the advent of generative artificial intelligence, every company and\nresearcher has been rushing to develop their own generative models, whether\ncommercial or not. Given the large number of users of these powerful new tools,\nthere is currently no intrinsically verifiable way to explain from the ground\nup what happens when LLMs (large language models) learn. For example, those\nbased on automatic speech recognition systems, which have to rely on huge and\nastronomical amounts of data collected from all over the web to produce fast\nand efficient results, In this article, we develop a backdoor attack called\nMarketBackFinal 2.0, based on acoustic data poisoning, MarketBackFinal 2.0 is\nmainly based on modern stock market models. In order to show the possible\nvulnerabilities of speech-based transformers that may rely on LLMs.\n","authors":["Orson Mengara"],"pdf_url":"https://arxiv.org/pdf/2407.14573v2.pdf","comment":"END :jumps-Diffusion and stock market: Better quantify uncertainty in\n  financial simulations"},{"id":"http://arxiv.org/abs/2304.09914v4","updated":"2024-08-07T08:20:43Z","published":"2023-04-19T18:32:49Z","title":"The Face of Populism: Examining Differences in Facial Emotional\n  Expressions of Political Leaders Using Machine Learning","summary":"  Populist rhetoric employed on online media is characterized as deeply\nimpassioned and often imbued with strong emotions. The aim of this paper is to\nempirically investigate the differences in affective nonverbal communication of\npolitical leaders. We use a deep-learning approach to process a sample of 220\nYouTube videos of political leaders from 15 different countries, analyze their\nfacial expressions of emotion and then examine differences in average emotion\nscores representing the relative presence of 6 emotional states (anger,\ndisgust, fear, happiness, sadness, and surprise) and a neutral expression for\neach frame of the YouTube video. Based on a sample of manually coded images, we\nfind that this deep-learning approach has 53-60\\% agreement with human labels.\nWe observe statistically significant differences in the average score of\nnegative emotions between groups of leaders with varying degrees of populist\nrhetoric.\n","authors":["Sara Major","Aleksandar Tomašević"],"pdf_url":"https://arxiv.org/pdf/2304.09914v4.pdf","comment":"Version 4.0: Annotation study added, supplementary information\n  extended"},{"id":"http://arxiv.org/abs/2408.03618v1","updated":"2024-08-07T08:19:44Z","published":"2024-08-07T08:19:44Z","title":"A Logical Fallacy-Informed Framework for Argument Generation","summary":"  Despite the remarkable performance of Large Language Models (LLMs), they\nstill struggle with generating logically sound arguments, resulting in\npotential risks such as spreading misinformation. An important factor\ncontributing to LLMs' suboptimal performance in generating coherent arguments\nis their oversight of logical fallacies. To address this issue, we introduce\nFIPO, a fallacy-informed framework that leverages preference optimization\nmethods to steer LLMs toward logically sound arguments. FIPO includes a\nclassification loss, to capture the fine-grained information on fallacy\ncategories. Our results on argumentation datasets show that our method reduces\nthe fallacy errors by up to 17.5%. Furthermore, our human evaluation results\nindicate that the quality of the generated arguments by our method\nsignificantly outperforms the fine-tuned baselines, as well as prior preference\noptimization methods, such as DPO. These findings highlight the importance of\nensuring models are aware of logical fallacies for effective argument\ngeneration.\n","authors":["Luca Mouchel","Debjit Paul","Shaobo Cui","Robert West","Antoine Bosselut","Boi Faltings"],"pdf_url":"https://arxiv.org/pdf/2408.03618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03617v1","updated":"2024-08-07T08:18:51Z","published":"2024-08-07T08:18:51Z","title":"Is Child-Directed Speech Effective Training Data for Language Models?","summary":"  While high-performing language models are typically trained on hundreds of\nbillions of words, human children become fluent language users with a much\nsmaller amount of data. What are the features of the data they receive, and how\ndo these features support language modeling objectives? To investigate this\nquestion, we train GPT-2 models on 29M words of English-language child-directed\nspeech and a new matched, synthetic dataset (TinyDialogues), comparing to a\nheterogeneous blend of datasets from the BabyLM challenge. We evaluate both the\nsyntactic and semantic knowledge of these models using developmentally-inspired\nevaluations. Through pretraining experiments, we test whether the global\ndevelopmental ordering or the local discourse ordering of children's training\ndata support high performance relative to other datasets. The local properties\nof the data affect model results, but somewhat surprisingly, global properties\ndo not. Further, child language input is not uniquely valuable for training\nlanguage models. These findings support the hypothesis that, rather than\nproceeding from better data, children's learning is instead substantially more\nefficient than current language modeling techniques.\n","authors":["Steven Y. Feng","Noah D. Goodman","Michael C. Frank"],"pdf_url":"https://arxiv.org/pdf/2408.03617v1.pdf","comment":"Preprint. Code and data will be released soon"},{"id":"http://arxiv.org/abs/2404.15311v2","updated":"2024-08-07T08:14:56Z","published":"2024-04-02T17:01:51Z","title":"Fusing Pretrained ViTs with TCNet for Enhanced EEG Regression","summary":"  The task of Electroencephalogram (EEG) analysis is paramount to the\ndevelopment of Brain-Computer Interfaces (BCIs). However, to reach the goal of\ndeveloping robust, useful BCIs depends heavily on the speed and the accuracy at\nwhich BCIs can understand neural dynamics. In response to that goal, this paper\ndetails the integration of pre-trained Vision Transformers (ViTs) with Temporal\nConvolutional Networks (TCNet) to enhance the precision of EEG regression. The\ncore of this approach lies in harnessing the sequential data processing\nstrengths of ViTs along with the superior feature extraction capabilities of\nTCNet, to significantly improve EEG analysis accuracy. In addition, we analyze\nthe importance of how to construct optimal patches for the attention mechanism\nto analyze, balancing both speed and accuracy tradeoffs. Our results showcase a\nsubstantial improvement in regression accuracy, as evidenced by the reduction\nof Root Mean Square Error (RMSE) from 55.4 to 51.8 on EEGEyeNet's Absolute\nPosition Task, outperforming existing state-of-the-art models. Without\nsacrificing performance, we increase the speed of this model by an order of\nmagnitude (up to 4.32x faster). This breakthrough not only sets a new benchmark\nin EEG regression analysis but also opens new avenues for future research in\nthe integration of transformer architectures with specialized feature\nextraction methods for diverse EEG datasets.\n","authors":["Eric Modesitt","Haicheng Yin","Williams Huang Wang","Brian Lu"],"pdf_url":"https://arxiv.org/pdf/2404.15311v2.pdf","comment":"Accepted HCI International 2024"},{"id":"http://arxiv.org/abs/2408.02835v2","updated":"2024-08-07T08:09:02Z","published":"2024-08-05T21:12:12Z","title":"Training a multilayer dynamical spintronic network with standard machine\n  learning tools to perform time series classification","summary":"  The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.\n","authors":["Erwan Plouet","Dédalo Sanz-Hernández","Aymeric Vecchiola","Julie Grollier","Frank Mizrahi"],"pdf_url":"https://arxiv.org/pdf/2408.02835v2.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.03612v1","updated":"2024-08-07T08:08:08Z","published":"2024-08-07T08:08:08Z","title":"JARViS: Detecting Actions in Video Using Unified Actor-Scene Context\n  Relation Modeling","summary":"  Video action detection (VAD) is a formidable vision task that involves the\nlocalization and classification of actions within the spatial and temporal\ndimensions of a video clip. Among the myriad VAD architectures, two-stage VAD\nmethods utilize a pre-trained person detector to extract the region of interest\nfeatures, subsequently employing these features for action detection. However,\nthe performance of two-stage VAD methods has been limited as they depend solely\non localized actor features to infer action semantics. In this study, we\npropose a new two-stage VAD framework called Joint Actor-scene context Relation\nmodeling based on Visual Semantics (JARViS), which effectively consolidates\ncross-modal action semantics distributed globally across spatial and temporal\ndimensions using Transformer attention. JARViS employs a person detector to\nproduce densely sampled actor features from a keyframe. Concurrently, it uses a\nvideo backbone to create spatio-temporal scene features from a video clip.\nFinally, the fine-grained interactions between actors and scenes are modeled\nthrough a Unified Action-Scene Context Transformer to directly output the final\nset of actions in parallel. Our experimental results demonstrate that JARViS\noutperforms existing methods by significant margins and achieves\nstate-of-the-art performance on three popular VAD datasets, including AVA,\nUCF101-24, and JHMDB51-21.\n","authors":["Seok Hwan Lee","Taein Son","Soo Won Seo","Jisong Kim","Jun Won Choi"],"pdf_url":"https://arxiv.org/pdf/2408.03612v1.pdf","comment":"31 pages, 10 figures"},{"id":"http://arxiv.org/abs/2404.08271v3","updated":"2024-08-07T08:00:43Z","published":"2024-04-12T06:50:32Z","title":"Transfer Learning Study of Motion Transformer-based Trajectory\n  Predictions","summary":"  Trajectory planning in autonomous driving is highly dependent on predicting\nthe emergent behavior of other road users. Learning-based methods are currently\nshowing impressive results in simulation-based challenges, with\ntransformer-based architectures technologically leading the way. Ultimately,\nhowever, predictions are needed in the real world. In addition to the shifts\nfrom simulation to the real world, many vehicle- and country-specific shifts,\ni.e. differences in sensor systems, fusion and perception algorithms as well as\ntraffic rules and laws, are on the agenda. Since models that can cover all\nsystem setups and design domains at once are not yet foreseeable, model\nadaptation plays a central role. Therefore, a simulation-based study on\ntransfer learning techniques is conducted on basis of a transformer-based\nmodel. Furthermore, the study aims to provide insights into possible trade-offs\nbetween computational time and performance to support effective transfers into\nthe real world.\n","authors":["Lars Ullrich","Alex McMaster","Knut Graichen"],"pdf_url":"https://arxiv.org/pdf/2404.08271v3.pdf","comment":"Published in 2024 IEEE Intelligent Vehicles Symposium (IV), Jeju\n  Shinhwa World, Jeju Island, Korea, June 2-5, 2024"},{"id":"http://arxiv.org/abs/2408.03608v1","updated":"2024-08-07T07:54:19Z","published":"2024-08-07T07:54:19Z","title":"InPer: Whole-Process Domain Generalization via Causal Intervention and\n  Perturbation","summary":"  Despite the considerable advancements achieved by deep neural networks, their\nperformance tends to degenerate when the test environment diverges from the\ntraining ones. Domain generalization (DG) solves this issue by learning\nrepresentations independent of domain-related information, thus facilitating\nextrapolation to unseen environments. Existing approaches typically focus on\nformulating tailored training objectives to extract shared features from the\nsource data. However, the disjointed training and testing procedures may\ncompromise robustness, particularly in the face of unforeseen variations during\ndeployment. In this paper, we propose a novel and holistic framework based on\ncausality, named InPer, designed to enhance model generalization by\nincorporating causal intervention during training and causal perturbation\nduring testing. Specifically, during the training phase, we employ\nentropy-based causal intervention (EnIn) to refine the selection of causal\nvariables. To identify samples with anti-interference causal variables from the\ntarget domain, we propose a novel metric, homeostatic score, through causal\nperturbation (HoPer) to construct a prototype classifier in test time.\nExperimental results across multiple cross-domain tasks confirm the efficacy of\nInPer.\n","authors":["Luyao Tang","Yuxuan Yuan","Chaoqi Chen","Xinghao Ding","Yue Huang"],"pdf_url":"https://arxiv.org/pdf/2408.03608v1.pdf","comment":"Accepted by BMVC2024"},{"id":"http://arxiv.org/abs/2407.18990v2","updated":"2024-08-07T07:46:39Z","published":"2024-07-25T12:07:55Z","title":"Stay Tuned: An Empirical Study of the Impact of Hyperparameters on LLM\n  Tuning in Real-World Applications","summary":"  Fine-tuning Large Language Models (LLMs) is an effective method to enhance\ntheir performance on downstream tasks. However, choosing the appropriate\nsetting of tuning hyperparameters (HPs) is a labor-intensive and\ncomputationally expensive process. Here, we provide recommended HP\nconfigurations for practical use-cases that represent a better starting point\nfor practitioners, when considering two SOTA LLMs and two commonly used tuning\nmethods. We describe Coverage-based Search (CBS), a process for ranking HP\nconfigurations based on an offline extensive grid search, such that the top\nranked configurations collectively provide a practical robust recommendation\nfor a wide range of datasets and domains. We focus our experiments on\nLlama-3-8B and Mistral-7B, as well as full fine-tuning and LoRa, conducting a\ntotal of > 10,000 tuning experiments. Our results suggest that, in general,\nLlama-3-8B and LoRA should be preferred, when possible. Moreover, we show that\nfor both models and tuning methods, exploring only a few HP configurations, as\nrecommended by our analysis, can provide excellent results in practice, making\nthis work a valuable resource for practitioners.\n","authors":["Alon Halfon","Shai Gretz","Ofir Arviv","Artem Spector","Orith Toledo-Ronen","Yoav Katz","Liat Ein-Dor","Michal Shmueli-Scheuer","Noam Slonim"],"pdf_url":"https://arxiv.org/pdf/2407.18990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03603v1","updated":"2024-08-07T07:46:08Z","published":"2024-08-07T07:46:08Z","title":"EnJa: Ensemble Jailbreak on Large Language Models","summary":"  As Large Language Models (LLMs) are increasingly being deployed in\nsafety-critical applications, their vulnerability to potential jailbreaks --\nmalicious prompts that can disable the safety mechanism of LLMs -- has\nattracted growing research attention. While alignment methods have been\nproposed to protect LLMs from jailbreaks, many have found that aligned LLMs can\nstill be jailbroken by carefully crafted malicious prompts, producing content\nthat violates policy regulations. Existing jailbreak attacks on LLMs can be\ncategorized into prompt-level methods which make up stories/logic to circumvent\nsafety alignment and token-level attack methods which leverage gradient methods\nto find adversarial tokens. In this work, we introduce the concept of Ensemble\nJailbreak and explore methods that can integrate prompt-level and token-level\njailbreak into a more powerful hybrid jailbreak attack. Specifically, we\npropose a novel EnJa attack to hide harmful instructions using prompt-level\njailbreak, boost the attack success rate using a gradient-based attack, and\nconnect the two types of jailbreak attacks via a template-based connector. We\nevaluate the effectiveness of EnJa on several aligned models and show that it\nachieves a state-of-the-art attack success rate with fewer queries and is much\nstronger than any individual jailbreak.\n","authors":["Jiahao Zhang","Zilong Wang","Ruofan Wang","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.03603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03599v1","updated":"2024-08-07T07:36:49Z","published":"2024-08-07T07:36:49Z","title":"Activations Through Extensions: A Framework To Boost Performance Of\n  Neural Networks","summary":"  Activation functions are non-linearities in neural networks that allow them\nto learn complex mapping between inputs and outputs. Typical choices for\nactivation functions are ReLU, Tanh, Sigmoid etc., where the choice generally\ndepends on the application domain. In this work, we propose a\nframework/strategy that unifies several works on activation functions and\ntheoretically explains the performance benefits of these works. We also propose\nnovel techniques that originate from the framework and allow us to obtain\n``extensions'' (i.e. special generalizations of a given neural network) of\nneural networks through operations on activation functions. We theoretically\nand empirically show that ``extensions'' of neural networks have performance\nbenefits compared to vanilla neural networks with insignificant space and time\ncomplexity costs on standard test functions. We also show the benefits of\nneural network ``extensions'' in the time-series domain on real-world datasets.\n","authors":["Chandramouli Kamanchi","Sumatra Mukherjee","Kameshwaran Sampath","Pankaj Dayama","Arindam Jati","Vijay Ekambaram","Dzung Phan"],"pdf_url":"https://arxiv.org/pdf/2408.03599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17640v2","updated":"2024-08-07T07:29:39Z","published":"2024-05-27T20:24:03Z","title":"Probabilistically Plausible Counterfactual Explanations with Normalizing\n  Flows","summary":"  We present PPCEF, a novel method for generating probabilistically plausible\ncounterfactual explanations (CFs). PPCEF advances beyond existing methods by\ncombining a probabilistic formulation that leverages the data distribution with\nthe optimization of plausibility within a unified framework. Compared to\nreference approaches, our method enforces plausibility by directly optimizing\nthe explicit density function without assuming a particular family of\nparametrized distributions. This ensures CFs are not only valid (i.e., achieve\nclass change) but also align with the underlying data's probability density.\nFor that purpose, our approach leverages normalizing flows as powerful density\nestimators to capture the complex high-dimensional data distribution.\nFurthermore, we introduce a novel loss that balances the trade-off between\nachieving class change and maintaining closeness to the original instance while\nalso incorporating a probabilistic plausibility term. PPCEF's unconstrained\nformulation allows for efficient gradient-based optimization with batch\nprocessing, leading to orders of magnitude faster computation compared to prior\nmethods. Moreover, the unconstrained formulation of PPCEF allows for the\nseamless integration of future constraints tailored to specific counterfactual\nproperties. Finally, extensive evaluations demonstrate PPCEF's superiority in\ngenerating high-quality, probabilistically plausible counterfactual\nexplanations in high-dimensional tabular settings. This makes PPCEF a powerful\ntool for not only interpreting complex machine learning models but also for\nimproving fairness, accountability, and trust in AI systems.\n","authors":["Patryk Wielopolski","Oleksii Furman","Jerzy Stefanowski","Maciej Zięba"],"pdf_url":"https://arxiv.org/pdf/2405.17640v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09032v2","updated":"2024-08-07T07:20:23Z","published":"2024-03-14T01:51:35Z","title":"CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language\n  Models to Coding Preferences","summary":"  Evaluating the alignment of large language models (LLMs) with user-defined\ncoding preferences is a challenging endeavour that requires a deep assessment\nof LLMs' outputs. Existing methods and benchmarks rely primarily on automated\nmetrics and static analysis tools, which often fail to capture the nuances of\nuser instructions and LLM outputs. To address this gap, we propose using the\nLLM-as-a-Judge methodology to evaluate the alignment of LLMs with coding\npreferences. Based on this approach, we present CodeUltraFeedback, a\ncomprehensive dataset designed to facilitate the evaluation and improvement of\nLLM alignment. CodeUltraFeedback consists of 10,000 coding instructions, each\nannotated with four responses generated from a diverse pool of 14 LLMs. These\nresponses are ranked based on five distinct coding preferences using GPT-3.5 as\na judge, providing both numerical scores and detailed textual feedback. Our\nanalysis of CodeUltraFeedback reveals that responses from GPT-3.5 and GPT-4 are\ngenerally preferred over those from open-weight LLMs, highlighting significant\ndifferences in alignment between closed and open-weight models. In turn, we\nexplore the usage of CodeUltraFeedback as feedback data to fine-tune and align\nCodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement\nlearning from AI feedback (RLAIF) with direct preference optimization (DPO).\nThe resulting aligned CodeLlama-7B-Instruct model outperforms larger LLMs in\nterms of alignment with coding preferences and shows improved functional\ncorrectness on the HumanEval+ benchmark compared to the original instruct\nmodel. Therefore, our contributions bridge the gap in preference tuning of LLMs\nfor code and set the stage for further advancements in model alignment and\nRLAIF in automated software engineering.\n","authors":["Martin Weyssow","Aton Kamanda","Houari Sahraoui"],"pdf_url":"https://arxiv.org/pdf/2403.09032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03591v1","updated":"2024-08-07T07:09:14Z","published":"2024-08-07T07:09:14Z","title":"Focal Depth Estimation: A Calibration-Free, Subject- and Daytime\n  Invariant Approach","summary":"  In an era where personalized technology is increasingly intertwined with\ndaily life, traditional eye-tracking systems and autofocal glasses face a\nsignificant challenge: the need for frequent, user-specific calibration, which\nimpedes their practicality. This study introduces a groundbreaking\ncalibration-free method for estimating focal depth, leveraging machine learning\ntechniques to analyze eye movement features within short sequences. Our\napproach, distinguished by its innovative use of LSTM networks and\ndomain-specific feature engineering, achieves a mean absolute error (MAE) of\nless than 10 cm, setting a new focal depth estimation accuracy standard. This\nadvancement promises to enhance the usability of autofocal glasses and pave the\nway for their seamless integration into extended reality environments, marking\na significant leap forward in personalized visual technology.\n","authors":["Benedikt W. Hosp","Björn Severitt","Rajat Agarwala","Evgenia Rusak","Yannick Sauer","Siegfried Wahl"],"pdf_url":"https://arxiv.org/pdf/2408.03591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03590v1","updated":"2024-08-07T07:09:06Z","published":"2024-08-07T07:09:06Z","title":"Sensitivity analysis using the Metamodel of Optimal Prognosis","summary":"  In real case applications within the virtual prototyping process, it is not\nalways possible to reduce the complexity of the physical models and to obtain\nnumerical models which can be solved quickly. Usually, every single numerical\nsimulation takes hours or even days. Although the progresses in numerical\nmethods and high performance computing, in such cases, it is not possible to\nexplore various model configurations, hence efficient surrogate models are\nrequired. Generally the available meta-model techniques show several advantages\nand disadvantages depending on the investigated problem. In this paper we\npresent an automatic approach for the selection of the optimal suitable\nmeta-model for the actual problem. Together with an automatic reduction of the\nvariable space using advanced filter techniques an efficient approximation is\nenabled also for high dimensional problems. This filter techniques enable a\nreduction of the high dimensional variable space to a much smaller subspace\nwhere meta-model-based sensitivity analyses are carried out to assess the\ninfluence of important variables and to identify the optimal subspace with\ncorresponding surrogate model which enables the most accurate probabilistic\nanalysis. For this purpose we investigate variance-based and moment-free\nsensitivity measures in combination with advanced meta-models as moving least\nsquares and kriging.\n","authors":["Thomas Most","Johannes Will"],"pdf_url":"https://arxiv.org/pdf/2408.03590v1.pdf","comment":"presented at 8th Optimization and Stochastic Days, Weimar, Germany,\n  24-25 November, 2011"},{"id":"http://arxiv.org/abs/2408.03588v1","updated":"2024-08-07T07:04:29Z","published":"2024-08-07T07:04:29Z","title":"Facing the Music: Tackling Singing Voice Separation in Cinematic Audio\n  Source Separation","summary":"  Cinematic audio source separation (CASS) is a fairly new subtask of audio\nsource separation. A typical setup of CASS is a three-stem problem, with the\naim of separating the mixture into the dialogue stem (DX), music stem (MX), and\neffects stem (FX). In practice, however, several edge cases exist as some sound\nsources do not fit neatly in either of these three stems, necessitating the use\nof additional auxiliary stems in production. One very common edge case is the\nsinging voice in film audio, which may belong in either the DX or MX, depending\nheavily on the cinematic context. In this work, we demonstrate a very\nstraightforward extension of the dedicated-decoder Bandit and query-based\nsingle-decoder Banquet models to a four-stem problem, treating non-musical\ndialogue, instrumental music, singing voice, and effects as separate stems.\nInterestingly, the query-based Banquet model outperformed the dedicated-decoder\nBandit model. We hypothesized that this is due to a better feature alignment at\nthe bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.\n","authors":["Karn N. Watcharasupat","Chih-Wei Wu","Iroro Orife"],"pdf_url":"https://arxiv.org/pdf/2408.03588v1.pdf","comment":"Submitted to the Late-Breaking Demo Session of the 25th International\n  Society for Music Information Retrieval (ISMIR) Conference, 2024"},{"id":"http://arxiv.org/abs/2405.15081v3","updated":"2024-08-07T07:03:11Z","published":"2024-05-23T22:07:54Z","title":"Distributed Harmonization: Federated Clustered Batch Effect Adjustment\n  and Generalization","summary":"  Independent and identically distributed (i.i.d.) data is essential to many\ndata analysis and modeling techniques. In the medical domain, collecting data\nfrom multiple sites or institutions is a common strategy that guarantees\nsufficient clinical diversity, determined by the decentralized nature of\nmedical data. However, data from various sites are easily biased by the local\nenvironment or facilities, thereby violating the i.i.d. rule. A common strategy\nis to harmonize the site bias while retaining important biological information.\nThe ComBat is among the most popular harmonization approaches and has recently\nbeen extended to handle distributed sites. However, when faced with situations\ninvolving newly joined sites in training or evaluating data from unknown/unseen\nsites, ComBat lacks compatibility and requires retraining with data from all\nthe sites. The retraining leads to significant computational and logistic\noverhead that is usually prohibitive. In this work, we develop a novel Cluster\nComBat harmonization algorithm, which leverages cluster patterns of the data in\ndifferent sites and greatly advances the usability of ComBat harmonization. We\nuse extensive simulation and real medical imaging data from ADNI to demonstrate\nthe superiority of the proposed approach. Our codes are provided in\nhttps://github.com/illidanlab/distributed-cluster-harmonization.\n","authors":["Bao Hoang","Yijiang Pang","Siqi Liang","Liang Zhan","Paul Thompson","Jiayu Zhou"],"pdf_url":"https://arxiv.org/pdf/2405.15081v3.pdf","comment":"11 pages, 7 figures, accepted to KDD2024-ADS"},{"id":"http://arxiv.org/abs/2407.21282v2","updated":"2024-08-07T07:00:13Z","published":"2024-07-31T02:12:05Z","title":"FedBChain: A Blockchain-enabled Federated Learning Framework for\n  Improving DeepConvLSTM with Comparative Strategy Insights","summary":"  Recent research in the field of Human Activity Recognition has shown that an\nimprovement in prediction performance can be achieved by reducing the number of\nLSTM layers. However, this kind of enhancement is only significant on\nmonolithic architectures, and when it runs on large-scale distributed training,\ndata security and privacy issues will be reconsidered, and its prediction\nperformance is unknown. In this paper, we introduce a novel framework:\nFedBChain, which integrates the federated learning paradigm based on a modified\nDeepConvLSTM architecture with a single LSTM layer. This framework performs\ncomparative tests of prediction performance on three different real-world\ndatasets based on three different hidden layer units (128, 256, and 512)\ncombined with five different federated learning strategies, respectively. The\nresults show that our architecture has significant improvements in Precision,\nRecall and F1-score compared to the centralized training approach on all\ndatasets with all hidden layer units for all strategies: FedAvg strategy\nimproves on average by 4.54%, FedProx improves on average by 4.57%,\nFedTrimmedAvg improves on average by 4.35%, Krum improves by 4.18% on average,\nand FedAvgM improves by 4.46% on average. Based on our results, it can be seen\nthat FedBChain not only improves in performance, but also guarantees the\nsecurity and privacy of user data compared to centralized training methods\nduring the training process. The code for our experiments is publicly available\n(https://github.com/Glen909/FedBChain).\n","authors":["Gaoxuan Li","Chern Hong Lim","Qiyao Ma","Xinyu Tang","Hwa Hui Tew","Fan Ding","Xuewen Luo"],"pdf_url":"https://arxiv.org/pdf/2407.21282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03585v1","updated":"2024-08-07T06:44:47Z","published":"2024-08-07T06:44:47Z","title":"Hierarchical Neural Constructive Solver for Real-world TSP Scenarios","summary":"  Existing neural constructive solvers for routing problems have predominantly\nemployed transformer architectures, conceptualizing the route construction as a\nset-to-sequence learning task. However, their efficacy has primarily been\ndemonstrated on entirely random problem instances that inadequately capture\nreal-world scenarios. In this paper, we introduce realistic Traveling Salesman\nProblem (TSP) scenarios relevant to industrial settings and derive the\nfollowing insights: (1) The optimal next node (or city) to visit often lies\nwithin proximity to the current node, suggesting the potential benefits of\nbiasing choices based on current locations. (2) Effectively solving the TSP\nrequires robust tracking of unvisited nodes and warrants succinct grouping\nstrategies. Building upon these insights, we propose integrating a learnable\nchoice layer inspired by Hypernetworks to prioritize choices based on the\ncurrent location, and a learnable approximate clustering algorithm inspired by\nthe Expectation-Maximization algorithm to facilitate grouping the unvisited\ncities. Together, these two contributions form a hierarchical approach towards\nsolving the realistic TSP by considering both immediate local neighbourhoods\nand learning an intermediate set of node representations. Our hierarchical\napproach yields superior performance compared to both classical and recent\ntransformer models, showcasing the efficacy of the key designs.\n","authors":["Yong Liang Goh","Zhiguang Cao","Yining Ma","Yanfei Dong","Mohammed Haroon Dupty","Wee Sun Lee"],"pdf_url":"https://arxiv.org/pdf/2408.03585v1.pdf","comment":"Accepted to KDD 2024"},{"id":"http://arxiv.org/abs/2408.03574v1","updated":"2024-08-07T06:26:04Z","published":"2024-08-07T06:26:04Z","title":"Teach CLIP to Develop a Number Sense for Ordinal Regression","summary":"  Ordinal regression is a fundamental problem within the field of computer\nvision, with customised well-trained models on specific tasks. While\npre-trained vision-language models (VLMs) have exhibited impressive performance\non various vision tasks, their potential for ordinal regression has received\nless exploration. In this study, we first investigate CLIP's potential for\nordinal regression, from which we expect the model could generalise to\ndifferent ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP\nfails on this task, since current VLMs have a well-documented limitation of\nencapsulating compositional concepts such as number sense. We propose a simple\nyet effective method called NumCLIP to improve the quantitative understanding\nof VLMs. We disassemble the exact image to number-specific text matching\nproblem into coarse classification and fine prediction stages. We discretize\nand phrase each numerical bin with common language concept to better leverage\nthe available pre-trained alignment in CLIP. To consider the inherent\ncontinuous property of ordinal regression, we propose a novel fine-grained\ncross-modal ranking-based regularisation loss specifically designed to keep\nboth semantic and ordinal alignment in CLIP's feature space. Experimental\nresults on three general ordinal regression tasks demonstrate the effectiveness\nof NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating\nand image aesthetics assessment task, respectively. Code is publicly available\nat https://github.com/xmed-lab/NumCLIP.\n","authors":["Yao Du","Qiang Zhai","Weihang Dai","Xiaomeng Li"],"pdf_url":"https://arxiv.org/pdf/2408.03574v1.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2408.03572v1","updated":"2024-08-07T06:16:17Z","published":"2024-08-07T06:16:17Z","title":"2D-OOB: Attributing Data Contribution through Joint Valuation Framework","summary":"  Data valuation has emerged as a powerful framework to quantify the\ncontribution of each datum to the training of a particular machine learning\nmodel. However, it is crucial to recognize that the quality of various cells\nwithin a single data point can vary greatly in practice. For example, even in\nthe case of an abnormal data point, not all cells are necessarily noisy. The\nsingle scalar valuation assigned by existing methods blurs the distinction\nbetween noisy and clean cells of a data point, thereby compromising the\ninterpretability of the valuation. In this paper, we propose 2D-OOB, an\nout-of-bag estimation framework for jointly determining helpful (or\ndetrimental) samples, as well as the particular cells that drive them. Our\ncomprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art\nperformance across multiple use cases, while being exponentially faster. 2D-OOB\nexcels in detecting and rectifying fine-grained outliers at the cell level, as\nwell as localizing backdoor triggers in data poisoning attacks.\n","authors":["Yifan Sun","Jingyan Shen","Yongchan Kwon"],"pdf_url":"https://arxiv.org/pdf/2408.03572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03569v1","updated":"2024-08-07T06:11:37Z","published":"2024-08-07T06:11:37Z","title":"Maximum a Posteriori Estimation for Linear Structural Dynamics Models\n  Using Bayesian Optimization with Rational Polynomial Chaos Expansions","summary":"  Bayesian analysis enables combining prior knowledge with measurement data to\nlearn model parameters. Commonly, one resorts to computing the maximum a\nposteriori (MAP) estimate, when only a point estimate of the parameters is of\ninterest. We apply MAP estimation in the context of structural dynamic models,\nwhere the system response can be described by the frequency response function.\nTo alleviate high computational demands from repeated expensive model calls, we\nutilize a rational polynomial chaos expansion (RPCE) surrogate model that\nexpresses the system frequency response as a rational of two polynomials with\ncomplex coefficients. We propose an extension to an existing sparse Bayesian\nlearning approach for RPCE based on Laplace's approximation for the posterior\ndistribution of the denominator coefficients. Furthermore, we introduce a\nBayesian optimization approach, which allows to adaptively enrich the\nexperimental design throughout the optimization process of MAP estimation.\nThereby, we utilize the expected improvement acquisition function as a means to\nidentify sample points in the input space that are possibly associated with\nlarge objective function values. The acquisition function is estimated through\nMonte Carlo sampling based on the posterior distribution of the expansion\ncoefficients identified in the sparse Bayesian learning process. By combining\nthe sparsity-inducing learning procedure with the sequential experimental\ndesign, we effectively reduce the number of model evaluations in the MAP\nestimation problem. We demonstrate the applicability of the presented methods\non the parameter updating problem of an algebraic two-degree-of-freedom system\nand the finite element model of a cross-laminated timber plate.\n","authors":["Felix Schneider","Iason Papaioannou","Bruno Sudret","Gerhard Müller"],"pdf_url":"https://arxiv.org/pdf/2408.03569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03568v1","updated":"2024-08-07T06:11:25Z","published":"2024-08-07T06:11:25Z","title":"A comparative study of generative adversarial networks for image\n  recognition algorithms based on deep learning and traditional methods","summary":"  In this paper, an image recognition algorithm based on the combination of\ndeep learning and generative adversarial network (GAN) is studied, and compared\nwith traditional image recognition methods. The purpose of this study is to\nevaluate the advantages and application prospects of deep learning technology,\nespecially GAN, in the field of image recognition. Firstly, this paper reviews\nthe basic principles and techniques of traditional image recognition methods,\nincluding the classical algorithms based on feature extraction such as SIFT,\nHOG and their combination with support vector machine (SVM), random forest, and\nother classifiers. Then, the working principle, network structure, and unique\nadvantages of GAN in image generation and recognition are introduced. In order\nto verify the effectiveness of GAN in image recognition, a series of\nexperiments are designed and carried out using multiple public image data sets\nfor training and testing. The experimental results show that compared with\ntraditional methods, GAN has excellent performance in processing complex\nimages, recognition accuracy, and anti-noise ability. Specifically, Gans are\nbetter able to capture high-dimensional features and details of images,\nsignificantly improving recognition performance. In addition, Gans shows unique\nadvantages in dealing with image noise, partial missing information, and\ngenerating high-quality images.\n","authors":["Yihao Zhong","Yijing Wei","Yingbin Liang","Xiqing Liu","Rongwei Ji","Yiru Cang"],"pdf_url":"https://arxiv.org/pdf/2408.03568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11755v3","updated":"2024-08-07T06:05:42Z","published":"2024-03-18T13:03:24Z","title":"Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs","summary":"  Prompt ensembling of Large Language Model (LLM) generated category-specific\nprompts has emerged as an effective method to enhance zero-shot recognition\nability of Vision-Language Models (VLMs). To obtain these category-specific\nprompts, the present methods rely on hand-crafting the prompts to the LLMs for\ngenerating VLM prompts for the downstream tasks. However, this requires\nmanually composing these task-specific prompts and still, they might not cover\nthe diverse set of visual concepts and task-specific styles associated with the\ncategories of interest. To effectively take humans out of the loop and\ncompletely automate the prompt generation process for zero-shot recognition, we\npropose Meta-Prompting for Visual Recognition (MPVR). Taking as input only\nminimal information about the target task, in the form of its short natural\nlanguage description, and a list of associated class labels, MPVR automatically\nproduces a diverse set of category-specific prompts resulting in a strong\nzero-shot classifier. MPVR generalizes effectively across various popular\nzero-shot image recognition benchmarks belonging to widely different domains\nwhen tested with multiple LLMs and VLMs. For example, MPVR obtains a zero-shot\nrecognition improvement over CLIP by up to 19.8% and 18.2% (5.0% and 4.5% on\naverage over 20 datasets) leveraging GPT and Mixtral LLMs, respectively\n","authors":["M. Jehanzeb Mirza","Leonid Karlinsky","Wei Lin","Sivan Doveh","Jakub Micorek","Mateusz Kozinski","Hilde Kuehne","Horst Possegger"],"pdf_url":"https://arxiv.org/pdf/2403.11755v3.pdf","comment":"ECCV Camera Ready. Code & Data:\n  https://jmiemirza.github.io/Meta-Prompting/"},{"id":"http://arxiv.org/abs/2408.03029v2","updated":"2024-08-07T05:59:46Z","published":"2024-08-06T08:22:16Z","title":"Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning","summary":"  Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to relevant baselines.\n","authors":["Haozhe Ma","Zhengding Luo","Thanh Vinh Vo","Kuankuan Sima","Tze-Yun Leong"],"pdf_url":"https://arxiv.org/pdf/2408.03029v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03561v1","updated":"2024-08-07T05:50:17Z","published":"2024-08-07T05:50:17Z","title":"MPC-Minimized Secure LLM Inference","summary":"  Many inference services based on large language models (LLMs) pose a privacy\nconcern, either revealing user prompts to the service or the proprietary\nweights to the user. Secure inference offers a solution to this problem through\nsecure multi-party computation (MPC), however, it is still impractical for\nmodern LLM workload due to the large overhead imposed by MPC. To address this\noverhead, we propose Marill, a framework that adapts LLM fine-tuning to\nminimize MPC usage during secure inference. Marill introduces high-level\narchitectural changes during fine-tuning that significantly reduce the number\nof expensive operations needed within MPC during inference, by removing some\nand relocating others outside MPC without compromising security. As a result,\nMarill-generated models are more efficient across all secure inference\nprotocols and our approach complements MPC-friendly approximations for such\noperations. Compared to standard fine-tuning, Marill results in 3.6-11.3x\nbetter runtime and 2.4-6.9x better communication during secure inference across\nvarious MPC settings, while typically preserving over 90% performance across\ndownstream tasks.\n","authors":["Deevashwer Rathee","Dacheng Li","Ion Stoica","Hao Zhang","Raluca Popa"],"pdf_url":"https://arxiv.org/pdf/2408.03561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03560v1","updated":"2024-08-07T05:48:05Z","published":"2024-08-07T05:48:05Z","title":"In2Core: Leveraging Influence Functions for Coreset Selection in\n  Instruction Finetuning of Large Language Models","summary":"  Despite advancements, fine-tuning Large Language Models (LLMs) remains costly\ndue to the extensive parameter count and substantial data requirements for\nmodel generalization. Accessibility to computing resources remains a barrier\nfor the open-source community. To address this challenge, we propose the\nIn2Core algorithm, which selects a coreset by analyzing the correlation between\ntraining and evaluation samples with a trained model. Notably, we assess the\nmodel's internal gradients to estimate this relationship, aiming to rank the\ncontribution of each training point. To enhance efficiency, we propose an\noptimization to compute influence functions with a reduced number of layers\nwhile achieving similar accuracy. By applying our algorithm to instruction\nfine-tuning data of LLMs, we can achieve similar performance with just 50% of\nthe training data. Meantime, using influence functions to analyze model\ncoverage to certain testing samples could provide a reliable and interpretable\nsignal on the training set's coverage of those test points.\n","authors":["Ayrton San Joaquin","Bin Wang","Zhengyuan Liu","Nicholas Asher","Brian Lim","Philippe Muller","Nancy Chen"],"pdf_url":"https://arxiv.org/pdf/2408.03560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03554v1","updated":"2024-08-07T05:30:10Z","published":"2024-08-07T05:30:10Z","title":"Empirical Analysis of Large Vision-Language Models against Goal\n  Hijacking via Visual Prompt Injection","summary":"  We explore visual prompt injection (VPI) that maliciously exploits the\nability of large vision-language models (LVLMs) to follow instructions drawn\nonto the input image. We propose a new VPI method, \"goal hijacking via visual\nprompt injection\" (GHVPI), that swaps the execution task of LVLMs from an\noriginal task to an alternative task designated by an attacker. The\nquantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and\ndemonstrates a notable attack success rate of 15.8%, which is an unignorable\nsecurity risk. Our analysis also shows that successful GHVPI requires high\ncharacter recognition capability and instruction-following ability in LVLMs.\n","authors":["Subaru Kimura","Ryota Tanaka","Shumpei Miyawaki","Jun Suzuki","Keisuke Sakaguchi"],"pdf_url":"https://arxiv.org/pdf/2408.03554v1.pdf","comment":"8 pages, 6 figures, Accepted to NAACL 2024 SRW"},{"id":"http://arxiv.org/abs/2106.11760v5","updated":"2024-08-07T05:28:30Z","published":"2021-06-19T06:25:10Z","title":"Fingerprinting Image-to-Image Generative Adversarial Networks","summary":"  Generative Adversarial Networks (GANs) have been widely used in various\napplication scenarios. Since the production of a commercial GAN requires\nsubstantial computational and human resources, the copyright protection of GANs\nis urgently needed. This paper presents a novel fingerprinting scheme for the\nIntellectual Property (IP) protection of image-to-image GANs based on a trusted\nthird party. We break through the stealthiness and robustness bottlenecks\nsuffered by previous fingerprinting methods for classification models being\nnaively transferred to GANs. Specifically, we innovatively construct a\ncomposite deep learning model from the target GAN and a classifier. Then we\ngenerate fingerprint samples from this composite model, and embed them in the\nclassifier for effective ownership verification. This scheme inspires some\nconcrete methodologies to practically protect the modern image-to-image\ntranslation GANs. Theoretical analysis proves that these methods can satisfy\ndifferent security requirements necessary for IP protection. We also conduct\nextensive experiments to show that our solutions outperform existing\nstrategies.\n","authors":["Guanlin Li","Guowen Xu","Han Qiu","Shangwei Guo","Run Wang","Jiwei Li","Tianwei Zhang","Rongxing Lu"],"pdf_url":"https://arxiv.org/pdf/2106.11760v5.pdf","comment":"Accepted by EuroS&P 2024"},{"id":"http://arxiv.org/abs/2302.01089v4","updated":"2024-08-07T05:22:57Z","published":"2023-02-02T13:22:18Z","title":"Curriculum Learning for ab initio Deep Learned Refractive Optics","summary":"  Deep optical optimization has recently emerged as a new paradigm for\ndesigning computational imaging systems using only the output image as the\nobjective. However, it has been limited to either simple optical systems\nconsisting of a single element such as a diffractive optical element (DOE) or\nmetalens, or the fine-tuning of compound lenses from good initial designs. Here\nwe present a DeepLens design method based on curriculum learning, which is able\nto learn optical designs of compound lenses ab initio from randomly initialized\nsurfaces without human intervention, therefore overcoming the need for a good\ninitial design. We demonstrate the effectiveness of our approach by fully\nautomatically designing both classical imaging lenses and a large field-of-view\nextended depth-of-field computational lens in a cellphone-style form factor,\nwith highly aspheric surfaces and a short back focal length.\n","authors":["Xinge Yang","Qiang Fu","Wolfgang Heidrich"],"pdf_url":"https://arxiv.org/pdf/2302.01089v4.pdf","comment":"Automatically design computational lenses from scratch with\n  differentiable ray tracing"},{"id":"http://arxiv.org/abs/2408.02050v2","updated":"2024-08-07T05:15:53Z","published":"2024-08-04T14:57:44Z","title":"Recovering the state and dynamics of autonomous system with partial\n  states solution using neural networks","summary":"  In this paper we explore the performance of deep hidden physics model (M.\nRaissi 2018) for autonomous systems. These systems are described by set of\nordinary differential equations which do not explicitly depend on time. Such\nsystems can be found in nature and have applications in modeling chemical\nconcentrations, population dynamics, n-body problems in physics etc. In this\nwork we consider dynamics of states, which explain how the states will evolve\nare unknown to us. We approximate state and dynamics both using neural\nnetworks. We have considered examples of 2D linear/nonlinear and Lorenz\nsystems. We observe that even without knowing all the states information, we\ncan estimate dynamics of certain states whose state information are known.\n","authors":["Vijay Kag"],"pdf_url":"https://arxiv.org/pdf/2408.02050v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11652v5","updated":"2024-08-07T05:14:24Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v5.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2304.06237v3","updated":"2024-08-07T04:59:21Z","published":"2023-04-13T03:20:45Z","title":"Deep learning based ECG segmentation for delineation of diverse\n  arrhythmias","summary":"  Accurate delineation of key waveforms in an ECG is a critical step in\nextracting relevant features to support the diagnosis and treatment of heart\nconditions. Although deep learning based methods using segmentation models to\nlocate P, QRS, and T waves have shown promising results, their ability to\nhandle arrhythmias has not been studied in any detail. In this paper we\ninvestigate the effect of arrhythmias on delineation quality and develop\nstrategies to improve performance in such cases. We introduce a U-Net-like\nsegmentation model for ECG delineation with a particular focus on diverse\narrhythmias. This is followed by a post-processing algorithm which removes\nnoise and automatically determines the boundaries of P, QRS, and T waves. Our\nmodel has been trained on a diverse dataset and evaluated against the LUDB and\nQTDB datasets to show strong performance, with F1-scores exceeding 99% for QRS\nand T waves, and over 97% for P waves in the LUDB dataset. Furthermore, we\nassess various models across a wide array of arrhythmias and observe that\nmodels with a strong performance on standard benchmarks may still perform\npoorly on arrhythmias that are underrepresented in these benchmarks, such as\ntachycardias. We propose solutions to address this discrepancy.\n","authors":["Chankyu Joung","Mijin Kim","Taejin Paik","Seong-Ho Kong","Seung-Young Oh","Won Kyeong Jeon","Jae-hu Jeon","Joong-Sik Hong","Wan-Joong Kim","Woong Kook","Myung-Jin Cha","Otto van Koert"],"pdf_url":"https://arxiv.org/pdf/2304.06237v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03539v1","updated":"2024-08-07T04:35:38Z","published":"2024-08-07T04:35:38Z","title":"Deep Reinforcement Learning for Robotics: A Survey of Real-World\n  Successes","summary":"  Reinforcement learning (RL), particularly its combination with deep neural\nnetworks referred to as deep RL (DRL), has shown tremendous promise across a\nwide range of applications, suggesting its potential for enabling the\ndevelopment of sophisticated robotic behaviors. Robotics problems, however,\npose fundamental difficulties for the application of RL, stemming from the\ncomplexity and cost of interacting with the physical world. This article\nprovides a modern survey of DRL for robotics, with a particular focus on\nevaluating the real-world successes achieved with DRL in realizing several key\nrobotic competencies. Our analysis aims to identify the key factors underlying\nthose exciting successes, reveal underexplored areas, and provide an overall\ncharacterization of the status of DRL in robotics. We highlight several\nimportant avenues for future work, emphasizing the need for stable and\nsample-efficient real-world RL paradigms, holistic approaches for discovering\nand integrating various competencies to tackle complex long-horizon, open-world\ntasks, and principled development and evaluation procedures. This survey is\ndesigned to offer insights for both RL practitioners and roboticists toward\nharnessing RL's power to create generally capable real-world robotic systems.\n","authors":["Chen Tang","Ben Abbatematteo","Jiaheng Hu","Rohan Chandra","Roberto Martín-Martín","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2408.03539v1.pdf","comment":"The first three authors contributed equally. Accepted to Annual\n  Review of Control, Robotics, and Autonomous Systems"},{"id":"http://arxiv.org/abs/2408.03526v1","updated":"2024-08-07T03:37:25Z","published":"2024-08-07T03:37:25Z","title":"Minimum Enclosing Ball Synthetic Minority Oversampling Technique from a\n  Geometric Perspective","summary":"  Class imbalance refers to the significant difference in the number of samples\nfrom different classes within a dataset, making it challenging to identify\nminority class samples correctly. This issue is prevalent in real-world\nclassification tasks, such as software defect prediction, medical diagnosis,\nand fraud detection. The synthetic minority oversampling technique (SMOTE) is\nwidely used to address class imbalance issue, which is based on interpolation\nbetween randomly selected minority class samples and their neighbors. However,\ntraditional SMOTE and most of its variants only interpolate between existing\nsamples, which may be affected by noise samples in some cases and synthesize\nsamples that lack diversity. To overcome these shortcomings, this paper\nproposes the Minimum Enclosing Ball SMOTE (MEB-SMOTE) method from a geometry\nperspective. Specifically, MEB is innovatively introduced into the oversampling\nmethod to construct a representative point. Then, high-quality samples are\nsynthesized by interpolation between this representative point and the existing\nsamples. The rationale behind constructing a representative point is discussed,\ndemonstrating that the center of MEB is more suitable as the representative\npoint. To exhibit the superiority of MEB-SMOTE, experiments are conducted on 15\nreal-world imbalanced datasets. The results indicate that MEB-SMOTE can\neffectively improve the classification performance on imbalanced datasets.\n","authors":["Yi-Yang Shangguan","Shi-Shun Chen","Xiao-Yang Li"],"pdf_url":"https://arxiv.org/pdf/2408.03526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04360v2","updated":"2024-08-07T03:36:51Z","published":"2024-04-05T19:14:14Z","title":"Prompt Public Large Language Models to Synthesize Data for Private\n  On-device Applications","summary":"  Pre-training on public data is an effective method to improve the performance\nfor federated learning (FL) with differential privacy (DP). This paper\ninvestigates how large language models (LLMs) trained on public data can\nimprove the quality of pre-training data for the on-device language models\ntrained with DP and FL. We carefully design LLM prompts to filter and transform\nexisting public data, and generate new data to resemble the real user data\ndistribution. The model pre-trained on our synthetic dataset achieves relative\nimprovement of 19.0% and 22.8% in next word prediction accuracy compared to the\nbaseline model pre-trained on a standard public dataset, when evaluated over\nthe real user data in Gboard (Google Keyboard, a production mobile keyboard\napplication). Furthermore, our method achieves evaluation accuracy better than\nor comparable to the baseline during the DP FL fine-tuning over millions of\nmobile devices, and our final model outperforms the baseline in production A/B\ntesting. Our experiments demonstrate the strengths of LLMs in synthesizing data\nclose to the private distribution even without accessing the private data, and\nalso suggest future research directions to further reduce the distribution gap.\n","authors":["Shanshan Wu","Zheng Xu","Yanxiang Zhang","Yuanbo Zhang","Daniel Ramage"],"pdf_url":"https://arxiv.org/pdf/2404.04360v2.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2305.18403v5","updated":"2024-08-07T03:30:30Z","published":"2023-05-28T15:15:48Z","title":"LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient\n  Fine-Tuning","summary":"  Large Language Models (LLMs), such as LLaMA and T5, have shown exceptional\nperformance across various tasks through fine-tuning. Although low-rank\nadaption (LoRA) has emerged to cheaply fine-tune these LLMs on downstream\ntasks, their deployment is still hindered by the vast model scale and\ncomputational costs. Post-training model pruning offers a way to compress LLMs.\nHowever, the current pruning methods designed for LLMs are not compatible with\nLoRA. This is due to their utilization of unstructured pruning on LLMs,\nimpeding the merging of LoRA weights, or their dependence on the gradients of\npre-trained weights to guide pruning, which can impose significant memory\noverhead. To this end, we propose LoRAPrune, a new framework that delivers an\naccurate structured pruned model in a highly memory-efficient manner.\nSpecifically, we first design a LoRA-guided pruning criterion, which uses the\nweights and gradients of LoRA, rather than the gradients of pre-trained weights\nfor importance estimation. We subsequently integrate this criterion into an\niterative pruning process, effectively removing redundant channels and heads.\nExtensive experimental results demonstrate the superior performance of our\nLoRAPrune over existing approaches on the LLaMA series models. At a 50\\%\ncompression rate, LoRAPrune demonstrates superior performance over LLM-Pruner,\nachieving a reduction in perplexity by 4.81 on WikiText2 and 3.46 on PTB, while\nalso decreasing memory usage by 52.6%. Besides, LoRAPrune also matches\nsemi-structural pruning across multiple LLMs, proving its wide applicability.\nThe code is available at https://github.com/aim-uofa/LoRAPrune.\n","authors":["Mingyang Zhang","Hao Chen","Chunhua Shen","Zhen Yang","Linlin Ou","Xinyi Yu","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2305.18403v5.pdf","comment":"accepted by acl 2024 findings"},{"id":"http://arxiv.org/abs/2408.03516v1","updated":"2024-08-07T02:54:43Z","published":"2024-08-07T02:54:43Z","title":"Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in\n  Autonomous Driving","summary":"  This paper introduces a novel method for open-vocabulary 3D scene\nunderstanding in autonomous driving by combining Language Embedded 3D Gaussians\nwith Large Language Models (LLMs) for enhanced inference. We propose utilizing\nLLMs to generate contextually relevant canonical phrases for segmentation and\nscene interpretation. Our method leverages the contextual and semantic\ncapabilities of LLMs to produce a set of canonical phrases, which are then\ncompared with the language features embedded in the 3D Gaussians. This\nLLM-guided approach significantly improves zero-shot scene understanding and\ndetection of objects of interest, even in the most challenging or unfamiliar\nenvironments. Experimental results on the WayveScenes101 dataset demonstrate\nthat our approach surpasses state-of-the-art methods in terms of accuracy and\nflexibility for open-vocabulary object detection and segmentation. This work\nrepresents a significant advancement towards more intelligent, context-aware\nautonomous driving systems, effectively bridging 3D scene representation with\nhigh-level semantic understanding.\n","authors":["Amirhosein Chahe","Lifeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.03516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16087v4","updated":"2024-08-07T02:36:19Z","published":"2024-06-23T12:02:17Z","title":"Imperative Learning: A Self-supervised Neural-Symbolic Learning\n  Framework for Robot Autonomy","summary":"  Data-driven methods such as reinforcement and imitation learning have\nachieved remarkable success in robot autonomy. However, their data-centric\nnature still hinders them from generalizing well to ever-changing environments.\nMoreover, collecting large datasets for robotic tasks is often impractical and\nexpensive. To overcome these challenges, we introduce a new self-supervised\nneural-symbolic (NeSy) computational framework, imperative learning (IL), for\nrobot autonomy, leveraging the generalization abilities of symbolic reasoning.\nThe framework of IL consists of three primary components: a neural module, a\nreasoning engine, and a memory system. We formulate IL as a special bilevel\noptimization (BLO), which enables reciprocal learning over the three modules.\nThis overcomes the label-intensive obstacles associated with data-driven\napproaches and takes advantage of symbolic reasoning concerning logical\nreasoning, physical principles, geometric analysis, etc. We discuss several\noptimization techniques for IL and verify their effectiveness in five distinct\nrobot autonomy tasks including path planning, rule induction, optimal control,\nvisual odometry, and multi-robot routing. Through various experiments, we show\nthat IL can significantly enhance robot autonomy capabilities and we anticipate\nthat it will catalyze further research across diverse domains.\n","authors":["Chen Wang","Kaiyi Ji","Junyi Geng","Zhongqiang Ren","Taimeng Fu","Fan Yang","Yifan Guo","Haonan He","Xiangyu Chen","Zitong Zhan","Qiwei Du","Shaoshu Su","Bowen Li","Yuheng Qiu","Yi Du","Qihang Li","Yifan Yang","Xiao Lin","Zhipeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.16087v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03508v1","updated":"2024-08-07T02:19:17Z","published":"2024-08-07T02:19:17Z","title":"Unsupervised, Self-driving Multi-Step Growth of InAs/GaAs Quantum Dots\n  Heterostructures Guided by Machine Learning","summary":"  The semiconductor industry has prioritized automating repetitive tasks by\nclosed-loop, autonomous experimentation which enables accelerated optimization\nof complex multi-step processes. The emergence of machine learning (ML) has\nushered in automated process with minimal human intervention. In this work, we\ndevelop SemiEpi, a self-driving automation platform capable of executing\nmolecular beam epitaxy (MBE) growth with multi-steps, continuous in-situ\nmonitoring, and on-the-fly feedback control. By integrating standard hardware,\nhomemade software, curve fitting, and multiple ML models, SemiEpi operates\nautonomously, eliminating the need for extensive expertise in MBE processes to\nachieve optimal outcomes. The platform actively learns from previous\nexperimental results, identifying favorable conditions and proposing new\nexperiments to achieve the desired results. We standardize and optimize growth\nfor InAs/GaAs quantum dots (QDs) heterostructures to showcase the power of\nML-guided multi-step growth. A temperature calibration was implemented to get\nthe initial growth condition, and fine control of the process was executed\nusing ML. Leveraging RHEED movies acquired during the growth, SemiEpi\nsuccessfully identified and optimized a novel route for multi-step\nheterostructure growth. This work demonstrates the capabilities of closed-loop,\nML-guided systems in addressing challenges in multi-step growth for any device.\nOur method is critical to achieve repeatable materials growth using\ncommercially scalable tools. Our strategy facilitates the development of a\nhardware-independent process and enhancing process repeatability and stability,\neven without exhaustive knowledge of growth parameters.\n","authors":["Chao Shen","Wenkang Zhan","Hongyu Sun","Kaiyao Xin","Bo Xu","Zhanguo Wang","Chao Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.03508v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2407.03089v3","updated":"2024-08-07T02:06:13Z","published":"2024-07-03T13:26:31Z","title":"Spatio-Temporal Adaptive Diffusion Models for EEG Super-Resolution in\n  Epilepsy Diagnosis","summary":"  Electroencephalogram (EEG) technology, particularly high-density EEG (HD EEG)\ndevices, is widely used in fields such as neuroscience. HD EEG devices improve\nthe spatial resolution of EEG by placing more electrodes on the scalp, meeting\nthe requirements of clinical diagnostic applications such as epilepsy focus\nlocalization. However, this technique faces challenges such as high acquisition\ncosts and limited usage scenarios. In this paper, spatio-temporal adaptive\ndiffusion models (STADMs) are proposed to pioneer the use of diffusion models\nfor achieving spatial SR reconstruction from low-resolution (LR, 64 channels or\nfewer) EEG to high-resolution (HR, 256 channels) EEG. Specifically, a\nspatio-temporal condition module is designed to extract the spatio-temporal\nfeatures of LR EEG, which then serve as conditional inputs to guide the reverse\ndenoising process of diffusion models. Additionally, a multi-scale Transformer\ndenoising module is constructed to leverage multi-scale convolution blocks and\ncross-attention-based diffusion Transformer blocks for conditional guidance to\ngenerate subject-adaptive SR EEG. Experimental results demonstrate that the\nproposed method effectively enhances the spatial resolution of LR EEG and\nquantitatively outperforms existing methods. Furthermore, STADMs demonstrate\ntheir value by applying synthetic SR EEG to classification and source\nlocalization tasks of epilepsy patients, indicating their potential to\nsignificantly improve the spatial resolution of LR EEG.\n","authors":["Tong Zhou","Shuqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2407.03089v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09274v4","updated":"2024-08-07T01:46:11Z","published":"2024-01-17T15:25:50Z","title":"Avoiding strict saddle points of nonconvex regularized problems","summary":"  In this paper, we consider a class of non-convex and non-smooth sparse\noptimization problems, which encompass most existing nonconvex\nsparsity-inducing terms. We show the second-order optimality conditions only\ndepend on the nonzeros of the stationary points. We propose two damped\niterative reweighted algorithms including the iteratively reweighted $\\ell_1$\nalgorithm (DIRL$_1$) and the iteratively reweighted $\\ell_2$ (DIRL$_2$)\nalgorithm, to solve these problems. For DIRL$_1$, we show the reweighted\n$\\ell_1$ subproblem has support identification property so that DIRL$_1$\nlocally reverts to a gradient descent algorithm around a stationary point. For\nDIRL$_2$, we show the solution map of the reweighted $\\ell_2$ subproblem is\ndifferentiable and Lipschitz continuous everywhere. Therefore, the map of\nDIRL$_1$ and DIRL$_2$ and their inverse are Lipschitz continuous, and the\nstrict saddle points are their unstable fixed points. By applying the stable\nmanifold theorem, these algorithms are shown to converge only to local\nminimizers with randomly initialization when the strictly saddle point property\nis assumed.\n","authors":["Luwei Bai","Yaohua Hu","Hao Wang","Xiaoqi Yang"],"pdf_url":"https://arxiv.org/pdf/2401.09274v4.pdf","comment":"34 pages,4 figures"},{"id":"http://arxiv.org/abs/2408.03497v1","updated":"2024-08-07T01:37:10Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v1.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2407.02702v3","updated":"2024-08-07T01:35:58Z","published":"2024-07-02T22:51:01Z","title":"Practical Guide for Causal Pathways and Sub-group Disparity Analysis","summary":"  In this study, we introduce the application of causal disparity analysis to\nunveil intricate relationships and causal pathways between sensitive attributes\nand the targeted outcomes within real-world observational data. Our methodology\ninvolves employing causal decomposition analysis to quantify and examine the\ncausal interplay between sensitive attributes and outcomes. We also emphasize\nthe significance of integrating heterogeneity assessment in causal disparity\nanalysis to gain deeper insights into the impact of sensitive attributes within\nspecific sub-groups on outcomes. Our two-step investigation focuses on datasets\nwhere race serves as the sensitive attribute. The results on two datasets\nindicate the benefit of leveraging causal analysis and heterogeneity assessment\nnot only for quantifying biases in the data but also for disentangling their\ninfluences on outcomes. We demonstrate that the sub-groups identified by our\napproach to be affected the most by disparities are the ones with the largest\nML classification errors. We also show that grouping the data only based on a\nsensitive attribute is not enough, and through these analyses, we can find\nsub-groups that are directly affected by disparities. We hope that our findings\nwill encourage the adoption of such methodologies in future ethical AI\npractices and bias audits, fostering a more equitable and fair technological\nlandscape.\n","authors":["Farnaz Kohankhaki","Shaina Raza","Oluwanifemi Bamgbose","Deval Pandya","Elham Dolatabadi"],"pdf_url":"https://arxiv.org/pdf/2407.02702v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03490v1","updated":"2024-08-07T01:01:35Z","published":"2024-08-07T01:01:35Z","title":"Simultaneous and Meshfree Topology Optimization with Physics-informed\n  Gaussian Processes","summary":"  Topology optimization (TO) provides a principled mathematical approach for\noptimizing the performance of a structure by designing its material spatial\ndistribution in a pre-defined domain and subject to a set of constraints. The\nmajority of existing TO approaches leverage numerical solvers for design\nevaluations during the optimization and hence have a nested nature and rely on\ndiscretizing the design variables. Contrary to these approaches, herein we\ndevelop a new class of TO methods based on the framework of Gaussian processes\n(GPs) whose mean functions are parameterized via deep neural networks.\nSpecifically, we place GP priors on all design and state variables to represent\nthem via parameterized continuous functions. These GPs share a deep neural\nnetwork as their mean function but have as many independent kernels as there\nare state and design variables. We estimate all the parameters of our model in\na single for loop that optimizes a penalized version of the performance metric\nwhere the penalty terms correspond to the state equations and design\nconstraints. Attractive features of our approach include $(1)$ having a\nbuilt-in continuation nature since the performance metric is optimized at the\nsame time that the state equations are solved, and $(2)$ being\ndiscretization-invariant and accommodating complex domains and topologies. To\ntest our method against conventional TO approaches implemented in commercial\nsoftware, we evaluate it on four problems involving the minimization of\ndissipated power in Stokes flow. The results indicate that our approach does\nnot need filtering techniques, has consistent computational costs, and is\nhighly robust against random initializations and problem setup.\n","authors":["Amin Yousefpour","Shirin Hosseinmardi","Carlos Mora","Ramin Bostanabad"],"pdf_url":"https://arxiv.org/pdf/2408.03490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03281v2","updated":"2024-08-07T01:00:55Z","published":"2024-08-06T16:28:30Z","title":"StructEval: Deepen and Broaden Large Language Model Assessment via\n  Structured Evaluation","summary":"  Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.\n","authors":["Boxi Cao","Mengjie Ren","Hongyu Lin","Xianpei Han","Feng Zhang","Junfeng Zhan","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2408.03281v2.pdf","comment":"ACL 2024;Benchmark at https://github.com/c-box/StructEval\n  ;Leaderboard at https://huggingface.co/spaces/Bowieee/StructEval_leaderboard"},{"id":"http://arxiv.org/abs/2408.04131v1","updated":"2024-08-07T23:41:09Z","published":"2024-08-07T23:41:09Z","title":"Heterogeneous Graph Sequence Neural Networks for Dynamic Traffic\n  Assignment","summary":"  Traffic assignment and traffic flow prediction provide critical insights for\nurban planning, traffic management, and the development of intelligent\ntransportation systems. An efficient model for calculating traffic flows over\nthe entire transportation network could provide a more detailed and realistic\nunderstanding of traffic dynamics. However, existing traffic prediction\napproaches, such as those utilizing graph neural networks, are typically\nlimited to locations where sensors are deployed and cannot predict traffic\nflows beyond sensor locations. To alleviate this limitation, inspired by\nfundamental relationship that exists between link flows and the\norigin-destination (OD) travel demands, we proposed the Heterogeneous\nSpatio-Temporal Graph Sequence Network (HSTGSN). HSTGSN exploits dependency\nbetween origin and destination nodes, even when it is long-range, and learns\nimplicit vehicle route choices under different origin-destination demands. This\nmodel is based on a heterogeneous graph which consists of road links, OD links\n(virtual links connecting origins and destinations) and a spatio-temporal graph\nencoder-decoder that captures the spatio-temporal relationship between OD\ndemands and flow distribution. We will show how the graph encoder-decoder is\nable to recover the incomplete information in the OD demand, by using node\nembedding from the graph decoder to predict the temporal changes in flow\ndistribution. Using extensive experimental studies on real-world networks with\ncomplete/incomplete OD demands, we demonstrate that our method can not only\ncapture the implicit spatio-temporal relationship between link traffic flows\nand OD demands but also achieve accurate prediction performance and\ngeneralization capability.\n","authors":["Tong Liu","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2408.04131v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.04129v1","updated":"2024-08-07T23:30:53Z","published":"2024-08-07T23:30:53Z","title":"Out-of-Core Dimensionality Reduction for Large Data via Out-of-Sample\n  Extensions","summary":"  Dimensionality reduction (DR) is a well-established approach for the\nvisualization of high-dimensional data sets. While DR methods are often applied\nto typical DR benchmark data sets in the literature, they might suffer from\nhigh runtime complexity and memory requirements, making them unsuitable for\nlarge data visualization especially in environments outside of high-performance\ncomputing. To perform DR on large data sets, we propose the use of\nout-of-sample extensions. Such extensions allow inserting new data into\nexisting projections, which we leverage to iteratively project data into a\nreference projection that consists only of a small manageable subset. This\nprocess makes it possible to perform DR out-of-core on large data, which would\notherwise not be possible due to memory and runtime limitations. For metric\nmultidimensional scaling (MDS), we contribute an implementation with\nout-of-sample projection capability since typical software libraries do not\nsupport it. We provide an evaluation of the projection quality of five common\nDR algorithms (MDS, PCA, t-SNE, UMAP, and autoencoders) using quality metrics\nfrom the literature and analyze the trade-off between the size of the reference\nset and projection quality. The runtime behavior of the algorithms is also\nquantified with respect to reference set size, out-of-sample batch size, and\ndimensionality of the data sets. Furthermore, we compare the out-of-sample\napproach to other recently introduced DR methods, such as PaCMAP and TriMAP,\nwhich claim to handle larger data sets than traditional approaches. To showcase\nthe usefulness of DR on this large scale, we contribute a use case where we\nanalyze ensembles of streamlines amounting to one billion projected instances.\n","authors":["Luca Reichmann","David Hägele","Daniel Weiskopf"],"pdf_url":"https://arxiv.org/pdf/2408.04129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04125v1","updated":"2024-08-07T23:22:58Z","published":"2024-08-07T23:22:58Z","title":"Exploring RAG-based Vulnerability Augmentation with LLMs","summary":"  Detecting vulnerabilities is a crucial task for maintaining the integrity,\navailability, and security of software systems. Utilizing DL-based models for\nvulnerability detection has become commonplace in recent years. However, such\ndeep learning-based vulnerability detectors (DLVD) suffer from a shortage of\nsizable datasets to train effectively. Data augmentation can potentially\nalleviate the shortage of data, but augmenting vulnerable code is challenging\nand requires designing a generative solution that maintains vulnerability.\nHence, the work on generating vulnerable code samples has been limited and\nprevious works have only focused on generating samples that contain single\nstatements or specific types of vulnerabilities. Lately, large language models\n(LLMs) are being used for solving various code generation and comprehension\ntasks and have shown inspiring results, especially when fused with retrieval\naugmented generation (RAG). In this study, we explore three different\nstrategies to augment vulnerabilities both single and multi-statement\nvulnerabilities, with LLMs, namely Mutation, Injection, and Extension. We\nconducted an extensive evaluation of our proposed approach on three\nvulnerability datasets and three DLVD models, using two LLMs. Our results show\nthat our injection-based clustering-enhanced RAG method beats the baseline\nsetting (NoAug), Vulgen, and VGX (two SOTA methods), and Random Oversampling\n(ROS) by 30.80\\%, 27.48\\%, 27.93\\%, and 15.41\\% in f1-score with 5K generated\nvulnerable samples on average, and 53.84\\%, 54.10\\%, 69.90\\%, and 40.93\\% with\n15K generated vulnerable samples. Our approach demonstrates its feasibility for\nlarge-scale data augmentation by generating 1K samples at as cheap as US$ 1.88.\n","authors":["Seyed Shayan Daneshvar","Yu Nong","Xu Yang","Shaowei Wang","Haipeng Cai"],"pdf_url":"https://arxiv.org/pdf/2408.04125v1.pdf","comment":"13 pages, 6 figures, 5 tables, 3 prompt templates, 1 algorithm"},{"id":"http://arxiv.org/abs/2408.04122v1","updated":"2024-08-07T23:15:21Z","published":"2024-08-07T23:15:21Z","title":"Overcoming Brittleness in Pareto-Optimal Learning-Augmented Algorithms","summary":"  The study of online algorithms with machine-learned predictions has gained\nconsiderable prominence in recent years. One of the common objectives in the\ndesign and analysis of such algorithms is to attain (Pareto) optimal tradeoffs\nbetween the consistency of the algorithm, i.e., its performance assuming\nperfect predictions, and its robustness, i.e., the performance of the algorithm\nunder adversarial predictions. In this work, we demonstrate that this\noptimization criterion can be extremely brittle, in that the performance of\nPareto-optimal algorithms may degrade dramatically even in the presence of\nimperceptive prediction error. To remedy this drawback, we propose a new\nframework in which the smoothness in the performance of the algorithm is\nenforced by means of a user-specified profile. This allows us to regulate the\nperformance of the algorithm as a function of the prediction error, while\nsimultaneously maintaining the analytical notion of consistency/robustness\ntradeoffs, adapted to the profile setting. We apply this new approach to a\nwell-studied online problem, namely the one-way trading problem. For this\nproblem, we further address another limitation of the state-of-the-art\nPareto-optimal algorithms, namely the fact that they are tailored to\nworst-case, and extremely pessimistic inputs. We propose a new Pareto-optimal\nalgorithm that leverages any deviation from the worst-case input to its\nbenefit, and introduce a new metric that allows us to compare any two\nPareto-optimal algorithms via a dominance relation.\n","authors":["Spyros Angelopoulos","Christoph Dürr","Alex Elenter","Yanni Lefki"],"pdf_url":"https://arxiv.org/pdf/2408.04122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01536v2","updated":"2024-08-07T22:46:04Z","published":"2024-04-02T00:02:00Z","title":"Laying Anchors: Semantically Priming Numerals in Language Modeling","summary":"  Off-the-shelf pre-trained language models have become the de facto standard\nin NLP pipelines for a multitude of downstream tasks. However, the inability of\nthese models to properly encode numerals limits their performance on tasks\nrequiring numeric comprehension. We introduce strategies to semantically prime\nnumerals in any corpus by generating anchors governed by the distribution of\nnumerals in said corpus, thereby enabling mathematically grounded\nrepresentations of these numeral tokens. We establish the superiority of our\nproposed techniques through evaluation on a range of numeracy tasks for both\nin-domain (seen) and out-domain (unseen) numerals. Further, we expand our\nempirical evaluations to numerals ranging from 1 to 10 billion, a significantly\nbroader range compared to previous studies of the same nature, and we\ndemonstrate significant improvements in the mathematical grounding of our\nlearned embeddings.\n","authors":["Mandar Sharma","Rutuja Murlidhar Taware","Pravesh Koirala","Nikhil Muralidhar","Naren Ramakrishnan"],"pdf_url":"https://arxiv.org/pdf/2404.01536v2.pdf","comment":"Accepted to the findings of NAACL 2024"},{"id":"http://arxiv.org/abs/2311.03366v4","updated":"2024-08-07T22:43:10Z","published":"2023-10-16T22:20:31Z","title":"Functional Overlap Reranking for Neural Code Generation","summary":"  Code Large Language Models (CodeLLMs) have ushered in a new era in code\ngeneration advancements. However, selecting the best code solutions from all\npossible CodeLLM outputs remains a challenge. Previous methods often overlooked\nthe intricate functional similarities and interactions between solution\nclusters. We introduce SRank, a novel reranking strategy for selecting the best\nsolutions from code generation, focusing on modeling the relationships between\nclusters of solutions. By quantifying the functional overlap between solution\nclusters, our approach provides a better ranking strategy for code solutions.\nEmpirical results show that our method achieves remarkable results on the\npass@1 score. For instance, on the Human-Eval benchmark, we achieve 69.66% in\npass@1 with Codex002, 75.31% with WizardCoder, 53.99% with StarCoder, and\n60.55% with CodeGen, surpassing state-of-the-art code generation reranking\nmethods such as CodeT and Coder-Reviewer on the same CodeLLM by a significant\nmargin (approximately 6.1% improvement on average). Even in scenarios with a\nlimited number of sampled solutions and test cases, our approach demonstrates\nrobustness and superiority, marking a new benchmark in code generation\nreranking. Our implementation can be found at\nhttps://github.com/FSoft-AI4Code/SRank-CodeRanker.\n","authors":["Hung Quoc To","Minh Huynh Nguyen","Nghi D. Q. Bui"],"pdf_url":"https://arxiv.org/pdf/2311.03366v4.pdf","comment":"ACL 2024, Long Findings"},{"id":"http://arxiv.org/abs/2408.04116v1","updated":"2024-08-07T22:40:05Z","published":"2024-08-07T22:40:05Z","title":"Combining Neural Architecture Search and Automatic Code Optimization: A\n  Survey","summary":"  Deep Learning models have experienced exponential growth in complexity and\nresource demands in recent years. Accelerating these models for efficient\nexecution on resource-constrained devices has become more crucial than ever.\nTwo notable techniques employed to achieve this goal are Hardware-aware Neural\nArchitecture Search (HW-NAS) and Automatic Code Optimization (ACO). HW-NAS\nautomatically designs accurate yet hardware-friendly neural networks, while ACO\ninvolves searching for the best compiler optimizations to apply on neural\nnetworks for efficient mapping and inference on the target hardware. This\nsurvey explores recent works that combine these two techniques within a single\nframework. We present the fundamental principles of both domains and\ndemonstrate their sub-optimality when performed independently. We then\ninvestigate their integration into a joint optimization process that we call\nHardware Aware-Neural Architecture and Compiler Optimizations co-Search\n(NACOS).\n","authors":["Inas Bachiri","Hadjer Benmeziane","Smail Niar","Riyadh Baghdadi","Hamza Ouarnoughi","Abdelkrime Aries"],"pdf_url":"https://arxiv.org/pdf/2408.04116v1.pdf","comment":"version 0, 13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.04114v1","updated":"2024-08-07T22:32:19Z","published":"2024-08-07T22:32:19Z","title":"Zero-shot Factual Consistency Evaluation Across Domains","summary":"  This work addresses the challenge of factual consistency in text generation\nsystems. We unify the tasks of Natural Language Inference, Summarization\nEvaluation, Factuality Verification and Factual Consistency Evaluation to train\nmodels capable of evaluating the factual consistency of source-target pairs\nacross diverse domains. We rigorously evaluate these against eight baselines on\na comprehensive benchmark suite comprising 22 datasets that span various tasks,\ndomains, and document lengths. Results demonstrate that our method achieves\nstate-of-the-art performance on this heterogeneous benchmark while addressing\nefficiency concerns and attaining cross-domain generalization.\n","authors":["Raunak Agarwal"],"pdf_url":"https://arxiv.org/pdf/2408.04114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04113v1","updated":"2024-08-07T22:30:43Z","published":"2024-08-07T22:30:43Z","title":"UpLIF: An Updatable Self-Tuning Learned Index Framework","summary":"  The emergence of learned indexes has caused a paradigm shift in our\nperception of indexing by considering indexes as predictive models that\nestimate keys' positions within a data set, resulting in notable improvements\nin key search efficiency and index size reduction; however, a significant\nchallenge inherent in learned index modeling is its constrained support for\nupdate operations, necessitated by the requirement for a fixed distribution of\nrecords. Previous studies have proposed various approaches to address this\nissue with the drawback of high overhead due to multiple model retraining. In\nthis paper, we present UpLIF, an adaptive self-tuning learned index that\nadjusts the model to accommodate incoming updates, predicts the distribution of\nupdates for performance improvement, and optimizes its index structure using\nreinforcement learning. We also introduce the concept of balanced model\nadjustment, which determines the model's inherent properties (i.e. bias and\nvariance), enabling the integration of these factors into the existing index\nmodel without the need for retraining with new data. Our comprehensive\nexperiments show that the system surpasses state-of-the-art indexing solutions\n(both traditional and ML-based), achieving an increase in throughput of up to\n3.12 times with 1000 times less memory usage.\n","authors":["Alireza Heidari","Amirhossein Ahmadi","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.04113v1.pdf","comment":"20 pages, ACM IDEAS 2024"},{"id":"http://arxiv.org/abs/2408.04107v1","updated":"2024-08-07T22:10:26Z","published":"2024-08-07T22:10:26Z","title":"Zero-Delay QKV Compression for Mitigating KV Cache and Network\n  Bottlenecks in LLM Inference","summary":"  In large-language models, memory constraints in the key-value cache (KVC)\npose a challenge during inference, especially with long prompts. In this work,\nwe observed that compressing KV values is more effective than compressing the\nmodel regarding accuracy and job completion time (JCT). However, quantizing KV\nvalues and dropping less-important tokens incur significant runtime\ncomputational time overhead, delaying JCT. These methods also cannot reduce\ncomputation time or high network communication time overhead in\nsequence-parallelism (SP) frameworks for long prompts. To tackle these issues,\nbased on our insightful observations from experimental analysis, we propose\nZeroC, a Zero-delay QKV Compression system that eliminates time overhead and\neven reduces computation and communication time of the model operations. ZeroC\ninnovatively embeds compression and decompression operations within model\noperations and adaptively determines compression ratios at a hybrid layer-token\nlevel. Further, it enables a communication-efficient SP inference framework.\nTrace-driven experiments demonstrate that ZeroC achieves up to 80% lower\naverage JCT, 35% lower average perplexity, and 2.8x higher throughput with the\nsame latency compared to state-of-the-art compression methods. ZeroC also\nreduces the average JCT of current LLM serving systems by up to 91% with the\nconstraint of 0.1 perplexity increase. We open-sourced the code.\n","authors":["Zeyu Zhang","Haiying Shen"],"pdf_url":"https://arxiv.org/pdf/2408.04107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04868v3","updated":"2024-08-07T22:00:18Z","published":"2024-06-07T12:07:16Z","title":"Perturb-and-Project: Differentially Private Similarities and Marginals","summary":"  We revisit the input perturbations framework for differential privacy where\nnoise is added to the input $A\\in \\mathcal{S}$ and the result is then projected\nback to the space of admissible datasets $\\mathcal{S}$. Through this framework,\nwe first design novel efficient algorithms to privately release pair-wise\ncosine similarities. Second, we derive a novel algorithm to compute $k$-way\nmarginal queries over $n$ features. Prior work could achieve comparable\nguarantees only for $k$ even. Furthermore, we extend our results to $t$-sparse\ndatasets, where our efficient algorithms yields novel, stronger guarantees\nwhenever $t\\le n^{5/6}/\\log n\\,.$ Finally, we provide a theoretical perspective\non why \\textit{fast} input perturbation algorithms works well in practice. The\nkey technical ingredients behind our results are tight sum-of-squares\ncertificates upper bounding the Gaussian complexity of sets of solutions.\n","authors":["Vincent Cohen-Addad","Tommaso d'Orsi","Alessandro Epasto","Vahab Mirrokni","Peilin Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.04868v3.pdf","comment":"21 ppages, ICML 2024"},{"id":"http://arxiv.org/abs/2404.10859v2","updated":"2024-08-07T21:57:20Z","published":"2024-04-16T19:17:23Z","title":"Forcing Diffuse Distributions out of Language Models","summary":"  Despite being trained specifically to follow user instructions, today's\ninstructiontuned language models perform poorly when instructed to produce\nrandom outputs. For example, when prompted to pick a number uniformly between\none and ten Llama-2-13B-chat disproportionately favors the number five, and\nwhen tasked with picking a first name at random, Mistral-7B-Instruct chooses\nAvery 40 times more often than we would expect based on the U.S. population.\nWhen these language models are used for real-world tasks where diversity of\noutputs is crucial, such as language model assisted dataset construction, their\ninability to produce diffuse distributions over valid choices is a major\nhurdle. In this work, we propose a fine-tuning method that encourages language\nmodels to output distributions that are diffuse over valid outcomes. The\nmethods we introduce generalize across a variety of tasks and distributions and\nmake large language models practical for synthetic dataset generation with\nlittle human intervention.\n","authors":["Yiming Zhang","Avi Schwarzschild","Nicholas Carlini","Zico Kolter","Daphne Ippolito"],"pdf_url":"https://arxiv.org/pdf/2404.10859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01391v2","updated":"2024-08-07T21:55:08Z","published":"2024-08-02T17:01:36Z","title":"FT K-means: A High-Performance K-means on GPU with Fault Tolerance","summary":"  K-means is a widely used algorithm in clustering, however, its efficiency is\nprimarily constrained by the computational cost of distance computing. Existing\nimplementations suffer from suboptimal utilization of computational units and\nlack resilience against soft errors. To address these challenges, we introduce\nFT K-means, a high-performance GPU-accelerated implementation of K-means with\nonline fault tolerance. We first present a stepwise optimization strategy that\nachieves competitive performance compared to NVIDIA's cuML library. We further\nimprove FT K-means with a template-based code generation framework that\nsupports different data types and adapts to different input shapes. A novel\nwarp-level tensor-core error correction scheme is proposed to address the\nfailure of existing fault tolerance methods due to memory asynchronization\nduring copy operations. Our experimental evaluations on NVIDIA T4 GPU and A100\nGPU demonstrate that FT K-means without fault tolerance outperforms cuML's\nK-means implementation, showing a performance increase of 10\\%-300\\% in\nscenarios involving irregular data shapes. Moreover, the fault tolerance\nfeature of FT K-means introduces only an overhead of 11\\%, maintaining robust\nperformance even with tens of errors injected per second.\n","authors":["Shixun Wu","Yitong Ding","Yujia Zhai","Jinyang Liu","Jiajun Huang","Zizhe Jian","Huangliang Dai","Sheng Di","Bryan M. Wong","Zizhong Chen","Franck Cappello"],"pdf_url":"https://arxiv.org/pdf/2408.01391v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04104v1","updated":"2024-08-07T21:45:01Z","published":"2024-08-07T21:45:01Z","title":"Hardware-Assisted Virtualization of Neural Processing Units for Cloud\n  Platforms","summary":"  Cloud platforms today have been deploying hardware accelerators like neural\nprocessing units (NPUs) for powering machine learning (ML) inference services.\nTo maximize the resource utilization while ensuring reasonable quality of\nservice, a natural approach is to virtualize NPUs for efficient resource\nsharing for multi-tenant ML services. However, virtualizing NPUs for modern\ncloud platforms is not easy. This is not only due to the lack of system\nabstraction support for NPU hardware, but also due to the lack of architectural\nand ISA support for enabling fine-grained dynamic operator scheduling for\nvirtualized NPUs.\n  We present TCloud, a holistic NPU virtualization framework. We investigate\nvirtualization techniques for NPUs across the entire software and hardware\nstack. TCloud consists of (1) a flexible NPU abstraction called vNPU, which\nenables fine-grained virtualization of the heterogeneous compute units in a\nphysical NPU (pNPU); (2) a vNPU resource allocator that enables pay-as-you-go\ncomputing model and flexible vNPU-to-pNPU mappings for improved resource\nutilization and cost-effectiveness; (3) an ISA extension of modern NPU\narchitecture for facilitating fine-grained tensor operator scheduling for\nmultiple vNPUs. We implement TCloud based on a production-level NPU simulator.\nOur experiments show that TCloud improves the throughput of ML inference\nservices by up to 1.4$\\times$ and reduces the tail latency by up to\n4.6$\\times$, while improving the NPU utilization by 1.2$\\times$ on average,\ncompared to state-of-the-art NPU sharing approaches.\n","authors":["Yuqi Xue","Yiqi Liu","Lifeng Nai","Jian Huang"],"pdf_url":"https://arxiv.org/pdf/2408.04104v1.pdf","comment":"Accepted to MICRO'24"},{"id":"http://arxiv.org/abs/2408.04093v1","updated":"2024-08-07T21:16:55Z","published":"2024-08-07T21:16:55Z","title":"Tree Attention: Topology-aware Decoding for Long-Context Attention on\n  GPU clusters","summary":"  Self-attention is the core mathematical operation of modern transformer\narchitectures and is also a significant computational bottleneck due to its\nquadratic complexity in the sequence length. In this work, we derive the scalar\nenergy function whose gradient computes the self-attention block, thus\nelucidating the theoretical underpinnings of self-attention, providing a\nBayesian interpretation of the operation and linking it closely with\nenergy-based models such as Hopfield Networks. Moreover, due to this\nformulation, we discover that we can use efficient and optimized\nautomatic-differentiation techniques to derive a highly efficient Tree\nAttention algorithm to compute the gradient of the energy and hence\nself-attention. Our formulation reveals that the reduction across the sequence\naxis can be efficiently computed in parallel through a tree reduction. Our\nalgorithm, for parallelizing attention computation across multiple GPUs,\nenables cross-device decoding to be performed asymptotically faster (up to 8x\nfaster) than alternative approaches such as Ring Attention, while also\nrequiring significantly less communication volume and incurring 2x less peak\nmemory. Our code is publicly available here:\n\\url{https://github.com/Zyphra/tree_attention}\n","authors":["Vasudev Shyam","Jonathan Pilault","Emily Shepperd","Quentin Anthony","Beren Millidge"],"pdf_url":"https://arxiv.org/pdf/2408.04093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11651v4","updated":"2024-08-07T21:14:03Z","published":"2023-09-20T21:32:58Z","title":"Drift Control of High-Dimensional RBM: A Computational Method Based on\n  Neural Networks","summary":"  Motivated by applications in queueing theory, we consider a stochastic\ncontrol problem whose state space is the $d$-dimensional positive orthant. The\ncontrolled process $Z$ evolves as a reflected Brownian motion whose covariance\nmatrix is exogenously specified, as are its directions of reflection from the\northant's boundary surfaces. A system manager chooses a drift vector\n$\\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at\ntime $t$ depends on both $Z(t)$ and $\\theta(t)$. In our initial problem\nformulation, the objective is to minimize expected discounted cost over an\ninfinite planning horizon, after which we treat the corresponding ergodic\ncontrol problem. Extending earlier work by Han et al. (Proceedings of the\nNational Academy of Sciences, 2018, 8505-8510), we develop and illustrate a\nsimulation-based computational method that relies heavily on deep neural\nnetwork technology. For test problems studied thus far, our method is accurate\nto within a fraction of one percent, and is computationally feasible in\ndimensions up to at least $d=30$.\n","authors":["Baris Ata","J. Michael Harrison","Nian Si"],"pdf_url":"https://arxiv.org/pdf/2309.11651v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14631v2","updated":"2024-08-07T21:10:30Z","published":"2024-07-19T19:07:53Z","title":"Two new feature selection methods based on learn-heuristic techniques\n  for breast cancer prediction: A comprehensive analysis","summary":"  Breast cancer is not preventable because of its unknown causes. However, its\nearly diagnosis increases patients' recovery chances. Machine learning (ML) can\nbe utilized to improve treatment outcomes in healthcare operations while\ndiminishing costs and time. In this research, we suggest two novel feature\nselection (FS) methods based upon an imperialist competitive algorithm (ICA)\nand a bat algorithm (BA) and their combination with ML algorithms. This study\naims to enhance diagnostic models' efficiency and present a comprehensive\nanalysis to help clinical physicians make much more precise and reliable\ndecisions than before. K-nearest neighbors, support vector machine, decision\ntree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,\nlogistic regression, and artificial neural network are some of the methods\nemployed. This paper applied a distinctive integration of evaluation measures\nand ML algorithms using the wrapper feature selection based on ICA (WFSIC) and\nBA (WFSB) separately. We compared two proposed approaches for the performance\nof the classifiers. Also, we compared our best diagnostic model with previous\nworks reported in the literature survey. Experimentations were performed on the\nWisconsin diagnostic breast cancer dataset. Results reveal that the proposed\nframework that uses the BA with an accuracy of 99.12\\%, surpasses the framework\nusing the ICA and most previous works. Additionally, the RF classifier in the\napproach of FS based on BA emerges as the best model and outperforms others\nregarding its criteria. Besides, the results illustrate the role of our\ntechniques in reducing the dataset dimensions up to 90\\% and increasing the\nperformance of diagnostic models by over 99\\%. Moreover, the result\ndemonstrates that there are more critical features than the optimum dataset\nobtained by proposed FS approaches that have been selected by most ML models.\n","authors":["Kamyab Karimi","Ali Ghodratnama","Reza Tavakkoli-Moghaddam"],"pdf_url":"https://arxiv.org/pdf/2407.14631v2.pdf","comment":"36 pages, 3 figures, 12 tables"},{"id":"http://arxiv.org/abs/2203.08248v2","updated":"2024-08-07T20:39:29Z","published":"2022-03-15T20:50:26Z","title":"Non-Linear Reinforcement Learning in Large Action Spaces: Structural\n  Conditions and Sample-efficiency of Posterior Sampling","summary":"  Provably sample-efficient Reinforcement Learning (RL) with rich observations\nand function approximation has witnessed tremendous recent progress,\nparticularly when the underlying function approximators are linear. In this\nlinear regime, computationally and statistically efficient methods exist where\nthe potentially infinite state and action spaces can be captured through a\nknown feature embedding, with the sample complexity scaling with the\n(intrinsic) dimension of these features. When the action space is finite,\nsignificantly more sophisticated results allow non-linear function\napproximation under appropriate structural constraints on the underlying RL\nproblem, permitting for instance, the learning of good features instead of\nassuming access to them. In this work, we present the first result for\nnon-linear function approximation which holds for general action spaces under a\nlinear embeddability condition, which generalizes all linear and finite action\nsettings. We design a novel optimistic posterior sampling strategy, TS^3 for\nsuch problems, and show worst case sample complexity guarantees that scale with\na rank parameter of the RL problem, the linear embedding dimension introduced\nin this work and standard measures of the function class complexity.\n","authors":["Alekh Agarwal","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2203.08248v2.pdf","comment":"Fixes an error in the earlier version in the proof of Proposition 13"},{"id":"http://arxiv.org/abs/2406.10407v2","updated":"2024-08-07T20:10:14Z","published":"2024-06-14T20:31:22Z","title":"Suboptimality bounds for trace-bounded SDPs enable a faster and scalable\n  low-rank SDP solver SDPLR+","summary":"  Semidefinite programs (SDPs) and their solvers are powerful tools with many\napplications in machine learning and data science. Designing scalable SDP\nsolvers is challenging because by standard the positive semidefinite decision\nvariable is an $n \\times n$ dense matrix, even though the input is often $n\n\\times n$ sparse matrices. However, the information in the solution may not\ncorrespond to a full-rank dense matrix as shown by Barvinok and Pataki. Two\ndecades ago, Burer and Monteiro developed an SDP solver $\\texttt{SDPLR}$ that\noptimizes over a low-rank factorization instead of the full matrix. This\ngreatly decreases the storage cost and works well for many problems. The\noriginal solver $\\texttt{SDPLR}$ tracks only the primal infeasibility of the\nsolution, limiting the technique's flexibility to produce moderate accuracy\nsolutions. We use a suboptimality bound for trace-bounded SDP problems that\nenables us to track the progress better and perform early termination. We then\ndevelop $\\texttt{SDPLR+}$, which starts the optimization with an extremely\nlow-rank factorization and dynamically updates the rank based on the primal\ninfeasibility and suboptimality. This further speeds up the computation and\nsaves the storage cost. Numerical experiments on Max Cut, Minimum Bisection,\nCut Norm, and Lov\\'{a}sz Theta problems with many recent memory-efficient\nscalable SDP solvers demonstrate its scalability up to problems with\nmillion-by-million decision variables and it is often the fastest solver to a\nmoderate accuracy of $10^{-2}$.\n","authors":["Yufan Huang","David F. Gleich"],"pdf_url":"https://arxiv.org/pdf/2406.10407v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2408.04065v1","updated":"2024-08-07T20:07:25Z","published":"2024-08-07T20:07:25Z","title":"Do Sharpness-based Optimizers Improve Generalization in Medical Image\n  Analysis?","summary":"  Effective clinical deployment of deep learning models in healthcare demands\nhigh generalization performance to ensure accurate diagnosis and treatment\nplanning. In recent years, significant research has focused on improving the\ngeneralization of deep learning models by regularizing the sharpness of the\nloss landscape. Among the optimization approaches that explicitly minimize\nsharpness, Sharpness-Aware Minimization (SAM) has shown potential in enhancing\ngeneralization performance on general domain image datasets. This success has\nled to the development of several advanced sharpness-based algorithms aimed at\naddressing the limitations of SAM, such as Adaptive SAM, surrogate-Gap SAM,\nWeighted SAM, and Curvature Regularized SAM. These sharpness-based optimizers\nhave shown improvements in model generalization compared to conventional\nstochastic gradient descent optimizers and their variants on general domain\nimage datasets, but they have not been thoroughly evaluated on medical images.\nThis work provides a review of recent sharpness-based methods for improving the\ngeneralization of deep learning networks and evaluates the methods performance\non medical breast ultrasound images. Our findings indicate that the initial SAM\nmethod successfully enhances the generalization of various deep learning\nmodels. While Adaptive SAM improves generalization of convolutional neural\nnetworks, it fails to do so for vision transformers. Other sharpness-based\noptimizers, however, do not demonstrate consistent results. The results reveal\nthat, contrary to findings in the non-medical domain, SAM is the only\nrecommended sharpness-based optimizer that consistently improves generalization\nin medical image analysis, and further research is necessary to refine the\nvariants of SAM to enhance generalization performance in this field\n","authors":["Mohamed Hassan","Aleksander Vakanski","Min Xian"],"pdf_url":"https://arxiv.org/pdf/2408.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02058v2","updated":"2024-08-07T19:45:05Z","published":"2024-04-02T15:57:32Z","title":"Generalizable, Fast, and Accurate DeepQSPR with fastprop","summary":"  Quantitative Structure Property Relationship studies aim to define a mapping\nbetween molecular structure and arbitrary quantities of interest. This was\nhistorically accomplished via the development of descriptors which requires\nsignificant domain expertise and struggles to generalize. Thus the field has\nmorphed into Molecular Property Prediction and been given over to learned\nrepresentations which are highly generalizable. The paper introduces fastprop,\na DeepQSPR framework which uses a cogent set of molecular level descriptors to\nmeet and exceed the performance of learned representations on diverse datasets\nin dramatically less time. fastprop is freely available on github at\ngithub.com/JacksonBurns/fastprop.\n","authors":["Jackson Burns","William Green"],"pdf_url":"https://arxiv.org/pdf/2404.02058v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04057v1","updated":"2024-08-07T19:39:37Z","published":"2024-08-07T19:39:37Z","title":"PowerPM: Foundation Model for Power Systems","summary":"  The emergence of abundant electricity time series (ETS) data provides ample\nopportunities for various applications in the power systems, including\ndemand-side management, grid stability, and consumer behavior analysis. Deep\nlearning models have advanced ETS modeling by effectively capturing sequence\ndependence. Nevertheless, learning a generic representation of ETS data for\nvarious applications remains challenging due to the inherently complex\nhierarchical structure of ETS data. Moreover, ETS data exhibits intricate\ntemporal dependencies and is suscepti ble to the influence of exogenous\nvariables. Furthermore, different instances exhibit diverse electricity\nconsumption behavior. In this paper, we propose a foundation model PowerPM to\nmodel ETS data, providing a large-scale, off-the-shelf model for power systems.\nPowerPM consists of a temporal encoder and a hierarchical encoder. The temporal\nencoder captures both temporal dependencies in ETS data, considering exogenous\nvariables. The hierarchical encoder models the correlation between hierarchy.\nFurthermore, PowerPM leverages a novel self-supervised pretraining framework\nconsisting of masked ETS modeling and dual-view contrastive learning, which\nenable PowerPM to capture temporal dependency within ETS windows and aware the\ndiscrepancy across ETS windows, providing two different perspectives to learn\ngeneric representation. Our experiments involve five real world scenario\ndatasets, comprising private and public data. Through pre-training on massive\nETS data, PowerPM achieves SOTA performance on diverse downstream tasks within\nthe private dataset. Impressively, when transferred to the public datasets,\nPowerPM maintains its superiority, showcasing its remarkable generalization\nability across various tasks and domains. Moreover, ablation studies, few-shot\nexperiments provide additional evidence of the effectiveness of our model.\n","authors":["Shihao Tu","Yupeng Zhang","Jing Zhang","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2408.04057v1.pdf","comment":"23 pages, 5 figures, 8 tables"},{"id":"http://arxiv.org/abs/2408.04055v1","updated":"2024-08-07T19:34:42Z","published":"2024-08-07T19:34:42Z","title":"Machine Learning-Based Reward-Driven Tuning of Scanning Probe\n  Microscopy: Towards Fully Automated Microscopy","summary":"  Since the dawn of scanning probe microscopy (SPM), tapping or intermittent\ncontact mode has been one of the most widely used imaging modes. Manual\noptimization of tapping mode not only takes a lot of instrument and operator\ntime, but also often leads to frequent probe and sample damage, poor image\nquality and reproducibility issues for new types of samples or inexperienced\nusers. Despite wide use, optimization of tapping mode imaging is an extremely\nhard problem, ill-suited to either classical control methods or machine\nlearning. Here we introduce a reward-driven workflow to automate the\noptimization of SPM in the tapping mode. The reward function is defined based\non multiple channels with physical and empirical knowledge of good scans\nencoded, representing a sample-agnostic measure of image quality and imitating\nthe decision-making logic employed by human operators. This automated workflow\ngives optimal scanning parameters for different probes and samples and gives\nhigh-quality SPM images consistently in the attractive mode. This study\nbroadens the application and accessibility of SPM and opens the door for fully\nautomated SPM.\n","authors":["Yu Liu","Roger Proksch","Jason Bemis","Utkarsh Pratiush","Astita Dubey","Mahshid Ahmadi","Reece Emery","Philip D. Rack","Yu-Chen Liu","Jan-Chi Yang","Sergei V. Kalinin"],"pdf_url":"https://arxiv.org/pdf/2408.04055v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.09611v2","updated":"2024-08-07T19:27:53Z","published":"2024-02-14T22:57:03Z","title":"Towards Privacy-Aware Sign Language Translation at Scale","summary":"  A major impediment to the advancement of sign language translation (SLT) is\ndata scarcity. Much of the sign language data currently available on the web\ncannot be used for training supervised models due to the lack of aligned\ncaptions. Furthermore, scaling SLT using large-scale web-scraped datasets bears\nprivacy risks due to the presence of biometric information, which the\nresponsible development of SLT technologies should account for. In this work,\nwe propose a two-stage framework for privacy-aware SLT at scale that addresses\nboth of these issues. We introduce SSVP-SLT, which leverages self-supervised\nvideo pretraining on anonymized and unannotated videos, followed by supervised\nSLT finetuning on a curated parallel dataset. SSVP-SLT achieves\nstate-of-the-art finetuned and zero-shot gloss-free SLT performance on the\nHow2Sign dataset, outperforming the strongest respective baselines by over 3\nBLEU-4. Based on controlled experiments, we further discuss the advantages and\nlimitations of self-supervised pretraining and anonymization via facial\nobfuscation for SLT.\n","authors":["Phillip Rust","Bowen Shi","Skyler Wang","Necati Cihan Camgöz","Jean Maillard"],"pdf_url":"https://arxiv.org/pdf/2402.09611v2.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2408.04053v1","updated":"2024-08-07T19:24:02Z","published":"2024-08-07T19:24:02Z","title":"Deep Generative Models for Subgraph Prediction","summary":"  Graph Neural Networks (GNNs) are important across different domains, such as\nsocial network analysis and recommendation systems, due to their ability to\nmodel complex relational data. This paper introduces subgraph queries as a new\ntask for deep graph learning. Unlike traditional graph prediction tasks that\nfocus on individual components like link prediction or node classification,\nsubgraph queries jointly predict the components of a target subgraph based on\nevidence that is represented by an observed subgraph. For instance, a subgraph\nquery can predict a set of target links and/or node labels. To answer subgraph\nqueries, we utilize a probabilistic deep Graph Generative Model. Specifically,\nwe inductively train a Variational Graph Auto-Encoder (VGAE) model, augmented\nto represent a joint distribution over links, node features and labels.\nBayesian optimization is used to tune a weighting for the relative importance\nof links, node features and labels in a specific domain. We describe a\ndeterministic and a sampling-based inference method for estimating subgraph\nprobabilities from the VGAE generative graph distribution, without retraining,\nin zero-shot fashion. For evaluation, we apply the inference methods on a range\nof subgraph queries on six benchmark datasets. We find that inference from a\nmodel achieves superior predictive performance, surpassing independent\nprediction baselines with improvements in AUC scores ranging from 0.06 to 0.2\npoints, depending on the dataset.\n","authors":["Erfaneh Mahmoudzadeh","Parmis Naddaf","Kiarash Zahirnia","Oliver Schulte"],"pdf_url":"https://arxiv.org/pdf/2408.04053v1.pdf","comment":"accepted at ECAI 2024"},{"id":"http://arxiv.org/abs/2307.07176v3","updated":"2024-08-07T19:08:36Z","published":"2023-07-14T06:00:08Z","title":"SafeDreamer: Safe Reinforcement Learning with World Models","summary":"  The deployment of Reinforcement Learning (RL) in real-world applications is\nconstrained by its failure to satisfy safety criteria. Existing Safe\nReinforcement Learning (SafeRL) methods, which rely on cost functions to\nenforce safety, often fail to achieve zero-cost performance in complex\nscenarios, especially vision-only tasks. These limitations are primarily due to\nmodel inaccuracies and inadequate sample efficiency. The integration of the\nworld model has proven effective in mitigating these shortcomings. In this\nwork, we introduce SafeDreamer, a novel algorithm incorporating\nLagrangian-based methods into world model planning processes within the\nsuperior Dreamer framework. Our method achieves nearly zero-cost performance on\nvarious tasks, spanning low-dimensional and vision-only input, within the\nSafety-Gymnasium benchmark, showcasing its efficacy in balancing performance\nand safety in RL tasks. Further details can be found in the code repository:\n\\url{https://github.com/PKU-Alignment/SafeDreamer}.\n","authors":["Weidong Huang","Jiaming Ji","Chunhe Xia","Borong Zhang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2307.07176v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2408.04046v1","updated":"2024-08-07T18:55:58Z","published":"2024-08-07T18:55:58Z","title":"Learning Rate-Free Reinforcement Learning: A Case for Model Selection\n  with Non-Stationary Objectives","summary":"  The performance of reinforcement learning (RL) algorithms is sensitive to the\nchoice of hyperparameters, with the learning rate being particularly\ninfluential. RL algorithms fail to reach convergence or demand an extensive\nnumber of samples when the learning rate is not optimally set. In this work, we\nshow that model selection can help to improve the failure modes of RL that are\ndue to suboptimal choices of learning rate. We present a model selection\nframework for Learning Rate-Free Reinforcement Learning that employs model\nselection methods to select the optimal learning rate on the fly. This approach\nof adaptive learning rate tuning neither depends on the underlying RL algorithm\nnor the optimizer and solely uses the reward feedback to select the learning\nrate; hence, the framework can input any RL algorithm and produce a learning\nrate-free version of it. We conduct experiments for policy optimization methods\nand evaluate various model selection strategies within our framework. Our\nresults indicate that data-driven model selection algorithms are better\nalternatives to standard bandit algorithms when the optimal choice of\nhyperparameter is time-dependent and non-stationary.\n","authors":["Aida Afshar","Aldo Pacchiano"],"pdf_url":"https://arxiv.org/pdf/2408.04046v1.pdf","comment":"RLC 2024 Workshop on Failure Modes of Sequential Decision-Making in\n  Practice"},{"id":"http://arxiv.org/abs/2408.04042v1","updated":"2024-08-07T18:47:58Z","published":"2024-08-07T18:47:58Z","title":"Scaling Law of Sim2Real Transfer Learning in Expanding Computational\n  Materials Databases for Real-World Predictions","summary":"  To address the challenge of limited experimental materials data, extensive\nphysical property databases are being developed based on high-throughput\ncomputational experiments, such as molecular dynamics simulations. Previous\nstudies have shown that fine-tuning a predictor pretrained on a computational\ndatabase to a real system can result in models with outstanding generalization\ncapabilities compared to learning from scratch. This study demonstrates the\nscaling law of simulation-to-real (Sim2Real) transfer learning for several\nmachine learning tasks in materials science. Case studies of three prediction\ntasks for polymers and inorganic materials reveal that the prediction error on\nreal systems decreases according to a power-law as the size of the\ncomputational data increases. Observing the scaling behavior offers various\ninsights for database development, such as determining the sample size\nnecessary to achieve a desired performance, identifying equivalent sample sizes\nfor physical and computational experiments, and guiding the design of data\nproduction protocols for downstream real-world tasks.\n","authors":["Shunya Minami","Yoshihiro Hayashi","Stephen Wu","Kenji Fukumizu","Hiroki Sugisawa","Masashi Ishii","Isao Kuwajima","Kazuya Shiratori","Ryo Yoshida"],"pdf_url":"https://arxiv.org/pdf/2408.04042v1.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.07812v2","updated":"2024-08-07T18:27:59Z","published":"2024-02-12T17:17:50Z","title":"Retrieval Augmented Thought Process for Private Data Handling in\n  Healthcare","summary":"  Large Language Models (LLMs) have demonstrated the strong potential to assist\nboth clinicians and the general public with their extensive medical knowledge.\nHowever, their application in healthcare is constrained due to concerns about\nthe privacy of data used in training, which prevents the integration of private\nand personal information because of security and ethical issues. Moreover, if\ntheir capabilities can be enhanced with information retrieval to access\nup-to-date knowledge, the current integration of LLMs with Information\nretrieval lacks robustness to imperfect retrieval, which can hinder their\neffectiveness and even reduce overall performance. In this work, we address\nthis challenge by introducing the Retrieval-Augmented Thought Process (RATP).\nGiven access to external knowledge, RATP formulates the thought generation of\nLLMs as a multiple-step decision process. To optimise such a thought process,\nRATP leverages Monte-Carlo Tree Search and learns a proxy reward function that\npermits cost-efficient inference. On a private dataset of electronic medical\nrecords, deliberately excluded from any LLM training set, RATP achieves 35%\nadditional accuracy compared to in-context retrieval-augmented generation for\nthe question-answering task.\n","authors":["Thomas Pouplin","Hao Sun","Samuel Holt","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2402.07812v2.pdf","comment":"17 pages, 18 figures"},{"id":"http://arxiv.org/abs/2408.04026v1","updated":"2024-08-07T18:19:18Z","published":"2024-08-07T18:19:18Z","title":"Multimodal Gender Fairness in Depression Prediction: Insights on Data\n  from the USA & China","summary":"  Social agents and robots are increasingly being used in wellbeing settings.\nHowever, a key challenge is that these agents and robots typically rely on\nmachine learning (ML) algorithms to detect and analyse an individual's mental\nwellbeing. The problem of bias and fairness in ML algorithms is becoming an\nincreasingly greater source of concern. In concurrence, existing literature has\nalso indicated that mental health conditions can manifest differently across\ngenders and cultures. We hypothesise that the representation of features\n(acoustic, textual, and visual) and their inter-modal relations would vary\namong subjects from different cultures and genders, thus impacting the\nperformance and fairness of various ML models. We present the very first\nevaluation of multimodal gender fairness in depression manifestation by\nundertaking a study on two different datasets from the USA and China. We\nundertake thorough statistical and ML experimentation and repeat the\nexperiments for several different algorithms to ensure that the results are not\nalgorithm-dependent. Our findings indicate that though there are differences\nbetween both datasets, it is not conclusive whether this is due to the\ndifference in depression manifestation as hypothesised or other external\nfactors such as differences in data collection methodology. Our findings\nfurther motivate a call for a more consistent and culturally aware data\ncollection process in order to address the problem of ML bias in depression\ndetection and to promote the development of fairer agents and robots for\nwellbeing.\n","authors":["Joseph Cameron","Jiaee Cheong","Micol Spitale","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2408.04026v1.pdf","comment":"9 Pages, 7 Tables. To be published and indexed in the IEEE Xplore\n  Digital Library under the ACII 2024 Workshop Proceedings"},{"id":"http://arxiv.org/abs/2403.00952v2","updated":"2024-08-07T18:14:12Z","published":"2024-03-01T20:03:44Z","title":"MediSwift: Efficient Sparse Pre-trained Biomedical Language Models","summary":"  Large language models (LLMs) are typically trained on general source data for\nvarious domains, but a recent surge in domain-specific LLMs has shown their\npotential to outperform general-purpose models in domain-specific tasks (e.g.,\nbiomedicine). Although domain-specific pre-training enhances efficiency and\nleads to smaller models, the computational costs of training these LLMs remain\nhigh, posing budgeting challenges. We introduce MediSwift, a suite of\nbiomedical LMs that leverage sparse pre-training on domain-specific biomedical\ntext data. By inducing up to 75% weight sparsity during the pre-training phase,\nMediSwift achieves a 2-2.5x reduction in training FLOPs. Notably, all sparse\npre-training was performed on the Cerebras CS-2 system, which is specifically\ndesigned to realize the acceleration benefits from unstructured weight\nsparsity, thereby significantly enhancing the efficiency of the MediSwift\nmodels. Through subsequent dense fine-tuning and strategic soft prompting,\nMediSwift models outperform existing LLMs up to 7B parameters on biomedical\ntasks, setting new benchmarks w.r.t efficiency-accuracy on tasks such as\nPubMedQA. Our results show that sparse pre-training, along with dense\nfine-tuning and soft prompting, offers an effective method for creating\nhigh-performing, computationally efficient models in specialized domains.\n","authors":["Vithursan Thangarasa","Mahmoud Salem","Shreyas Saxena","Kevin Leong","Joel Hestness","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2403.00952v2.pdf","comment":"14 pages, 2 Figures, 5 Tables (Main Paper) + 3 pages (Supplementary\n  Material). Published at ACL 2024"},{"id":"http://arxiv.org/abs/2405.15682v3","updated":"2024-08-07T17:44:58Z","published":"2024-05-24T16:20:46Z","title":"The Road Less Scheduled","summary":"  Existing learning rate schedules that do not require specification of the\noptimization stopping step T are greatly out-performed by learning rate\nschedules that depend on T. We propose an approach that avoids the need for\nthis stopping time by eschewing the use of schedules entirely, while exhibiting\nstate-of-the-art performance compared to schedules across a wide family of\nproblems ranging from convex problems to large-scale deep learning problems.\nOur Schedule-Free approach introduces no additional hyper-parameters over\nstandard optimizers with momentum. Our method is a direct consequence of a new\ntheory we develop that unifies scheduling and iterate averaging. An open source\nimplementation of our method is available\n(https://github.com/facebookresearch/schedule_free).\n","authors":["Aaron Defazio","Xingyu Alice Yang","Harsh Mehta","Konstantin Mishchenko","Ahmed Khaled","Ashok Cutkosky"],"pdf_url":"https://arxiv.org/pdf/2405.15682v3.pdf","comment":null}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2302.04262v3","updated":"2024-08-07T16:54:40Z","published":"2023-02-08T18:55:49Z","title":"Algorithmic Collective Action in Machine Learning","summary":"  We initiate a principled study of algorithmic collective action on digital\nplatforms that deploy machine learning algorithms. We propose a simple\ntheoretical model of a collective interacting with a firm's learning algorithm.\nThe collective pools the data of participating individuals and executes an\nalgorithmic strategy by instructing participants how to modify their own data\nto achieve a collective goal. We investigate the consequences of this model in\nthree fundamental learning-theoretic settings: the case of a nonparametric\noptimal learning algorithm, a parametric risk minimizer, and gradient-based\noptimization. In each setting, we come up with coordinated algorithmic\nstrategies and characterize natural success criteria as a function of the\ncollective's size. Complementing our theory, we conduct systematic experiments\non a skill classification task involving tens of thousands of resumes from a\ngig platform for freelancers. Through more than two thousand model training\nruns of a BERT-like language model, we see a striking correspondence emerge\nbetween our empirical observations and the predictions made by our theory.\nTaken together, our theory and experiments broadly support the conclusion that\nalgorithmic collectives of exceedingly small fractional size can exert\nsignificant control over a platform's learning algorithm.\n","authors":["Moritz Hardt","Eric Mazumdar","Celestine Mendler-Dünner","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2302.04262v3.pdf","comment":"Published at ICML 2023; Revision corrects epsilon-dependence in the\n  analysis"},{"id":"http://arxiv.org/abs/2408.03769v1","updated":"2024-08-07T13:43:21Z","published":"2024-08-07T13:43:21Z","title":"Nadaraya-Watson kernel smoothing as a random energy model","summary":"  We investigate the behavior of the Nadaraya-Watson kernel smoothing estimator\nin high dimensions using its relationship to the random energy model and to\ndense associative memories.\n","authors":["Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2408.03769v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.03746v1","updated":"2024-08-07T12:59:58Z","published":"2024-08-07T12:59:58Z","title":"Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion\n  Posterior Sampling","summary":"  Bayesian Last Layer (BLL) models focus solely on uncertainty in the output\nlayer of neural networks, demonstrating comparable performance to more complex\nBayesian models. However, the use of Gaussian priors for last layer weights in\nBayesian Last Layer (BLL) models limits their expressive capacity when faced\nwith non-Gaussian, outlier-rich, or high-dimensional datasets. To address this\nshortfall, we introduce a novel approach that combines diffusion techniques and\nimplicit priors for variational learning of Bayesian last layer weights. This\nmethod leverages implicit distributions for modeling weight priors in BLL,\ncoupled with diffusion samplers for approximating true posterior predictions,\nthereby establishing a comprehensive Bayesian prior and posterior estimation\nstrategy. By delivering an explicit and computationally efficient variational\nlower bound, our method aims to augment the expressive abilities of BLL models,\nenhancing model accuracy, calibration, and out-of-distribution detection\nproficiency. Through detailed exploration and experimental validation, We\nshowcase the method's potential for improving predictive accuracy and\nuncertainty quantification while ensuring computational efficiency.\n","authors":["Jian Xu","Zhiqi Lin","Shigui Li","Min Chen","Junmei Yang","Delu Zeng","John Paisley"],"pdf_url":"https://arxiv.org/pdf/2408.03746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03733v1","updated":"2024-08-07T12:41:56Z","published":"2024-08-07T12:41:56Z","title":"Bayes-optimal learning of an extensive-width neural network from\n  quadratically many samples","summary":"  We consider the problem of learning a target function corresponding to a\nsingle hidden layer neural network, with a quadratic activation function after\nthe first layer, and random weights. We consider the asymptotic limit where the\ninput dimension and the network width are proportionally large. Recent work\n[Cui & al '23] established that linear regression provides Bayes-optimal test\nerror to learn such a function when the number of available samples is only\nlinear in the dimension. That work stressed the open challenge of theoretically\nanalyzing the optimal test error in the more interesting regime where the\nnumber of samples is quadratic in the dimension. In this paper, we solve this\nchallenge for quadratic activations and derive a closed-form expression for the\nBayes-optimal test error. We also provide an algorithm, that we call GAMP-RIE,\nwhich combines approximate message passing with rotationally invariant matrix\ndenoising, and that asymptotically achieves the optimal performance.\nTechnically, our result is enabled by establishing a link with recent works on\noptimal denoising of extensive-rank matrices and on the ellipsoid fitting\nproblem. We further show empirically that, in the absence of noise,\nrandomly-initialized gradient descent seems to sample the space of weights,\nleading to zero training loss, and averaging over initialization leads to a\ntest error equal to the Bayes-optimal one.\n","authors":["Antoine Maillard","Emanuele Troiani","Simon Martin","Florent Krzakala","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2408.03733v1.pdf","comment":"47 pages"},{"id":"http://arxiv.org/abs/2208.03703v2","updated":"2024-08-07T09:18:40Z","published":"2022-08-07T12:02:48Z","title":"Granger Causality using Neural Networks","summary":"  Dependence between nodes in a network is an important concept that pervades\nmany areas including finance, politics, sociology, genomics and the brain\nsciences. One way to characterize dependence between components of a\nmultivariate time series data is via Granger Causality (GC). Standard\ntraditional approaches to GC estimation / inference commonly assume linear\ndynamics, however such simplification does not hold in many real-world\napplications where signals are inherently non-linear. In such cases, imposing\nlinear models such as vector autoregressive (VAR) models can lead to\nmis-characterization of true Granger Causal interactions. To overcome this\nlimitation, Tank et al (IEEE Transactions on Pattern Analysis and Machine\nLearning, 2022) proposed a solution that uses neural networks with sparse\nregularization penalties. The regularization encourages learnable weights to be\nsparse, which enables inference on GC. This paper overcomes the limitations of\ncurrent methods by leveraging advances in machine learning and deep learning\nwhich have been demonstrated to learn hidden patterns in the data. We propose\nnovel classes of models that can handle underlying non-linearity in a\ncomputationally efficient manner, simultaneously providing GC and lag order\nselection. Firstly, we present the Learned Kernel VAR (LeKVAR) model that\nlearns kernel parameterized by a shared neural net followed by penalization on\nlearnable weights to discover GC structure. Secondly, we show one can directly\ndecouple lags and individual time series importance via decoupled penalties.\nThis is important as we want to select the lag order during the process of GC\nestimation. This decoupling acts as a filtering and can be extended to any DL\nmodel including Multi-Layer Perceptrons (MLP), Recurrent Neural Networks (RNN),\nLong Short Term Memory Networks (LSTM), Transformers etc, for simultaneous GC\nestimation and lag selection.\n","authors":["Malik Shahid Sultan","Samuel Horvath","Hernando Ombao"],"pdf_url":"https://arxiv.org/pdf/2208.03703v2.pdf","comment":"To be Submitted to a Journal work Presented at JSM. arXiv admin note:\n  text overlap with arXiv:1802.05842 by other authors"},{"id":"http://arxiv.org/abs/2408.03626v1","updated":"2024-08-07T08:37:23Z","published":"2024-08-07T08:37:23Z","title":"On the choice of the non-trainable internal weights in random feature\n  maps","summary":"  The computationally cheap machine learning architecture of random feature\nmaps can be viewed as a single-layer feedforward network in which the weights\nof the hidden layer are random but fixed and only the outer weights are learned\nvia linear regression. The internal weights are typically chosen from a\nprescribed distribution. The choice of the internal weights significantly\nimpacts the accuracy of random feature maps. We address here the task of how to\nbest select the internal weights. In particular, we consider the forecasting\nproblem whereby random feature maps are used to learn a one-step propagator map\nfor a dynamical system. We provide a computationally cheap hit-and-run\nalgorithm to select good internal weights which lead to good forecasting skill.\nWe show that the number of good features is the main factor controlling the\nforecasting skill of random feature maps and acts as an effective feature\ndimension. Lastly, we compare random feature maps with single-layer feedforward\nneural networks in which the internal weights are now learned using gradient\ndescent. We find that random feature maps have superior forecasting\ncapabilities whilst having several orders of magnitude lower computational\ncost.\n","authors":["Pinak Mandal","Georg A. Gottwald"],"pdf_url":"https://arxiv.org/pdf/2408.03626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03590v1","updated":"2024-08-07T07:09:06Z","published":"2024-08-07T07:09:06Z","title":"Sensitivity analysis using the Metamodel of Optimal Prognosis","summary":"  In real case applications within the virtual prototyping process, it is not\nalways possible to reduce the complexity of the physical models and to obtain\nnumerical models which can be solved quickly. Usually, every single numerical\nsimulation takes hours or even days. Although the progresses in numerical\nmethods and high performance computing, in such cases, it is not possible to\nexplore various model configurations, hence efficient surrogate models are\nrequired. Generally the available meta-model techniques show several advantages\nand disadvantages depending on the investigated problem. In this paper we\npresent an automatic approach for the selection of the optimal suitable\nmeta-model for the actual problem. Together with an automatic reduction of the\nvariable space using advanced filter techniques an efficient approximation is\nenabled also for high dimensional problems. This filter techniques enable a\nreduction of the high dimensional variable space to a much smaller subspace\nwhere meta-model-based sensitivity analyses are carried out to assess the\ninfluence of important variables and to identify the optimal subspace with\ncorresponding surrogate model which enables the most accurate probabilistic\nanalysis. For this purpose we investigate variance-based and moment-free\nsensitivity measures in combination with advanced meta-models as moving least\nsquares and kriging.\n","authors":["Thomas Most","Johannes Will"],"pdf_url":"https://arxiv.org/pdf/2408.03590v1.pdf","comment":"presented at 8th Optimization and Stochastic Days, Weimar, Germany,\n  24-25 November, 2011"},{"id":"http://arxiv.org/abs/2408.03569v1","updated":"2024-08-07T06:11:37Z","published":"2024-08-07T06:11:37Z","title":"Maximum a Posteriori Estimation for Linear Structural Dynamics Models\n  Using Bayesian Optimization with Rational Polynomial Chaos Expansions","summary":"  Bayesian analysis enables combining prior knowledge with measurement data to\nlearn model parameters. Commonly, one resorts to computing the maximum a\nposteriori (MAP) estimate, when only a point estimate of the parameters is of\ninterest. We apply MAP estimation in the context of structural dynamic models,\nwhere the system response can be described by the frequency response function.\nTo alleviate high computational demands from repeated expensive model calls, we\nutilize a rational polynomial chaos expansion (RPCE) surrogate model that\nexpresses the system frequency response as a rational of two polynomials with\ncomplex coefficients. We propose an extension to an existing sparse Bayesian\nlearning approach for RPCE based on Laplace's approximation for the posterior\ndistribution of the denominator coefficients. Furthermore, we introduce a\nBayesian optimization approach, which allows to adaptively enrich the\nexperimental design throughout the optimization process of MAP estimation.\nThereby, we utilize the expected improvement acquisition function as a means to\nidentify sample points in the input space that are possibly associated with\nlarge objective function values. The acquisition function is estimated through\nMonte Carlo sampling based on the posterior distribution of the expansion\ncoefficients identified in the sparse Bayesian learning process. By combining\nthe sparsity-inducing learning procedure with the sequential experimental\ndesign, we effectively reduce the number of model evaluations in the MAP\nestimation problem. We demonstrate the applicability of the presented methods\non the parameter updating problem of an algebraic two-degree-of-freedom system\nand the finite element model of a cross-laminated timber plate.\n","authors":["Felix Schneider","Iason Papaioannou","Bruno Sudret","Gerhard Müller"],"pdf_url":"https://arxiv.org/pdf/2408.03569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03560v1","updated":"2024-08-07T05:48:05Z","published":"2024-08-07T05:48:05Z","title":"In2Core: Leveraging Influence Functions for Coreset Selection in\n  Instruction Finetuning of Large Language Models","summary":"  Despite advancements, fine-tuning Large Language Models (LLMs) remains costly\ndue to the extensive parameter count and substantial data requirements for\nmodel generalization. Accessibility to computing resources remains a barrier\nfor the open-source community. To address this challenge, we propose the\nIn2Core algorithm, which selects a coreset by analyzing the correlation between\ntraining and evaluation samples with a trained model. Notably, we assess the\nmodel's internal gradients to estimate this relationship, aiming to rank the\ncontribution of each training point. To enhance efficiency, we propose an\noptimization to compute influence functions with a reduced number of layers\nwhile achieving similar accuracy. By applying our algorithm to instruction\nfine-tuning data of LLMs, we can achieve similar performance with just 50% of\nthe training data. Meantime, using influence functions to analyze model\ncoverage to certain testing samples could provide a reliable and interpretable\nsignal on the training set's coverage of those test points.\n","authors":["Ayrton San Joaquin","Bin Wang","Zhengyuan Liu","Nicholas Asher","Brian Lim","Philippe Muller","Nancy Chen"],"pdf_url":"https://arxiv.org/pdf/2408.03560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03534v1","updated":"2024-08-07T04:27:58Z","published":"2024-08-07T04:27:58Z","title":"NeurAM: nonlinear dimensionality reduction for uncertainty\n  quantification through neural active manifolds","summary":"  We present a new approach for nonlinear dimensionality reduction,\nspecifically designed for computationally expensive mathematical models. We\nleverage autoencoders to discover a one-dimensional neural active manifold\n(NeurAM) capturing the model output variability, plus a simultaneously learnt\nsurrogate model with inputs on this manifold. The proposed dimensionality\nreduction framework can then be applied to perform outer loop many-query tasks,\nlike sensitivity analysis and uncertainty propagation. In particular, we prove,\nboth theoretically under idealized conditions, and numerically in challenging\ntest cases, how NeurAM can be used to obtain multifidelity sampling estimators\nwith reduced variance by sampling the models on the discovered low-dimensional\nand shared manifold among models. Several numerical examples illustrate the\nmain features of the proposed dimensionality reduction strategy, and highlight\nits advantages with respect to existing approaches in the literature.\n","authors":["Andrea Zanoni","Gianluca Geraci","Matteo Salvador","Alison L. Marsden","Daniele E. Schiavazzi"],"pdf_url":"https://arxiv.org/pdf/2408.03534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09129v4","updated":"2024-08-07T01:24:39Z","published":"2023-09-17T01:45:13Z","title":"$L^1$ Estimation: On the Optimality of Linear Estimators","summary":"  Consider the problem of estimating a random variable $X$ from noisy\nobservations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity\ncriterion. It is well known that the optimal Bayesian estimator in this setting\nis the conditional median. This work shows that the only prior distribution on\n$X$ that induces linearity in the conditional median is Gaussian.\n  Along the way, several other results are presented. In particular, it is\ndemonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for\nall $y$, then $X$ must follow a Gaussian distribution. Additionally, we\nconsider other $L^p$ losses and observe the following phenomenon: for $p \\in\n[1,2]$, Gaussian is the only prior distribution that induces a linear optimal\nBayesian estimator, and for $p \\in (2,\\infty)$, infinitely many prior\ndistributions on $X$ can induce linearity. Finally, extensions are provided to\nencompass noise models leading to conditional distributions from certain\nexponential families.\n","authors":["Leighton P. Barnes","Alex Dytso","Jingbo Liu","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2309.09129v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01698v2","updated":"2024-08-07T22:31:10Z","published":"2024-07-01T18:10:19Z","title":"Column and row subset selection using nuclear scores: algorithms and\n  theory for Nyström approximation, CUR decomposition, and graph Laplacian\n  reduction","summary":"  Column selection is an essential tool for structure-preserving low-rank\napproximation, with wide-ranging applications across many fields, such as data\nscience, machine learning, and theoretical chemistry. In this work, we develop\nunified methodologies for fast, efficient, and theoretically guaranteed column\nselection. First we derive and implement a sparsity-exploiting deterministic\nalgorithm applicable to tasks including kernel approximation and CUR\ndecomposition. Next, we develop a matrix-free formalism relying on a\nrandomization scheme satisfying guaranteed concentration bounds, applying this\nconstruction both to CUR decomposition and to the approximation of matrix\nfunctions of graph Laplacians. Importantly, the randomization is only relevant\nfor the computation of the scores that we use for column selection, not the\nselection itself given these scores. For both deterministic and matrix-free\nalgorithms, we bound the performance favorably relative to the expected\nperformance of determinantal point process (DPP) sampling and, in select\nscenarios, that of exactly optimal subset selection. The general case requires\nnew analysis of the DPP expectation. Finally, we demonstrate strong real-world\nperformance of our algorithms on a diverse set of example approximation tasks.\n","authors":["Mark Fornace","Michael Lindsey"],"pdf_url":"https://arxiv.org/pdf/2407.01698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14631v2","updated":"2024-08-07T21:10:30Z","published":"2024-07-19T19:07:53Z","title":"Two new feature selection methods based on learn-heuristic techniques\n  for breast cancer prediction: A comprehensive analysis","summary":"  Breast cancer is not preventable because of its unknown causes. However, its\nearly diagnosis increases patients' recovery chances. Machine learning (ML) can\nbe utilized to improve treatment outcomes in healthcare operations while\ndiminishing costs and time. In this research, we suggest two novel feature\nselection (FS) methods based upon an imperialist competitive algorithm (ICA)\nand a bat algorithm (BA) and their combination with ML algorithms. This study\naims to enhance diagnostic models' efficiency and present a comprehensive\nanalysis to help clinical physicians make much more precise and reliable\ndecisions than before. K-nearest neighbors, support vector machine, decision\ntree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,\nlogistic regression, and artificial neural network are some of the methods\nemployed. This paper applied a distinctive integration of evaluation measures\nand ML algorithms using the wrapper feature selection based on ICA (WFSIC) and\nBA (WFSB) separately. We compared two proposed approaches for the performance\nof the classifiers. Also, we compared our best diagnostic model with previous\nworks reported in the literature survey. Experimentations were performed on the\nWisconsin diagnostic breast cancer dataset. Results reveal that the proposed\nframework that uses the BA with an accuracy of 99.12\\%, surpasses the framework\nusing the ICA and most previous works. Additionally, the RF classifier in the\napproach of FS based on BA emerges as the best model and outperforms others\nregarding its criteria. Besides, the results illustrate the role of our\ntechniques in reducing the dataset dimensions up to 90\\% and increasing the\nperformance of diagnostic models by over 99\\%. Moreover, the result\ndemonstrates that there are more critical features than the optimum dataset\nobtained by proposed FS approaches that have been selected by most ML models.\n","authors":["Kamyab Karimi","Ali Ghodratnama","Reza Tavakkoli-Moghaddam"],"pdf_url":"https://arxiv.org/pdf/2407.14631v2.pdf","comment":"36 pages, 3 figures, 12 tables"},{"id":"http://arxiv.org/abs/2407.20128v2","updated":"2024-08-07T19:04:48Z","published":"2024-07-29T15:56:49Z","title":"Finite-Sample Guarantees for Best-Response Learning Dynamics in Zero-Sum\n  Matrix Games","summary":"  We study best-response type learning dynamics for two player zero-sum matrix\ngames. We consider two settings that are distinguished by the type of\ninformation that each player has about the game and their opponent's strategy.\nThe first setting is the full information case, in which each player knows\ntheir own and the opponent's payoff matrices and observes the opponent's mixed\nstrategy. The second setting is the minimal information case, where players do\nnot observe the opponent's strategy and are not aware of either of the payoff\nmatrices (instead they only observe their realized payoffs). For this setting,\nalso known as the radically uncoupled case in the learning in games literature,\nwe study a two-timescale learning dynamics that combine smoothed best-response\ntype updates for strategy estimates with a TD-learning update to estimate a\nlocal payoff function. For these dynamics, without additional exploration, we\nprovide polynomial-time finite-sample guarantees for convergence to an\n$\\epsilon$-Nash equilibrium.\n","authors":["Fathima Zarin Faizal","Asuman Ozdaglar","Martin J. Wainwright"],"pdf_url":"https://arxiv.org/pdf/2407.20128v2.pdf","comment":"36 pages; under review"},{"id":"http://arxiv.org/abs/2405.15682v3","updated":"2024-08-07T17:44:58Z","published":"2024-05-24T16:20:46Z","title":"The Road Less Scheduled","summary":"  Existing learning rate schedules that do not require specification of the\noptimization stopping step T are greatly out-performed by learning rate\nschedules that depend on T. We propose an approach that avoids the need for\nthis stopping time by eschewing the use of schedules entirely, while exhibiting\nstate-of-the-art performance compared to schedules across a wide family of\nproblems ranging from convex problems to large-scale deep learning problems.\nOur Schedule-Free approach introduces no additional hyper-parameters over\nstandard optimizers with momentum. Our method is a direct consequence of a new\ntheory we develop that unifies scheduling and iterate averaging. An open source\nimplementation of our method is available\n(https://github.com/facebookresearch/schedule_free).\n","authors":["Aaron Defazio","Xingyu Alice Yang","Harsh Mehta","Konstantin Mishchenko","Ahmed Khaled","Ashok Cutkosky"],"pdf_url":"https://arxiv.org/pdf/2405.15682v3.pdf","comment":null}]},"2024-08-08T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2408.04633v1","updated":"2024-08-08T17:59:58Z","published":"2024-08-08T17:59:58Z","title":"LiDAR-Event Stereo Fusion with Hallucinations","summary":"  Event stereo matching is an emerging technique to estimate depth from\nneuromorphic cameras; however, events are unlikely to trigger in the absence of\nmotion or the presence of large, untextured regions, making the correspondence\nproblem extremely challenging. Purposely, we propose integrating a stereo event\ncamera with a fixed-frequency active sensor -- e.g., a LiDAR -- collecting\nsparse depth measurements, overcoming the aforementioned limitations. Such\ndepth hints are used by hallucinating -- i.e., inserting fictitious events --\nthe stacks or raw input streams, compensating for the lack of information in\nthe absence of brightness changes. Our techniques are general, can be adapted\nto any structured representation to stack events and outperform\nstate-of-the-art fusion methods applied to event-based stereo.\n","authors":["Luca Bartolomei","Matteo Poggi","Andrea Conti","Stefano Mattoccia"],"pdf_url":"https://arxiv.org/pdf/2408.04633v1.pdf","comment":"ECCV 2024. Code: https://github.com/bartn8/eventvppstereo/ - Project\n  Page: https://eventvppstereo.github.io/"},{"id":"http://arxiv.org/abs/2408.04632v1","updated":"2024-08-08T17:59:46Z","published":"2024-08-08T17:59:46Z","title":"Arctic-TILT. Business Document Understanding at Sub-Billion Scale","summary":"  The vast portion of workloads employing LLMs involves answering questions\ngrounded on PDF or scan content. We introduce the Arctic-TILT achieving\naccuracy on par with models 1000$\\times$ its size on these use cases. It can be\nfine-tuned and deployed on a single 24GB GPU, lowering operational costs while\nprocessing Visually Rich Documents with up to 400k tokens. The model\nestablishes state-of-the-art results on seven diverse Document Understanding\nbenchmarks, as well as provides reliable confidence scores and quick inference,\nwhich are essential for processing files in large-scale or time-sensitive\nenterprise environments.\n","authors":["Łukasz Borchmann","Michał Pietruszka","Wojciech Jaśkowski","Dawid Jurkiewicz","Piotr Halama","Paweł Józiak","Łukasz Garncarek","Paweł Liskowski","Karolina Szyndler","Andrzej Gretkowski","Julita Ołtusek","Gabriela Nowakowska","Artur Zawłocki","Łukasz Duhr","Paweł Dyda","Michał Turski"],"pdf_url":"https://arxiv.org/pdf/2408.04632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04631v1","updated":"2024-08-08T17:59:38Z","published":"2024-08-08T17:59:38Z","title":"Puppet-Master: Scaling Interactive Video Generation as a Motion Prior\n  for Part-Level Dynamics","summary":"  We present Puppet-Master, an interactive video generative model that can\nserve as a motion prior for part-level dynamics. At test time, given a single\nimage and a sparse set of motion trajectories (i.e., drags), Puppet-Master can\nsynthesize a video depicting realistic part-level motion faithful to the given\ndrag interactions. This is achieved by fine-tuning a large-scale pre-trained\nvideo diffusion model, for which we propose a new conditioning architecture to\ninject the dragging control effectively. More importantly, we introduce the\nall-to-first attention mechanism, a drop-in replacement for the widely adopted\nspatial attention modules, which significantly improves generation quality by\naddressing the appearance and background issues in existing models. Unlike\nother motion-conditioned video generators that are trained on in-the-wild\nvideos and mostly move an entire object, Puppet-Master is learned from\nObjaverse-Animation-HQ, a new dataset of curated part-level motion clips. We\npropose a strategy to automatically filter out sub-optimal animations and\naugment the synthetic renderings with meaningful motion trajectories.\nPuppet-Master generalizes well to real images across various categories and\noutperforms existing methods in a zero-shot manner on a real-world benchmark.\nSee our project page for more results: vgg-puppetmaster.github.io.\n","authors":["Ruining Li","Chuanxia Zheng","Christian Rupprecht","Andrea Vedaldi"],"pdf_url":"https://arxiv.org/pdf/2408.04631v1.pdf","comment":"Project page: https://vgg-puppetmaster.github.io/"},{"id":"http://arxiv.org/abs/2408.04628v1","updated":"2024-08-08T17:58:06Z","published":"2024-08-08T17:58:06Z","title":"LogogramNLP: Comparing Visual and Textual Representations of Ancient\n  Logographic Writing Systems for NLP","summary":"  Standard natural language processing (NLP) pipelines operate on symbolic\nrepresentations of language, which typically consist of sequences of discrete\ntokens. However, creating an analogous representation for ancient logographic\nwriting systems is an extremely labor intensive process that requires expert\nknowledge. At present, a large portion of logographic data persists in a purely\nvisual form due to the absence of transcription -- this issue poses a\nbottleneck for researchers seeking to apply NLP toolkits to study ancient\nlogographic languages: most of the relevant data are images of writing.\n  This paper investigates whether direct processing of visual representations\nof language offers a potential solution. We introduce LogogramNLP, the first\nbenchmark enabling NLP analysis of ancient logographic languages, featuring\nboth transcribed and visual datasets for four writing systems along with\nannotations for tasks like classification, translation, and parsing. Our\nexperiments compare systems that employ recent visual and text encoding\nstrategies as backbones. The results demonstrate that visual representations\noutperform textual representations for some investigated tasks, suggesting that\nvisual processing pipelines may unlock a large amount of cultural heritage data\nof logographic languages for NLP-based analyses.\n","authors":["Danlu Chen","Freda Shi","Aditi Agarwal","Jacobo Myerston","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2408.04628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07061v2","updated":"2024-08-08T17:52:16Z","published":"2024-01-13T12:32:29Z","title":"Dual-View Data Hallucination with Semantic Relation Guidance for\n  Few-Shot Image Recognition","summary":"  Learning to recognize novel concepts from just a few image samples is very\nchallenging as the learned model is easily overfitted on the few data and\nresults in poor generalizability. One promising but underexplored solution is\nto compensate the novel classes by generating plausible samples. However, most\nexisting works of this line exploit visual information only, rendering the\ngenerated data easy to be distracted by some challenging factors contained in\nthe few available samples. Being aware of the semantic information in the\ntextual modality that reflects human concepts, this work proposes a novel\nframework that exploits semantic relations to guide dual-view data\nhallucination for few-shot image recognition. The proposed framework enables\ngenerating more diverse and reasonable data samples for novel classes through\neffective information transfer from base classes. Specifically, an\ninstance-view data hallucination module hallucinates each sample of a novel\nclass to generate new data by employing local semantic correlated attention and\nglobal semantic feature fusion derived from base classes. Meanwhile, a\nprototype-view data hallucination module exploits semantic-aware measure to\nestimate the prototype of a novel class and the associated distribution from\nthe few samples, which thereby harvests the prototype as a more stable sample\nand enables resampling a large number of samples. We conduct extensive\nexperiments and comparisons with state-of-the-art methods on several popular\nfew-shot benchmarks to verify the effectiveness of the proposed framework.\n","authors":["Hefeng Wu","Guangzhi Ye","Ziyang Zhou","Ling Tian","Qing Wang","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2401.07061v2.pdf","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2408.04610v1","updated":"2024-08-08T17:28:32Z","published":"2024-08-08T17:28:32Z","title":"Quantifying the Impact of Population Shift Across Age and Sex for\n  Abdominal Organ Segmentation","summary":"  Deep learning-based medical image segmentation has seen tremendous progress\nover the last decade, but there is still relatively little transfer into\nclinical practice. One of the main barriers is the challenge of domain\ngeneralisation, which requires segmentation models to maintain high performance\nacross a wide distribution of image data. This challenge is amplified by the\nmany factors that contribute to the diverse appearance of medical images, such\nas acquisition conditions and patient characteristics. The impact of shifting\npatient characteristics such as age and sex on segmentation performance remains\nrelatively under-studied, especially for abdominal organs, despite that this is\ncrucial for ensuring the fairness of the segmentation model. We perform the\nfirst study to determine the impact of population shift with respect to age and\nsex on abdominal CT image segmentation, by leveraging two large public\ndatasets, and introduce a novel metric to quantify the impact. We find that\npopulation shift is a challenge similar in magnitude to cross-dataset shift for\nabdominal organ segmentation, and that the effect is asymmetric and\ndataset-dependent. We conclude that dataset diversity in terms of known patient\ncharacteristics is not necessarily equivalent to dataset diversity in terms of\nimage features. This implies that simple population matching to ensure good\ngeneralisation and fairness may be insufficient, and we recommend that fairness\nresearch should be directed towards better understanding and quantifying\nmedical image dataset diversity in terms of performance-relevant\ncharacteristics such as organ morphology.\n","authors":["Kate Čevora","Ben Glocker","Wenjia Bai"],"pdf_url":"https://arxiv.org/pdf/2408.04610v1.pdf","comment":"This paper has been accepted for publication by the MICCAI 2024\n  Fairness of AI in Medical Imaging (FAIMI) Workshop"},{"id":"http://arxiv.org/abs/2408.04606v1","updated":"2024-08-08T17:26:56Z","published":"2024-08-08T17:26:56Z","title":"Enhanced Prototypical Part Network (EPPNet) For Explainable Image\n  Classification Via Prototypes","summary":"  Explainable Artificial Intelligence (xAI) has the potential to enhance the\ntransparency and trust of AI-based systems. Although accurate predictions can\nbe made using Deep Neural Networks (DNNs), the process used to arrive at such\npredictions is usually hard to explain. In terms of perceptibly human-friendly\nrepresentations, such as word phrases in text or super-pixels in images,\nprototype-based explanations can justify a model's decision. In this work, we\nintroduce a DNN architecture for image classification, the Enhanced\nPrototypical Part Network (EPPNet), which achieves strong performance while\ndiscovering relevant prototypes that can be used to explain the classification\nresults. This is achieved by introducing a novel cluster loss that helps to\ndiscover more relevant human-understandable prototypes. We also introduce a\nfaithfulness score to evaluate the explainability of the results based on the\ndiscovered prototypes. Our score not only accounts for the relevance of the\nlearned prototypes but also the performance of a model. Our evaluations on the\nCUB-200-2011 dataset show that the EPPNet outperforms state-of-the-art\nxAI-based methods, in terms of both classification accuracy and explainability\n","authors":["Bhushan Atote","Victor Sanchez"],"pdf_url":"https://arxiv.org/pdf/2408.04606v1.pdf","comment":"Accepted at the International Conference on Image Processing (ICIP),\n  IEEE (2024), we will update the new version after published through IEEE"},{"id":"http://arxiv.org/abs/2408.04605v1","updated":"2024-08-08T17:24:54Z","published":"2024-08-08T17:24:54Z","title":"Fall Detection for Industrial Setups Using YOLOv8 Variants","summary":"  This paper presents the development of an industrial fall detection system\nutilizing YOLOv8 variants, enhanced by our proposed augmentation pipeline to\nincrease dataset variance and improve detection accuracy. Among the models\nevaluated, the YOLOv8m model, consisting of 25.9 million parameters and 79.1\nGFLOPs, demonstrated a respectable balance between computational efficiency and\ndetection performance, achieving a mean Average Precision (mAP) of 0.971 at 50%\nIntersection over Union (IoU) across both \"Fall Detected\" and \"Human in Motion\"\ncategories. Although the YOLOv8l and YOLOv8x models presented higher precision\nand recall, particularly in fall detection, their higher computational demands\nand model size make them less suitable for resource-constrained environments.\n","authors":["Gracile Astlin Pereira"],"pdf_url":"https://arxiv.org/pdf/2408.04605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04604v1","updated":"2024-08-08T17:24:03Z","published":"2024-08-08T17:24:03Z","title":"Towards High-resolution 3D Anomaly Detection via Group-Level Feature\n  Contrastive Learning","summary":"  High-resolution point clouds~(HRPCD) anomaly detection~(AD) plays a critical\nrole in precision machining and high-end equipment manufacturing. Despite\nconsiderable 3D-AD methods that have been proposed recently, they still cannot\nmeet the requirements of the HRPCD-AD task. There are several challenges: i) It\nis difficult to directly capture HRPCD information due to large amounts of\npoints at the sample level; ii) The advanced transformer-based methods usually\nobtain anisotropic features, leading to degradation of the representation; iii)\nThe proportion of abnormal areas is very small, which makes it difficult to\ncharacterize. To address these challenges, we propose a novel group-level\nfeature-based network, called Group3AD, which has a significantly efficient\nrepresentation ability. First, we design an Intercluster Uniformity\nNetwork~(IUN) to present the mapping of different groups in the feature space\nas several clusters, and obtain a more uniform distribution between clusters\nrepresenting different parts of the point clouds in the feature space. Then, an\nIntracluster Alignment Network~(IAN) is designed to encourage groups within the\ncluster to be distributed tightly in the feature space. In addition, we propose\nan Adaptive Group-Center Selection~(AGCS) based on geometric information to\nimprove the pixel density of potential anomalous regions during inference. The\nexperimental results verify the effectiveness of our proposed Group3AD, which\nsurpasses Reg3D-AD by the margin of 5\\% in terms of object-level AUROC on\nReal3D-AD. We provide the code and supplementary information on our website:\nhttps://github.com/M-3LAB/Group3AD.\n","authors":["Hongze Zhu","Guoyang Xie","Chengbin Hou","Tao Dai","Can Gao","Jinbao Wang","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2408.04604v1.pdf","comment":"ACMMM24, 12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.04600v1","updated":"2024-08-08T17:20:08Z","published":"2024-08-08T17:20:08Z","title":"Improving Network Interpretability via Explanation Consistency\n  Evaluation","summary":"  While deep neural networks have achieved remarkable performance, they tend to\nlack transparency in prediction. The pursuit of greater interpretability in\nneural networks often results in a degradation of their original performance.\nSome works strive to improve both interpretability and performance, but they\nprimarily depend on meticulously imposed conditions. In this paper, we propose\na simple yet effective framework that acquires more explainable activation\nheatmaps and simultaneously increase the model performance, without the need\nfor any extra supervision. Specifically, our concise framework introduces a new\nmetric, i.e., explanation consistency, to reweight the training samples\nadaptively in model learning. The explanation consistency metric is utilized to\nmeasure the similarity between the model's visual explanations of the original\nsamples and those of semantic-preserved adversarial samples, whose background\nregions are perturbed by using image adversarial attack techniques. Our\nframework then promotes the model learning by paying closer attention to those\ntraining samples with a high difference in explanations (i.e., low explanation\nconsistency), for which the current model cannot provide robust\ninterpretations. Comprehensive experimental results on various benchmarks\ndemonstrate the superiority of our framework in multiple aspects, including\nhigher recognition accuracy, greater data debiasing capability, stronger\nnetwork robustness, and more precise localization ability on both regular\nnetworks and interpretable networks. We also provide extensive ablation studies\nand qualitative analyses to unveil the detailed contribution of each component.\n","authors":["Hefeng Wu","Hao Jiang","Keze Wang","Ziyi Tang","Xianghuan He","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2408.04600v1.pdf","comment":"To appear in IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2408.04594v1","updated":"2024-08-08T17:10:16Z","published":"2024-08-08T17:10:16Z","title":"Img-Diff: Contrastive Data Synthesis for Multimodal Large Language\n  Models","summary":"  High-performance Multimodal Large Language Models (MLLMs) rely heavily on\ndata quality. This study introduces a novel dataset named Img-Diff, designed to\nenhance fine-grained image recognition in MLLMs by leveraging insights from\ncontrastive learning and image difference captioning. By analyzing object\ndifferences between similar images, we challenge models to identify both\nmatching and distinct components. We utilize the Stable-Diffusion-XL model and\nadvanced image editing techniques to create pairs of similar images that\nhighlight object replacements. Our methodology includes a Difference Area\nGenerator for object differences identifying, followed by a Difference Captions\nGenerator for detailed difference descriptions. The result is a relatively\nsmall but high-quality dataset of \"object replacement\" samples. We use the the\nproposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B,\nyielding comprehensive improvements of performance scores over SOTA models that\ntrained with larger-scale datasets, in numerous image difference and Visual\nQuestion Answering tasks. For instance, our trained models notably surpass the\nSOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate\nalternative methods for generating image difference data through \"object\nremoval\" and conduct thorough evaluation to confirm the dataset's diversity,\nquality, and robustness, presenting several insights on synthesis of such\ncontrastive dataset. To encourage further research and advance the field of\nmultimodal data synthesis and enhancement of MLLMs' fundamental capabilities\nfor image understanding, we release our codes and dataset at\nhttps://github.com/modelscope/data-juicer/tree/ImgDiff.\n","authors":["Qirui Jiao","Daoyuan Chen","Yilun Huang","Yaliang Li","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2408.04594v1.pdf","comment":"14 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2408.04593v1","updated":"2024-08-08T17:08:57Z","published":"2024-08-08T17:08:57Z","title":"SAM 2 in Robotic Surgery: An Empirical Evaluation for Robustness and\n  Generalization in Surgical Video Segmentation","summary":"  The recent Segment Anything Model (SAM) 2 has demonstrated remarkable\nfoundational competence in semantic segmentation, with its memory mechanism and\nmask decoder further addressing challenges in video tracking and object\nocclusion, thereby achieving superior results in interactive segmentation for\nboth images and videos. Building upon our previous empirical studies, we\nfurther explore the zero-shot segmentation performance of SAM 2 in\nrobot-assisted surgery based on prompts, alongside its robustness against\nreal-world corruption. For static images, we employ two forms of prompts:\n1-point and bounding box, while for video sequences, the 1-point prompt is\napplied to the initial frame. Through extensive experimentation on the MICCAI\nEndoVis 2017 and EndoVis 2018 benchmarks, SAM 2, when utilizing bounding box\nprompts, outperforms state-of-the-art (SOTA) methods in comparative\nevaluations. The results with point prompts also exhibit a substantial\nenhancement over SAM's capabilities, nearing or even surpassing existing\nunprompted SOTA methodologies. Besides, SAM 2 demonstrates improved inference\nspeed and less performance degradation against various image corruption.\nAlthough slightly unsatisfactory results remain in specific edges or regions,\nSAM 2's robust adaptability to 1-point prompts underscores its potential for\ndownstream surgical tasks with limited prompt requirements.\n","authors":["Jieming Yu","An Wang","Wenzhen Dong","Mengya Xu","Mobarakol Islam","Jie Wang","Long Bai","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2408.04593v1.pdf","comment":"Empirical study. Previous work \"SAM Meets Robotic Surgery\" is\n  accessible at: arXiv:2308.07156"},{"id":"http://arxiv.org/abs/2408.04591v1","updated":"2024-08-08T17:04:06Z","published":"2024-08-08T17:04:06Z","title":"HiLo: A Learning Framework for Generalized Category Discovery Robust to\n  Domain Shifts","summary":"  Generalized Category Discovery (GCD) is a challenging task in which, given a\npartially labelled dataset, models must categorize all unlabelled instances,\nregardless of whether they come from labelled categories or from new ones. In\nthis paper, we challenge a remaining assumption in this task: that all images\nshare the same domain. Specifically, we introduce a new task and method to\nhandle GCD when the unlabelled data also contains images from different domains\nto the labelled set. Our proposed `HiLo' networks extract High-level semantic\nand Low-level domain features, before minimizing the mutual information between\nthe representations. Our intuition is that the clusterings based on domain\ninformation and semantic information should be independent. We further extend\nour method with a specialized domain augmentation tailored for the GCD task, as\nwell as a curriculum learning approach. Finally, we construct a benchmark from\ncorrupted fine-grained datasets as well as a large-scale evaluation on\nDomainNet with real-world domain shifts, reimplementing a number of GCD\nbaselines in this setting. We demonstrate that HiLo outperforms SoTA category\ndiscovery models by a large margin on all evaluations.\n","authors":["Hongjun Wang","Sagar Vaze","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2408.04591v1.pdf","comment":"39 pages, 9 figures, 26 tables"},{"id":"http://arxiv.org/abs/2408.04586v1","updated":"2024-08-08T16:56:03Z","published":"2024-08-08T16:56:03Z","title":"Sampling for View Synthesis: From Local Light Field Fusion to Neural\n  Radiance Fields and Beyond","summary":"  Capturing and rendering novel views of complex real-world scenes is a\nlong-standing problem in computer graphics and vision, with applications in\naugmented and virtual reality, immersive experiences and 3D photography. The\nadvent of deep learning has enabled revolutionary advances in this area,\nclassically known as image-based rendering. However, previous approaches\nrequire intractably dense view sampling or provide little or no guidance for\nhow users should sample views of a scene to reliably render high-quality novel\nviews. Local light field fusion proposes an algorithm for practical view\nsynthesis from an irregular grid of sampled views that first expands each\nsampled view into a local light field via a multiplane image scene\nrepresentation, then renders novel views by blending adjacent local light\nfields. Crucially, we extend traditional plenoptic sampling theory to derive a\nbound that specifies precisely how densely users should sample views of a given\nscene when using our algorithm. We achieve the perceptual quality of Nyquist\nrate view sampling while using up to 4000x fewer views. Subsequent developments\nhave led to new scene representations for deep learning with view synthesis,\nnotably neural radiance fields, but the problem of sparse view synthesis from a\nsmall number of images has only grown in importance. We reprise some of the\nrecent results on sparse and even single image view synthesis, while posing the\nquestion of whether prescriptive sampling guidelines are feasible for the new\ngeneration of image-based rendering algorithms.\n","authors":["Ravi Ramamoorthi"],"pdf_url":"https://arxiv.org/pdf/2408.04586v1.pdf","comment":"Article written for Frontiers of Science Award, International\n  Congress on Basic Science, 2024"},{"id":"http://arxiv.org/abs/2312.02647v2","updated":"2024-08-08T16:47:26Z","published":"2023-12-05T10:39:37Z","title":"TPA3D: Triplane Attention for Fast Text-to-3D Generation","summary":"  Due to the lack of large-scale text-3D correspondence data, recent text-to-3D\ngeneration works mainly rely on utilizing 2D diffusion models for synthesizing\n3D data. Since diffusion-based methods typically require significant\noptimization time for both training and inference, the use of GAN-based models\nwould still be desirable for fast 3D generation. In this work, we propose\nTriplane Attention for text-guided 3D generation (TPA3D), an end-to-end\ntrainable GAN-based deep learning model for fast text-to-3D generation. With\nonly 3D shape data and their rendered 2D images observed during training, our\nTPA3D is designed to retrieve detailed visual descriptions for synthesizing the\ncorresponding 3D mesh data. This is achieved by the proposed attention\nmechanisms on the extracted sentence and word-level text features. In our\nexperiments, we show that TPA3D generates high-quality 3D textured shapes\naligned with fine-grained descriptions, while impressive computation efficiency\ncan be observed.\n","authors":["Bin-Shih Wu","Hong-En Chen","Sheng-Yu Huang","Yu-Chiang Frank Wang"],"pdf_url":"https://arxiv.org/pdf/2312.02647v2.pdf","comment":"ECCV2024"},{"id":"http://arxiv.org/abs/2408.04579v1","updated":"2024-08-08T16:40:15Z","published":"2024-08-08T16:40:15Z","title":"SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream\n  Tasks: Camouflage, Shadow, Medical Image Segmentation, and More","summary":"  The advent of large models, also known as foundation models, has\nsignificantly transformed the AI research landscape, with models like Segment\nAnything (SAM) achieving notable success in diverse image segmentation\nscenarios. Despite its advancements, SAM encountered limitations in handling\nsome complex low-level segmentation tasks like camouflaged object and medical\nimaging. In response, in 2023, we introduced SAM-Adapter, which demonstrated\nimproved performance on these challenging tasks. Now, with the release of\nSegment Anything 2 (SAM2), a successor with enhanced architecture and a larger\ntraining corpus, we reassess these challenges. This paper introduces\nSAM2-Adapter, the first adapter designed to overcome the persistent limitations\nobserved in SAM2 and achieve new state-of-the-art (SOTA) results in specific\ndownstream tasks including medical image segmentation, camouflaged (concealed)\nobject detection, and shadow detection. SAM2-Adapter builds on the\nSAM-Adapter's strengths, offering enhanced generalizability and composability\nfor diverse applications. We present extensive experimental results\ndemonstrating SAM2-Adapter's effectiveness. We show the potential and encourage\nthe research community to leverage the SAM2 model with our SAM2-Adapter for\nachieving superior segmentation outcomes. Code, pre-trained models, and data\nprocessing protocols are available at\nhttp://tianrun-chen.github.io/SAM-Adaptor/\n","authors":["Tianrun Chen","Ankang Lu","Lanyun Zhu","Chaotao Ding","Chunan Yu","Deyi Ji","Zejian Li","Lingyun Sun","Papa Mao","Ying Zang"],"pdf_url":"https://arxiv.org/pdf/2408.04579v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2304.09148"},{"id":"http://arxiv.org/abs/2408.04567v1","updated":"2024-08-08T16:27:37Z","published":"2024-08-08T16:27:37Z","title":"Sketch2Scene: Automatic Generation of Interactive 3D Game Scenes from\n  User's Casual Sketches","summary":"  3D Content Generation is at the heart of many computer graphics applications,\nincluding video gaming, film-making, virtual and augmented reality, etc. This\npaper proposes a novel deep-learning based approach for automatically\ngenerating interactive and playable 3D game scenes, all from the user's casual\nprompts such as a hand-drawn sketch. Sketch-based input offers a natural, and\nconvenient way to convey the user's design intention in the content creation\nprocess. To circumvent the data-deficient challenge in learning (i.e. the lack\nof large training data of 3D scenes), our method leverages a pre-trained 2D\ndenoising diffusion model to generate a 2D image of the scene as the conceptual\nguidance. In this process, we adopt the isometric projection mode to factor out\nunknown camera poses while obtaining the scene layout. From the generated\nisometric image, we use a pre-trained image understanding method to segment the\nimage into meaningful parts, such as off-ground objects, trees, and buildings,\nand extract the 2D scene layout. These segments and layouts are subsequently\nfed into a procedural content generation (PCG) engine, such as a 3D video game\nengine like Unity or Unreal, to create the 3D scene. The resulting 3D scene can\nbe seamlessly integrated into a game development environment and is readily\nplayable. Extensive tests demonstrate that our method can efficiently generate\nhigh-quality and interactive 3D game scenes with layouts that closely follow\nthe user's intention.\n","authors":["Yongzhi Xu","Yonhon Ng","Yifu Wang","Inkyu Sa","Yunfei Duan","Yang Li","Pan Ji","Hongdong Li"],"pdf_url":"https://arxiv.org/pdf/2408.04567v1.pdf","comment":"Project Page: https://xrvisionlabs.github.io/Sketch2Scene/"},{"id":"http://arxiv.org/abs/2307.02694v3","updated":"2024-08-08T16:24:52Z","published":"2023-07-05T23:53:55Z","title":"Loss Functions and Metrics in Deep Learning","summary":"  When training or evaluating deep learning models, two essential parts are\npicking the proper loss function and deciding on performance metrics. In this\npaper, we provide a comprehensive overview of the most common loss functions\nand metrics used across many different types of deep learning tasks, from\ngeneral tasks such as regression and classification to more specific tasks in\nComputer Vision and Natural Language Processing. We introduce the formula for\neach loss and metric, discuss their strengths and limitations, and describe how\nthese methods can be applied to various problems within deep learning. We hope\nthis work serves as a reference for researchers and practitioners in the field,\nhelping them make informed decisions when selecting the most appropriate loss\nfunction and performance metrics for their deep learning projects.\n","authors":["Juan Terven","Diana M. Cordova-Esparza","Alfonso Ramirez-Pedraza","Edgar A. Chavez-Urbiola","Julio A. Romero-Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2307.02694v3.pdf","comment":"76 pages, 4 figures, 13 tables, 127 equations"},{"id":"http://arxiv.org/abs/2407.14153v3","updated":"2024-08-08T16:20:02Z","published":"2024-07-19T09:32:30Z","title":"ESP-MedSAM: Efficient Self-Prompting SAM for Universal\n  Domain-Generalized Image Segmentation","summary":"  The universality of deep neural networks across different modalities and\ntheir generalization capabilities to unseen domains play an essential role in\nmedical image segmentation. The recent Segment Anything Model (SAM) has\ndemonstrated its potential in both settings. However, the huge computational\ncosts, demand for manual annotations as prompts and conflict-prone decoding\nprocess of SAM degrade its generalizability and applicability in clinical\nscenarios. To address these issues, we propose an efficient self-prompting SAM\nfor universal domain-generalized medical image segmentation, named ESP-MedSAM.\nSpecifically, we first devise the Multi-Modal Decoupled Knowledge Distillation\n(MMDKD) strategy to construct a lightweight semi-parameter sharing image\nencoder that produces discriminative visual features for diverse modalities.\nFurther, we introduce the Self-Patch Prompt Generator (SPPG) to automatically\ngenerate high-quality dense prompt embeddings for guiding segmentation\ndecoding. Finally, we design the Query-Decoupled Modality Decoder (QDMD) that\nleverages a one-to-one strategy to provide an independent decoding channel for\nevery modality. Extensive experiments indicate that ESP-MedSAM outperforms\nstate-of-the-arts in diverse medical imaging segmentation tasks, displaying\nsuperior modality universality and generalization capabilities. Especially,\nESP-MedSAM uses only 4.5\\% parameters compared to SAM-H. The source code is\navailable at https://github.com/xq141839/ESP-MedSAM.\n","authors":["Qing Xu","Jiaxuan Li","Xiangjian He","Ziyu Liu","Zhen Chen","Wenting Duan","Chenxin Li","Maggie M. He","Fiseha B. Tesema","Wooi P. Cheah","Yi Wang","Rong Qu","Jonathan M. Garibaldi"],"pdf_url":"https://arxiv.org/pdf/2407.14153v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2208.03561v2","updated":"2024-08-08T16:12:51Z","published":"2022-08-06T18:30:53Z","title":"Study of detecting behavioral signatures within DeepFake videos","summary":"  There is strong interest in the generation of synthetic video imagery of\npeople talking for various purposes, including entertainment, communication,\ntraining, and advertisement. With the development of deep fake generation\nmodels, synthetic video imagery will soon be visually indistinguishable to the\nnaked eye from a naturally capture video. In addition, many methods are\ncontinuing to improve to avoid more careful, forensic visual analysis. Some\ndeep fake videos are produced through the use of facial puppetry, which\ndirectly controls the head and face of the synthetic image through the\nmovements of the actor, allow the actor to 'puppet' the image of another. In\nthis paper, we address the question of whether one person's movements can be\ndistinguished from the original speaker by controlling the visual appearance of\nthe speaker but transferring the behavior signals from another source. We\nconduct a study by comparing synthetic imagery that: 1) originates from a\ndifferent person speaking a different utterance, 2) originates from the same\nperson speaking a different utterance, and 3) originates from a different\nperson speaking the same utterance. Our study shows that synthetic videos in\nall three cases are seen as less real and less engaging than the original\nsource video. Our results indicate that there could be a behavioral signature\nthat is detectable from a person's movements that is separate from their visual\nappearance, and that this behavioral signature could be used to distinguish a\ndeep fake from a properly captured video.\n","authors":["Qiaomu Miao","Sinhwa Kang","Stacy Marsella","Steve DiPaola","Chao Wang","Ari Shapiro"],"pdf_url":"https://arxiv.org/pdf/2208.03561v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2406.01561v3","updated":"2024-08-08T16:00:01Z","published":"2024-06-03T17:44:11Z","title":"Long and Short Guidance in Score identity Distillation for One-Step\n  Text-to-Image Generation","summary":"  Diffusion-based text-to-image generation models trained on extensive\ntext-image pairs have shown the capacity to generate photorealistic images\nconsistent with textual descriptions. However, a significant limitation of\nthese models is their slow sample generation, which requires iterative\nrefinement through the same network. In this paper, we enhance Score identity\nDistillation (SiD) by developing long and short classifier-free guidance (LSG)\nto efficiently distill pretrained Stable Diffusion models without using real\ntraining data. SiD aims to optimize a model-based explicit score matching loss,\nutilizing a score-identity-based approximation alongside the proposed LSG for\npractical computation. By training exclusively with fake images synthesized\nwith its one-step generator, SiD equipped with LSG rapidly improves FID and\nCLIP scores, achieving state-of-the-art FID performance while maintaining a\ncompetitive CLIP score. Specifically, its data-free distillation of Stable\nDiffusion 1.5 achieves a record low FID of 8.15 on the COCO-2014 validation\nset, with a CLIP score of 0.304 at an LSG scale of 1.5, and an FID of 9.56 with\na CLIP score of 0.313 at an LSG scale of 2. Our code and distilled one-step\ntext-to-image generators are available at\nhttps://github.com/mingyuanzhou/SiD-LSG.\n","authors":["Mingyuan Zhou","Zhendong Wang","Huangjie Zheng","Hai Huang"],"pdf_url":"https://arxiv.org/pdf/2406.01561v3.pdf","comment":"Code and model checkpoints available at\n  https://github.com/mingyuanzhou/SiD-LSG"},{"id":"http://arxiv.org/abs/2404.02282v3","updated":"2024-08-08T15:25:44Z","published":"2024-04-02T20:15:43Z","title":"Smooth Deep Saliency","summary":"  In this work, we investigate methods to reduce the noise in deep saliency\nmaps coming from convolutional downsampling. Those methods make the\ninvestigated models more interpretable for gradient-based saliency maps,\ncomputed in hidden layers. We evaluate the faithfulness of those methods using\ninsertion and deletion metrics, finding that saliency maps computed in hidden\nlayers perform better compared to both the input layer and GradCAM. We test our\napproach on different models trained for image classification on ImageNet1K,\nand models trained for tumor detection on Camelyon16 and in-house real-world\ndigital pathology scans of stained tissue samples. Our results show that the\ncheckerboard noise in the gradient gets reduced, resulting in smoother and\ntherefore easier to interpret saliency maps.\n","authors":["Rudolf Herdt","Maximilian Schmidt","Daniel Otero Baguer","Peter Maaß"],"pdf_url":"https://arxiv.org/pdf/2404.02282v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04523v1","updated":"2024-08-08T15:24:07Z","published":"2024-08-08T15:24:07Z","title":"Depth Any Canopy: Leveraging Depth Foundation Models for Canopy Height\n  Estimation","summary":"  Estimating global tree canopy height is crucial for forest conservation and\nclimate change applications. However, capturing high-resolution ground truth\ncanopy height using LiDAR is expensive and not available globally. An efficient\nalternative is to train a canopy height estimator to operate on single-view\nremotely sensed imagery. The primary obstacle to this approach is that these\nmethods require significant training data to generalize well globally and\nacross uncommon edge cases. Recent monocular depth estimation foundation models\nhave show strong zero-shot performance even for complex scenes. In this paper\nwe leverage the representations learned by these models to transfer to the\nremote sensing domain for measuring canopy height. Our findings suggest that\nour proposed Depth Any Canopy, the result of fine-tuning the Depth Anything v2\nmodel for canopy height estimation, provides a performant and efficient\nsolution, surpassing the current state-of-the-art with superior or comparable\nperformance using only a fraction of the computational resources and\nparameters. Furthermore, our approach requires less than \\$1.30 in compute and\nresults in an estimated carbon footprint of 0.14 kgCO2. Code, experimental\nresults, and model checkpoints are openly available at\nhttps://github.com/DarthReca/depth-any-canopy.\n","authors":["Daniele Rege Cambrin","Isaac Corley","Paolo Garza"],"pdf_url":"https://arxiv.org/pdf/2408.04523v1.pdf","comment":"Accepted at ECCV 2024 CV4E Workshop"},{"id":"http://arxiv.org/abs/2408.04515v1","updated":"2024-08-08T15:15:48Z","published":"2024-08-08T15:15:48Z","title":"Saliency Detection in Educational Videos: Analyzing the Performance of\n  Current Models, Identifying Limitations and Advancement Directions","summary":"  Identifying the regions of a learning resource that a learner pays attention\nto is crucial for assessing the material's impact and improving its design and\nrelated support systems. Saliency detection in videos addresses the automatic\nrecognition of attention-drawing regions in single frames. In educational\nsettings, the recognition of pertinent regions in a video's visual stream can\nenhance content accessibility and information retrieval tasks such as video\nsegmentation, navigation, and summarization. Such advancements can pave the way\nfor the development of advanced AI-assisted technologies that support learning\nwith greater efficacy. However, this task becomes particularly challenging for\neducational videos due to the combination of unique characteristics such as\ntext, voice, illustrations, animations, and more. To the best of our knowledge,\nthere is currently no study that evaluates saliency detection approaches in\neducational videos. In this paper, we address this gap by evaluating four\nstate-of-the-art saliency detection approaches for educational videos. We\nreproduce the original studies and explore the replication capabilities for\ngeneral-purpose (non-educational) datasets. Then, we investigate the\ngeneralization capabilities of the models and evaluate their performance on\neducational videos. We conduct a comprehensive analysis to identify common\nfailure scenarios and possible areas of improvement. Our experimental results\nshow that educational videos remain a challenging context for generic video\nsaliency detection models.\n","authors":["Evelyn Navarrete","Ralph Ewerth","Anett Hoppe"],"pdf_url":"https://arxiv.org/pdf/2408.04515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16677v2","updated":"2024-08-08T15:02:13Z","published":"2024-03-25T12:14:48Z","title":"FOOL: Addressing the Downlink Bottleneck in Satellite Computing with\n  Neural Feature Compression","summary":"  Nanosatellite constellations equipped with sensors capturing large geographic\nregions provide unprecedented opportunities for Earth observation. As\nconstellation sizes increase, network contention poses a downlink bottleneck.\nOrbital Edge Computing (OEC) leverages limited onboard compute resources to\nreduce transfer costs by processing the raw captures at the source. However,\ncurrent solutions have limited practicability due to reliance on crude\nfiltering methods or over-prioritizing particular downstream tasks.\n  This work presents FOOL, an OEC-native and task-agnostic feature compression\nmethod that preserves prediction performance. FOOL partitions high-resolution\nsatellite imagery to maximize throughput. Further, it embeds context and\nleverages inter-tile dependencies to lower transfer costs with negligible\noverhead. While FOOL is a feature compressor, it can recover images with\ncompetitive scores on quality measures at lower bitrates. We extensively\nevaluate transfer cost reduction by including the peculiarity of intermittently\navailable network connections in low earth orbit. Lastly, we test the\nfeasibility of our system for standardized nanosatellite form factors. We\ndemonstrate that FOOL permits downlinking over 100x the data volume without\nrelying on prior information on the downstream tasks.\n","authors":["Alireza Furutanpey","Qiyang Zhang","Philipp Raith","Tobias Pfandzelter","Shangguang Wang","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2403.16677v2.pdf","comment":"18 pages, double column, 19 figures, 7 tables, Revision 1"},{"id":"http://arxiv.org/abs/2408.04491v1","updated":"2024-08-08T14:41:32Z","published":"2024-08-08T14:41:32Z","title":"Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver\n  Segmentation in MRIs","summary":"  Liver cirrhosis, a leading cause of global mortality, requires precise\nsegmentation of ROIs for effective disease monitoring and treatment planning.\nExisting segmentation models often fail to capture complex feature interactions\nand generalize across diverse datasets. To address these limitations, we\npropose a novel synergistic theory that leverages complementary latent spaces\nfor enhanced feature interaction modeling. Our proposed architecture,\nnnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes\nand features auto-configured training. This approach captures both fine-grained\nand coarse features, enabling effective modeling of intricate feature\ninteractions. We empirically validated nnSynergyNet3D on a private dataset of\n628 high-resolution T1 abdominal MRI scans from 339 patients. Our model\noutperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot\ntesting on healthy liver CT scans from the public LiTS dataset demonstrated\nsuperior cross-modal generalization capabilities. These results highlight the\npotential of synergistic latent space models to improve segmentation accuracy\nand robustness, thereby enhancing clinical workflows by ensuring consistency\nacross CT and MRI modalities.\n","authors":["Vandan Gorade","Onkar Susladkar","Gorkem Durak","Elif Keles","Ertugrul Aktas","Timurhan Cebeci","Alpay Medetalibeyoglu","Daniela Ladner","Debesh Jha","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2408.04491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06657v3","updated":"2024-08-08T14:34:52Z","published":"2023-03-12T13:13:05Z","title":"Color Mismatches in Stereoscopic Video: Real-World Dataset and Deep\n  Correction Method","summary":"  Stereoscopic videos can contain color mismatches between the left and right\nviews due to minor variations in camera settings, lenses, and even object\nreflections captured from different positions. The presence of color mismatches\ncan lead to viewer discomfort and headaches. This problem can be solved by\ntransferring color between stereoscopic views, but traditional methods often\nlack quality, while neural-network-based methods can easily overfit on\nartificial data. The scarcity of stereoscopic videos with real-world color\nmismatches hinders the evaluation of different methods' performance. Therefore,\nwe filmed a video dataset, which includes both distorted frames with color\nmismatches and ground-truth data, using a beam-splitter. Our second\ncontribution is a deep multiscale neural network that solves the\ncolor-mismatch-correction task by leveraging stereo correspondences. The\nexperimental results demonstrate the effectiveness of the proposed method on a\nconventional dataset, but there remains room for improvement on challenging\nreal-world data.\n","authors":["Egor Chistov","Nikita Alutis","Dmitriy Vatolin"],"pdf_url":"https://arxiv.org/pdf/2303.06657v3.pdf","comment":"The code and datasets are at\n  https://github.com/egorchistov/color-transfer/"},{"id":"http://arxiv.org/abs/2407.15787v2","updated":"2024-08-08T14:33:12Z","published":"2024-07-22T16:47:29Z","title":"Unsupervised Mastoidectomy for Cochlear CT Mesh Reconstruction Using\n  Highly Noisy Data","summary":"  Cochlear Implant (CI) procedures involve inserting an array of electrodes\ninto the cochlea located inside the inner ear. Mastoidectomy is a surgical\nprocedure that uses a high-speed drill to remove part of the mastoid region of\nthe temporal bone, providing safe access to the cochlea through the middle and\ninner ear. We aim to develop an intraoperative navigation system that registers\nplans created using 3D preoperative Computerized Tomography (CT) volumes with\nthe 2D surgical microscope view. Herein, we propose a method to synthesize the\nmastoidectomy volume using only the preoperative CT scan, where the mastoid is\nintact. We introduce an unsupervised learning framework designed to synthesize\nmastoidectomy. For model training purposes, this method uses postoperative CT\nscans to avoid manual data cleaning or labeling, even when the region removed\nduring mastoidectomy is visible but affected by metal artifacts, low\nsignal-to-noise ratio, or electrode wiring. Our approach estimates\nmastoidectomy regions with a mean dice score of 70.0%. This approach represents\na major step forward for CI intraoperative navigation by predicting realistic\nmastoidectomy-removed regions in preoperative planning that can be used to\nregister the pre-surgery plan to intraoperative microscopy.\n","authors":["Yike Zhang","Dingjie Su","Eduardo Davalos","Jack H. Noble"],"pdf_url":"https://arxiv.org/pdf/2407.15787v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12904v3","updated":"2024-08-08T14:21:35Z","published":"2023-10-19T16:57:49Z","title":"Unsupervised Object Localization in the Era of Self-Supervised ViTs: A\n  Survey","summary":"  The recent enthusiasm for open-world vision systems show the high interest of\nthe community to perform perception tasks outside of the closed-vocabulary\nbenchmark setups which have been so popular until now. Being able to discover\nobjects in images/videos without knowing in advance what objects populate the\ndataset is an exciting prospect. But how to find objects without knowing\nanything about them? Recent works show that it is possible to perform\nclass-agnostic unsupervised object localization by exploiting self-supervised\npre-trained features. We propose here a survey of unsupervised object\nlocalization methods that discover objects in images without requiring any\nmanual annotation in the era of self-supervised ViTs. We gather links of\ndiscussed methods in the repository\nhttps://github.com/valeoai/Awesome-Unsupervised-Object-Localization.\n","authors":["Oriane Siméoni","Éloi Zablocki","Spyros Gidaris","Gilles Puy","Patrick Pérez"],"pdf_url":"https://arxiv.org/pdf/2310.12904v3.pdf","comment":"IJCV 2024"},{"id":"http://arxiv.org/abs/2408.04482v1","updated":"2024-08-08T14:19:11Z","published":"2024-08-08T14:19:11Z","title":"SegXAL: Explainable Active Learning for Semantic Segmentation in Driving\n  Scene Scenarios","summary":"  Most of the sophisticated AI models utilize huge amounts of annotated data\nand heavy training to achieve high-end performance. However, there are certain\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\ni.e., inefficient use of unlabeled data, lack of incorporation of human\nexpertise, and lack of interpretation of the results. To mitigate these\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\nand (iii) augment the model decisions in an interpretable way. In particular,\nwe investigate the application of the SegXAL model for semantic segmentation in\ndriving scene scenarios. The SegXAL model proposes the image regions that\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\n(EBU) module to get an Explainable Error Mask, which enables the machine\nteachers/human experts to provide intuitive reasoning behind the results and to\nsolicit feedback to the AI system via an active learning strategy. Such a\nmechanism bridges the semantic gap between man and machine through\ncollaborative intelligence, where humans and AI actively enhance each other's\ncomplementary strengths. A novel high-confidence sample selection technique\nbased on the DICE similarity coefficient is also presented within the SegXAL\nframework. Extensive quantitative and qualitative analyses are carried out in\nthe benchmarking Cityscape dataset. Results show the outperformance of our\nproposed SegXAL against other state-of-the-art models.\n","authors":["Sriram Mandalika","Athira Nambiar"],"pdf_url":"https://arxiv.org/pdf/2408.04482v1.pdf","comment":"17 pages, 7 figures. To appear in the proceedings of the 27th\n  International Conference on Pattern Recognition (ICPR), 01-05 December, 2024,\n  Kolkata, India"},{"id":"http://arxiv.org/abs/2408.04471v1","updated":"2024-08-08T14:01:12Z","published":"2024-08-08T14:01:12Z","title":"What could go wrong? Discovering and describing failure modes in\n  computer vision","summary":"  Deep learning models are effective, yet brittle. Even carefully trained,\ntheir behavior tends to be hard to predict when confronted with\nout-of-distribution samples. In this work, our goal is to propose a simple yet\neffective solution to predict and describe via natural language potential\nfailure modes of computer vision models. Given a pretrained model and a set of\nsamples, our aim is to find sentences that accurately describe the visual\nconditions in which the model underperforms. In order to study this important\ntopic and foster future research on it, we formalize the problem of\nLanguage-Based Error Explainability (LBEE) and propose a set of metrics to\nevaluate and compare different methods for this task. We propose solutions that\noperate in a joint vision-and-language embedding space, and can characterize\nthrough language descriptions model failures caused, e.g., by objects unseen\nduring training or adverse visual conditions. We experiment with different\ntasks, such as classification under the presence of dataset bias and semantic\nsegmentation in unseen environments, and show that the proposed methodology\nisolates nontrivial sentences associated with specific error causes. We hope\nour work will help practitioners better understand the behavior of models,\nincreasing their overall safety and interpretability.\n","authors":["Gabriela Csurka","Tyler L. Hayes","Diane Larlus","Riccardo Volpi"],"pdf_url":"https://arxiv.org/pdf/2408.04471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07128v2","updated":"2024-08-08T13:58:51Z","published":"2023-12-12T10:04:11Z","title":"MS-Twins: Multi-Scale Deep Self-Attention Networks for Medical Image\n  Segmentation","summary":"  Chest X-ray is one of the most common radiological examination types for the\ndiagnosis of chest diseases. Nowadays, the automatic classification technology\nof radiological images has been widely used in clinical diagnosis and treatment\nplans. However, each disease has its own different response characteristic\nreceptive field region, which is the main challenge for chest disease\nclassification tasks. Besides, the imbalance of sample data categories further\nincreases the difficulty of tasks. To solve these problems, we propose a new\nmulti-label chest disease image classification scheme based on a multi-scale\nattention network. In this scheme, multi-scale information is iteratively fused\nto focus on regions with a high probability of disease, to effectively mine\nmore meaningful information from data, and the classification performance can\nbe improved only by image level annotation. We also designed a new loss\nfunction to improve the rationality of visual perception and the performance of\nmulti-label image classification by forcing the consistency of attention\nregions before and after image transformation. A comprehensive experiment was\ncarried out on the public Chest X-Ray14 and CheXpert datasets to achieve state\nof the art results, which verified the effectiveness of this method in chest\nX-ray image classification.\n","authors":["Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2312.07128v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12539v3","updated":"2024-08-08T13:57:35Z","published":"2023-11-21T11:33:15Z","title":"GMISeg: General Medical Image Segmentation without Re-Training","summary":"  The online shopping behavior has the characteristics of rich granularity\ndimension and data sparsity and previous researches on user behavior prediction\ndid not seriously discuss feature selection and ensemble design. In this paper,\nwe proposed a SE-Stacking model based on information fusion and ensemble\nlearning for user purchase behavior prediction. After successfully utilizing\nthe ensemble feature selection method to screen purchase-related factors, we\nused the Stacking algorithm for user purchase behavior prediction. In our\nefforts to avoid the deviation of prediction results, we optimized the model by\nselecting ten different kinds of models as base learners and modifying relevant\nparameters specifically for them. The experiments conducted on a\npublicly-available dataset shows that the SE-Stacking model can achieve a\n98.40% F1-score, about 0.09% higher than the optimal base models. The\nSE-Stacking model not only has a good application in the prediction of user\npurchase behavior but also has practical value combining with the actual\ne-commerce scene. At the same time, it has important significance for academic\nresearch and the development of this field.\n","authors":["Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2311.12539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12487v2","updated":"2024-08-08T13:40:06Z","published":"2024-05-21T04:10:26Z","title":"3DSS-Mamba: 3D-Spectral-Spatial Mamba for Hyperspectral Image\n  Classification","summary":"  Hyperspectral image (HSI) classification constitutes the fundamental research\nin remote sensing fields. Convolutional Neural Networks (CNNs) and Transformers\nhave demonstrated impressive capability in capturing spectral-spatial\ncontextual dependencies. However, these architectures suffer from limited\nreceptive fields and quadratic computational complexity, respectively.\nFortunately, recent Mamba architectures built upon the State Space Model\nintegrate the advantages of long-range sequence modeling and linear\ncomputational efficiency, exhibiting substantial potential in low-dimensional\nscenarios. Motivated by this, we propose a novel 3D-Spectral-Spatial Mamba\n(3DSS-Mamba) framework for HSI classification, allowing for global\nspectral-spatial relationship modeling with greater computational efficiency.\nTechnically, a spectral-spatial token generation (SSTG) module is designed to\nconvert the HSI cube into a set of 3D spectral-spatial tokens. To overcome the\nlimitations of traditional Mamba, which is confined to modeling causal\nsequences and inadaptable to high-dimensional scenarios, a 3D-Spectral-Spatial\nSelective Scanning (3DSS) mechanism is introduced, which performs pixel-wise\nselective scanning on 3D hyperspectral tokens along the spectral and spatial\ndimensions. Five scanning routes are constructed to investigate the impact of\ndimension prioritization. The 3DSS scanning mechanism combined with\nconventional mapping operations forms the 3D-spectral-spatial mamba block\n(3DMB), enabling the extraction of global spectral-spatial semantic\nrepresentations. Experimental results and analysis demonstrate that the\nproposed method outperforms the state-of-the-art methods on HSI classification\nbenchmarks.\n","authors":["Yan He","Bing Tu","Bo Liu","Jun Li","Antonio Plaza"],"pdf_url":"https://arxiv.org/pdf/2405.12487v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03166v4","updated":"2024-08-08T13:32:21Z","published":"2024-02-05T16:35:29Z","title":"RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein\n  Segmentation and Classification","summary":"  The caliber and configuration of retinal blood vessels serve as important\nbiomarkers for various diseases and medical conditions. A thorough analysis of\nthe retinal vasculature requires the segmentation of the blood vessels and\ntheir classification into arteries and veins, typically performed on color\nfundus images obtained by retinography. However, manually performing these\ntasks is labor-intensive and prone to human error. While several automated\nmethods have been proposed to address this task, the current state of art faces\nchallenges due to manifest classification errors affecting the topological\nconsistency of segmentation maps. In this work, we introduce RRWNet, a novel\nend-to-end deep learning framework that addresses this limitation. The\nframework consists of a fully convolutional neural network that recursively\nrefines semantic segmentation maps, correcting manifest classification errors\nand thus improving topological consistency. In particular, RRWNet is composed\nof two specialized subnetworks: a Base subnetwork that generates base\nsegmentation maps from the input images, and a Recursive Refinement subnetwork\nthat iteratively and recursively improves these maps. Evaluation on three\ndifferent public datasets demonstrates the state-of-the-art performance of the\nproposed method, yielding more topologically consistent segmentation maps with\nfewer manifest classification errors than existing approaches. In addition, the\nRecursive Refinement module within RRWNet proves effective in post-processing\nsegmentation maps from other methods, further demonstrating its potential. The\nmodel code, weights, and predictions will be publicly available at\nhttps://github.com/j-morano/rrwnet.\n","authors":["José Morano","Guilherme Aresta","Hrvoje Bogunović"],"pdf_url":"https://arxiv.org/pdf/2402.03166v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04439v1","updated":"2024-08-08T13:10:03Z","published":"2024-08-08T13:10:03Z","title":"Deep Learning for identifying systolic complexes in SCG traces: a\n  cross-dataset analysis","summary":"  The seismocardiographic signal is a promising alternative to the traditional\nECG in the analysis of the cardiac activity. In particular, the systolic\ncomplex is known to be the most informative part of the seismocardiogram, thus\nrequiring further analysis. State-of-art solutions to detect the systolic\ncomplex are based on Deep Learning models, which have been proven effective in\npioneering studies. However, these solutions have only been tested in a\ncontrolled scenario considering only clean signals acquired from users\nmaintained still in supine position. On top of that, all these studies consider\ndata coming from a single dataset, ignoring the benefits and challenges related\nto a cross-dataset scenario. In this work, a cross-dataset experimental\nanalysis was performed considering also data from a real-world scenario. Our\nfindings prove the effectiveness of a deep learning solution, while showing the\nimportance of a personalization step to contrast the domain shift, namely a\nchange in data distribution between training and testing data. Finally, we\ndemonstrate the benefits of a multi-channels approach, leveraging the\ninformation extracted from both accelerometers and gyroscopes data.\n","authors":["Michele Craighero","Sarah Solbiati","Federica Mozzini","Enrico Caiani","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2408.04439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04426v1","updated":"2024-08-08T12:51:23Z","published":"2024-08-08T12:51:23Z","title":"A Review of 3D Reconstruction Techniques for Deformable Tissues in\n  Robotic Surgery","summary":"  As a crucial and intricate task in robotic minimally invasive surgery,\nreconstructing surgical scenes using stereo or monocular endoscopic video holds\nimmense potential for clinical applications. NeRF-based techniques have\nrecently garnered attention for the ability to reconstruct scenes implicitly.\nOn the other hand, Gaussian splatting-based 3D-GS represents scenes explicitly\nusing 3D Gaussians and projects them onto a 2D plane as a replacement for the\ncomplex volume rendering in NeRF. However, these methods face challenges\nregarding surgical scene reconstruction, such as slow inference, dynamic\nscenes, and surgical tool occlusion. This work explores and reviews\nstate-of-the-art (SOTA) approaches, discussing their innovations and\nimplementation principles. Furthermore, we replicate the models and conduct\ntesting and evaluation on two datasets. The test results demonstrate that with\nadvancements in these techniques, achieving real-time, high-quality\nreconstructions becomes feasible.\n","authors":["Mengya Xu","Ziqi Guo","An Wang","Long Bai","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2408.04426v1.pdf","comment":"To appear in MICCAI 2024 EARTH Workshop. Code availability:\n  https://github.com/Epsilon404/surgicalnerf"},{"id":"http://arxiv.org/abs/2406.18284v2","updated":"2024-08-08T12:18:30Z","published":"2024-06-26T12:09:59Z","title":"RealTalk: Real-time and Realistic Audio-driven Face Generation with 3D\n  Facial Prior-guided Identity Alignment Network","summary":"  Person-generic audio-driven face generation is a challenging task in computer\nvision. Previous methods have achieved remarkable progress in audio-visual\nsynchronization, but there is still a significant gap between current results\nand practical applications. The challenges are two-fold: 1) Preserving unique\nindividual traits for achieving high-precision lip synchronization. 2)\nGenerating high-quality facial renderings in real-time performance. In this\npaper, we propose a novel generalized audio-driven framework RealTalk, which\nconsists of an audio-to-expression transformer and a high-fidelity\nexpression-to-face renderer. In the first component, we consider both identity\nand intra-personal variation features related to speaking lip movements. By\nincorporating cross-modal attention on the enriched facial priors, we can\neffectively align lip movements with audio, thus attaining greater precision in\nexpression prediction. In the second component, we design a lightweight facial\nidentity alignment (FIA) module which includes a lip-shape control structure\nand a face texture reference structure. This novel design allows us to generate\nfine details in real-time, without depending on sophisticated and inefficient\nfeature alignment modules. Our experimental results, both quantitative and\nqualitative, on public datasets demonstrate the clear advantages of our method\nin terms of lip-speech synchronization and generation quality. Furthermore, our\nmethod is efficient and requires fewer computational resources, making it\nwell-suited to meet the needs of practical applications.\n","authors":["Xiaozhong Ji","Chuming Lin","Zhonggan Ding","Ying Tai","Junwei Zhu","Xiaobin Hu","Donghao Luo","Yanhao Ge","Chengjie Wang"],"pdf_url":"https://arxiv.org/pdf/2406.18284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04407v1","updated":"2024-08-08T12:16:14Z","published":"2024-08-08T12:16:14Z","title":"Clutter Classification Using Deep Learning in Multiple Stages","summary":"  Path loss prediction for wireless communications is highly dependent on the\nlocal environment. Propagation models including clutter information have been\nshown to significantly increase model accuracy. This paper explores the\napplication of deep learning to satellite imagery to identify environmental\nclutter types automatically. Recognizing these clutter types has numerous uses,\nbut our main application is to use clutter information to enhance propagation\nprediction models. Knowing the type of obstruction (tree, building, and further\nclassifications) can improve the prediction accuracy of key propagation metrics\nsuch as path loss.\n","authors":["Ryan Dempsey","Jonathan Ethier"],"pdf_url":"https://arxiv.org/pdf/2408.04407v1.pdf","comment":"SoutheastCon 2024"},{"id":"http://arxiv.org/abs/2403.08214v2","updated":"2024-08-08T11:51:15Z","published":"2024-03-13T03:23:50Z","title":"P2LHAP:Wearable sensor-based human activity recognition, segmentation\n  and forecast through Patch-to-Label Seq2Seq Transformer","summary":"  Traditional deep learning methods struggle to simultaneously segment,\nrecognize, and forecast human activities from sensor data. This limits their\nusefulness in many fields such as healthcare and assisted living, where\nreal-time understanding of ongoing and upcoming activities is crucial. This\npaper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles\nall three tasks in a efficient single-task model. P2LHAP divides sensor data\nstreams into a sequence of \"patches\", served as input tokens, and outputs a\nsequence of patch-level activity labels including the predicted future\nactivities. A unique smoothing technique based on surrounding patch labels, is\nproposed to identify activity boundaries accurately. Additionally, P2LHAP\nlearns patch-level representation by sensor signal channel-independent\nTransformer encoders and decoders. All channels share embedding and Transformer\nweights across all sequences. Evaluated on three public datasets, P2LHAP\nsignificantly outperforms the state-of-the-art in all three tasks,\ndemonstrating its effectiveness and potential for real-world applications.\n","authors":["Shuangjian Li","Tao Zhu","Mingxing Nie","Huansheng Ning","Zhenyu Liu","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2403.08214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09630v2","updated":"2024-08-08T11:38:21Z","published":"2024-03-14T17:58:33Z","title":"GenAD: Generalized Predictive Model for Autonomous Driving","summary":"  In this paper, we introduce the first large-scale video prediction model in\nthe autonomous driving discipline. To eliminate the restriction of high-cost\ndata collection and empower the generalization ability of our model, we acquire\nmassive data from the web and pair it with diverse and high-quality text\ndescriptions. The resultant dataset accumulates over 2000 hours of driving\nvideos, spanning areas all over the world with diverse weather conditions and\ntraffic scenarios. Inheriting the merits from recent latent diffusion models,\nour model, dubbed GenAD, handles the challenging dynamics in driving scenes\nwith novel temporal reasoning blocks. We showcase that it can generalize to\nvarious unseen driving datasets in a zero-shot manner, surpassing general or\ndriving-specific video prediction counterparts. Furthermore, GenAD can be\nadapted into an action-conditioned prediction model or a motion planner,\nholding great potential for real-world driving applications.\n","authors":["Jiazhi Yang","Shenyuan Gao","Yihang Qiu","Li Chen","Tianyu Li","Bo Dai","Kashyap Chitta","Penghao Wu","Jia Zeng","Ping Luo","Jun Zhang","Andreas Geiger","Yu Qiao","Hongyang Li"],"pdf_url":"https://arxiv.org/pdf/2403.09630v2.pdf","comment":"CVPR 2024 Highlight Paper. Dataset:\n  https://github.com/OpenDriveLab/DriveAGI"},{"id":"http://arxiv.org/abs/2408.01669v3","updated":"2024-08-08T11:19:37Z","published":"2024-08-03T05:35:13Z","title":"SynopGround: A Large-Scale Dataset for Multi-Paragraph Video Grounding\n  from TV Dramas and Synopses","summary":"  Video grounding is a fundamental problem in multimodal content understanding,\naiming to localize specific natural language queries in an untrimmed video.\nHowever, current video grounding datasets merely focus on simple events and are\neither limited to shorter videos or brief sentences, which hinders the model\nfrom evolving toward stronger multimodal understanding capabilities. To address\nthese limitations, we present a large-scale video grounding dataset named\nSynopGround, in which more than 2800 hours of videos are sourced from popular\nTV dramas and are paired with accurately localized human-written synopses. Each\nparagraph in the synopsis serves as a language query and is manually annotated\nwith precise temporal boundaries in the long video. These paragraph queries are\ntightly correlated to each other and contain a wealth of abstract expressions\nsummarizing video storylines and specific descriptions portraying event\ndetails, which enables the model to learn multimodal perception on more\nintricate concepts over longer context dependencies. Based on the dataset, we\nfurther introduce a more complex setting of video grounding dubbed\nMulti-Paragraph Video Grounding (MPVG), which takes as input multiple\nparagraphs and a long video for grounding each paragraph query to its temporal\ninterval. In addition, we propose a novel Local-Global Multimodal Reasoner\n(LGMR) to explicitly model the local-global structures of long-term multimodal\ninputs for MPVG. Our method provides an effective baseline solution to the\nmulti-paragraph video grounding problem. Extensive experiments verify the\nproposed model's effectiveness as well as its superiority in long-term\nmulti-paragraph video grounding over prior state-of-the-arts. Dataset and code\nare publicly available. Project page: https://synopground.github.io/.\n","authors":["Chaolei Tan","Zihang Lin","Junfu Pu","Zhongang Qi","Wei-Yi Pei","Zhi Qu","Yexin Wang","Ying Shan","Wei-Shi Zheng","Jian-Fang Hu"],"pdf_url":"https://arxiv.org/pdf/2408.01669v3.pdf","comment":"Accepted to ACM MM 2024. Project page: https://synopground.github.io/"},{"id":"http://arxiv.org/abs/2408.04367v1","updated":"2024-08-08T10:55:55Z","published":"2024-08-08T10:55:55Z","title":"MultiViPerFrOG: A Globally Optimized Multi-Viewpoint Perception\n  Framework for Camera Motion and Tissue Deformation","summary":"  Reconstructing the 3D shape of a deformable environment from the information\ncaptured by a moving depth camera is highly relevant to surgery. The underlying\nchallenge is the fact that simultaneously estimating camera motion and tissue\ndeformation in a fully deformable scene is an ill-posed problem, especially\nfrom a single arbitrarily moving viewpoint. Current solutions are often\norgan-specific and lack the robustness required to handle large deformations.\nHere we propose a multi-viewpoint global optimization framework that can\nflexibly integrate the output of low-level perception modules (data\nassociation, depth, and relative scene flow) with kinematic and scene-modeling\npriors to jointly estimate multiple camera motions and absolute scene flow. We\nuse simulated noisy data to show three practical examples that successfully\nconstrain the convergence to a unique solution. Overall, our method shows\nrobustness to combined noisy input measures and can process hundreds of points\nin a few milliseconds. MultiViPerFrOG builds a generalized learning-free\nscaffolding for spatio-temporal encoding that can unlock advanced surgical\nscene representations and will facilitate the development of the\ncomputer-assisted-surgery technologies of the future.\n","authors":["Guido Caccianiga","Julian Nubert","Cesar Cadena","Marco Hutter","Katherine J. Kuchenbecker"],"pdf_url":"https://arxiv.org/pdf/2408.04367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04360v1","updated":"2024-08-08T10:47:02Z","published":"2024-08-08T10:47:02Z","title":"Detecting Car Speed using Object Detection and Depth Estimation: A Deep\n  Learning Framework","summary":"  Road accidents are quite common in almost every part of the world, and, in\nmajority, fatal accidents are attributed to over speeding of vehicles. The\ntendency to over speeding is usually tried to be controlled using check points\nat various parts of the road but not all traffic police have the device to\ncheck speed with existing speed estimating devices such as LIDAR based, or\nRadar based guns. The current project tries to address the issue of vehicle\nspeed estimation with handheld devices such as mobile phones or wearable\ncameras with network connection to estimate the speed using deep learning\nframeworks.\n","authors":["Subhasis Dasgupta","Arshi Naaz","Jayeeta Choudhury","Nancy Lahiri"],"pdf_url":"https://arxiv.org/pdf/2408.04360v1.pdf","comment":"This is the pre-print of the paper which was accepted for oral\n  presentation and publication in the proceedings of IEEE CONIT 2024, organized\n  at Pune from June 21 to 23, 2024. The paper is 6 pages long and it contains\n  11 figures and 1 table. This is not the final version of the paper"},{"id":"http://arxiv.org/abs/2408.04347v1","updated":"2024-08-08T10:16:02Z","published":"2024-08-08T10:16:02Z","title":"AggSS: An Aggregated Self-Supervised Approach for Class-Incremental\n  Learning","summary":"  This paper investigates the impact of self-supervised learning, specifically\nimage rotations, on various class-incremental learning paradigms. Here, each\nimage with a predefined rotation is considered as a new class for training. At\ninference, all image rotation predictions are aggregated for the final\nprediction, a strategy we term Aggregated Self-Supervision (AggSS). We observe\na shift in the deep neural network's attention towards intrinsic object\nfeatures as it learns through AggSS strategy. This learning approach\nsignificantly enhances class-incremental learning by promoting robust feature\nlearning. AggSS serves as a plug-and-play module that can be seamlessly\nincorporated into any class-incremental learning framework, leveraging its\npowerful feature learning capabilities to enhance performance across various\nclass-incremental learning approaches. Extensive experiments conducted on\nstandard incremental learning datasets CIFAR-100 and ImageNet-Subset\ndemonstrate the significant role of AggSS in improving performance within these\nparadigms.\n","authors":["Jayateja Kalla","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2408.04347v1.pdf","comment":"Accepted in BMVC 2024"},{"id":"http://arxiv.org/abs/2407.06704v2","updated":"2024-08-08T09:41:40Z","published":"2024-07-09T09:31:15Z","title":"Self-supervised visual learning from interactions with objects","summary":"  Self-supervised learning (SSL) has revolutionized visual representation\nlearning, but has not achieved the robustness of human vision. A reason for\nthis could be that SSL does not leverage all the data available to humans\nduring learning. When learning about an object, humans often purposefully turn\nor move around objects and research suggests that these interactions can\nsubstantially enhance their learning. Here we explore whether such\nobject-related actions can boost SSL. For this, we extract the actions\nperformed to change from one ego-centric view of an object to another in four\nvideo datasets. We then introduce a new loss function to learn visual and\naction embeddings by aligning the performed action with the representations of\ntwo images extracted from the same clip. This permits the performed actions to\nstructure the latent visual representation. Our experiments show that our\nmethod consistently outperforms previous methods on downstream category\nrecognition. In our analysis, we find that the observed improvement is\nassociated with a better viewpoint-wise alignment of different objects from the\nsame category. Overall, our work demonstrates that embodied interactions with\nobjects can improve SSL of object categories.\n","authors":["Arthur Aubret","Céline Teulière","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2407.06704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.08995v2","updated":"2024-08-08T09:40:29Z","published":"2023-03-15T23:59:18Z","title":"Fast and Accurate Object Detection on Asymmetrical Receptive Field","summary":"  Object detection has been used in a wide range of industries. For example, in\nautonomous driving, the task of object detection is to accurately and\nefficiently identify and locate a large number of predefined classes of object\ninstances (vehicles, pedestrians, traffic signs, etc.) from videos of roads. In\nrobotics, the industry robot needs to recognize specific machine elements. In\nthe security field, the camera should accurately recognize each face of people.\nWith the wide application of deep learning, the accuracy and efficiency of\nobject detection have been greatly improved, but object detection based on deep\nlearning still faces challenges. Different applications of object detection\nhave different requirements, including highly accurate detection,\nmulti-category object detection, real-time detection, robustness to occlusions,\netc. To address the above challenges, based on extensive literature research,\nthis paper analyzes methods for improving and optimizing mainstream object\ndetection algorithms from the perspective of evolution of one-stage and\ntwo-stage object detection algorithms. Furthermore, this article proposes\nmethods for improving object detection accuracy from the perspective of\nchanging receptive fields. The new model is based on the original YOLOv5 (You\nLook Only Once) with some modifications. The structure of the head part of\nYOLOv5 is modified by adding asymmetrical pooling layers. As a result, the\naccuracy of the algorithm is improved while ensuring the speed. The\nperformances of the new model in this article are compared with original YOLOv5\nmodel and analyzed from several parameters. And the evaluation of the new model\nis presented in four situations. Moreover, the summary and outlooks are made on\nthe problems to be solved and the research directions in the future.\n","authors":["Tianhao Lin"],"pdf_url":"https://arxiv.org/pdf/2303.08995v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20183v3","updated":"2024-08-08T09:40:10Z","published":"2024-03-29T13:57:46Z","title":"HARMamba: Efficient and Lightweight Wearable Sensor Human Activity\n  Recognition Based on Bidirectional Mamba","summary":"  Wearable sensor-based human activity recognition (HAR) is a critical research\ndomain in activity perception. However, achieving high efficiency and long\nsequence recognition remains a challenge. Despite the extensive investigation\nof temporal deep learning models, such as CNNs, RNNs, and transformers, their\nextensive parameters often pose significant computational and memory\nconstraints, rendering them less suitable for resource-constrained mobile\nhealth applications. This study introduces HARMamba, an innovative light-weight\nand versatile HAR architecture that combines selective bidirectional State\nSpaces Model and hardware-aware design. To optimize real-time resource\nconsumption in practical scenarios, HARMamba employs linear recursive\nmechanisms and parameter discretization, allowing it to selectively focus on\nrelevant input sequences while efficiently fusing scan and recompute\noperations. The model employs independent channels to process sensor data\nstreams, dividing each channel into patches and appending classification tokens\nto the end of the sequence. It utilizes position embedding to represent the\nsequence order. The patch sequence is subsequently processed by HARMamba Block,\nand the classification head finally outputs the activity category. The HARMamba\nBlock serves as the fundamental component of the HARMamba architecture,\nenabling the effective capture of more discriminative activity sequence\nfeatures. HARMamba outperforms contemporary state-of-the-art frameworks,\ndelivering comparable or better accuracy with significantly reducing\ncomputational and memory demands. It's effectiveness has been extensively\nvalidated on 4 publically available datasets namely PAMAP2, WISDM, UNIMIB SHAR\nand UCI. The F1 scores of HARMamba on the four datasets are 99.74%, 99.20%,\n88.23% and 97.01%, respectively.\n","authors":["Shuangjian Li","Tao Zhu","Furong Duan","Liming Chen","Huansheng Ning","Christopher Nugent","Yaping Wan"],"pdf_url":"https://arxiv.org/pdf/2403.20183v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04331v1","updated":"2024-08-08T09:31:24Z","published":"2024-08-08T09:31:24Z","title":"Enhancing Journalism with AI: A Study of Contextualized Image Captioning\n  for News Articles using LLMs and LMMs","summary":"  Large language models (LLMs) and large multimodal models (LMMs) have\nsignificantly impacted the AI community, industry, and various economic\nsectors. In journalism, integrating AI poses unique challenges and\nopportunities, particularly in enhancing the quality and efficiency of news\nreporting. This study explores how LLMs and LMMs can assist journalistic\npractice by generating contextualised captions for images accompanying news\narticles. We conducted experiments using the GoodNews dataset to evaluate the\nability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of\ncontext: entire news articles, or extracted named entities. In addition, we\ncompared their performance to a two-stage pipeline composed of a captioning\nmodel (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs\n(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the\nchoice of contextualisation model is a significant factor for the two-stage\npipelines, this is not the case in the LMMs, where smaller, open-source models\nperform well compared to proprietary, GPT-powered ones. Additionally, we found\nthat controlling the amount of provided context enhances performance. These\nresults highlight the limitations of a fully automated approach and underscore\nthe necessity for an interactive, human-in-the-loop strategy.\n","authors":["Aliki Anagnostopoulou","Thiago Gouvea","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2408.04331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08389v3","updated":"2024-08-08T09:28:22Z","published":"2023-05-15T07:12:19Z","title":"Edit As You Wish: Video Caption Editing with Multi-grained User Control","summary":"  Automatically narrating videos in natural language complying with user\nrequests, i.e. Controllable Video Captioning task, can help people manage\nmassive videos with desired intentions. However, existing works suffer from two\nshortcomings: 1) the control signal is single-grained which can not satisfy\ndiverse user intentions; 2) the video description is generated in a single\nround which can not be further edited to meet dynamic needs. In this paper, we\npropose a novel \\textbf{V}ideo \\textbf{C}aption \\textbf{E}diting \\textbf{(VCE)}\ntask to automatically revise an existing video description guided by\nmulti-grained user requests. Inspired by human writing-revision habits, we\ndesign the user command as a pivotal triplet \\{\\textit{operation, position,\nattribute}\\} to cover diverse user needs from coarse-grained to fine-grained.\nTo facilitate the VCE task, we \\textit{automatically} construct an open-domain\nbenchmark dataset named VATEX-EDIT and \\textit{manually} collect an e-commerce\ndataset called EMMAD-EDIT. We further propose a specialized small-scale model\n(i.e., OPA) compared with two generalist Large Multi-modal Models to perform an\nexhaustive analysis of the novel task. For evaluation, we adopt comprehensive\nmetrics considering caption fluency, command-caption consistency, and\nvideo-caption alignment. Experiments reveal the task challenges of fine-grained\nmulti-modal semantics understanding and processing. Our datasets, codes, and\nevaluation tools are available at https://github.com/yaolinli/VCE.\n","authors":["Linli Yao","Yuanmeng Zhang","Ziheng Wang","Xinglin Hou","Tiezheng Ge","Yuning Jiang","Xu Sun","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2305.08389v3.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2408.04326v1","updated":"2024-08-08T09:09:37Z","published":"2024-08-08T09:09:37Z","title":"Multi-Scale and Detail-Enhanced Segment Anything Model for Salient\n  Object Detection","summary":"  Salient Object Detection (SOD) aims to identify and segment the most\nprominent objects in images. Advanced SOD methods often utilize various\nConvolutional Neural Networks (CNN) or Transformers for deep feature\nextraction. However, these methods still deliver low performance and poor\ngeneralization in complex cases. Recently, Segment Anything Model (SAM) has\nbeen proposed as a visual fundamental model, which gives strong segmentation\nand generalization capabilities. Nonetheless, SAM requires accurate prompts of\ntarget objects, which are unavailable in SOD. Additionally, SAM lacks the\nutilization of multi-scale and multi-level information, as well as the\nincorporation of fine-grained details. To address these shortcomings, we\npropose a Multi-scale and Detail-enhanced SAM (MDSAM) for SOD. Specifically, we\nfirst introduce a Lightweight Multi-Scale Adapter (LMSA), which allows SAM to\nlearn multi-scale information with very few trainable parameters. Then, we\npropose a Multi-Level Fusion Module (MLFM) to comprehensively utilize the\nmulti-level information from the SAM's encoder. Finally, we propose a Detail\nEnhancement Module (DEM) to incorporate SAM with fine-grained details.\nExperimental results demonstrate the superior performance of our model on\nmultiple SOD datasets and its strong generalization on other segmentation\ntasks. The source code is released at https://github.com/BellyBeauty/MDSAM.\n","authors":["Shixuan Gao","Pingping Zhang","Tianyu Yan","Huchuan Lu"],"pdf_url":"https://arxiv.org/pdf/2408.04326v1.pdf","comment":"This work is accepted by ACM MM2024"},{"id":"http://arxiv.org/abs/2408.04318v1","updated":"2024-08-08T08:52:29Z","published":"2024-08-08T08:52:29Z","title":"Deep Transfer Learning for Kidney Cancer Diagnosis","summary":"  Many incurable diseases prevalent across global societies stem from various\ninfluences, including lifestyle choices, economic conditions, social factors,\nand genetics. Research predominantly focuses on these diseases due to their\nwidespread nature, aiming to decrease mortality, enhance treatment options, and\nimprove healthcare standards. Among these, kidney disease stands out as a\nparticularly severe condition affecting men and women worldwide. Nonetheless,\nthere is a pressing need for continued research into innovative, early\ndiagnostic methods to develop more effective treatments for such diseases.\nRecently, automatic diagnosis of Kidney Cancer has become an important\nchallenge especially when using deep learning (DL) due to the importance of\ntraining medical datasets, which in most cases are difficult and expensive to\nobtain. Furthermore, in most cases, algorithms require data from the same\ndomain and a powerful computer with efficient storage capacity. To overcome\nthis issue, a new type of learning known as transfer learning (TL) has been\nproposed that can produce impressive results based on other different\npre-trained data. This paper presents, to the best of the authors' knowledge,\nthe first comprehensive survey of DL-based TL frameworks for kidney cancer\ndiagnosis. This is a strong contribution to help researchers understand the\ncurrent challenges and perspectives of this topic. Hence, the main limitations\nand advantages of each framework are identified and detailed critical analyses\nare provided. Looking ahead, the article identifies promising directions for\nfuture research. Moving on, the discussion is concluded by reflecting on the\npivotal role of TL in the development of precision medicine and its effects on\nclinical practice and research in oncology.\n","authors":["Yassine Habchi","Hamza Kheddar","Yassine Himeur","Abdelkrim Boukabou","Shadi Atalla","Wathiq Mansoor","Hussain Al-Ahmad"],"pdf_url":"https://arxiv.org/pdf/2408.04318v1.pdf","comment":"32 pages, 8 figures and 8 tables"},{"id":"http://arxiv.org/abs/2403.11868v7","updated":"2024-08-08T08:45:08Z","published":"2024-03-18T15:22:09Z","title":"View-Consistent 3D Editing with Gaussian Splatting","summary":"  The advent of 3D Gaussian Splatting (3DGS) has revolutionized 3D editing,\noffering efficient, high-fidelity rendering and enabling precise local\nmanipulations. Currently, diffusion-based 2D editing models are harnessed to\nmodify multi-view rendered images, which then guide the editing of 3DGS models.\nHowever, this approach faces a critical issue of multi-view inconsistency,\nwhere the guidance images exhibit significant discrepancies across views,\nleading to mode collapse and visual artifacts of 3DGS. To this end, we\nintroduce View-consistent Editing (VcEdit), a novel framework that seamlessly\nincorporates 3DGS into image editing processes, ensuring multi-view consistency\nin edited guidance images and effectively mitigating mode collapse issues.\nVcEdit employs two innovative consistency modules: the Cross-attention\nConsistency Module and the Editing Consistency Module, both designed to reduce\ninconsistencies in edited images. By incorporating these consistency modules\ninto an iterative pattern, VcEdit proficiently resolves the issue of multi-view\ninconsistency, facilitating high-quality 3DGS editing across a diverse range of\nscenes. Further video results are shown in http://vcedit.github.io.\n","authors":["Yuxuan Wang","Xuanyu Yi","Zike Wu","Na Zhao","Long Chen","Hanwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.11868v7.pdf","comment":"accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2407.11652v6","updated":"2024-08-08T08:44:29Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v6.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2401.10110v4","updated":"2024-08-08T08:42:31Z","published":"2024-01-18T16:27:09Z","title":"SVIPTR: Fast and Efficient Scene Text Recognition with Vision Permutable\n  Extractor","summary":"  Scene Text Recognition (STR) is an important and challenging upstream task\nfor building structured information databases, that involves recognizing text\nwithin images of natural scenes. Although current state-of-the-art (SOTA)\nmodels for STR exhibit high performance, they typically suffer from low\ninference efficiency due to their reliance on hybrid architectures comprised of\nvisual encoders and sequence decoders. In this work, we propose a VIsion\nPermutable extractor for fast and efficient Scene Text Recognition (SVIPTR),\nwhich achieves an impressive balance between high performance and rapid\ninference speeds in the domain of STR. Specifically, SVIPTR leverages a\nvisual-semantic extractor with a pyramid structure, characterized by the\nPermutation and combination of local and global self-attention layers. This\ndesign results in a lightweight and efficient model and its inference is\ninsensitive to input length. Extensive experimental results on various standard\ndatasets for both Chinese and English scene text recognition validate the\nsuperiority of SVIPTR. Notably, the SVIPTR-T (Tiny) variant delivers highly\ncompetitive accuracy on par with other lightweight models and achieves SOTA\ninference speeds. Meanwhile, the SVIPTR-L (Large) attains SOTA accuracy in\nsingle-encoder-type models, while maintaining a low parameter count and\nfavorable inference speed. Our proposed method provides a compelling solution\nfor the STR challenge, which greatly benefits real-world applications requiring\nfast and efficient STR. The code is publicly available at\nhttps://github.com/cxfyxl/VIPTR.\n","authors":["Xianfu Cheng","Weixiao Zhou","Xiang Li","Jian Yang","Hang Zhang","Tao Sun","Wei Zhang","Yuying Mai","Tongliang Li","Xiaoming Chen","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2401.10110v4.pdf","comment":"10 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2408.04300v1","updated":"2024-08-08T08:35:21Z","published":"2024-08-08T08:35:21Z","title":"An Explainable Non-local Network for COVID-19 Diagnosis","summary":"  The CNN has achieved excellent results in the automatic classification of\nmedical images. In this study, we propose a novel deep residual 3D attention\nnon-local network (NL-RAN) to classify CT images included COVID-19, common\npneumonia, and normal to perform rapid and explainable COVID-19 diagnosis. We\nbuilt a deep residual 3D attention non-local network that could achieve\nend-to-end training. The network is embedded with a nonlocal module to capture\nglobal information, while a 3D attention module is embedded to focus on the\ndetails of the lesion so that it can directly analyze the 3D lung CT and output\nthe classification results. The output of the attention module can be used as a\nheat map to increase the interpretability of the model. 4079 3D CT scans were\nincluded in this study. Each scan had a unique label (novel coronavirus\npneumonia, common pneumonia, and normal). The CT scans cohort was randomly\nsplit into a training set of 3263 scans, a validation set of 408 scans, and a\ntesting set of 408 scans. And compare with existing mainstream classification\nmethods, such as CovNet, CBAM, ResNet, etc. Simultaneously compare the\nvisualization results with visualization methods such as CAM. Model performance\nwas evaluated using the Area Under the ROC Curve(AUC), precision, and F1-score.\nThe NL-RAN achieved the AUC of 0.9903, the precision of 0.9473, and the\nF1-score of 0.9462, surpass all the classification methods compared. The heat\nmap output by the attention module is also clearer than the heat map output by\nCAM. Our experimental results indicate that our proposed method performs\nsignificantly better than existing methods. In addition, the first attention\nmodule outputs a heat map containing detailed outline information to increase\nthe interpretability of the model. Our experiments indicate that the inference\nof our model is fast. It can provide real-time assistance with diagnosis.\n","authors":["Jingfu Yang","Peng Huang","Jing Hu","Shu Hu","Siwei Lyu","Xin Wang","Jun Guo","Xi Wu"],"pdf_url":"https://arxiv.org/pdf/2408.04300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04299v1","updated":"2024-08-08T08:25:38Z","published":"2024-08-08T08:25:38Z","title":"Respiratory Subtraction for Pulmonary Microwave Ablation Evaluation","summary":"  Currently, lung cancer is a leading cause of global cancer mortality, often\nnecessitating minimally invasive interventions. Microwave ablation (MWA) is\nextensively utilized for both primary and secondary lung tumors. Although\nnumerous clinical guidelines and standards for MWA have been established, the\nclinical evaluation of ablation surgery remains challenging and requires\nlong-term patient follow-up for confirmation. In this paper, we propose a\nmethod termed respiratory subtraction to evaluate lung tumor ablation therapy\nperformance based on pre- and post-operative image guidance. Initially,\npreoperative images undergo coarse rigid registration to their corresponding\npostoperative positions, followed by further non-rigid registration.\nSubsequently, subtraction images are generated by subtracting the registered\npreoperative images from the postoperative ones. Furthermore, to enhance the\nclinical assessment of MWA treatment performance, we devise a quantitative\nanalysis metric to evaluate ablation efficacy by comparing differences between\ntumor areas and treatment areas. To the best of our knowledge, this is the\npioneering work in the field to facilitate the assessment of MWA surgery\nperformance on pulmonary tumors. Extensive experiments involving 35 clinical\ncases further validate the efficacy of the respiratory subtraction method. The\nexperimental results confirm the effectiveness of the respiratory subtraction\nmethod and the proposed quantitative evaluation metric in assessing lung tumor\ntreatment.\n","authors":["Wan Li","Xinyun Zhong","Wei Li","Song Zhang","Moheng Rong","Yan Xi","Peng Yuan","Zechen Wang","Xiaolei Jiang","Rongxi Yi","Hui Tang","Yang Chen","Chaohui Tong","Zhan Wu","Feng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.04299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04294v1","updated":"2024-08-08T08:17:50Z","published":"2024-08-08T08:17:50Z","title":"Dual-branch PolSAR Image Classification Based on GraphMAE and Local\n  Feature Extraction","summary":"  The annotation of polarimetric synthetic aperture radar (PolSAR) images is a\nlabor-intensive and time-consuming process. Therefore, classifying PolSAR\nimages with limited labels is a challenging task in remote sensing domain. In\nrecent years, self-supervised learning approaches have proven effective in\nPolSAR image classification with sparse labels. However, we observe a lack of\nresearch on generative selfsupervised learning in the studied task. Motivated\nby this, we propose a dual-branch classification model based on generative\nself-supervised learning in this paper. The first branch is a\nsuperpixel-branch, which learns superpixel-level polarimetric representations\nusing a generative self-supervised graph masked autoencoder. To acquire finer\nclassification results, a convolutional neural networks-based pixel-branch is\nfurther incorporated to learn pixel-level features. Classification with fused\ndual-branch features is finally performed to obtain the predictions.\nExperimental results on the benchmark Flevoland dataset demonstrate that our\napproach yields promising classification results.\n","authors":["Yuchen Wang","Ziyi Guo","Haixia Bi","Danfeng Hong","Chen Xu"],"pdf_url":"https://arxiv.org/pdf/2408.04294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04290v1","updated":"2024-08-08T08:06:42Z","published":"2024-08-08T08:06:42Z","title":"Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale\n  Transformer Approach","summary":"  Pneumonia, a severe respiratory disease, poses significant diagnostic\nchallenges, especially in underdeveloped regions. Traditional diagnostic\nmethods, such as chest X-rays, suffer from variability in interpretation among\nradiologists, necessitating reliable automated tools. In this study, we propose\na novel approach combining deep learning and transformer-based attention\nmechanisms to enhance pneumonia detection from chest X-rays. Our method begins\nwith lung segmentation using a TransUNet model that integrates our specialized\ntransformer module, which has fewer parameters compared to common transformers\nwhile maintaining performance. This model is trained on the \"Chest Xray Masks\nand Labels\" dataset and then applied to the Kermany and Cohen datasets to\nisolate lung regions, enhancing subsequent classification tasks. For\nclassification, we employ pre-trained ResNet models (ResNet-50 and ResNet-101)\nto extract multi-scale feature maps, processed through our modified transformer\nmodule. By employing our specialized transformer, we attain superior results\nwith significantly fewer parameters compared to common transformer models. Our\napproach achieves high accuracy rates of 92.79% on the Kermany dataset and\n95.11% on the Cohen dataset, ensuring robust and efficient performance suitable\nfor resource-constrained environments.\n\"https://github.com/amirrezafateh/Multi-Scale-Transformer-Pneumonia\"\n","authors":["Alireza Saber","Pouria Parhami","Alimihammad Siahkarzadeh","Amirreza Fateh"],"pdf_url":"https://arxiv.org/pdf/2408.04290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04158v2","updated":"2024-08-08T07:51:10Z","published":"2024-06-06T15:18:59Z","title":"Sparse Multi-baseline SAR Cross-modal 3D Reconstruction of Vehicle\n  Targets","summary":"  Multi-baseline SAR 3D imaging faces significant challenges due to data\nsparsity. In recent years, deep learning techniques have achieved notable\nsuccess in enhancing the quality of sparse SAR 3D imaging. However, previous\nwork typically rely on full-aperture high-resolution radar images to supervise\nthe training of deep neural networks (DNNs), utilizing only single-modal\ninformation from radar data. Consequently, imaging performance is limited, and\nacquiring full-aperture data for multi-baseline SAR is costly and sometimes\nimpractical in real-world applications. In this paper, we propose a Cross-Modal\nReconstruction Network (CMR-Net), which integrates differentiable render and\ncross-modal supervision with optical images to reconstruct highly sparse\nmulti-baseline SAR 3D images of vehicle targets into visually structured and\nhigh-resolution images. We meticulously designed the network architecture and\ntraining strategies to enhance network generalization capability. Remarkably,\nCMR-Net, trained solely on simulated data, demonstrates high-resolution\nreconstruction capabilities on both publicly available simulation datasets and\nreal measured datasets, outperforming traditional sparse reconstruction\nalgorithms based on compressed sensing and other learning-based methods.\nAdditionally, using optical images as supervision provides a cost-effective way\nto build training datasets, reducing the difficulty of method dissemination.\nOur work showcases the broad prospects of deep learning in multi-baseline SAR\n3D imaging and offers a novel path for researching radar imaging based on\ncross-modal learning theory.\n","authors":["Da Li","Guoqiang Zhao","Houjun Sun","Jiacheng Bao"],"pdf_url":"https://arxiv.org/pdf/2406.04158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09767v2","updated":"2024-08-08T07:44:14Z","published":"2023-12-15T13:15:42Z","title":"DreamTalk: When Emotional Talking Head Generation Meets Diffusion\n  Probabilistic Models","summary":"  Emotional talking head generation has attracted growing attention. Previous\nmethods, which are mainly GAN-based, still struggle to consistently produce\nsatisfactory results across diverse emotions and cannot conveniently specify\npersonalized emotions. In this work, we leverage powerful diffusion models to\naddress the issue and propose DreamTalk, a framework that employs meticulous\ndesign to unlock the potential of diffusion models in generating emotional\ntalking heads. Specifically, DreamTalk consists of three crucial components: a\ndenoising network, a style-aware lip expert, and a style predictor. The\ndiffusion-based denoising network can consistently synthesize high-quality\naudio-driven face motions across diverse emotions. To enhance lip-motion\naccuracy and emotional fullness, we introduce a style-aware lip expert that can\nguide lip-sync while preserving emotion intensity. To more conveniently specify\npersonalized emotions, a diffusion-based style predictor is utilized to predict\nthe personalized emotion directly from the audio, eliminating the need for\nextra emotion reference. By this means, DreamTalk can consistently generate\nvivid talking faces across diverse emotions and conveniently specify\npersonalized emotions. Extensive experiments validate DreamTalk's effectiveness\nand superiority. The code is available at\nhttps://github.com/ali-vilab/dreamtalk.\n","authors":["Yifeng Ma","Shiwei Zhang","Jiayu Wang","Xiang Wang","Yingya Zhang","Zhidong Deng"],"pdf_url":"https://arxiv.org/pdf/2312.09767v2.pdf","comment":"Project Page: https://dreamtalk-project.github.io"},{"id":"http://arxiv.org/abs/2408.04273v1","updated":"2024-08-08T07:14:57Z","published":"2024-08-08T07:14:57Z","title":"SG-JND: Semantic-Guided Just Noticeable Distortion Predictor For Image\n  Compression","summary":"  Just noticeable distortion (JND), representing the threshold of distortion in\nan image that is minimally perceptible to the human visual system (HVS), is\ncrucial for image compression algorithms to achieve a trade-off between\ntransmission bit rate and image quality. However, traditional JND prediction\nmethods only rely on pixel-level or sub-band level features, lacking the\nability to capture the impact of image content on JND. To bridge this gap, we\npropose a Semantic-Guided JND (SG-JND) network to leverage semantic information\nfor JND prediction. In particular, SG-JND consists of three essential modules:\nthe image preprocessing module extracts semantic-level patches from images, the\nfeature extraction module extracts multi-layer features by utilizing the\ncross-scale attention layers, and the JND prediction module regresses the\nextracted features into the final JND value. Experimental results show that\nSG-JND achieves the state-of-the-art performance on two publicly available JND\ndatasets, which demonstrates the effectiveness of SG-JND and highlight the\nsignificance of incorporating semantic information in JND assessment.\n","authors":["Linhan Cao","Wei Sun","Xiongkuo Min","Jun Jia","Zicheng Zhang","Zijian Chen","Yucheng Zhu","Lizhou Liu","Qiubo Chen","Jing Chen","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2408.04273v1.pdf","comment":"Accepted by ICIP 2024"},{"id":"http://arxiv.org/abs/2408.04268v1","updated":"2024-08-08T07:11:57Z","published":"2024-08-08T07:11:57Z","title":"Evaluating Modern Approaches in 3D Scene Reconstruction: NeRF vs\n  Gaussian-Based Methods","summary":"  Exploring the capabilities of Neural Radiance Fields (NeRF) and\nGaussian-based methods in the context of 3D scene reconstruction, this study\ncontrasts these modern approaches with traditional Simultaneous Localization\nand Mapping (SLAM) systems. Utilizing datasets such as Replica and ScanNet, we\nassess performance based on tracking accuracy, mapping fidelity, and view\nsynthesis. Findings reveal that NeRF excels in view synthesis, offering unique\ncapabilities in generating new perspectives from existing data, albeit at\nslower processing speeds. Conversely, Gaussian-based methods provide rapid\nprocessing and significant expressiveness but lack comprehensive scene\ncompletion. Enhanced by global optimization and loop closure techniques, newer\nmethods like NICE-SLAM and SplaTAM not only surpass older frameworks such as\nORB-SLAM2 in terms of robustness but also demonstrate superior performance in\ndynamic and complex environments. This comparative analysis bridges theoretical\nresearch with practical implications, shedding light on future developments in\nrobust 3D scene reconstruction across various real-world applications.\n","authors":["Yiming Zhou","Zixuan Zeng","Andi Chen","Xiaofan Zhou","Haowei Ni","Shiyao Zhang","Panfeng Li","Liangxi Liu","Mengyao Zheng","Xupeng Chen"],"pdf_url":"https://arxiv.org/pdf/2408.04268v1.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2401.10373v2","updated":"2024-08-08T07:06:40Z","published":"2024-01-18T20:43:43Z","title":"Harmonized Spatial and Spectral Learning for Robust and Generalized\n  Medical Image Segmentation","summary":"  Deep learning has demonstrated remarkable achievements in medical image\nsegmentation. However, prevailing deep learning models struggle with poor\ngeneralization due to (i) intra-class variations, where the same class appears\ndifferently in different samples, and (ii) inter-class independence, resulting\nin difficulties capturing intricate relationships between distinct objects,\nleading to higher false negative cases. This paper presents a novel approach\nthat synergies spatial and spectral representations to enhance\ndomain-generalized medical image segmentation. We introduce the innovative\nSpectral Correlation Coefficient objective to improve the model's capacity to\ncapture middle-order features and contextual long-range dependencies. This\nobjective complements traditional spatial objectives by incorporating valuable\nspectral information. Extensive experiments reveal that optimizing this\nobjective with existing architectures like UNet and TransUNet significantly\nenhances generalization, interpretability, and noise robustness, producing more\nconfident predictions. For instance, in cardiac segmentation, we observe a 0.81\npp and 1.63 pp (pp = percentage point) improvement in DSC over UNet and\nTransUNet, respectively. Our interpretability study demonstrates that, in most\ntasks, objectives optimized with UNet outperform even TransUNet by introducing\nglobal contextual information alongside local details. These findings\nunderscore the versatility and effectiveness of our proposed method across\ndiverse imaging modalities and medical domains.\n","authors":["Vandan Gorade","Sparsh Mittal","Debesh Jha","Rekha Singhal","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2401.10373v2.pdf","comment":"Early Accepted at ICPR-2024 for Oral Presentation"},{"id":"http://arxiv.org/abs/2408.04262v1","updated":"2024-08-08T06:59:32Z","published":"2024-08-08T06:59:32Z","title":"CoBooM: Codebook Guided Bootstrapping for Medical Image Representation\n  Learning","summary":"  Self-supervised learning (SSL) has emerged as a promising paradigm for\nmedical image analysis by harnessing unannotated data. Despite their potential,\nthe existing SSL approaches overlook the high anatomical similarity inherent in\nmedical images. This makes it challenging for SSL methods to capture diverse\nsemantic content in medical images consistently. This work introduces a novel\nand generalized solution that implicitly exploits anatomical similarities by\nintegrating codebooks in SSL. The codebook serves as a concise and informative\ndictionary of visual patterns, which not only aids in capturing nuanced\nanatomical details but also facilitates the creation of robust and generalized\nfeature representations. In this context, we propose CoBooM, a novel framework\nfor self-supervised medical image learning by integrating continuous and\ndiscrete representations. The continuous component ensures the preservation of\nfine-grained details, while the discrete aspect facilitates coarse-grained\nfeature extraction through the structured embedding space. To understand the\neffectiveness of CoBooM, we conduct a comprehensive evaluation of various\nmedical datasets encompassing chest X-rays and fundus images. The experimental\nresults reveal a significant performance gain in classification and\nsegmentation tasks.\n","authors":["Azad Singh","Deepak Mishra"],"pdf_url":"https://arxiv.org/pdf/2408.04262v1.pdf","comment":"Accepted in MICCAI 2024"},{"id":"http://arxiv.org/abs/2408.04261v1","updated":"2024-08-08T06:58:48Z","published":"2024-08-08T06:58:48Z","title":"Unveiling Hidden Visual Information: A Reconstruction Attack Against\n  Adversarial Visual Information Hiding","summary":"  This paper investigates the security vulnerabilities of\nadversarial-example-based image encryption by executing data reconstruction\n(DR) attacks on encrypted images. A representative image encryption method is\nthe adversarial visual information hiding (AVIH), which uses type-I adversarial\nexample training to protect gallery datasets used in image recognition tasks.\nIn the AVIH method, the type-I adversarial example approach creates images that\nappear completely different but are still recognized by machines as the\noriginal ones. Additionally, the AVIH method can restore encrypted images to\ntheir original forms using a predefined private key generative model. For the\nbest security, assigning a unique key to each image is recommended; however,\nstorage limitations may necessitate some images sharing the same key model.\nThis raises a crucial security question for AVIH: How many images can safely\nshare the same key model without being compromised by a DR attack? To address\nthis question, we introduce a dual-strategy DR attack against the AVIH\nencryption method by incorporating (1) generative-adversarial loss and (2)\naugmented identity loss, which prevent DR from overfitting -- an issue akin to\nthat in machine learning. Our numerical results validate this approach through\nimage recognition and re-identification benchmarks, demonstrating that our\nstrategy can significantly enhance the quality of reconstructed images, thereby\nrequiring fewer key-sharing encrypted images. Our source code to reproduce our\nresults will be available soon.\n","authors":["Jonggyu Jang","Hyeonsu Lyu","Seongjin Hwang","Hyun Jong Yang"],"pdf_url":"https://arxiv.org/pdf/2408.04261v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2408.04258v1","updated":"2024-08-08T06:56:33Z","published":"2024-08-08T06:56:33Z","title":"UHNet: An Ultra-Lightweight and High-Speed Edge Detection Network","summary":"  Edge detection is crucial in medical image processing, enabling precise\nextraction of structural information to support lesion identification and image\nanalysis. Traditional edge detection models typically rely on complex\nConvolutional Neural Networks and Vision Transformer architectures. Due to\ntheir numerous parameters and high computational demands, these models are\nlimited in their application on resource-constrained devices. This paper\npresents an ultra-lightweight edge detection model (UHNet), characterized by\nits minimal parameter count, rapid computation speed, negligible of\npre-training costs, and commendable performance. UHNet boasts impressive\nperformance metrics with 42.3k parameters, 166 FPS, and 0.79G FLOPs. By\nemploying an innovative feature extraction module and optimized residual\nconnection method, UHNet significantly reduces model complexity and\ncomputational requirements. Additionally, a lightweight feature fusion strategy\nis explored, enhancing detection accuracy. Experimental results on the BSDS500,\nNYUD, and BIPED datasets validate that UHNet achieves remarkable edge detection\nperformance while maintaining high efficiency. This work not only provides new\ninsights into the design of lightweight edge detection models but also\ndemonstrates the potential and application prospects of the UHNet model in\nengineering applications such as medical image processing. The codes are\navailable at https://github.com/stoneLi20cv/UHNet\n","authors":["Fuzhang Li","Chuan Lin"],"pdf_url":"https://arxiv.org/pdf/2408.04258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03030v2","updated":"2024-08-08T06:32:30Z","published":"2024-08-06T08:24:47Z","title":"Nighttime Pedestrian Detection Based on Fore-Background Contrast\n  Learning","summary":"  The significance of background information is frequently overlooked in\ncontemporary research concerning channel attention mechanisms. This study\naddresses the issue of suboptimal single-spectral nighttime pedestrian\ndetection performance under low-light conditions by incorporating background\ninformation into the channel attention mechanism. Despite numerous studies\nfocusing on the development of efficient channel attention mechanisms, the\nrelevance of background information has been largely disregarded. By adopting a\ncontrast learning approach, we reexamine channel attention with regard to\npedestrian objects and background information for nighttime pedestrian\ndetection, resulting in the proposed Fore-Background Contrast Attention (FBCA).\nFBCA possesses two primary attributes: (1) channel descriptors form remote\ndependencies with global spatial feature information; (2) the integration of\nbackground information enhances the distinction between channels concentrating\non low-light pedestrian features and those focusing on background information.\nConsequently, the acquired channel descriptors exhibit a higher semantic level\nand spatial accuracy. Experimental outcomes demonstrate that FBCA significantly\noutperforms existing methods in single-spectral nighttime pedestrian detection,\nachieving state-of-the-art results on the NightOwls and TJU-DHD-pedestrian\ndatasets. Furthermore, this methodology also yields performance improvements\nfor the multispectral LLVIP dataset. These findings indicate that integrating\nbackground information into the channel attention mechanism effectively\nmitigates detector performance degradation caused by illumination factors in\nnighttime scenarios.\n","authors":["He Yao","Yongjun Zhang","Huachun Jian","Li Zhang","Ruzhong Cheng"],"pdf_url":"https://arxiv.org/pdf/2408.03030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04249v1","updated":"2024-08-08T06:29:32Z","published":"2024-08-08T06:29:32Z","title":"InstantStyleGaussian: Efficient Art Style Transfer with 3D Gaussian\n  Splatting","summary":"  We present InstantStyleGaussian, an innovative 3D style transfer method based\non the 3D Gaussian Splatting (3DGS) scene representation. By inputting a target\nstyle image, it quickly generates new 3D GS scenes. Our approach operates on\npre-reconstructed GS scenes, combining diffusion models with an improved\niterative dataset update strategy. It utilizes diffusion models to generate\ntarget style images, adds these new images to the training dataset, and uses\nthis dataset to iteratively update and optimize the GS scenes. Extensive\nexperimental results demonstrate that our method ensures high-quality stylized\nscenes while offering significant advantages in style transfer speed and\nconsistency.\n","authors":["Xin-Yi Yu","Jun-Xin Yu","Li-Bo Zhou","Yan Wei","Lin-Lin Ou"],"pdf_url":"https://arxiv.org/pdf/2408.04249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04243v1","updated":"2024-08-08T06:16:00Z","published":"2024-08-08T06:16:00Z","title":"MU-MAE: Multimodal Masked Autoencoders-Based One-Shot Learning","summary":"  With the exponential growth of multimedia data, leveraging multimodal sensors\npresents a promising approach for improving accuracy in human activity\nrecognition. Nevertheless, accurately identifying these activities using both\nvideo data and wearable sensor data presents challenges due to the\nlabor-intensive data annotation, and reliance on external pretrained models or\nadditional data. To address these challenges, we introduce Multimodal Masked\nAutoencoders-Based One-Shot Learning (Mu-MAE). Mu-MAE integrates a multimodal\nmasked autoencoder with a synchronized masking strategy tailored for wearable\nsensors. This masking strategy compels the networks to capture more meaningful\nspatiotemporal features, which enables effective self-supervised pretraining\nwithout the need for external data. Furthermore, Mu-MAE leverages the\nrepresentation extracted from multimodal masked autoencoders as prior\ninformation input to a cross-attention multimodal fusion layer. This fusion\nlayer emphasizes spatiotemporal features requiring attention across different\nmodalities while highlighting differences from other classes, aiding in the\nclassification of various classes in metric-based one-shot learning.\nComprehensive evaluations on MMAct one-shot classification show that Mu-MAE\noutperforms all the evaluated approaches, achieving up to an 80.17% accuracy\nfor five-way one-shot multimodal classification, without the use of additional\ndata.\n","authors":["Rex Liu","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.04243v1.pdf","comment":"IEEE MIPR 2024"},{"id":"http://arxiv.org/abs/2408.04235v1","updated":"2024-08-08T05:41:09Z","published":"2024-08-08T05:41:09Z","title":"LLDif: Diffusion Models for Low-light Emotion Recognition","summary":"  This paper introduces LLDif, a novel diffusion-based facial expression\nrecognition (FER) framework tailored for extremely low-light (LL) environments.\nImages captured under such conditions often suffer from low brightness and\nsignificantly reduced contrast, presenting challenges to conventional methods.\nThese challenges include poor image quality that can significantly reduce the\naccuracy of emotion recognition. LLDif addresses these issues with a novel\ntwo-stage training process that combines a Label-aware CLIP (LA-CLIP), an\nembedding prior network (PNET), and a transformer-based network adept at\nhandling the noise of low-light images. The first stage involves LA-CLIP\ngenerating a joint embedding prior distribution (EPD) to guide the LLformer in\nlabel recovery. In the second stage, the diffusion model (DM) refines the EPD\ninference, ultilising the compactness of EPD for precise predictions.\nExperimental evaluations on various LL-FER datasets have shown that LLDif\nachieves competitive performance, underscoring its potential to enhance FER\napplications in challenging lighting conditions.\n","authors":["Zhifeng Wang","Kaihao Zhang","Ramesh Sankaranarayana"],"pdf_url":"https://arxiv.org/pdf/2408.04235v1.pdf","comment":"Accepted by ICPR2024"},{"id":"http://arxiv.org/abs/2408.04227v1","updated":"2024-08-08T05:30:59Z","published":"2024-08-08T05:30:59Z","title":"Physical prior guided cooperative learning framework for joint\n  turbulence degradation estimation and infrared video restoration","summary":"  Infrared imaging and turbulence strength measurements are in widespread\ndemand in many fields. This paper introduces a Physical Prior Guided\nCooperative Learning (P2GCL) framework to jointly enhance atmospheric\nturbulence strength estimation and infrared image restoration. P2GCL involves a\ncyclic collaboration between two models, i.e., a TMNet measures turbulence\nstrength and outputs the refractive index structure constant (Cn2) as a\nphysical prior, a TRNet conducts infrared image sequence restoration based on\nCn2 and feeds the restored images back to the TMNet to boost the measurement\naccuracy. A novel Cn2-guided frequency loss function and a physical constraint\nloss are introduced to align the training process with physical theories.\nExperiments demonstrate P2GCL achieves the best performance for both turbulence\nstrength estimation (improving Cn2 MAE by 0.0156, enhancing R2 by 0.1065) and\nimage restoration (enhancing PSNR by 0.2775 dB), validating the significant\nimpact of physical prior guided cooperative learning.\n","authors":["Ziran Zhang","Yuhang Tang","Zhigang Wang","Yueting Chen","Bin Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.04227v1.pdf","comment":"21"},{"id":"http://arxiv.org/abs/2408.04224v1","updated":"2024-08-08T05:17:27Z","published":"2024-08-08T05:17:27Z","title":"Cross-View Meets Diffusion: Aerial Image Synthesis with Geometry and\n  Text Guidance","summary":"  Aerial imagery analysis is critical for many research fields. However,\nobtaining frequent high-quality aerial images is not always accessible due to\nits high effort and cost requirements. One solution is to use the\nGround-to-Aerial (G2A) technique to synthesize aerial images from easily\ncollectible ground images. However, G2A is rarely studied, because of its\nchallenges, including but not limited to, the drastic view changes, occlusion,\nand range of visibility. In this paper, we present a novel Geometric Preserving\nGround-to-Aerial (G2A) image synthesis (GPG2A) model that can generate\nrealistic aerial images from ground images. GPG2A consists of two stages. The\nfirst stage predicts the Bird's Eye View (BEV) segmentation (referred to as the\nBEV layout map) from the ground image. The second stage synthesizes the aerial\nimage from the predicted BEV layout map and text descriptions of the ground\nimage. To train our model, we present a new multi-modal cross-view dataset,\nnamely VIGORv2 which is built upon VIGOR with newly collected aerial images,\nmaps, and text descriptions. Our extensive experiments illustrate that GPG2A\nsynthesizes better geometry-preserved aerial images than existing models. We\nalso present two applications, data augmentation for cross-view\ngeo-localization and sketch-based region search, to further verify the\neffectiveness of our GPG2A. The code and data will be publicly available.\n","authors":["Ahmad Arrabi","Xiaohan Zhang","Waqas Sultan","Chen Chen","Safwan Wshah"],"pdf_url":"https://arxiv.org/pdf/2408.04224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15143v2","updated":"2024-08-08T05:15:07Z","published":"2024-07-21T12:32:00Z","title":"Rethinking Feature Backbone Fine-tuning for Remote Sensing Object\n  Detection","summary":"  Recently, numerous methods have achieved impressive performance in remote\nsensing object detection, relying on convolution or transformer architectures.\nSuch detectors typically have a feature backbone to extract useful features\nfrom raw input images. For the remote sensing domain, a common practice among\ncurrent detectors is to initialize the backbone with pre-training on ImageNet\nconsisting of natural scenes. Fine-tuning the backbone is then typically\nrequired to generate features suitable for remote-sensing images. However, this\ncould hinder the extraction of basic visual features in long-term training,\nthus restricting performance improvement. To mitigate this issue, we propose a\nnovel method named DBF (Dynamic Backbone Freezing) for feature backbone\nfine-tuning on remote sensing object detection. Our method aims to handle the\ndilemma of whether the backbone should extract low-level generic features or\npossess specific knowledge of the remote sensing domain, by introducing a\nmodule called 'Freezing Scheduler' to dynamically manage the update of backbone\nfeatures during training. Extensive experiments on DOTA and DIOR-R show that\nour approach enables more accurate model learning while substantially reducing\ncomputational costs. Our method can be seamlessly adopted without additional\neffort due to its straightforward design.\n","authors":["Yechan Kim","JongHyun Park","SooYeon Kim","Moongu Jeon"],"pdf_url":"https://arxiv.org/pdf/2407.15143v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2408.04223v1","updated":"2024-08-08T05:14:07Z","published":"2024-08-08T05:14:07Z","title":"VideoQA in the Era of LLMs: An Empirical Study","summary":"  Video Large Language Models (Video-LLMs) are flourishing and has advanced\nmany video-language tasks. As a golden testbed, Video Question Answering\n(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a\ntimely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to\nelucidate their success and failure modes, and provide insights towards more\nhuman-like video understanding and question answering. Our analyses demonstrate\nthat Video-LLMs excel in VideoQA; they can correlate contextual cues and\ngenerate plausible responses to questions about varied video contents. However,\nmodels falter in handling video temporality, both in reasoning about temporal\ncontent ordering and grounding QA-relevant temporal moments. Moreover, the\nmodels behave unintuitively - they are unresponsive to adversarial video\nperturbations while being sensitive to simple variations of candidate answers\nand questions. Also, they do not necessarily generalize better. The findings\ndemonstrate Video-LLMs' QA capability in standard condition yet highlight their\nsevere deficiency in robustness and interpretability, suggesting the urgent\nneed on rationales in Video-LLM developing.\n","authors":["Junbin Xiao","Nanxin Huang","Hangyu Qin","Dongyang Li","Yicong Li","Fengbin Zhu","Zhulin Tao","Jianxing Yu","Liang Lin","Tat-Seng Chua","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2408.04223v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2408.04221v1","updated":"2024-08-08T05:09:02Z","published":"2024-08-08T05:09:02Z","title":"Connective Viewpoints of Signal-to-Noise Diffusion Models","summary":"  Diffusion models (DM) have become fundamental components of generative\nmodels, excelling across various domains such as image creation, audio\ngeneration, and complex data interpolation. Signal-to-Noise diffusion models\nconstitute a diverse family covering most state-of-the-art diffusion models.\nWhile there have been several attempts to study Signal-to-Noise (S2N) diffusion\nmodels from various perspectives, there remains a need for a comprehensive\nstudy connecting different viewpoints and exploring new perspectives. In this\nstudy, we offer a comprehensive perspective on noise schedulers, examining\ntheir role through the lens of the signal-to-noise ratio (SNR) and its\nconnections to information theory. Building upon this framework, we have\ndeveloped a generalized backward equation to enhance the performance of the\ninference process.\n","authors":["Khanh Doan","Long Tung Vuong","Tuan Nguyen","Anh Tuan Bui","Quyen Tran","Thanh-Toan Do","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2408.04221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02369v2","updated":"2024-08-08T04:54:47Z","published":"2024-08-05T10:38:50Z","title":"The NPU-ASLP System Description for Visual Speech Recognition in CNVSRC\n  2024","summary":"  This paper delineates the visual speech recognition (VSR) system introduced\nby the NPU-ASLP (Team 237) in the second Chinese Continuous Visual Speech\nRecognition Challenge (CNVSRC 2024), engaging in all four tracks, including the\nfixed and open tracks of Single-Speaker VSR Task and Multi-Speaker VSR Task. In\nterms of data processing, we leverage the lip motion extractor from the\nbaseline1 to produce multiscale video data. Besides, various augmentation\ntechniques are applied during training, encompassing speed perturbation, random\nrotation, horizontal flipping, and color transformation. The VSR model adopts\nan end-to-end architecture with joint CTC/attention loss, introducing Enhanced\nResNet3D visual frontend, E-Branchformer encoder, and Bi-directional\nTransformer decoder. Our approach yields a 30.47% CER for the Single-Speaker\nTask and 34.30% CER for the Multi-Speaker Task, securing second place in the\nopen track of the Single-Speaker Task and first place in the other three\ntracks.\n","authors":["He Wang","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2408.02369v2.pdf","comment":"2 pages, 2 figures, CNVSRC 2024 System Report"},{"id":"http://arxiv.org/abs/2312.02934v4","updated":"2024-08-08T04:42:52Z","published":"2023-12-05T18:05:14Z","title":"WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera\n  Driving Scene Generation","summary":"  Generating multi-camera street-view videos is critical for augmenting\nautonomous driving datasets, addressing the urgent demand for extensive and\nvaried data. Due to the limitations in diversity and challenges in handling\nlighting conditions, traditional rendering-based methods are increasingly being\nsupplanted by diffusion-based methods. However, a significant challenge in\ndiffusion-based methods is ensuring that the generated sensor data preserve\nboth intra-world consistency and inter-sensor coherence. To address these\nchallenges, we combine an additional explicit world volume and propose the\nWorld Volume-aware Multi-camera Driving Scene Generator (WoVoGen). This system\nis specifically designed to leverage 4D world volume as a foundational element\nfor video generation. Our model operates in two distinct phases: (i)\nenvisioning the future 4D temporal world volume based on vehicle control\nsequences, and (ii) generating multi-camera videos, informed by this envisioned\n4D temporal world volume and sensor interconnectivity. The incorporation of the\n4D world volume empowers WoVoGen not only to generate high-quality street-view\nvideos in response to vehicle control inputs but also to facilitate scene\nediting tasks.\n","authors":["Jiachen Lu","Ze Huang","Zeyu Yang","Jiahui Zhang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.02934v4.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2408.04212v1","updated":"2024-08-08T04:34:29Z","published":"2024-08-08T04:34:29Z","title":"Is SAM 2 Better than SAM in Medical Image Segmentation?","summary":"  Segment Anything Model (SAM) demonstrated impressive performance in zero-shot\npromptable segmentation on natural images. The recently released Segment\nAnything Model 2 (SAM 2) model claims to have better performance than SAM on\nimages while extending the model's capabilities to video segmentation. It is\nimportant to evaluate the recent model's ability in medical image segmentation\nin a zero-shot promptable manner. In this work, we performed extensive studies\nwith multiple datasets from different imaging modalities to compare the\nperformance between SAM and SAM 2. We used two point prompt strategies: (i)\nsingle positive prompt near the centroid of the target structure and (ii)\nadditional positive prompts placed randomly within the target structure. The\nevaluation included 21 unique organ-modality combinations including abdominal\nstructures, cardiac structures, and fetal head images acquired from publicly\navailable MRI, CT, and Ultrasound datasets. The preliminary results, based on\n2D images, indicate that while SAM 2 may perform slightly better in a few\ncases, but it does not in general surpass SAM for medical image segmentation.\nEspecially when the contrast is lower like in CT, Ultrasound images, SAM 2\nperforms poorly than SAM. For MRI images, SAM 2 performs at par or better than\nSAM. Similar to SAM, SAM 2 also suffers from over-segmentation issue especially\nwhen the boundaries of the to-be-segmented organ is fuzzy in nature.\n","authors":["Sourya Sengupta","Satrajit Chakrabarty","Ravi Soni"],"pdf_url":"https://arxiv.org/pdf/2408.04212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.11528v3","updated":"2024-08-08T04:18:34Z","published":"2021-06-22T03:44:03Z","title":"Recent Deep Semi-supervised Learning Approaches and Related Works","summary":"  This work proposes an overview of the recent semi-supervised learning\napproaches and related works. Despite the remarkable success of neural networks\nin various applications, there exist a few formidable constraints, including\nthe need for a large amount of labeled data. Therefore, semi-supervised\nlearning, which is a learning scheme in which scarce labels and a larger amount\nof unlabeled data are utilized to train models (e.g., deep neural networks), is\ngetting more important. Based on the key assumptions of semi-supervised\nlearning, which are the manifold assumption, cluster assumption, and continuity\nassumption, the work reviews the recent semi-supervised learning approaches. In\nparticular, the methods in regard to using deep neural networks in a\nsemi-supervised learning setting are primarily discussed. In addition, the\nexisting works are first classified based on the underlying idea and explained,\nthen the holistic approaches that unify the aforementioned ideas are detailed.\n","authors":["Gyeongho Kim"],"pdf_url":"https://arxiv.org/pdf/2106.11528v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11106v2","updated":"2024-08-08T04:03:27Z","published":"2023-10-17T09:44:30Z","title":"3D Structure-guided Network for Tooth Alignment in 2D Photograph","summary":"  Orthodontics focuses on rectifying misaligned teeth (i.e., malocclusions),\naffecting both masticatory function and aesthetics. However, orthodontic\ntreatment often involves complex, lengthy procedures. As such, generating a 2D\nphotograph depicting aligned teeth prior to orthodontic treatment is crucial\nfor effective dentist-patient communication and, more importantly, for\nencouraging patients to accept orthodontic intervention. In this paper, we\npropose a 3D structure-guided tooth alignment network that takes 2D photographs\nas input (e.g., photos captured by smartphones) and aligns the teeth within the\n2D image space to generate an orthodontic comparison photograph featuring\naesthetically pleasing, aligned teeth. Notably, while the process operates\nwithin a 2D image space, our method employs 3D intra-oral scanning models\ncollected in clinics to learn about orthodontic treatment, i.e., projecting the\npre- and post-orthodontic 3D tooth structures onto 2D tooth contours, followed\nby a diffusion model to learn the mapping relationship. Ultimately, the aligned\ntooth contours are leveraged to guide the generation of a 2D photograph with\naesthetically pleasing, aligned teeth and realistic textures. We evaluate our\nnetwork on various facial photographs, demonstrating its exceptional\nperformance and strong applicability within the orthodontic industry.\n","authors":["Yulong Dou","Lanzhuju Mei","Dinggang Shen","Zhiming Cui"],"pdf_url":"https://arxiv.org/pdf/2310.11106v2.pdf","comment":"Accepted by The 34th British Machine Vision Conference (BMVC 2023)\n  Our BMVC webpage is https://proceedings.bmvc2023.org/322/"},{"id":"http://arxiv.org/abs/2407.19451v3","updated":"2024-08-08T04:01:03Z","published":"2024-07-28T10:05:11Z","title":"Perm: A Parametric Representation for Multi-Style 3D Hair Modeling","summary":"  We present Perm, a learned parametric model of human 3D hair designed to\nfacilitate various hair-related applications. Unlike previous work that jointly\nmodels the global hair shape and local strand details, we propose to\ndisentangle them using a PCA-based strand representation in the frequency\ndomain, thereby allowing more precise editing and output control. Specifically,\nwe leverage our strand representation to fit and decompose hair geometry\ntextures into low- to high-frequency hair structures. These decomposed textures\nare later parameterized with different generative models, emulating common\nstages in the hair modeling process. We conduct extensive experiments to\nvalidate the architecture design of \\textsc{Perm}, and finally deploy the\ntrained model as a generic prior to solve task-agnostic problems, further\nshowcasing its flexibility and superiority in tasks such as 3D hair\nparameterization, hairstyle interpolation, single-view hair reconstruction, and\nhair-conditioned image generation. Our code, data, and supplemental can be\nfound at our project page: https://cs.yale.edu/homes/che/projects/perm/\n","authors":["Chengan He","Xin Sun","Zhixin Shu","Fujun Luan","Sören Pirk","Jorge Alejandro Amador Herrera","Dominik L. Michels","Tuanfeng Y. Wang","Meng Zhang","Holly Rushmeier","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.19451v3.pdf","comment":"Project page: https://cs.yale.edu/homes/che/projects/perm/"},{"id":"http://arxiv.org/abs/2402.17485v3","updated":"2024-08-08T03:48:38Z","published":"2024-02-27T13:10:11Z","title":"EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with\n  Audio2Video Diffusion Model under Weak Conditions","summary":"  In this work, we tackle the challenge of enhancing the realism and\nexpressiveness in talking head video generation by focusing on the dynamic and\nnuanced relationship between audio cues and facial movements. We identify the\nlimitations of traditional techniques that often fail to capture the full\nspectrum of human expressions and the uniqueness of individual facial styles.\nTo address these issues, we propose EMO, a novel framework that utilizes a\ndirect audio-to-video synthesis approach, bypassing the need for intermediate\n3D models or facial landmarks. Our method ensures seamless frame transitions\nand consistent identity preservation throughout the video, resulting in highly\nexpressive and lifelike animations. Experimental results demonsrate that EMO is\nable to produce not only convincing speaking videos but also singing videos in\nvarious styles, significantly outperforming existing state-of-the-art\nmethodologies in terms of expressiveness and realism.\n","authors":["Linrui Tian","Qi Wang","Bang Zhang","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2402.17485v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06342v3","updated":"2024-08-08T03:25:02Z","published":"2024-05-10T09:18:17Z","title":"Compression-Realized Deep Structural Network for Video Quality\n  Enhancement","summary":"  This paper focuses on the task of quality enhancement for compressed videos.\nAlthough deep network-based video restorers achieve impressive progress, most\nof the existing methods lack a structured design to optimally leverage the\npriors within compression codecs. Since the quality degradation of the video is\nprimarily induced by the compression algorithm, a new paradigm is urgently\nneeded for a more ``conscious'' process of quality enhancement. As a result, we\npropose the Compression-Realized Deep Structural Network (CRDS), introducing\nthree inductive biases aligned with the three primary processes in the classic\ncompression codec, merging the strengths of classical encoder architecture with\ndeep network capabilities. Inspired by the residual extraction and domain\ntransformation process in the codec, a pre-trained Latent Degradation Residual\nAuto-Encoder is proposed to transform video frames into a latent feature space,\nand the mutual neighborhood attention mechanism is integrated for precise\nmotion estimation and residual extraction. Furthermore, drawing inspiration\nfrom the quantization noise distribution of the codec, CRDS proposes a novel\nProgressive Denoising framework with intermediate supervision that decomposes\nthe quality enhancement into a series of simpler denoising sub-tasks.\nExperimental results on datasets like LDV 2.0 and MFQE 2.0 indicate our\napproach surpasses state-of-the-art models.\n","authors":["Hanchi Sun","Xiaohong Liu","Xinyang Jiang","Yifei Shen","Dongsheng Li","Xiongkuo Min","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2405.06342v3.pdf","comment":"Accepted by ACM MM'24"},{"id":"http://arxiv.org/abs/2301.01156v3","updated":"2024-08-08T03:22:43Z","published":"2023-01-03T15:33:48Z","title":"Reference Twice: A Simple and Unified Baseline for Few-Shot Instance\n  Segmentation","summary":"  Few-Shot Instance Segmentation (FSIS) requires detecting and segmenting novel\nclasses with limited support examples. Existing methods based on Region\nProposal Networks (RPNs) face two issues: 1) Overfitting suppresses novel class\nobjects; 2) Dual-branch models require complex spatial correlation strategies\nto prevent spatial information loss when generating class prototypes. We\nintroduce a unified framework, Reference Twice (RefT), to exploit the\nrelationship between support and query features for FSIS and related tasks. Our\nthree main contributions are: 1) A novel transformer-based baseline that avoids\noverfitting, offering a new direction for FSIS; 2) Demonstrating that support\nobject queries encode key factors after base training, allowing query features\nto be enhanced twice at both feature and query levels using simple\ncross-attention, thus avoiding complex spatial correlation interaction; 3)\nIntroducing a class-enhanced base knowledge distillation loss to address the\nissue of DETR-like models struggling with incremental settings due to the input\nprojection layer, enabling easy extension to incremental FSIS. Extensive\nexperimental evaluations on the COCO dataset under three FSIS settings\ndemonstrate that our method performs favorably against existing approaches\nacross different shots, \\eg, $+8.2/+9.4$ performance gain over state-of-the-art\nmethods with 10/30-shots. Source code and models will be available at\nhttps://github.com/hanyue1648/RefT.\n","authors":["Yue Han","Jiangning Zhang","Yabiao Wang","Chengjie Wang","Yong Liu","Lu Qi","Xiangtai Li","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2301.01156v3.pdf","comment":"Accepted by T-PAMI"},{"id":"http://arxiv.org/abs/2406.18037v2","updated":"2024-08-08T03:16:23Z","published":"2024-06-26T03:10:57Z","title":"Towards Synchronous Memorizability and Generalizability with\n  Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation","summary":"  The ability to learn sequentially from different data sites is crucial for a\ndeep network in solving practical medical image diagnosis problems due to\nprivacy restrictions and storage limitations. However, adapting on incoming\nsite leads to catastrophic forgetting on past sites and decreases\ngeneralizablity on unseen sites. Existing Continual Learning (CL) and Domain\nGeneralization (DG) methods have been proposed to solve these two challenges\nrespectively, but none of them can address both simultaneously. Recognizing\nthis limitation, this paper proposes a novel training paradigm, learning\ntowards Synchronous Memorizability and Generalizability (SMG-Learning). To\nachieve this, we create the orientational gradient alignment to ensure\nmemorizability on previous sites, and arbitrary gradient alignment to enhance\ngeneralizability on unseen sites. This approach is named as Parallel Gradient\nAlignment (PGA). Furthermore, we approximate the PGA as dual meta-objectives\nusing the first-order Taylor expansion to reduce computational cost of aligning\ngradients. Considering that performing gradient alignments, especially for\nprevious sites, is not feasible due to the privacy constraints, we design a\nSite-Modulated Diffusion (SMD) model to generate images with site-specific\nlearnable prompts, replaying images have similar data distributions as previous\nsites. We evaluate our method on two medical image segmentation tasks, where\ndata from different sites arrive sequentially. Experimental results show that\nour method efficiently enhances both memorizability and generalizablity better\nthan other state-of-the-art methods, delivering satisfactory performance across\nall sites. Our code will be available at:\nhttps://github.com/dyxu-cuhkcse/SMG-Learning.\n","authors":["Dunyuan Xu","Xi Wang","Jingyang Zhang","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.18037v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.04187v1","updated":"2024-08-08T03:11:12Z","published":"2024-08-08T03:11:12Z","title":"Medical Graph RAG: Towards Safe Medical Large Language Model via Graph\n  Retrieval-Augmented Generation","summary":"  We introduce a novel graph-based Retrieval-Augmented Generation (RAG)\nframework specifically designed for the medical domain, called\n\\textbf{MedGraphRAG}, aimed at enhancing Large Language Model (LLM)\ncapabilities and generating evidence-based results, thereby improving safety\nand reliability when handling private medical data. Our comprehensive pipeline\nbegins with a hybrid static-semantic approach to document chunking,\nsignificantly improving context capture over traditional methods. Extracted\nentities are used to create a three-tier hierarchical graph structure, linking\nentities to foundational medical knowledge sourced from medical papers and\ndictionaries. These entities are then interconnected to form meta-graphs, which\nare merged based on semantic similarities to develop a comprehensive global\ngraph. This structure supports precise information retrieval and response\ngeneration. The retrieval process employs a U-retrieve method to balance global\nawareness and indexing efficiency of the LLM. Our approach is validated through\na comprehensive ablation study comparing various methods for document chunking,\ngraph construction, and information retrieval. The results not only demonstrate\nthat our hierarchical graph construction method consistently outperforms\nstate-of-the-art models on multiple medical Q\\&A benchmarks, but also confirms\nthat the responses generated include source documentation, significantly\nenhancing the reliability of medical LLMs in practical applications. Code will\nbe at: https://github.com/MedicineToken/Medical-Graph-RAG/tree/main\n","authors":["Junde Wu","Jiayuan Zhu","Yunli Qi"],"pdf_url":"https://arxiv.org/pdf/2408.04187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.11703v3","updated":"2024-08-08T03:09:21Z","published":"2022-02-23T18:58:56Z","title":"Paying U-Attention to Textures: Multi-Stage Hourglass Vision Transformer\n  for Universal Texture Synthesis","summary":"  We present a novel U-Attention vision Transformer for universal texture\nsynthesis. We exploit the natural long-range dependencies enabled by the\nattention mechanism to allow our approach to synthesize diverse textures while\npreserving their structures in a single inference. We propose a hierarchical\nhourglass backbone that attends to the global structure and performs patch\nmapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by\nskip connection and convolution designs that propagate and fuse information at\ndifferent scales, our hierarchical U-Attention architecture unifies attention\nto features from macro structures to micro details, and progressively refines\nsynthesis results at successive stages. Our method achieves stronger 2$\\times$\nsynthesis than previous work on both stochastic and structured textures while\ngeneralizing to unseen textures without fine-tuning. Ablation studies\ndemonstrate the effectiveness of each component of our architecture.\n","authors":["Shouchang Guo","Valentin Deschaintre","Douglas Noll","Arthur Roullier"],"pdf_url":"https://arxiv.org/pdf/2202.11703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04424v2","updated":"2024-08-08T03:01:31Z","published":"2023-12-07T16:49:09Z","title":"Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted\n  Nearby Views","summary":"  Synthesizing multi-view 3D from one single image is a significant but\nchallenging task. Zero-1-to-3 methods have achieved great success by lifting a\n2D latent diffusion model to the 3D scope. The target view image is generated\nwith a single-view source image and the camera pose as condition information.\nHowever, due to the high sparsity of the single input image, Zero-1-to-3 tends\nto produce geometry and appearance inconsistency across views, especially for\ncomplex objects. To tackle this issue, we propose to supply more condition\ninformation for the generation model but in a self-prompt way. A cascade\nframework is constructed with two Zero-1-to-3 models, named Cascade-Zero123,\nwhich progressively extract 3D information from the source image. Specifically,\nseveral nearby views are first generated by the first model and then fed into\nthe second-stage model along with the source image as generation conditions.\nWith amplified self-prompted condition images, our Cascade-Zero123 generates\nmore consistent novel-view images than Zero-1-to-3. Experiment results\ndemonstrate remarkable promotion, especially for various complex and\nchallenging scenes, involving insects, humans, transparent objects, and stacked\nmultiple objects etc. More demos and code are available at\nhttps://cascadezero123.github.io.\n","authors":["Yabo Chen","Jiemin Fang","Yuyang Huang","Taoran Yi","Xiaopeng Zhang","Lingxi Xie","Xinggang Wang","Wenrui Dai","Hongkai Xiong","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2312.04424v2.pdf","comment":"ECCV 2024. Project page: https://cascadezero123.github.io/"},{"id":"http://arxiv.org/abs/2408.03361v2","updated":"2024-08-08T02:43:06Z","published":"2024-08-06T17:59:21Z","title":"GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards\n  General Medical AI","summary":"  Large Vision-Language Models (LVLMs) are capable of handling diverse data\ntypes such as imaging, text, and physiological signals, and can be applied in\nvarious fields. In the medical field, LVLMs have a high potential to offer\nsubstantial assistance for diagnosis and treatment. Before that, it is crucial\nto develop benchmarks to evaluate LVLMs' effectiveness in various medical\napplications. Current benchmarks are often built upon specific academic\nliterature, mainly focusing on a single domain, and lacking varying perceptual\ngranularities. Thus, they face specific challenges, including limited clinical\nrelevance, incomplete evaluations, and insufficient guidance for interactive\nLVLMs. To address these limitations, we developed the GMAI-MMBench, the most\ncomprehensive general medical AI benchmark with well-categorized data structure\nand multi-perceptual granularity to date. It is constructed from 285 datasets\nacross 39 medical image modalities, 18 clinical-related tasks, 18 departments,\nand 4 perceptual granularities in a Visual Question Answering (VQA) format.\nAdditionally, we implemented a lexical tree structure that allows users to\ncustomize evaluation tasks, accommodating various assessment needs and\nsubstantially supporting medical AI research and applications. We evaluated 50\nLVLMs, and the results show that even the advanced GPT-4o only achieves an\naccuracy of 52%, indicating significant room for improvement. Moreover, we\nidentified five key insufficiencies in current cutting-edge LVLMs that need to\nbe addressed to advance the development of better medical applications. We\nbelieve that GMAI-MMBench will stimulate the community to build the next\ngeneration of LVLMs toward GMAI.\n  Project Page: https://uni-medical.github.io/GMAI-MMBench.github.io/\n","authors":["Pengcheng Chen","Jin Ye","Guoan Wang","Yanjun Li","Zhongying Deng","Wei Li","Tianbin Li","Haodong Duan","Ziyan Huang","Yanzhou Su","Benyou Wang","Shaoting Zhang","Bin Fu","Jianfei Cai","Bohan Zhuang","Eric J Seibel","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.03361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19674v4","updated":"2024-08-08T02:39:15Z","published":"2024-07-29T03:30:09Z","title":"Advancing Prompt Learning through an External Layer","summary":"  Prompt learning represents a promising method for adapting pre-trained\nvision-language models (VLMs) to various downstream tasks by learning a set of\ntext embeddings. One challenge inherent to these methods is the poor\ngeneralization performance due to the invalidity of the learned text embeddings\nfor unseen tasks. A straightforward approach to bridge this gap is to freeze\nthe text embeddings in prompts, which results in a lack of capacity to adapt\nVLMs for downstream tasks. To address this dilemma, we propose a paradigm\ncalled EnPrompt with a novel External Layer (EnLa). Specifically, we propose a\ntextual external layer and learnable visual embeddings for adapting VLMs to\ndownstream tasks. The learnable external layer is built upon valid embeddings\nof pre-trained CLIP. This design considers the balance of learning capabilities\nbetween the two branches. To align the textual and visual features, we propose\na novel two-pronged approach: i) we introduce the optimal transport as the\ndiscrepancy metric to align the vision and text modalities, and ii) we\nintroduce a novel strengthening feature to enhance the interaction between\nthese two modalities. Four representative experiments (i.e., base-to-novel\ngeneralization, few-shot learning, cross-dataset generalization, domain shifts\ngeneralization) across 15 datasets demonstrate that our method outperforms the\nexisting prompt learning method.\n","authors":["Fangming Cui","Xun Yang","Chao Wu","Liang Xiao","Xinmei Tian"],"pdf_url":"https://arxiv.org/pdf/2407.19674v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04175v1","updated":"2024-08-08T02:38:19Z","published":"2024-08-08T02:38:19Z","title":"pyBregMan: A Python library for Bregman Manifolds","summary":"  A Bregman manifold is a synonym for a dually flat space in information\ngeometry which admits as a canonical divergence a Bregman divergence. Bregman\nmanifolds are induced by smooth strictly convex functions like the cumulant or\npartition functions of regular exponential families, the negative entropy of\nmixture families, or the characteristic functions of regular cones just to list\na few such convex Bregman generators. We describe the design of pyBregMan, a\nlibrary which implements generic operations on Bregman manifolds and\ninstantiate several common Bregman manifolds used in information sciences. At\nthe core of the library is the notion of Legendre-Fenchel duality inducing a\ncanonical pair of dual potential functions and dual Bregman divergences. The\nlibrary also implements the Fisher-Rao manifolds of categorical/multinomial\ndistributions and multivariate normal distributions. To demonstrate the use of\nthe pyBregMan kernel manipulating those Bregman and Fisher-Rao manifolds, the\nlibrary also provides several core algorithms for various applications in\nstatistics, machine learning, information fusion, and so on.\n","authors":["Frank Nielsen","Alexander Soen"],"pdf_url":"https://arxiv.org/pdf/2408.04175v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2406.07822v2","updated":"2024-08-08T02:36:04Z","published":"2024-06-12T02:43:19Z","title":"Tell Me What's Next: Textual Foresight for Generic UI Representations","summary":"  Mobile app user interfaces (UIs) are rich with action, text, structure, and\nimage content that can be utilized to learn generic UI representations for\ntasks like automating user commands, summarizing content, and evaluating the\naccessibility of user interfaces. Prior work has learned strong visual\nrepresentations with local or global captioning losses, but fails to retain\nboth granularities. To combat this, we propose Textual Foresight, a novel\npretraining objective for learning UI screen representations. Textual Foresight\ngenerates global text descriptions of future UI states given a current UI and\nlocal action taken. Our approach requires joint reasoning over elements and\nentire screens, resulting in improved UI features: on generation tasks, UI\nagents trained with Textual Foresight outperform state-of-the-art by 2% with\n28x fewer images. We train with our newly constructed mobile app dataset,\nOpenApp, which results in the first public dataset for app UI representation\nlearning. OpenApp enables new baselines, and we find Textual Foresight improves\naverage task performance over them by 5.7% while having access to 2x less data.\n","authors":["Andrea Burns","Kate Saenko","Bryan A. Plummer"],"pdf_url":"https://arxiv.org/pdf/2406.07822v2.pdf","comment":"Accepted to ACL 2024 Findings. Data and code to be released at\n  https://github.com/aburns4/textualforesight"},{"id":"http://arxiv.org/abs/2408.04172v1","updated":"2024-08-08T02:34:41Z","published":"2024-08-08T02:34:41Z","title":"MultiColor: Image Colorization by Learning from Multiple Color Spaces","summary":"  Deep networks have shown impressive performance in the image restoration\ntasks, such as image colorization. However, we find that previous approaches\nrely on the digital representation from single color model with a specific\nmapping function, a.k.a., color space, during the colorization pipeline. In\nthis paper, we first investigate the modeling of different color spaces, and\nfind each of them exhibiting distinctive characteristics with unique\ndistribution of colors. The complementarity among multiple color spaces leads\nto benefits for the image colorization task.\n  We present MultiColor, a new learning-based approach to automatically\ncolorize grayscale images that combines clues from multiple color spaces.\nSpecifically, we employ a set of dedicated colorization modules for individual\ncolor space. Within each module, a transformer decoder is first employed to\nrefine color query embeddings and then a color mapper produces color channel\nprediction using the embeddings and semantic features. With these predicted\ncolor channels representing various color spaces, a complementary network is\ndesigned to exploit the complementarity and generate pleasing and reasonable\ncolorized images. We conduct extensive experiments on real-world datasets, and\nthe results demonstrate superior performance over the state-of-the-arts.\n","authors":["Xiangcheng Du","Zhao Zhou","Yanlong Wang","Zhuoyao Wang","Yingbin Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2408.04172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04171v1","updated":"2024-08-08T02:32:48Z","published":"2024-08-08T02:32:48Z","title":"Rotation center identification based on geometric relationships for\n  rotary motion deblurring","summary":"  Non-blind rotary motion deblurring (RMD) aims to recover the latent clear\nimage from a rotary motion blurred (RMB) image. The rotation center is a\ncrucial input parameter in non-blind RMD methods. Existing methods directly\nestimate the rotation center from the RMB image. However they always suffer\nsignificant errors, and the performance of RMD is limited. For the assembled\nimaging systems, the position of the rotation center remains fixed. Leveraging\nthis prior knowledge, we propose a geometric-based method for rotation center\nidentification and analyze its error range. Furthermore, we construct a RMB\nimaging system. The experiment demonstrates that our method achieves less than\n1-pixel error along a single axis (x-axis or y-axis). We utilize the\nconstructed imaging system to capture real RMB images, and experimental results\nshow that our method can help existing RMD approaches yield better RMD images.\n","authors":["Jinhui Qin","Yong Ma","Jun Huang","Fan Fan","You Du"],"pdf_url":"https://arxiv.org/pdf/2408.04171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04170v1","updated":"2024-08-08T02:31:04Z","published":"2024-08-08T02:31:04Z","title":"M2EF-NNs: Multimodal Multi-instance Evidence Fusion Neural Networks for\n  Cancer Survival Prediction","summary":"  Accurate cancer survival prediction is crucial for assisting clinical doctors\nin formulating treatment plans. Multimodal data, including histopathological\nimages and genomic data, offer complementary and comprehensive information that\ncan greatly enhance the accuracy of this task. However, the current methods,\ndespite yielding promising results, suffer from two notable limitations: they\ndo not effectively utilize global context and disregard modal uncertainty. In\nthis study, we put forward a neural network model called M2EF-NNs, which\nleverages multimodal and multi-instance evidence fusion techniques for accurate\ncancer survival prediction. Specifically, to capture global information in the\nimages, we use a pre-trained Vision Transformer (ViT) model to obtain patch\nfeature embeddings of histopathological images. Then, we introduce a multimodal\nattention module that uses genomic embeddings as queries and learns the\nco-attention mapping between genomic and histopathological images to achieve an\nearly interaction fusion of multimodal information and better capture their\ncorrelations. Subsequently, we are the first to apply the Dempster-Shafer\nevidence theory (DST) to cancer survival prediction. We parameterize the\ndistribution of class probabilities using the processed multimodal features and\nintroduce subjective logic to estimate the uncertainty associated with\ndifferent modalities. By combining with the Dempster-Shafer theory, we can\ndynamically adjust the weights of class probabilities after multimodal fusion\nto achieve trusted survival prediction. Finally, Experimental validation on the\nTCGA datasets confirms the significant improvements achieved by our proposed\nmethod in cancer survival prediction and enhances the reliability of the model.\n","authors":["Hui Luo","Jiashuang Huang","Hengrong Ju","Tianyi Zhou","Weiping Ding"],"pdf_url":"https://arxiv.org/pdf/2408.04170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08759v2","updated":"2024-08-08T02:28:17Z","published":"2024-06-13T02:41:11Z","title":"GaussianForest: Hierarchical-Hybrid 3D Gaussian Splatting for Compressed\n  Scene Modeling","summary":"  The field of novel-view synthesis has recently witnessed the emergence of 3D\nGaussian Splatting, which represents scenes in a point-based manner and renders\nthrough rasterization. This methodology, in contrast to Radiance Fields that\nrely on ray tracing, demonstrates superior rendering quality and speed.\nHowever, the explicit and unstructured nature of 3D Gaussians poses a\nsignificant storage challenge, impeding its broader application. To address\nthis challenge, we introduce the Gaussian-Forest modeling framework, which\nhierarchically represents a scene as a forest of hybrid 3D Gaussians. Each\nhybrid Gaussian retains its unique explicit attributes while sharing implicit\nones with its sibling Gaussians, thus optimizing parameterization with\nsignificantly fewer variables. Moreover, adaptive growth and pruning strategies\nare designed, ensuring detailed representation in complex regions and a notable\nreduction in the number of required Gaussians. Extensive experiments\ndemonstrate that Gaussian-Forest not only maintains comparable speed and\nquality but also achieves a compression rate surpassing 10 times, marking a\nsignificant advancement in efficient scene modeling. Codes will be available at\nhttps://github.com/Xian-Bei/GaussianForest.\n","authors":["Fengyi Zhang","Yadan Luo","Tianjun Zhang","Lin Zhang","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2406.08759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01976v2","updated":"2024-08-08T02:15:41Z","published":"2024-08-04T09:44:47Z","title":"Single-Point Supervised High-Resolution Dynamic Network for Infrared\n  Small Target Detection","summary":"  Infrared small target detection (IRSTD) tasks are extremely challenging for\ntwo main reasons: 1) it is difficult to obtain accurate labelling information\nthat is critical to existing methods, and 2) infrared (IR) small target\ninformation is easily lost in deep networks. To address these issues, we\npropose a single-point supervised high-resolution dynamic network (SSHD-Net).\nIn contrast to existing methods, we achieve state-of-the-art (SOTA) detection\nperformance using only single-point supervision. Specifically, we first design\na high-resolution cross-feature extraction module (HCEM), that achieves\nbi-directional feature interaction through stepped feature cascade channels\n(SFCC). It balances network depth and feature resolution to maintain deep IR\nsmall-target information. Secondly, the effective integration of global and\nlocal features is achieved through the dynamic coordinate fusion module (DCFM),\nwhich enhances the anti-interference ability in complex backgrounds. In\naddition, we introduce the high-resolution multilevel residual module (HMRM) to\nenhance the semantic information extraction capability. Finally, we design the\nadaptive target localization detection head (ATLDH) to improve detection\naccuracy. Experiments on the publicly available datasets NUDT-SIRST and\nIRSTD-1k demonstrate the effectiveness of our method. Compared to other SOTA\nmethods, our method can achieve better detection performance with only a single\npoint of supervision.\n","authors":["Jing Wu","Rixiang Ni","Feng Huang","Zhaobing Qiu","Liqiong Chen","Changhai Luo","Yunxiang Li","Youli Li"],"pdf_url":"https://arxiv.org/pdf/2408.01976v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04158v1","updated":"2024-08-08T02:03:10Z","published":"2024-08-08T02:03:10Z","title":"Efficient Single Image Super-Resolution with Entropy Attention and\n  Receptive Field Augmentation","summary":"  Transformer-based deep models for single image super-resolution (SISR) have\ngreatly improved the performance of lightweight SISR tasks in recent years.\nHowever, they often suffer from heavy computational burden and slow inference\ndue to the complex calculation of multi-head self-attention (MSA), seriously\nhindering their practical application and deployment. In this work, we present\nan efficient SR model to mitigate the dilemma between model efficiency and SR\nperformance, which is dubbed Entropy Attention and Receptive Field Augmentation\nnetwork (EARFA), and composed of a novel entropy attention (EA) and a shifting\nlarge kernel attention (SLKA). From the perspective of information theory, EA\nincreases the entropy of intermediate features conditioned on a Gaussian\ndistribution, providing more informative input for subsequent reasoning. On the\nother hand, SLKA extends the receptive field of SR models with the assistance\nof channel shifting, which also favors to boost the diversity of hierarchical\nfeatures. Since the implementation of EA and SLKA does not involve complex\ncomputations (such as extensive matrix multiplications), the proposed method\ncan achieve faster nonlinear inference than Transformer-based SR models while\nmaintaining better SR performance. Extensive experiments show that the proposed\nmodel can significantly reduce the delay of model inference while achieving the\nSR performance comparable with other advanced models.\n","authors":["Xiaole Zhao","Linze Li","Chengxing Xie","Xiaoming Zhang","Ting Jiang","Wenjie Lin","Shuaicheng Liu","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2408.04158v1.pdf","comment":"Accepted to ACM MM 2024"},{"id":"http://arxiv.org/abs/2406.01916v2","updated":"2024-08-08T01:50:52Z","published":"2024-06-04T02:57:09Z","title":"FastLGS: Speeding up Language Embedded Gaussians with Feature Grid\n  Mapping","summary":"  The semantically interactive radiance field has always been an appealing task\nfor its potential to facilitate user-friendly and automated real-world 3D scene\nunderstanding applications. However, it is a challenging task to achieve high\nquality, efficiency and zero-shot ability at the same time with semantics in\nradiance fields. In this work, we present FastLGS, an approach that supports\nreal-time open-vocabulary query within 3D Gaussian Splatting (3DGS) under high\nresolution. We propose the semantic feature grid to save multi-view CLIP\nfeatures which are extracted based on Segment Anything Model (SAM) masks, and\nmap the grids to low dimensional features for semantic field training through\n3DGS. Once trained, we can restore pixel-aligned CLIP embeddings through\nfeature grids from rendered features for open-vocabulary queries. Comparisons\nwith other state-of-the-art methods prove that FastLGS can achieve the first\nplace performance concerning both speed and accuracy, where FastLGS is 98x\nfaster than LERF and 4x faster than LangSplat. Meanwhile, experiments show that\nFastLGS is adaptive and compatible with many downstream tasks, such as 3D\nsegmentation and 3D object inpainting, which can be easily applied to other 3D\nmanipulation systems.\n","authors":["Yuzhou Ji","He Zhu","Junshu Tang","Wuyi Liu","Zhizhong Zhang","Yuan Xie","Xin Tan"],"pdf_url":"https://arxiv.org/pdf/2406.01916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04150v1","updated":"2024-08-08T01:31:38Z","published":"2024-08-08T01:31:38Z","title":"Decorrelating Structure via Adapters Makes Ensemble Learning Practical\n  for Semi-supervised Learning","summary":"  In computer vision, traditional ensemble learning methods exhibit either a\nlow training efficiency or the limited performance to enhance the reliability\nof deep neural networks. In this paper, we propose a lightweight,\nloss-function-free, and architecture-agnostic ensemble learning by the\nDecorrelating Structure via Adapters (DSA) for various visual tasks.\nConcretely, the proposed DSA leverages the structure-diverse adapters to\ndecorrelate multiple prediction heads without any tailed regularization or\nloss. This allows DSA to be easily extensible to architecture-agnostic networks\nfor a range of computer vision tasks. Importantly, the theoretically analysis\nshows that the proposed DSA has a lower bias and variance than that of the\nsingle head based method (which is adopted by most of the state of art\napproaches). Consequently, the DSA makes deep networks reliable and robust for\nthe various real-world challenges, \\textit{e.g.}, data corruption, and label\nnoises. Extensive experiments combining the proposed method with FreeMatch\nachieved the accuracy improvements of 5.35% on CIFAR-10 dataset with 40 labeled\ndata and 0.71% on CIFAR-100 dataset with 400 labeled data. Besides, combining\nthe proposed method with DualPose achieved the improvements in the Percentage\nof Correct Keypoints (PCK) by 2.08% on the Sniffing dataset with 100 data (30\nlabeled data), 5.2% on the FLIC dataset with 100 data (including 50 labeled\ndata), and 2.35% on the LSP dataset with 200 data (100 labeled data).\n","authors":["Jiaqi Wu","Junbiao Pang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2408.04150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04145v1","updated":"2024-08-08T01:12:21Z","published":"2024-08-08T01:12:21Z","title":"ComKD-CLIP: Comprehensive Knowledge Distillation for Contrastive\n  Language-Image Pre-traning Model","summary":"  Contrastive Language-Image Pre-training (CLIP) excels in integrating semantic\ninformation between images and text through contrastive learning techniques. It\nhas achieved remarkable performance in various multimodal tasks. However, the\ndeployment of large CLIP models is hindered in resource-limited environments,\nwhile smaller models frequently fall short of meeting performance benchmarks\nnecessary for practical applications. In this paper, we propose a novel\napproach, coined as ComKD-CLIP: Comprehensive Knowledge Distillation for\nContrastive Language-Image Pre-traning Model, which aims to comprehensively\ndistill the knowledge from a large teacher CLIP model into a smaller student\nmodel, ensuring comparable performance with significantly reduced parameters.\nComKD-CLIP is composed of two key mechanisms: Image Feature Alignment (IFAlign)\nand Educational Attention (EduAttention). IFAlign makes the image features\nextracted by the student model closely match those extracted by the teacher\nmodel, enabling the student to learn teacher's knowledge of extracting image\nfeatures. EduAttention explores the cross-relationships between text features\nextracted by the teacher model and image features extracted by the student\nmodel, enabling the student model to learn how the teacher model integrates\ntext-image features. In addition, ComKD-CLIP can refine the knowledge distilled\nfrom IFAlign and EduAttention leveraging the results of text-image feature\nfusion by the teacher model, ensuring student model accurately absorbs the\nknowledge of teacher model. Extensive experiments conducted on 11 datasets have\ndemonstrated the superiority of the proposed method.\n","authors":["Yifan Chen","Xiaozhen Qiao","Zhe Sun","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.04145v1.pdf","comment":"first submit"},{"id":"http://arxiv.org/abs/2408.04144v1","updated":"2024-08-08T01:07:28Z","published":"2024-08-08T01:07:28Z","title":"Integrated Dynamic Phenological Feature for Remote Sensing Image Land\n  Cover Change Detection","summary":"  Remote sensing image change detection (CD) is essential for analyzing land\nsurface changes over time, with a significant challenge being the\ndifferentiation of actual changes from complex scenes while filtering out\npseudo-changes. A primary contributor to this challenge is the intra-class\ndynamic changes due to phenological characteristics in natural areas. To\novercome this, we introduce the InPhea model, which integrates phenological\nfeatures into a remote sensing image CD framework. The model features a\ndetector with a differential attention module for improved feature\nrepresentation of change information, coupled with high-resolution feature\nextraction and spatial pyramid blocks to enhance performance. Additionally, a\nconstrainer with four constraint modules and a multi-stage contrastive learning\napproach is employed to aid in the model's understanding of phenological\ncharacteristics. Experiments on the HRSCD, SECD, and PSCD-Wuhan datasets reveal\nthat InPhea outperforms other models, confirming its effectiveness in\naddressing phenological pseudo-changes and its overall model superiority.\n","authors":["Yi Liu","Chenhao Sun","Hao Ye","Xiangying Liu","Weilong Ju"],"pdf_url":"https://arxiv.org/pdf/2408.04144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16043v2","updated":"2024-08-08T00:54:09Z","published":"2023-11-27T18:07:58Z","title":"Relightable 3D Gaussians: Realistic Point Cloud Relighting with BRDF\n  Decomposition and Ray Tracing","summary":"  In this paper, we present a novel differentiable point-based rendering\nframework to achieve photo-realistic relighting. To make the reconstructed\nscene relightable, we enhance vanilla 3D Gaussians by associating extra\nproperties, including normal vectors, BRDF parameters, and incident lighting\nfrom various directions. From a collection of multi-view images, the 3D scene\nis optimized through 3D Gaussian Splatting while BRDF and lighting are\ndecomposed by physically based differentiable rendering. To produce plausible\nshadow effects in photo-realistic relighting, we introduce an innovative\npoint-based ray tracing with the bounding volume hierarchies for efficient\nvisibility pre-computation. Extensive experiments demonstrate our improved BRDF\nestimation, novel view synthesis and relighting results compared to\nstate-of-the-art approaches. The proposed framework showcases the potential to\nrevolutionize the mesh-based graphics pipeline with a point-based pipeline\nenabling editing, tracing, and relighting.\n","authors":["Jian Gao","Chun Gu","Youtian Lin","Zhihao Li","Hao Zhu","Xun Cao","Li Zhang","Yao Yao"],"pdf_url":"https://arxiv.org/pdf/2311.16043v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.09340v4","updated":"2024-08-08T00:30:35Z","published":"2023-03-16T14:21:45Z","title":"Improving Automated Hemorrhage Detection in Sparse-view Computed\n  Tomography via Deep Convolutional Neural Network based Artifact Reduction","summary":"  This is a preprint. The latest version has been published here:\nhttps://pubs.rsna.org/doi/10.1148/ryai.230275\n  Purpose: Sparse-view computed tomography (CT) is an effective way to reduce\ndose by lowering the total number of views acquired, albeit at the expense of\nimage quality, which, in turn, can impact the ability to detect diseases. We\nexplore deep learning-based artifact reduction in sparse-view cranial CT scans\nand its impact on automated hemorrhage detection. Methods: We trained a U-Net\nfor artefact reduction on simulated sparse-view cranial CT scans from 3000\npatients obtained from a public dataset and reconstructed with varying levels\nof sub-sampling. Additionally, we trained a convolutional neural network on\nfully sampled CT data from 17,545 patients for automated hemorrhage detection.\nWe evaluated the classification performance using the area under the receiver\noperator characteristic curves (AUC-ROCs) with corresponding 95% confidence\nintervals (CIs) and the DeLong test, along with confusion matrices. The\nperformance of the U-Net was compared to an analytical approach based on total\nvariation (TV). Results: The U-Net performed superior compared to unprocessed\nand TV-processed images with respect to image quality and automated hemorrhage\ndiagnosis. With U-Net post-processing, the number of views can be reduced from\n4096 (AUC-ROC: 0.974; 95% CI: 0.972-0.976) views to 512 views (0.973;\n0.971-0.975) with minimal decrease in hemorrhage detection (P<.001) and to 256\nviews (0.967; 0.964-0.969) with a slight performance decrease (P<.001).\nConclusion: The results suggest that U-Net based artifact reduction\nsubstantially enhances automated hemorrhage detection in sparse-view cranial\nCTs. Our findings highlight that appropriate post-processing is crucial for\noptimal image quality and diagnostic accuracy while minimizing radiation dose.\n","authors":["Johannes Thalhammer","Manuel Schultheiss","Tina Dorosti","Tobias Lasser","Franz Pfeiffer","Daniela Pfeiffer","Florian Schaff"],"pdf_url":"https://arxiv.org/pdf/2303.09340v4.pdf","comment":"11 pages, 6 figures, 1 table"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2408.04619v1","updated":"2024-08-08T17:49:07Z","published":"2024-08-08T17:49:07Z","title":"Transformer Explainer: Interactive Learning of Text-Generative Models","summary":"  Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.\n","authors":["Aeree Cho","Grace C. Kim","Alexander Karpekov","Alec Helbling","Zijie J. Wang","Seongmin Lee","Benjamin Hoover","Duen Horng Chau"],"pdf_url":"https://arxiv.org/pdf/2408.04619v1.pdf","comment":"To be presented at IEEE VIS 2024"},{"id":"http://arxiv.org/abs/2408.04614v1","updated":"2024-08-08T17:42:32Z","published":"2024-08-08T17:42:32Z","title":"Better Alignment with Instruction Back-and-Forth Translation","summary":"  We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.\n","authors":["Thao Nguyen","Jeffrey Li","Sewoong Oh","Ludwig Schmidt","Jason Weston","Luke Zettlemoyer","Xian Li"],"pdf_url":"https://arxiv.org/pdf/2408.04614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04607v1","updated":"2024-08-08T17:27:29Z","published":"2024-08-08T17:27:29Z","title":"Risk and cross validation in ridge regression with correlated samples","summary":"  Recent years have seen substantial advances in our understanding of\nhigh-dimensional ridge regression, but existing theories assume that training\nexamples are independent. By leveraging recent techniques from random matrix\ntheory and free probability, we provide sharp asymptotics for the in- and\nout-of-sample risks of ridge regression when the data points have arbitrary\ncorrelations. We demonstrate that in this setting, the generalized cross\nvalidation estimator (GCV) fails to correctly predict the out-of-sample risk.\nHowever, in the case where the noise residuals have the same correlations as\nthe data points, one can modify the GCV to yield an efficiently-computable\nunbiased estimator that concentrates in the high-dimensional limit, which we\ndub CorrGCV. We further extend our asymptotic analysis to the case where the\ntest point has nontrivial correlations with the training set, a setting often\nencountered in time series forecasting. Assuming knowledge of the correlation\nstructure of the time series, this again yields an extension of the GCV\nestimator, and sharply characterizes the degree to which such test points yield\nan overly optimistic prediction of long-time risk. We validate the predictions\nof our theory across a variety of high dimensional data.\n","authors":["Alexander Atanasov","Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2408.04607v1.pdf","comment":"44 pages, 18 figures"},{"id":"http://arxiv.org/abs/2408.04595v1","updated":"2024-08-08T17:11:36Z","published":"2024-08-08T17:11:36Z","title":"Inference with the Upper Confidence Bound Algorithm","summary":"  In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.\n","authors":["Koulik Khamaru","Cun-Hui Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.04595v1.pdf","comment":"17 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.04590v1","updated":"2024-08-08T17:01:26Z","published":"2024-08-08T17:01:26Z","title":"Learn To Learn More Precisely","summary":"  Meta-learning has been extensively applied in the domains of few-shot\nlearning and fast adaptation, achieving remarkable performance. While\nMeta-learning methods like Model-Agnostic Meta-Learning (MAML) and its variants\nprovide a good set of initial parameters for the model, the model still tends\nto learn shortcut features, which leads to poor generalization. In this paper,\nwe propose the formal conception of \"learn to learn more precisely\", which aims\nto make the model learn precise target knowledge from data and reduce the\neffect of noisy knowledge, such as background and noise. To achieve this\ntarget, we proposed a simple and effective meta-learning framework named Meta\nSelf-Distillation(MSD) to maximize the consistency of learned knowledge,\nenhancing the models' ability to learn precise target knowledge. In the inner\nloop, MSD uses different augmented views of the same support data to update the\nmodel respectively. Then in the outer loop, MSD utilizes the same query data to\noptimize the consistency of learned knowledge, enhancing the model's ability to\nlearn more precisely. Our experiment demonstrates that MSD exhibits remarkable\nperformance in few-shot classification tasks in both standard and augmented\nscenarios, effectively boosting the accuracy and consistency of knowledge\nlearned by the model.\n","authors":["Runxi Cheng","Yongxian Wei","Xianglong He","Wanyun Zhu","Songsong Huang","Fei Richard Yu","Fei Ma","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2408.04590v1.pdf","comment":"10pages,4 figures, meta learning"},{"id":"http://arxiv.org/abs/2401.12731v2","updated":"2024-08-08T16:56:42Z","published":"2024-01-23T13:04:02Z","title":"The Distributional Uncertainty of the SHAP score in Explainable Machine\n  Learning","summary":"  Attribution scores reflect how important the feature values in an input\nentity are for the output of a machine learning model. One of the most popular\nattribution scores is the SHAP score, which is an instantiation of the general\nShapley value used in coalition game theory. The definition of this score\nrelies on a probability distribution on the entity population. Since the exact\ndistribution is generally unknown, it needs to be assigned subjectively or be\nestimated from data, which may lead to misleading feature scores. In this\npaper, we propose a principled framework for reasoning on SHAP scores under\nunknown entity population distributions. In our framework, we consider an\nuncertainty region that contains the potential distributions, and the SHAP\nscore of a feature becomes a function defined over this region. We study the\nbasic problems of finding maxima and minima of this function, which allows us\nto determine tight ranges for the SHAP scores of all features. In particular,\nwe pinpoint the complexity of these problems, and other related ones, showing\nthem to be NP-complete. Finally, we present experiments on a real-world\ndataset, showing that our framework may contribute to a more robust feature\nscoring.\n","authors":["Santiago Cifuentes","Leopoldo Bertossi","Nina Pardal","Sergio Abriola","Maria Vanina Martinez","Miguel Romero"],"pdf_url":"https://arxiv.org/pdf/2401.12731v2.pdf","comment":"In ECAI 2024 proceedings"},{"id":"http://arxiv.org/abs/2408.04586v1","updated":"2024-08-08T16:56:03Z","published":"2024-08-08T16:56:03Z","title":"Sampling for View Synthesis: From Local Light Field Fusion to Neural\n  Radiance Fields and Beyond","summary":"  Capturing and rendering novel views of complex real-world scenes is a\nlong-standing problem in computer graphics and vision, with applications in\naugmented and virtual reality, immersive experiences and 3D photography. The\nadvent of deep learning has enabled revolutionary advances in this area,\nclassically known as image-based rendering. However, previous approaches\nrequire intractably dense view sampling or provide little or no guidance for\nhow users should sample views of a scene to reliably render high-quality novel\nviews. Local light field fusion proposes an algorithm for practical view\nsynthesis from an irregular grid of sampled views that first expands each\nsampled view into a local light field via a multiplane image scene\nrepresentation, then renders novel views by blending adjacent local light\nfields. Crucially, we extend traditional plenoptic sampling theory to derive a\nbound that specifies precisely how densely users should sample views of a given\nscene when using our algorithm. We achieve the perceptual quality of Nyquist\nrate view sampling while using up to 4000x fewer views. Subsequent developments\nhave led to new scene representations for deep learning with view synthesis,\nnotably neural radiance fields, but the problem of sparse view synthesis from a\nsmall number of images has only grown in importance. We reprise some of the\nrecent results on sparse and even single image view synthesis, while posing the\nquestion of whether prescriptive sampling guidelines are feasible for the new\ngeneration of image-based rendering algorithms.\n","authors":["Ravi Ramamoorthi"],"pdf_url":"https://arxiv.org/pdf/2408.04586v1.pdf","comment":"Article written for Frontiers of Science Award, International\n  Congress on Basic Science, 2024"},{"id":"http://arxiv.org/abs/2408.04583v1","updated":"2024-08-08T16:48:33Z","published":"2024-08-08T16:48:33Z","title":"Unveiling the Power of Sparse Neural Networks for Feature Selection","summary":"  Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient\nfeature selection. Leveraging the dynamic sparse training (DST) algorithms\nwithin SNNs has demonstrated promising feature selection capabilities while\ndrastically reducing computational overheads. Despite these advancements,\nseveral critical aspects remain insufficiently explored for feature selection.\nQuestions persist regarding the choice of the DST algorithm for network\ntraining, the choice of metric for ranking features/neurons, and the\ncomparative performance of these methods across diverse datasets when compared\nto dense networks. This paper addresses these gaps by presenting a\ncomprehensive systematic analysis of feature selection with sparse neural\nnetworks. Moreover, we introduce a novel metric considering sparse neural\nnetwork characteristics, which is designed to quantify feature importance\nwithin the context of SNNs. Our findings show that feature selection with SNNs\ntrained with DST algorithms can achieve, on average, more than $50\\%$ memory\nand $55\\%$ FLOPs reduction compared to the dense networks, while outperforming\nthem in terms of the quality of the selected features. Our code and the\nsupplementary material are available on GitHub\n(\\url{https://github.com/zahraatashgahi/Neuron-Attribution}).\n","authors":["Zahra Atashgahi","Tennison Liu","Mykola Pechenizkiy","Raymond Veldhuis","Decebal Constantin Mocanu","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2408.04583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00161v2","updated":"2024-08-08T16:31:05Z","published":"2024-07-31T21:12:21Z","title":"Automatic Generation of Behavioral Test Cases For Natural Language\n  Processing Using Clustering and Prompting","summary":"  Recent work in behavioral testing for natural language processing (NLP)\nmodels, such as Checklist, is inspired by related paradigms in software\nengineering testing. They allow evaluation of general linguistic capabilities\nand domain understanding, hence can help evaluate conceptual soundness and\nidentify model weaknesses. However, a major challenge is the creation of test\ncases. The current packages rely on semi-automated approach using manual\ndevelopment which requires domain expertise and can be time consuming. This\npaper introduces an automated approach to develop test cases by exploiting the\npower of large language models and statistical techniques. It clusters the text\nrepresentations to carefully construct meaningful groups and then apply\nprompting techniques to automatically generate Minimal Functionality Tests\n(MFT). The well-known Amazon Reviews corpus is used to demonstrate our\napproach. We analyze the behavioral test profiles across four different\nclassification algorithms and discuss the limitations and strengths of those\nmodels.\n","authors":["Ying Li","Rahul Singh","Tarun Joshi","Agus Sudjianto"],"pdf_url":"https://arxiv.org/pdf/2408.00161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04570v1","updated":"2024-08-08T16:29:09Z","published":"2024-08-08T16:29:09Z","title":"Mathematical Programming For Adaptive Experiments","summary":"  Adaptive experimentation can significantly improve statistical power, but\nstandard algorithms overlook important practical issues including batched and\ndelayed feedback, personalization, non-stationarity, multiple objectives, and\nconstraints. To address these issues, the current algorithm design paradigm\ncrafts tailored methods for each problem instance. Since it is infeasible to\ndevise novel algorithms for every real-world instance, practitioners often have\nto resort to suboptimal approximations that do not address all of their\nchallenges. Moving away from developing bespoke algorithms for each setting, we\npresent a mathematical programming view of adaptive experimentation that can\nflexibly incorporate a wide range of objectives, constraints, and statistical\nprocedures. By formulating a dynamic program in the batched limit, our modeling\nframework enables the use of scalable optimization methods (e.g., SGD and\nauto-differentiation) to solve for treatment allocations. We evaluate our\nframework on benchmarks modeled after practical challenges such as\nnon-stationarity, personalization, multi-objectives, and constraints. Unlike\nbespoke algorithms such as modified variants of Thomson sampling, our\nmathematical programming approach provides remarkably robust performance across\ninstances.\n","authors":["Ethan Che","Daniel R. Jiang","Hongseok Namkoong","Jimmy Wang"],"pdf_url":"https://arxiv.org/pdf/2408.04570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04569v1","updated":"2024-08-08T16:28:56Z","published":"2024-08-08T16:28:56Z","title":"Activation thresholds and expressiveness of polynomial neural networks","summary":"  Polynomial neural networks have been implemented in a range of applications\nand present an advantageous framework for theoretical machine learning. A\npolynomial neural network of fixed architecture and activation degree gives an\nalgebraic map from the network's weights to a set of polynomials. The image of\nthis map is the space of functions representable by the network. Its Zariski\nclosure is an affine variety known as a neurovariety. The dimension of a\npolynomial neural network's neurovariety provides a measure of its\nexpressivity. In this work, we introduce the notion of the activation threshold\nof a network architecture which expresses when the dimension of a neurovariety\nachieves its theoretical maximum. In addition, we prove expressiveness results\nfor polynomial neural networks with equi-width~architectures.\n","authors":["Bella Finkel","Jose Israel Rodriguez","Chenxi Wu","Thomas Yahl"],"pdf_url":"https://arxiv.org/pdf/2408.04569v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2307.02694v3","updated":"2024-08-08T16:24:52Z","published":"2023-07-05T23:53:55Z","title":"Loss Functions and Metrics in Deep Learning","summary":"  When training or evaluating deep learning models, two essential parts are\npicking the proper loss function and deciding on performance metrics. In this\npaper, we provide a comprehensive overview of the most common loss functions\nand metrics used across many different types of deep learning tasks, from\ngeneral tasks such as regression and classification to more specific tasks in\nComputer Vision and Natural Language Processing. We introduce the formula for\neach loss and metric, discuss their strengths and limitations, and describe how\nthese methods can be applied to various problems within deep learning. We hope\nthis work serves as a reference for researchers and practitioners in the field,\nhelping them make informed decisions when selecting the most appropriate loss\nfunction and performance metrics for their deep learning projects.\n","authors":["Juan Terven","Diana M. Cordova-Esparza","Alfonso Ramirez-Pedraza","Edgar A. Chavez-Urbiola","Julio A. Romero-Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2307.02694v3.pdf","comment":"76 pages, 4 figures, 13 tables, 127 equations"},{"id":"http://arxiv.org/abs/2408.04556v1","updated":"2024-08-08T16:13:26Z","published":"2024-08-08T16:13:26Z","title":"Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of\n  Large Language Models","summary":"  Large language models (LLMs) have exhibited remarkable proficiency across a\ndiverse array of natural language processing (NLP) tasks. However, adapting\nLLMs to downstream applications typically necessitates computationally\nintensive and memory-demanding fine-tuning procedures. To mitigate these\nburdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a\npromising approach to tailor LLMs with minimal computational overhead. While\nPEFT methods offer substantial advantages, they do not fully address the\npervasive issue of bias propagation from pre-training data. In this work, we\nintroduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method\ndesigned to counteract bias inheritance. BA-LoRA incorporates three distinct\nregularization terms: (1) consistency regularizer, (2) diversity regularizer,\nand (3) singular vector decomposition regularizer. These regularizers\ncollectively aim to improve the generative models' consistency, diversity, and\ngeneralization capabilities during the fine-tuning process. Through extensive\nexperiments on a variety of natural language understanding (NLU) and natural\nlanguage generation (NLG) tasks, employing prominent LLMs such as LLaMA,\nMistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of\nLoRA and its state-of-the-art variants. Moreover, our method effectively\nmitigates the deleterious effects of pre-training bias, leading to more\nreliable and robust model outputs. The code is available at\nhttps://github.com/cyp-jlu-ai/BA-LoRA.\n","authors":["Yupeng Chang","Yi Chang","Yuan Wu"],"pdf_url":"https://arxiv.org/pdf/2408.04556v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2405.01462v2","updated":"2024-08-08T16:11:33Z","published":"2024-05-02T16:50:47Z","title":"Uncertainty for Active Learning on Graphs","summary":"  Uncertainty Sampling is an Active Learning strategy that aims to improve the\ndata efficiency of machine learning models by iteratively acquiring labels of\ndata points with the highest uncertainty. While it has proven effective for\nindependent data its applicability to graphs remains under-explored. We propose\nthe first extensive study of Uncertainty Sampling for node classification: (1)\nWe benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a\nsignificant performance gap to other Active Learning strategies. (2) We develop\nground-truth Bayesian uncertainty estimates in terms of the data generating\nprocess and prove their effectiveness in guiding Uncertainty Sampling toward\noptimal queries. We confirm our results on synthetic data and design an\napproximate approach that consistently outperforms other uncertainty estimators\non real datasets. (3) Based on this analysis, we relate pitfalls in modeling\nuncertainty to existing methods. Our analysis enables and informs the\ndevelopment of principled uncertainty estimation on graphs.\n","authors":["Dominik Fuchsgruber","Tom Wollschläger","Bertrand Charpentier","Antonio Oroz","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2405.01462v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01561v3","updated":"2024-08-08T16:00:01Z","published":"2024-06-03T17:44:11Z","title":"Long and Short Guidance in Score identity Distillation for One-Step\n  Text-to-Image Generation","summary":"  Diffusion-based text-to-image generation models trained on extensive\ntext-image pairs have shown the capacity to generate photorealistic images\nconsistent with textual descriptions. However, a significant limitation of\nthese models is their slow sample generation, which requires iterative\nrefinement through the same network. In this paper, we enhance Score identity\nDistillation (SiD) by developing long and short classifier-free guidance (LSG)\nto efficiently distill pretrained Stable Diffusion models without using real\ntraining data. SiD aims to optimize a model-based explicit score matching loss,\nutilizing a score-identity-based approximation alongside the proposed LSG for\npractical computation. By training exclusively with fake images synthesized\nwith its one-step generator, SiD equipped with LSG rapidly improves FID and\nCLIP scores, achieving state-of-the-art FID performance while maintaining a\ncompetitive CLIP score. Specifically, its data-free distillation of Stable\nDiffusion 1.5 achieves a record low FID of 8.15 on the COCO-2014 validation\nset, with a CLIP score of 0.304 at an LSG scale of 1.5, and an FID of 9.56 with\na CLIP score of 0.313 at an LSG scale of 2. Our code and distilled one-step\ntext-to-image generators are available at\nhttps://github.com/mingyuanzhou/SiD-LSG.\n","authors":["Mingyuan Zhou","Zhendong Wang","Huangjie Zheng","Hai Huang"],"pdf_url":"https://arxiv.org/pdf/2406.01561v3.pdf","comment":"Code and model checkpoints available at\n  https://github.com/mingyuanzhou/SiD-LSG"},{"id":"http://arxiv.org/abs/2408.04543v1","updated":"2024-08-08T15:50:03Z","published":"2024-08-08T15:50:03Z","title":"Quantum Machine Learning: Performance and Security Implications in\n  Real-World Applications","summary":"  Quantum computing has garnered significant attention in recent years from\nboth academia and industry due to its potential to achieve a \"quantum\nadvantage\" over classical computers. The advent of quantum computing introduces\nnew challenges for security and privacy. This poster explores the performance\nand security implications of quantum computing through a case study of machine\nlearning in a real-world application. We compare the performance of quantum\nmachine learning (QML) algorithms to their classical counterparts using the\nAlzheimer's disease dataset. Our results indicate that QML algorithms show\npromising potential while they still have not surpassed classical algorithms in\nterms of learning capability and convergence difficulty, and running quantum\nalgorithms through simulations on classical computers requires significantly\nlarge memory space and CPU time. Our study also indicates that QMLs have\ninherited vulnerabilities from classical machine learning algorithms while also\nintroduce new attack vectors.\n","authors":["Zhengping Jay Luo","Tyler Stewart","Mourya Narasareddygari","Rui Duan","Shangqing Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.04543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03508v2","updated":"2024-08-08T15:37:19Z","published":"2024-08-07T02:19:17Z","title":"Autonomous, Self-driving Multi-Step Growth of Semiconductor\n  Heterostructures Guided by Machine Learning","summary":"  The semiconductor industry has prioritized automating repetitive tasks by\nclosed-loop, autonomous experimentation which enables accelerated optimization\nof complex multi-step processes. The emergence of machine learning (ML) has\nushered in automated process with minimal human intervention. In this work, we\ndevelop SemiEpi, a self-driving automation platform capable of executing\nmolecular beam epitaxy (MBE) growth with multi-steps, continuous in-situ\nmonitoring, and on-the-fly feedback control. By integrating standard hardware,\nhomemade software, curve fitting, and multiple ML models, SemiEpi operates\nautonomously, eliminating the need for extensive expertise in MBE processes to\nachieve optimal outcomes. The platform actively learns from previous\nexperimental results, identifying favorable conditions and proposing new\nexperiments to achieve the desired results. We standardize and optimize growth\nfor InAs/GaAs quantum dots (QDs) heterostructures to showcase the power of\nML-guided multi-step growth. A temperature calibration was implemented to get\nthe initial growth condition, and fine control of the process was executed\nusing ML. Leveraging RHEED movies acquired during the growth, SemiEpi\nsuccessfully identified and optimized a novel route for multi-step\nheterostructure growth. This work demonstrates the capabilities of closed-loop,\nML-guided systems in addressing challenges in multi-step growth for any device.\nOur method is critical to achieve repeatable materials growth using\ncommercially scalable tools. Our strategy facilitates the development of a\nhardware-independent process and enhancing process repeatability and stability,\neven without exhaustive knowledge of growth parameters.\n","authors":["Chao Shen","Wenkang Zhan","Hongyu Sun","Kaiyao Xin","Bo Xu","Zhanguo Wang","Chao Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.03508v2.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2408.04532v1","updated":"2024-08-08T15:33:02Z","published":"2024-08-08T15:33:02Z","title":"How Transformers Utilize Multi-Head Attention in In-Context Learning? A\n  Case Study on Sparse Linear Regression","summary":"  Despite the remarkable success of transformer-based models in various\nreal-world tasks, their underlying mechanisms remain poorly understood. Recent\nstudies have suggested that transformers can implement gradient descent as an\nin-context learner for linear regression problems and have developed various\ntheoretical analyses accordingly. However, these works mostly focus on the\nexpressive power of transformers by designing specific parameter constructions,\nlacking a comprehensive understanding of their inherent working mechanisms\npost-training. In this study, we consider a sparse linear regression problem\nand investigate how a trained multi-head transformer performs in-context\nlearning. We experimentally discover that the utilization of multi-heads\nexhibits different patterns across layers: multiple heads are utilized and\nessential in the first layer, while usually only a single head is sufficient\nfor subsequent layers. We provide a theoretical explanation for this\nobservation: the first layer preprocesses the context data, and the following\nlayers execute simple optimization steps based on the preprocessed context.\nMoreover, we demonstrate that such a preprocess-then-optimize algorithm can\nsignificantly outperform naive gradient descent and ridge regression\nalgorithms. Further experimental results support our explanations. Our findings\noffer insights into the benefits of multi-head attention and contribute to\nunderstanding the more intricate mechanisms hidden within trained transformers.\n","authors":["Xingwu Chen","Lei Zhao","Difan Zou"],"pdf_url":"https://arxiv.org/pdf/2408.04532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04531v1","updated":"2024-08-08T15:32:12Z","published":"2024-08-08T15:32:12Z","title":"AExGym: Benchmarks and Environments for Adaptive Experimentation","summary":"  Innovations across science and industry are evaluated using randomized trials\n(a.k.a. A/B tests). While simple and robust, such static designs are\ninefficient or infeasible for testing many hypotheses. Adaptive designs can\ngreatly improve statistical power in theory, but they have seen limited\nadoption due to their fragility in practice. We present a benchmark for\nadaptive experimentation based on real-world datasets, highlighting prominent\npractical challenges to operationalizing adaptivity: non-stationarity,\nbatched/delayed feedback, multiple outcomes and objectives, and external\nvalidity. Our benchmark aims to spur methodological development that puts\npractical performance (e.g., robustness) as a central concern, rather than\nmathematical guarantees on contrived instances. We release an open source\nlibrary, AExGym, which is designed with modularity and extensibility in mind to\nallow experimentation practitioners to develop custom environments and\nalgorithms.\n","authors":["Jimmy Wang","Ethan Che","Daniel R. Jiang","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2408.04531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04526v1","updated":"2024-08-08T15:26:18Z","published":"2024-08-08T15:26:18Z","title":"Hybrid Reinforcement Learning Breaks Sample Size Barriers in Linear MDPs","summary":"  Hybrid Reinforcement Learning (RL), where an agent learns from both an\noffline dataset and online explorations in an unknown environment, has garnered\nsignificant recent interest. A crucial question posed by Xie et al. (2022) is\nwhether hybrid RL can improve upon the existing lower bounds established in\npurely offline and purely online RL without relying on the single-policy\nconcentrability assumption. While Li et al. (2023) provided an affirmative\nanswer to this question in the tabular PAC RL case, the question remains\nunsettled for both the regret-minimizing RL case and the non-tabular case.\n  In this work, building upon recent advancements in offline RL and\nreward-agnostic exploration, we develop computationally efficient algorithms\nfor both PAC and regret-minimizing RL with linear function approximation,\nwithout single-policy concentrability. We demonstrate that these algorithms\nachieve sharper error or regret bounds that are no worse than, and can improve\non, the optimal sample complexity in offline RL (the first algorithm, for PAC\nRL) and online RL (the second algorithm, for regret-minimizing RL) in linear\nMarkov decision processes (MDPs), regardless of the quality of the behavior\npolicy. To our knowledge, this work establishes the tightest theoretical\nguarantees currently available for hybrid RL in linear MDPs.\n","authors":["Kevin Tan","Wei Fan","Yuting Wei"],"pdf_url":"https://arxiv.org/pdf/2408.04526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04520v1","updated":"2024-08-08T15:21:07Z","published":"2024-08-08T15:21:07Z","title":"Advancing Molecular Machine (Learned) Representations with\n  Stereoelectronics-Infused Molecular Graphs","summary":"  Molecular representation is a foundational element in our understanding of\nthe physical world. Its importance ranges from the fundamentals of chemical\nreactions to the design of new therapies and materials. Previous molecular\nmachine learning models have employed strings, fingerprints, global features,\nand simple molecular graphs that are inherently information-sparse\nrepresentations. However, as the complexity of prediction tasks increases, the\nmolecular representation needs to encode higher fidelity information. This work\nintroduces a novel approach to infusing quantum-chemical-rich information into\nmolecular graphs via stereoelectronic effects. We show that the explicit\naddition of stereoelectronic interactions significantly improves the\nperformance of molecular machine learning models. Furthermore,\nstereoelectronics-infused representations can be learned and deployed with a\ntailored double graph neural network workflow, enabling its application to any\ndownstream molecular machine learning task. Finally, we show that the learned\nrepresentations allow for facile stereoelectronic evaluation of previously\nintractable systems, such as entire proteins, opening new avenues of molecular\ndesign.\n","authors":["Daniil A. Boiko","Thiago Reschützegger","Benjamin Sanchez-Lengeling","Samuel M. Blau","Gabe Gomes"],"pdf_url":"https://arxiv.org/pdf/2408.04520v1.pdf","comment":"23 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.16677v2","updated":"2024-08-08T15:02:13Z","published":"2024-03-25T12:14:48Z","title":"FOOL: Addressing the Downlink Bottleneck in Satellite Computing with\n  Neural Feature Compression","summary":"  Nanosatellite constellations equipped with sensors capturing large geographic\nregions provide unprecedented opportunities for Earth observation. As\nconstellation sizes increase, network contention poses a downlink bottleneck.\nOrbital Edge Computing (OEC) leverages limited onboard compute resources to\nreduce transfer costs by processing the raw captures at the source. However,\ncurrent solutions have limited practicability due to reliance on crude\nfiltering methods or over-prioritizing particular downstream tasks.\n  This work presents FOOL, an OEC-native and task-agnostic feature compression\nmethod that preserves prediction performance. FOOL partitions high-resolution\nsatellite imagery to maximize throughput. Further, it embeds context and\nleverages inter-tile dependencies to lower transfer costs with negligible\noverhead. While FOOL is a feature compressor, it can recover images with\ncompetitive scores on quality measures at lower bitrates. We extensively\nevaluate transfer cost reduction by including the peculiarity of intermittently\navailable network connections in low earth orbit. Lastly, we test the\nfeasibility of our system for standardized nanosatellite form factors. We\ndemonstrate that FOOL permits downlinking over 100x the data volume without\nrelying on prior information on the downstream tasks.\n","authors":["Alireza Furutanpey","Qiyang Zhang","Philipp Raith","Tobias Pfandzelter","Shangguang Wang","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2403.16677v2.pdf","comment":"18 pages, double column, 19 figures, 7 tables, Revision 1"},{"id":"http://arxiv.org/abs/2408.04499v1","updated":"2024-08-08T14:50:48Z","published":"2024-08-08T14:50:48Z","title":"Knowledge-Aided Semantic Communication Leveraging Probabilistic\n  Graphical Modeling","summary":"  In this paper, we propose a semantic communication approach based on\nprobabilistic graphical model (PGM). The proposed approach involves\nconstructing a PGM from a training dataset, which is then shared as common\nknowledge between the transmitter and receiver. We evaluate the importance of\nvarious semantic features and present a PGM-based compression algorithm\ndesigned to eliminate predictable portions of semantic information.\nFurthermore, we introduce a technique to reconstruct the discarded semantic\ninformation at the receiver end, generating approximate results based on the\nPGM. Simulation results indicate a significant improvement in transmission\nefficiency over existing methods, while maintaining the quality of the\ntransmitted images.\n","authors":["Haowen Wan","Qianqian Yang","Jiancheng Tang","Zhiguo shi"],"pdf_url":"https://arxiv.org/pdf/2408.04499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04498v1","updated":"2024-08-08T14:46:01Z","published":"2024-08-08T14:46:01Z","title":"Model-Based Transfer Learning for Contextual Reinforcement Learning","summary":"  Deep reinforcement learning is a powerful approach to complex decision\nmaking. However, one issue that limits its practical application is its\nbrittleness, sometimes failing to train in the presence of small changes in the\nenvironment. This work is motivated by the empirical observation that directly\napplying an already trained model to a related task often works remarkably\nwell, also called zero-shot transfer. We take this practical trick one step\nfurther to consider how to systematically select good tasks to train,\nmaximizing overall performance across a range of tasks. Given the high cost of\ntraining, it is critical to choose a small set of training tasks. The key idea\nbehind our approach is to explicitly model the performance loss (generalization\ngap) incurred by transferring a trained model. We hence introduce Model-Based\nTransfer Learning (MBTL) for solving contextual RL problems. In this work, we\nmodel the performance loss as a simple linear function of task context\nsimilarity. Furthermore, we leverage Bayesian optimization techniques to\nefficiently model and estimate the unknown training performance of the task\nspace. We theoretically show that the method exhibits regret that is sublinear\nin the number of training tasks and discuss conditions to further tighten\nregret bounds. We experimentally validate our methods using urban traffic and\nstandard control benchmarks. Despite the conceptual simplicity, the\nexperimental results suggest that MBTL can achieve greater performance than\nstrong baselines, including exhaustive training on all tasks, multi-task\ntraining, and random selection of training tasks. This work lays the\nfoundations for investigating explicit modeling of generalization, thereby\nenabling principled yet effective methods for contextual RL.\n","authors":["Jung-Hoon Cho","Vindula Jayawardana","Sirui Li","Cathy Wu"],"pdf_url":"https://arxiv.org/pdf/2408.04498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.13458v3","updated":"2024-08-08T14:26:23Z","published":"2023-03-23T17:26:12Z","title":"Optimization Dynamics of Equivariant and Augmented Neural Networks","summary":"  We investigate the optimization of neural networks on symmetric data, and\ncompare the strategy of constraining the architecture to be equivariant to that\nof using data augmentation. Our analysis reveals that that the relative\ngeometry of the admissible and the equivariant layers, respectively, plays a\nkey role. Under natural assumptions on the data, network, loss, and group of\nsymmetries, we show that compatibility of the spaces of admissible layers and\nequivariant layers, in the sense that the corresponding orthogonal projections\ncommute, implies that the sets of equivariant stationary points are identical\nfor the two strategies. If the linear layers of the network also are given a\nunitary parametrization, the set of equivariant layers is even invariant under\nthe gradient flow for augmented models. Our analysis however also reveals that\neven in the latter situation, stationary points may be unstable for augmented\ntraining although they are stable for the manifestly equivariant models.\n","authors":["Oskar Nordenfors","Fredrik Ohlsson Axel Flinth"],"pdf_url":"https://arxiv.org/pdf/2303.13458v3.pdf","comment":"v3: Completely revised manuscript: New framework for neural nets, new\n  main result (involving compability condition), new experiments, new author.\n  v2: Revised manuscript. Mostly small edits, apart from new experiments (see\n  Appendix E)"},{"id":"http://arxiv.org/abs/2408.04482v1","updated":"2024-08-08T14:19:11Z","published":"2024-08-08T14:19:11Z","title":"SegXAL: Explainable Active Learning for Semantic Segmentation in Driving\n  Scene Scenarios","summary":"  Most of the sophisticated AI models utilize huge amounts of annotated data\nand heavy training to achieve high-end performance. However, there are certain\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\ni.e., inefficient use of unlabeled data, lack of incorporation of human\nexpertise, and lack of interpretation of the results. To mitigate these\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\nand (iii) augment the model decisions in an interpretable way. In particular,\nwe investigate the application of the SegXAL model for semantic segmentation in\ndriving scene scenarios. The SegXAL model proposes the image regions that\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\n(EBU) module to get an Explainable Error Mask, which enables the machine\nteachers/human experts to provide intuitive reasoning behind the results and to\nsolicit feedback to the AI system via an active learning strategy. Such a\nmechanism bridges the semantic gap between man and machine through\ncollaborative intelligence, where humans and AI actively enhance each other's\ncomplementary strengths. A novel high-confidence sample selection technique\nbased on the DICE similarity coefficient is also presented within the SegXAL\nframework. Extensive quantitative and qualitative analyses are carried out in\nthe benchmarking Cityscape dataset. Results show the outperformance of our\nproposed SegXAL against other state-of-the-art models.\n","authors":["Sriram Mandalika","Athira Nambiar"],"pdf_url":"https://arxiv.org/pdf/2408.04482v1.pdf","comment":"17 pages, 7 figures. To appear in the proceedings of the 27th\n  International Conference on Pattern Recognition (ICPR), 01-05 December, 2024,\n  Kolkata, India"},{"id":"http://arxiv.org/abs/2408.04478v1","updated":"2024-08-08T14:08:39Z","published":"2024-08-08T14:08:39Z","title":"NFDI4Health workflow and service for synthetic data generation,\n  assessment and risk management","summary":"  Individual health data is crucial for scientific advancements, particularly\nin developing Artificial Intelligence (AI); however, sharing real patient\ninformation is often restricted due to privacy concerns. A promising solution\nto this challenge is synthetic data generation. This technique creates entirely\nnew datasets that mimic the statistical properties of real data, while\npreserving confidential patient information. In this paper, we present the\nworkflow and different services developed in the context of Germany's National\nData Infrastructure project NFDI4Health. First, two state-of-the-art AI tools\n(namely, VAMBN and MultiNODEs) for generating synthetic health data are\noutlined. Further, we introduce SYNDAT (a public web-based tool) which allows\nusers to visualize and assess the quality and risk of synthetic data provided\nby desired generative models. Additionally, the utility of the proposed methods\nand the web-based tool is showcased using data from Alzheimer's Disease\nNeuroimaging Initiative (ADNI) and the Center for Cancer Registry Data of the\nRobert Koch Institute (RKI).\n","authors":["Sobhan Moazemi","Tim Adams","Hwei Geok NG","Lisa Kühnel","Julian Schneider","Anatol-Fiete Näher","Juliane Fluck","Holger Fröhlich"],"pdf_url":"https://arxiv.org/pdf/2408.04478v1.pdf","comment":"9 pages, 4 figures, accepted for publication in the proceedings of\n  the 69th Annual Conference of the Society for Medical Informatics, Biometry\n  and Epidemiology (GMDS)"},{"id":"http://arxiv.org/abs/2408.03685v2","updated":"2024-08-08T13:52:44Z","published":"2024-08-07T10:53:07Z","title":"RL-ADN: A High-Performance Deep Reinforcement Learning Environment for\n  Optimal Energy Storage Systems Dispatch in Active Distribution Networks","summary":"  Deep Reinforcement Learning (DRL) presents a promising avenue for optimizing\nEnergy Storage Systems (ESSs) dispatch in distribution networks. This paper\nintroduces RL-ADN, an innovative open-source library specifically designed for\nsolving the optimal ESSs dispatch in active distribution networks. RL-ADN\noffers unparalleled flexibility in modeling distribution networks, and ESSs,\naccommodating a wide range of research goals. A standout feature of RL-ADN is\nits data augmentation module, based on Gaussian Mixture Model and Copula (GMC)\nfunctions, which elevates the performance ceiling of DRL agents. Additionally,\nRL-ADN incorporates the Laurent power flow solver, significantly reducing the\ncomputational burden of power flow calculations during training without\nsacrificing accuracy. The effectiveness of RL-ADN is demonstrated using in\ndifferent sizes of distribution networks, showing marked performance\nimprovements in the adaptability of DRL algorithms for ESS dispatch tasks. This\nenhancement is particularly beneficial from the increased diversity of training\nscenarios. Furthermore, RL-ADN achieves a tenfold increase in computational\nefficiency during training, making it highly suitable for large-scale network\napplications. The library sets a new benchmark in DRL-based ESSs dispatch in\ndistribution networks and it is poised to advance DRL applications in\ndistribution network operations significantly. RL-ADN is available at:\nhttps://github.com/ShengrenHou/RL-ADN and\nhttps://github.com/distributionnetworksTUDelft/RL-ADN.\n","authors":["Shengren Hou","Shuyi Gao","Weijie Xia","Edgar Mauricio Salazar Duque","Peter Palensky","Pedro P. Vergara"],"pdf_url":"https://arxiv.org/pdf/2408.03685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04461v1","updated":"2024-08-08T13:42:18Z","published":"2024-08-08T13:42:18Z","title":"Random Walk Diffusion for Efficient Large-Scale Graph Generation","summary":"  Graph generation addresses the problem of generating new graphs that have a\ndata distribution similar to real-world graphs. While previous diffusion-based\ngraph generation methods have shown promising results, they often struggle to\nscale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive\nRandOm Walk Diffusion), a novel random walk-based diffusion approach for\nefficient large-scale graph generation. Our method encompasses two components\nin an iterative process of random walk sampling and graph pruning. We\ndemonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing\nother baseline methods in terms of both generation time and multiple graph\nstatistics, reflecting the high quality of the generated graphs.\n","authors":["Tobias Bernecker","Ghalia Rehawi","Francesco Paolo Casale","Janine Knauer-Arloth","Annalisa Marsico"],"pdf_url":"https://arxiv.org/pdf/2408.04461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04460v1","updated":"2024-08-08T13:39:09Z","published":"2024-08-08T13:39:09Z","title":"An experimental comparative study of backpropagation and alternatives\n  for training binary neural networks for image classification","summary":"  Current artificial neural networks are trained with parameters encoded as\nfloating point numbers that occupy lots of memory space at inference time. Due\nto the increase in the size of deep learning models, it is becoming very\ndifficult to consider training and using artificial neural networks on edge\ndevices. Binary neural networks promise to reduce the size of deep neural\nnetwork models, as well as to increase inference speed while decreasing energy\nconsumption. Thus, they may allow the deployment of more powerful models on\nedge devices. However, binary neural networks are still proven to be difficult\nto train using the backpropagation-based gradient descent scheme. This paper\nextends the work of \\cite{crulis2023alternatives}, which proposed adapting to\nbinary neural networks two promising alternatives to backpropagation originally\ndesigned for continuous neural networks, and experimented with them on simple\nimage classification datasets. This paper proposes new experiments on the\nImageNette dataset, compares three different model architectures for image\nclassification, and adds two additional alternatives to backpropagation.\n","authors":["Ben Crulis","Barthelemy Serres","Cyril de Runz","Gilles Venturini"],"pdf_url":"https://arxiv.org/pdf/2408.04460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13000v2","updated":"2024-08-08T13:33:12Z","published":"2024-03-12T16:25:38Z","title":"Duwak: Dual Watermarks in Large Language Models","summary":"  As large language models (LLM) are increasingly used for text generation\ntasks, it is critical to audit their usages, govern their applications, and\nmitigate their potential harms. Existing watermark techniques are shown\neffective in embedding single human-imperceptible and machine-detectable\npatterns without significantly affecting generated text quality and semantics.\nHowever, the efficiency in detecting watermarks, i.e., the minimum number of\ntokens required to assert detection with significance and robustness against\npost-editing, is still debatable. In this paper, we propose, Duwak, to\nfundamentally enhance the efficiency and quality of watermarking by embedding\ndual secret patterns in both token probability distribution and sampling\nschemes. To mitigate expression degradation caused by biasing toward certain\ntokens, we design a contrastive search to watermark the sampling scheme, which\nminimizes the token repetition and enhances the diversity. We theoretically\nexplain the interdependency of the two watermarks within Duwak. We evaluate\nDuwak extensively on Llama2 under various post-editing attacks, against four\nstate-of-the-art watermarking techniques and combinations of them. Our results\nshow that Duwak marked text achieves the highest watermarked text quality at\nthe lowest required token count for detection, up to 70% tokens less than\nexisting approaches, especially under post paraphrasing.\n","authors":["Chaoyi Zhu","Jeroen Galjaard","Pin-Yu Chen","Lydia Y. Chen"],"pdf_url":"https://arxiv.org/pdf/2403.13000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16449v2","updated":"2024-08-08T13:32:10Z","published":"2024-05-26T06:33:11Z","title":"Reinforcement Learning for Jump-Diffusions, with Financial Applications","summary":"  We study continuous-time reinforcement learning (RL) for stochastic control\nin which system dynamics are governed by jump-diffusion processes. We formulate\nan entropy-regularized exploratory control problem with stochastic policies to\ncapture the exploration--exploitation balance essential for RL. Unlike the pure\ndiffusion case initially studied by Wang et al. (2020), the derivation of the\nexploratory dynamics under jump-diffusions calls for a careful formulation of\nthe jump part. Through a theoretical analysis, we find that one can simply use\nthe same policy evaluation and $q$-learning algorithms in Jia and Zhou (2022a,\n2023), originally developed for controlled diffusions, without needing to check\na priori whether the underlying data come from a pure diffusion or a\njump-diffusion. However, we show that the presence of jumps ought to affect\nparameterizations of actors and critics in general. We investigate as an\napplication the mean--variance portfolio selection problem with stock price\nmodelled as a jump-diffusion, and show that both RL algorithms and\nparameterizations are invariant with respect to jumps. Finally, we present a\ndetailed study on applying the general theory to option hedging.\n","authors":["Xuefeng Gao","Lingfei Li","Xun Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2405.16449v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04442v1","updated":"2024-08-08T13:14:19Z","published":"2024-08-08T13:14:19Z","title":"FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly\n  Detection in Tabular Data","summary":"  The emergence of federated learning (FL) presents a promising approach to\nleverage decentralized data while preserving privacy. Furthermore, the\ncombination of FL and anomaly detection is particularly compelling because it\nallows for detecting rare and critical anomalies (usually also rare in locally\ngathered data) in sensitive data from multiple sources, such as cybersecurity\nand healthcare. However, benchmarking the performance of anomaly detection\nmethods in FL environments remains an underexplored area. This paper introduces\nFedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection\nalgorithms within the context of FL. We systematically analyze and compare the\nperformance of recent deep learning anomaly detection models under federated\nsettings, which were typically assessed solely in centralized settings.\nFedAD-Bench encompasses diverse datasets and metrics to provide a holistic\nevaluation. Through extensive experiments, we identify key challenges such as\nmodel aggregation inefficiencies and metric unreliability. We present insights\ninto FL's regularization effects, revealing scenarios in which it outperforms\ncentralized approaches due to its inherent ability to mitigate overfitting. Our\nwork aims to establish a standardized benchmark to guide future research and\ndevelopment in federated anomaly detection, promoting reproducibility and fair\ncomparison across studies.\n","authors":["Ahmed Anwar","Brian Moser","Dayananda Herurkar","Federico Raue","Vinit Hegiste","Tatjana Legler","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2408.04442v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.04439v1","updated":"2024-08-08T13:10:03Z","published":"2024-08-08T13:10:03Z","title":"Deep Learning for identifying systolic complexes in SCG traces: a\n  cross-dataset analysis","summary":"  The seismocardiographic signal is a promising alternative to the traditional\nECG in the analysis of the cardiac activity. In particular, the systolic\ncomplex is known to be the most informative part of the seismocardiogram, thus\nrequiring further analysis. State-of-art solutions to detect the systolic\ncomplex are based on Deep Learning models, which have been proven effective in\npioneering studies. However, these solutions have only been tested in a\ncontrolled scenario considering only clean signals acquired from users\nmaintained still in supine position. On top of that, all these studies consider\ndata coming from a single dataset, ignoring the benefits and challenges related\nto a cross-dataset scenario. In this work, a cross-dataset experimental\nanalysis was performed considering also data from a real-world scenario. Our\nfindings prove the effectiveness of a deep learning solution, while showing the\nimportance of a personalization step to contrast the domain shift, namely a\nchange in data distribution between training and testing data. Finally, we\ndemonstrate the benefits of a multi-channels approach, leveraging the\ninformation extracted from both accelerometers and gyroscopes data.\n","authors":["Michele Craighero","Sarah Solbiati","Federica Mozzini","Enrico Caiani","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2408.04439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08648v3","updated":"2024-08-08T13:09:51Z","published":"2022-12-16T18:48:54Z","title":"Connecting Permutation Equivariant Neural Networks and Partition\n  Diagrams","summary":"  Permutation equivariant neural networks are often constructed using tensor\npowers of $\\mathbb{R}^{n}$ as their layer spaces. We show that all of the\nweight matrices that appear in these neural networks can be obtained from\nSchur-Weyl duality between the symmetric group and the partition algebra. In\nparticular, we adapt Schur-Weyl duality to derive a simple, diagrammatic method\nfor calculating the weight matrices themselves.\n","authors":["Edward Pearce-Crump"],"pdf_url":"https://arxiv.org/pdf/2212.08648v3.pdf","comment":"ECAI 2024; 16 pages"},{"id":"http://arxiv.org/abs/2310.20609v2","updated":"2024-08-08T12:51:23Z","published":"2023-10-31T16:44:26Z","title":"Graph Matching via convex relaxation to the simplex","summary":"  This paper addresses the Graph Matching problem, which consists of finding\nthe best possible alignment between two input graphs, and has many applications\nin computer vision, network deanonymization and protein alignment. A common\napproach to tackle this problem is through convex relaxations of the NP-hard\n\\emph{Quadratic Assignment Problem} (QAP).\n  Here, we introduce a new convex relaxation onto the unit simplex and develop\nan efficient mirror descent scheme with closed-form iterations for solving this\nproblem. Under the correlated Gaussian Wigner model, we show that the simplex\nrelaxation admits a unique solution with high probability. In the noiseless\ncase, this is shown to imply exact recovery of the ground truth permutation.\nAdditionally, we establish a novel sufficiency condition for the input matrix\nin standard greedy rounding methods, which is less restrictive than the\ncommonly used `diagonal dominance' condition. We use this condition to show\nexact one-step recovery of the ground truth (holding almost surely) via the\nmirror descent scheme, in the noiseless setting. We also use this condition to\nobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.\n2019] in the noiseless setting.\n","authors":["Ernesto Araya Valdivia","Hemant Tyagi"],"pdf_url":"https://arxiv.org/pdf/2310.20609v2.pdf","comment":"We fixed some typos and added Lemma 4. Reference to the published\n  version below"},{"id":"http://arxiv.org/abs/2408.04424v1","updated":"2024-08-08T12:48:54Z","published":"2024-08-08T12:48:54Z","title":"Detection of Animal Movement from Weather Radar using Self-Supervised\n  Learning","summary":"  Detecting flying animals (e.g., birds, bats, and insects) using weather radar\nhelps gain insights into animal movement and migration patterns, aids in\nmanagement efforts (such as biosecurity) and enhances our understanding of the\necosystem.The conventional approach to detecting animals in weather radar\ninvolves thresholding: defining and applying thresholds for the radar\nvariables, based on expert opinion. More recently, Deep Learning approaches\nhave been shown to provide improved performance in detection. However,\nobtaining sufficient labelled weather radar data for flying animals to build\nlearning-based models is time-consuming and labor-intensive. To address the\nchallenge of data labelling, we propose a self-supervised learning method for\ndetecting animal movement. In our proposed method, we pre-train our model on a\nlarge dataset with noisy labels produced by a threshold approach. The key\nadvantage is that the pre-trained dataset size is limited only by the number of\nradar images available. We then fine-tune the model on a small human-labelled\ndataset. Our experiments on Australian weather radar data for waterbird\nsegmentation show that the proposed method outperforms the current state-of-the\nart approach by 43.53% in the dice co-efficient statistic.\n","authors":["Mubin Ul Haque","Joel Janek Dabrowski","Rebecca M. Rogers","Hazel Parry"],"pdf_url":"https://arxiv.org/pdf/2408.04424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04413v1","updated":"2024-08-08T12:40:27Z","published":"2024-08-08T12:40:27Z","title":"Deeploy: Enabling Energy-Efficient Deployment of Small Language Models\n  On Heterogeneous Microcontrollers","summary":"  With the rise of Embodied Foundation Models (EFMs), most notably Small\nLanguage Models (SLMs), adapting Transformers for edge applications has become\na very active field of research. However, achieving end-to-end deployment of\nSLMs on microcontroller (MCU)-class chips without high-bandwidth off-chip main\nmemory access is still an open challenge. In this paper, we demonstrate\nhigh-efficiency end-to-end SLM deployment on a multicore RISC-V (RV32) MCU\naugmented with ML instruction extensions and a hardware neural processing unit\n(NPU). To automate the exploration of the constrained, multi-dimensional memory\nvs. computation tradeoffs involved in aggressive SLM deployment on\nheterogeneous (multicore+NPU) resources, we introduce Deeploy, a novel Deep\nNeural Network (DNN) compiler, which generates highly-optimized C code\nrequiring minimal runtime support. We demonstrate that Deeploy generates\nend-to-end code for executing SLMs, fully exploiting the RV32 cores'\ninstruction extensions and the NPU: We achieve leading-edge energy and\nthroughput of \\SI{490}{\\micro\\joule \\per Token}, at \\SI{340}{Token \\per\n\\second} for an SLM trained on the TinyStories dataset, running for the first\ntime on an MCU-class device without external memory.\n","authors":["Moritz Scherer","Luka Macan","Victor Jung","Philip Wiese","Luca Bompani","Alessio Burrello","Francesco Conti","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2408.04413v1.pdf","comment":"Accepted for publication at ESWEEK - CASES 2024"},{"id":"http://arxiv.org/abs/2406.01661v2","updated":"2024-08-08T12:17:56Z","published":"2024-06-03T17:55:02Z","title":"A Diffusion Model Framework for Unsupervised Neural Combinatorial\n  Optimization","summary":"  Learning to sample from intractable distributions over discrete sets without\nrelying on corresponding training data is a central problem in a wide range of\nfields, including Combinatorial Optimization. Currently, popular deep\nlearning-based approaches rely primarily on generative models that yield exact\nsample likelihoods. This work introduces a method that lifts this restriction\nand opens the possibility to employ highly expressive latent variable models\nlike diffusion models. Our approach is conceptually based on a loss that upper\nbounds the reverse Kullback-Leibler divergence and evades the requirement of\nexact sample likelihoods. We experimentally validate our approach in data-free\nCombinatorial Optimization and demonstrate that our method achieves a new\nstate-of-the-art on a wide range of benchmark problems.\n","authors":["Sebastian Sanokowski","Sepp Hochreiter","Sebastian Lehner"],"pdf_url":"https://arxiv.org/pdf/2406.01661v2.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2408.04407v1","updated":"2024-08-08T12:16:14Z","published":"2024-08-08T12:16:14Z","title":"Clutter Classification Using Deep Learning in Multiple Stages","summary":"  Path loss prediction for wireless communications is highly dependent on the\nlocal environment. Propagation models including clutter information have been\nshown to significantly increase model accuracy. This paper explores the\napplication of deep learning to satellite imagery to identify environmental\nclutter types automatically. Recognizing these clutter types has numerous uses,\nbut our main application is to use clutter information to enhance propagation\nprediction models. Knowing the type of obstruction (tree, building, and further\nclassifications) can improve the prediction accuracy of key propagation metrics\nsuch as path loss.\n","authors":["Ryan Dempsey","Jonathan Ethier"],"pdf_url":"https://arxiv.org/pdf/2408.04407v1.pdf","comment":"SoutheastCon 2024"},{"id":"http://arxiv.org/abs/2408.04406v1","updated":"2024-08-08T12:15:45Z","published":"2024-08-08T12:15:45Z","title":"Finite sample learning of moving targets","summary":"  We consider a moving target that we seek to learn from samples. Our results\nextend randomized techniques developed in control and optimization for a\nconstant target to the case where the target is changing. We derive a novel\nbound on the number of samples that are required to construct a probably\napproximately correct (PAC) estimate of the target. Furthermore, when the\nmoving target is a convex polytope, we provide a constructive method of\ngenerating the PAC estimate using a mixed integer linear program (MILP). The\nproposed method is demonstrated on an application to autonomous emergency\nbraking.\n","authors":["Nikolaus Vertovec","Kostas Margellos","Maria Prandini"],"pdf_url":"https://arxiv.org/pdf/2408.04406v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2310.18247v3","updated":"2024-08-08T12:15:18Z","published":"2023-10-27T16:34:00Z","title":"Guided Data Augmentation for Offline Reinforcement Learning and\n  Imitation Learning","summary":"  In offline reinforcement learning (RL), an RL agent learns to solve a task\nusing only a fixed dataset of previously collected data. While offline RL has\nbeen successful in learning real-world robot control policies, it typically\nrequires large amounts of expert-quality data to learn effective policies that\ngeneralize to out-of-distribution states. Unfortunately, such data is often\ndifficult and expensive to acquire in real-world tasks. Several recent works\nhave leveraged data augmentation (DA) to inexpensively generate additional\ndata, but most DA works apply augmentations in a random fashion and ultimately\nproduce highly suboptimal augmented experience. In this work, we propose Guided\nData Augmentation (GuDA), a human-guided DA framework that generates\nexpert-quality augmented data. The key insight behind GuDA is that while it may\nbe difficult to demonstrate the sequence of actions required to produce expert\ndata, a user can often easily characterize when an augmented trajectory segment\nrepresents progress toward task completion. Thus, a user can restrict the space\nof possible augmentations to automatically reject suboptimal augmented data. To\nextract a policy from GuDA, we use off-the-shelf offline reinforcement learning\nand behavior cloning algorithms. We evaluate GuDA on a physical robot soccer\ntask as well as simulated D4RL navigation tasks, a simulated autonomous driving\ntask, and a simulated soccer task. Empirically, GuDA enables learning given a\nsmall initial dataset of potentially suboptimal experience and outperforms a\nrandom DA strategy as well as a model-based DA strategy.\n","authors":["Nicholas E. Corrado","Yuxiao Qu","John U. Balis","Adam Labiosa","Josiah P. Hanna"],"pdf_url":"https://arxiv.org/pdf/2310.18247v3.pdf","comment":"RLC 2024"},{"id":"http://arxiv.org/abs/2408.04405v1","updated":"2024-08-08T12:14:17Z","published":"2024-08-08T12:14:17Z","title":"Probabilistic energy forecasting through quantile regression in\n  reproducing kernel Hilbert spaces","summary":"  Accurate energy demand forecasting is crucial for sustainable and resilient\nenergy development. To meet the Net Zero Representative Concentration Pathways\n(RCP) $4.5$ scenario in the DACH countries, increased renewable energy\nproduction, energy storage, and reduced commercial building consumption are\nneeded. This scenario's success depends on hydroelectric capacity and climatic\nfactors. Informed decisions require quantifying uncertainty in forecasts. This\nstudy explores a non-parametric method based on \\emph{reproducing kernel\nHilbert spaces (RKHS)}, known as kernel quantile regression, for energy\nprediction. Our experiments demonstrate its reliability and sharpness, and we\nbenchmark it against state-of-the-art methods in load and price forecasting for\nthe DACH region. We offer our implementation in conjunction with additional\nscripts to ensure the reproducibility of our research.\n","authors":["Luca Pernigo","Rohan Sen","Davide Baroli"],"pdf_url":"https://arxiv.org/pdf/2408.04405v1.pdf","comment":"12 pages, {Owner/Author | ACM} {2024}. This is the author's version\n  of the work. It is posted here for your personal use. Not for redistribution.\n  The definitive Version of Record will published in https://energy.acm.org/eir"},{"id":"http://arxiv.org/abs/2408.04400v1","updated":"2024-08-08T12:08:55Z","published":"2024-08-08T12:08:55Z","title":"DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization","summary":"  This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.\n","authors":["Xin Sun","Liang Wang","Qiang Liu","Shu Wu","Zilei Wang","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2408.04400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04396v1","updated":"2024-08-08T12:03:03Z","published":"2024-08-08T12:03:03Z","title":"Evaluating the Impact of Pulse Oximetry Bias in Machine Learning under\n  Counterfactual Thinking","summary":"  Algorithmic bias in healthcare mirrors existing data biases. However, the\nfactors driving unfairness are not always known. Medical devices capture\nsignificant amounts of data but are prone to errors; for instance, pulse\noximeters overestimate the arterial oxygen saturation of darker-skinned\nindividuals, leading to worse outcomes. The impact of this bias in machine\nlearning (ML) models remains unclear. This study addresses the technical\nchallenges of quantifying the impact of medical device bias in downstream ML.\nOur experiments compare a \"perfect world\", without pulse oximetry bias, using\nSaO2 (blood-gas), to the \"actual world\", with biased measurements, using SpO2\n(pulse oximetry). Under this counterfactual design, two models are trained with\nidentical data, features, and settings, except for the method of measuring\noxygen saturation: models using SaO2 are a \"control\" and models using SpO2 a\n\"treatment\". The blood-gas oximetry linked dataset was a suitable test-bed,\ncontaining 163,396 nearly-simultaneous SpO2 - SaO2 paired measurements, aligned\nwith a wide array of clinical features and outcomes. We studied three\nclassification tasks: in-hospital mortality, respiratory SOFA score in the next\n24 hours, and SOFA score increase by two points. Models using SaO2 instead of\nSpO2 generally showed better performance. Patients with overestimation of O2 by\npulse oximetry of > 3% had significant decreases in mortality prediction\nrecall, from 0.63 to 0.59, P < 0.001. This mirrors clinical processes where\nbiased pulse oximetry readings provide clinicians with false reassurance of\npatients' oxygen levels. A similar degradation happened in ML models, with\npulse oximetry biases leading to more false negatives in predicting adverse\noutcomes.\n","authors":["Inês Martins","João Matos","Tiago Gonçalves","Leo A. Celi","A. Ian Wong","Jaime S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2408.04396v1.pdf","comment":"10 pages; accepted at MICCAI's Third Workshop on Applications of\n  Medical AI (2024)"},{"id":"http://arxiv.org/abs/2408.04391v1","updated":"2024-08-08T11:51:34Z","published":"2024-08-08T11:51:34Z","title":"Robustness investigation of quality measures for the assessment of\n  machine learning models","summary":"  In this paper the accuracy and robustness of quality measures for the\nassessment of machine learning models are investigated. The prediction quality\nof a machine learning model is evaluated model-independent based on a\ncross-validation approach, where the approximation error is estimated for\nunknown data. The presented measures quantify the amount of explained variation\nin the model prediction. The reliability of these measures is assessed by means\nof several numerical examples, where an additional data set for the\nverification of the estimated prediction error is available. Furthermore, the\nconfidence bounds of the presented quality measures are estimated and local\nquality measures are derived from the prediction residuals obtained by the\ncross-validation approach.\n","authors":["Thomas Most","Lars Gräning","Sebastian Wolff"],"pdf_url":"https://arxiv.org/pdf/2408.04391v1.pdf","comment":"under review, submitted to the journal Engineering Modelling,\n  Analysis & Simulation (EMAS)"},{"id":"http://arxiv.org/abs/2408.04380v1","updated":"2024-08-08T11:34:31Z","published":"2024-08-08T11:34:31Z","title":"Deep Generative Models in Robotics: A Survey on Learning from Multimodal\n  Demonstrations","summary":"  Learning from Demonstrations, the field that proposes to learn robot behavior\nmodels from data, is gaining popularity with the emergence of deep generative\nmodels. Although the problem has been studied for years under names such as\nImitation Learning, Behavioral Cloning, or Inverse Reinforcement Learning,\nclassical methods have relied on models that don't capture complex data\ndistributions well or don't scale well to large numbers of demonstrations. In\nrecent years, the robot learning community has shown increasing interest in\nusing deep generative models to capture the complexity of large datasets. In\nthis survey, we aim to provide a unified and comprehensive review of the last\nyear's progress in the use of deep generative models in robotics. We present\nthe different types of models that the community has explored, such as\nenergy-based models, diffusion models, action value maps, or generative\nadversarial networks. We also present the different types of applications in\nwhich deep generative models have been used, from grasp generation to\ntrajectory generation or cost learning. One of the most important elements of\ngenerative models is the generalization out of distributions. In our survey, we\nreview the different decisions the community has made to improve the\ngeneralization of the learned models. Finally, we highlight the research\nchallenges and propose a number of future directions for learning deep\ngenerative models in robotics.\n","authors":["Julen Urain","Ajay Mandlekar","Yilun Du","Mahi Shafiullah","Danfei Xu","Katerina Fragkiadaki","Georgia Chalvatzaki","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2408.04380v1.pdf","comment":"20 pages, 11 figures, submitted to TRO"},{"id":"http://arxiv.org/abs/2210.04797v3","updated":"2024-08-08T11:26:01Z","published":"2022-09-23T16:13:47Z","title":"DeepVol: Volatility Forecasting from High-Frequency Data with Dilated\n  Causal Convolutions","summary":"  Volatility forecasts play a central role among equity risk measures. Besides\ntraditional statistical models, modern forecasting techniques based on machine\nlearning can be employed when treating volatility as a univariate, daily\ntime-series. Moreover, econometric studies have shown that increasing the\nnumber of daily observations with high-frequency intraday data helps to improve\nvolatility predictions. In this work, we propose DeepVol, a model based on\nDilated Causal Convolutions that uses high-frequency data to forecast day-ahead\nvolatility. Our empirical findings demonstrate that dilated convolutional\nfilters are highly effective at extracting relevant information from intraday\nfinancial time-series, proving that this architecture can effectively leverage\npredictive information present in high-frequency data that would otherwise be\nlost if realised measures were precomputed. Simultaneously, dilated\nconvolutional filters trained with intraday high-frequency data help us avoid\nthe limitations of models that use daily data, such as model misspecification\nor manually designed handcrafted features, whose devise involves optimising the\ntrade-off between accuracy and computational efficiency and makes models prone\nto lack of adaptation into changing circumstances. In our analysis, we use two\nyears of intraday data from NASDAQ-100 to evaluate the performance of DeepVol.\nOur empirical results suggest that the proposed deep learning-based approach\neffectively learns global features from high-frequency data, resulting in more\naccurate predictions compared to traditional methodologies and producing more\naccurate risk measures.\n","authors":["Fernando Moreno-Pino","Stefan Zohren"],"pdf_url":"https://arxiv.org/pdf/2210.04797v3.pdf","comment":"Updated version"},{"id":"http://arxiv.org/abs/2408.04377v1","updated":"2024-08-08T11:22:52Z","published":"2024-08-08T11:22:52Z","title":"Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon","summary":"  Detecting anomalies in time series data is a critical challenge across\nvarious domains. Traditional methods typically focus on identifying anomalies\nin immediate subsequent steps, often underestimating the significance of\ntemporal dynamics such as delay time and horizons of anomalies, which generally\nrequire extensive post-analysis. This paper introduces a novel approach for\ntime series anomaly prediction, incorporating temporal information directly\ninto the prediction results. We propose a new dataset specifically designed to\nevaluate this approach and conduct comprehensive experiments using several\nstate-of-the-art methods. results demonstrate the efficacy of our approach in\nproviding timely and accurate anomaly predictions, setting a new benchmark for\nfuture research in this field.\n","authors":["Jiang You","Arben Cela","René Natowicz","Jacob Ouanounou","Patrick Siarry"],"pdf_url":"https://arxiv.org/pdf/2408.04377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04376v1","updated":"2024-08-08T11:18:40Z","published":"2024-08-08T11:18:40Z","title":"Deep Reinforcement Learning for the Design of Metamaterial Mechanisms\n  with Functional Compliance Control","summary":"  Metamaterial mechanisms are micro-architectured compliant structures that\noperate through the elastic deformation of specially designed flexible members.\nThis study develops an efficient design methodology for compliant mechanisms\nusing deep reinforcement learning (RL). For this purpose, design domains are\ndigitized into finite cells with various hinge connections, and finite element\nanalyses (FEAs) are conducted to evaluate the deformation behaviors of the\ncompliance mechanism with different cell combinations. The FEA data are learned\nthrough the RL method to obtain optimal compliant mechanisms for desired\nfunctional requirements. The RL algorithm is applied to the design of a\ncompliant door-latch mechanism, exploring the effect of human guidance and\ntiling direction. The optimal result is achieved with minimal human guidance\nand inward tiling, resulting in a threefold increase in the predefined reward\ncompared to human-designed mechanisms. The proposed approach is extended to the\ndesign of a soft gripper mechanism, where the effect of hinge connections is\nadditionally considered. The optimal design under hinge penalization reveals\nremarkably enhanced compliance, and its performance is validated by\nexperimental tests using an additively manufactured gripper. These findings\ndemonstrate that RL-optimized designs outperform those developed with human\ninsight, providing an efficient design methodology for cell-based compliant\nmechanisms in practical applications.\n","authors":["Yejun Choi","Yeoneung Kim","Keun Park"],"pdf_url":"https://arxiv.org/pdf/2408.04376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04369v1","updated":"2024-08-08T10:58:33Z","published":"2024-08-08T10:58:33Z","title":"Analyzing Consumer Reviews for Understanding Drivers of Hotels Ratings:\n  An Indian Perspective","summary":"  In the internet era, almost every business entity is trying to have its\ndigital footprint in digital media and other social media platforms. For these\nentities, word of mouse is also very important. Particularly, this is quite\ncrucial for the hospitality sector dealing with hotels, restaurants etc.\nConsumers do read other consumers reviews before making final decisions. This\nis where it becomes very important to understand which aspects are affecting\nmost in the minds of the consumers while giving their ratings. The current\nstudy focuses on the consumer reviews of Indian hotels to extract aspects\nimportant for final ratings. The study involves gathering data using web\nscraping methods, analyzing the texts using Latent Dirichlet Allocation for\ntopic extraction and sentiment analysis for aspect-specific sentiment mapping.\nFinally, it incorporates Random Forest to understand the importance of the\naspects in predicting the final rating of a user.\n","authors":["Subhasis Dasgupta","Soumya Roy","Jaydip Sen"],"pdf_url":"https://arxiv.org/pdf/2408.04369v1.pdf","comment":"This is the pre-print of the paper that was accepted for oral\n  presentation and publication in the proceedings of IEEE ICCCNT 2024 which was\n  organized as IIT Mandi, India from June 24 to 28, 2024. The paper is 5 pages\n  long and it contains 4 figures and 6 tables. The is not the final version of\n  the paper"},{"id":"http://arxiv.org/abs/2408.04360v1","updated":"2024-08-08T10:47:02Z","published":"2024-08-08T10:47:02Z","title":"Detecting Car Speed using Object Detection and Depth Estimation: A Deep\n  Learning Framework","summary":"  Road accidents are quite common in almost every part of the world, and, in\nmajority, fatal accidents are attributed to over speeding of vehicles. The\ntendency to over speeding is usually tried to be controlled using check points\nat various parts of the road but not all traffic police have the device to\ncheck speed with existing speed estimating devices such as LIDAR based, or\nRadar based guns. The current project tries to address the issue of vehicle\nspeed estimation with handheld devices such as mobile phones or wearable\ncameras with network connection to estimate the speed using deep learning\nframeworks.\n","authors":["Subhasis Dasgupta","Arshi Naaz","Jayeeta Choudhury","Nancy Lahiri"],"pdf_url":"https://arxiv.org/pdf/2408.04360v1.pdf","comment":"This is the pre-print of the paper which was accepted for oral\n  presentation and publication in the proceedings of IEEE CONIT 2024, organized\n  at Pune from June 21 to 23, 2024. The paper is 6 pages long and it contains\n  11 figures and 1 table. This is not the final version of the paper"},{"id":"http://arxiv.org/abs/2407.07454v3","updated":"2024-08-08T10:40:43Z","published":"2024-07-10T08:16:13Z","title":"CM-DQN: A Value-Based Deep Reinforcement Learning Model to Simulate\n  Confirmation Bias","summary":"  In human decision-making tasks, individuals learn through trials and\nprediction errors. When individuals learn the task, some are more influenced by\ngood outcomes, while others weigh bad outcomes more heavily. Such confirmation\nbias can lead to different learning effects. In this study, we propose a new\nalgorithm in Deep Reinforcement Learning, CM-DQN, which applies the idea of\ndifferent update strategies for positive or negative prediction errors, to\nsimulate the human decision-making process when the task's states are\ncontinuous while the actions are discrete. We test in Lunar Lander environment\nwith confirmatory, disconfirmatory bias and non-biased to observe the learning\neffects. Moreover, we apply the confirmation model in a multi-armed bandit\nproblem (environment in discrete states and discrete actions), which utilizes\nthe same idea as our proposed algorithm, as a contrast experiment to\nalgorithmically simulate the impact of different confirmation bias in\ndecision-making process. In both experiments, confirmatory bias indicates a\nbetter learning effect.\n","authors":["Jiacheng Shen","Lihan Feng"],"pdf_url":"https://arxiv.org/pdf/2407.07454v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16093v3","updated":"2024-08-08T10:20:02Z","published":"2023-11-27T18:58:34Z","title":"Visual cognition in multimodal large language models","summary":"  A chief goal of artificial intelligence is to build machines that think like\npeople. Yet it has been argued that deep neural network architectures fail to\naccomplish this. Researchers have asserted these models' limitations in the\ndomains of causal reasoning, intuitive physics, and intuitive psychology. Yet\nrecent advancements, namely the rise of large language models, particularly\nthose designed for visual processing, have rekindled interest in the potential\nto emulate human-like cognitive abilities. This paper evaluates the current\nstate of vision-based large language models in the domains of intuitive\nphysics, causal reasoning, and intuitive psychology. Through a series of\ncontrolled experiments, we investigate the extent to which these modern models\ngrasp complex physical interactions, causal relationships, and intuitive\nunderstanding of others' preferences. Our findings reveal that, while some of\nthese models demonstrate a notable proficiency in processing and interpreting\nvisual data, they still fall short of human capabilities in these areas. Our\nresults emphasize the need for integrating more robust mechanisms for\nunderstanding causality, physical dynamics, and social cognition into\nmodern-day, vision-based language models, and point out the importance of\ncognitively-inspired benchmarks.\n","authors":["Luca M. Schulze Buschoff","Elif Akata","Matthias Bethge","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2311.16093v3.pdf","comment":"Updated manuscript"},{"id":"http://arxiv.org/abs/2408.04339v1","updated":"2024-08-08T09:49:26Z","published":"2024-08-08T09:49:26Z","title":"Self-Supervised Contrastive Graph Clustering Network via Structural\n  Information Fusion","summary":"  Graph clustering, a classical task in graph learning, involves partitioning\nthe nodes of a graph into distinct clusters. This task has applications in\nvarious real-world scenarios, such as anomaly detection, social network\nanalysis, and community discovery. Current graph clustering methods commonly\nrely on module pre-training to obtain a reliable prior distribution for the\nmodel, which is then used as the optimization objective. However, these methods\noften overlook deeper supervised signals, leading to sub-optimal reliability of\nthe prior distribution. To address this issue, we propose a novel deep graph\nclustering method called CGCN. Our approach introduces contrastive signals and\ndeep structural information into the pre-training process. Specifically, CGCN\nutilizes a contrastive learning mechanism to foster information\ninteroperability among multiple modules and allows the model to adaptively\nadjust the degree of information aggregation for different order structures.\nOur CGCN method has been experimentally validated on multiple real-world graph\ndatasets, showcasing its ability to boost the dependability of prior clustering\ndistributions acquired through pre-training. As a result, we observed notable\nenhancements in the performance of the model.\n","authors":["Xiaoyang Ji","Yuchen Zhou","Haofu Yang","Shiyue Xu","Jiahao Li"],"pdf_url":"https://arxiv.org/pdf/2408.04339v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.06704v2","updated":"2024-08-08T09:41:40Z","published":"2024-07-09T09:31:15Z","title":"Self-supervised visual learning from interactions with objects","summary":"  Self-supervised learning (SSL) has revolutionized visual representation\nlearning, but has not achieved the robustness of human vision. A reason for\nthis could be that SSL does not leverage all the data available to humans\nduring learning. When learning about an object, humans often purposefully turn\nor move around objects and research suggests that these interactions can\nsubstantially enhance their learning. Here we explore whether such\nobject-related actions can boost SSL. For this, we extract the actions\nperformed to change from one ego-centric view of an object to another in four\nvideo datasets. We then introduce a new loss function to learn visual and\naction embeddings by aligning the performed action with the representations of\ntwo images extracted from the same clip. This permits the performed actions to\nstructure the latent visual representation. Our experiments show that our\nmethod consistently outperforms previous methods on downstream category\nrecognition. In our analysis, we find that the observed improvement is\nassociated with a better viewpoint-wise alignment of different objects from the\nsame category. Overall, our work demonstrates that embodied interactions with\nobjects can improve SSL of object categories.\n","authors":["Arthur Aubret","Céline Teulière","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2407.06704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16010v2","updated":"2024-08-08T09:12:13Z","published":"2024-07-22T19:33:12Z","title":"AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations","summary":"  For many use-cases, it is often important to explain the prediction of a\nblack-box model by identifying the most influential training data samples.\nExisting approaches lack customization for user intent and often provide a\nhomogeneous set of explanation samples, failing to reveal the model's reasoning\nfrom different angles.\n  In this paper, we propose AIDE, an approach for providing antithetical (i.e.,\ncontrastive), intent-based, diverse explanations for opaque and complex models.\nAIDE distinguishes three types of explainability intents: interpreting a\ncorrect, investigating a wrong, and clarifying an ambiguous prediction. For\neach intent, AIDE selects an appropriate set of influential training samples\nthat support or oppose the prediction either directly or by contrast. To\nprovide a succinct summary, AIDE uses diversity-aware sampling to avoid\nredundancy and increase coverage of the training data.\n  We demonstrate the effectiveness of AIDE on image and text classification\ntasks, in three ways: quantitatively, assessing correctness and continuity;\nqualitatively, comparing anecdotal evidence from AIDE and other example-based\napproaches; and via a user study, evaluating multiple aspects of AIDE. The\nresults show that AIDE addresses the limitations of existing methods and\nexhibits desirable traits for an explainability method.\n","authors":["Ikhtiyor Nematov","Dimitris Sacharidis","Tomer Sagi","Katja Hose"],"pdf_url":"https://arxiv.org/pdf/2407.16010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02407v2","updated":"2024-08-08T09:06:50Z","published":"2024-08-05T12:01:42Z","title":"Terracorder: Sense Long and Prosper","summary":"  In-situ sensing devices need to be deployed in remote environments for long\nperiods of time; minimizing their power consumption is vital for maximising\nboth their operational lifetime and coverage. We introduce Terracorder -- a\nversatile multi-sensor device -- and showcase its exceptionally low power\nconsumption using an on-device reinforcement learning scheduler. We prototype a\nunique device setup for biodiversity monitoring and compare its battery life\nusing our scheduler against a number of fixed schedules; the scheduler captures\nmore than 80% of events at less than 50% of the number of activations of the\nbest-performing fixed schedule. We then explore how a collaborative scheduler\ncan maximise the useful operation of a network of devices, improving overall\nnetwork power consumption and robustness.\n","authors":["Josh Millar","Sarab Sethi","Hamed Haddadi","Anil Madhavapeddy"],"pdf_url":"https://arxiv.org/pdf/2408.02407v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2404.03710v2","updated":"2024-08-08T09:03:51Z","published":"2024-04-04T13:43:17Z","title":"Self-organized free-flight arrival for urban air mobility","summary":"  Urban air mobility is an innovative mode of transportation in which electric\nvertical takeoff and landing (eVTOL) vehicles operate between nodes called\nvertiports. We outline a self-organized vertiport arrival system based on deep\nreinforcement learning. The airspace around the vertiport is assumed to be\ncircular, and the vehicles can freely operate inside. Each aircraft is\nconsidered an individual agent and follows a shared policy, resulting in\ndecentralized actions that are based on local information. We investigate the\ndevelopment of the reinforcement learning policy during training and illustrate\nhow the algorithm moves from suboptimal local holding patterns to a safe and\nefficient final policy. The latter is validated in simulation-based scenarios,\nincluding robustness analyses against sensor noise and a changing distribution\nof inbound traffic. Lastly, we deploy the final policy on small-scale unmanned\naerial vehicles to showcase its real-world usability.\n","authors":["Martin Waltz","Ostap Okhrin","Michael Schultz"],"pdf_url":"https://arxiv.org/pdf/2404.03710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04318v1","updated":"2024-08-08T08:52:29Z","published":"2024-08-08T08:52:29Z","title":"Deep Transfer Learning for Kidney Cancer Diagnosis","summary":"  Many incurable diseases prevalent across global societies stem from various\ninfluences, including lifestyle choices, economic conditions, social factors,\nand genetics. Research predominantly focuses on these diseases due to their\nwidespread nature, aiming to decrease mortality, enhance treatment options, and\nimprove healthcare standards. Among these, kidney disease stands out as a\nparticularly severe condition affecting men and women worldwide. Nonetheless,\nthere is a pressing need for continued research into innovative, early\ndiagnostic methods to develop more effective treatments for such diseases.\nRecently, automatic diagnosis of Kidney Cancer has become an important\nchallenge especially when using deep learning (DL) due to the importance of\ntraining medical datasets, which in most cases are difficult and expensive to\nobtain. Furthermore, in most cases, algorithms require data from the same\ndomain and a powerful computer with efficient storage capacity. To overcome\nthis issue, a new type of learning known as transfer learning (TL) has been\nproposed that can produce impressive results based on other different\npre-trained data. This paper presents, to the best of the authors' knowledge,\nthe first comprehensive survey of DL-based TL frameworks for kidney cancer\ndiagnosis. This is a strong contribution to help researchers understand the\ncurrent challenges and perspectives of this topic. Hence, the main limitations\nand advantages of each framework are identified and detailed critical analyses\nare provided. Looking ahead, the article identifies promising directions for\nfuture research. Moving on, the discussion is concluded by reflecting on the\npivotal role of TL in the development of precision medicine and its effects on\nclinical practice and research in oncology.\n","authors":["Yassine Habchi","Hamza Kheddar","Yassine Himeur","Abdelkrim Boukabou","Shadi Atalla","Wathiq Mansoor","Hussain Al-Ahmad"],"pdf_url":"https://arxiv.org/pdf/2408.04318v1.pdf","comment":"32 pages, 8 figures and 8 tables"},{"id":"http://arxiv.org/abs/2408.04315v1","updated":"2024-08-08T08:48:54Z","published":"2024-08-08T08:48:54Z","title":"Federated Cubic Regularized Newton Learning with\n  Sparsification-amplified Differential Privacy","summary":"  This paper investigates the use of the cubic-regularized Newton method within\na federated learning framework while addressing two major concerns that\ncommonly arise in federated learning: privacy leakage and communication\nbottleneck. We introduce a federated learning algorithm called Differentially\nPrivate Federated Cubic Regularized Newton (DP-FCRN). By leveraging\nsecond-order techniques, our algorithm achieves lower iteration complexity\ncompared to first-order methods. We also incorporate noise perturbation during\nlocal computations to ensure privacy. Furthermore, we employ sparsification in\nuplink transmission, which not only reduces the communication costs but also\namplifies the privacy guarantee. Specifically, this approach reduces the\nnecessary noise intensity without compromising privacy protection. We analyze\nthe convergence properties of our algorithm and establish the privacy\nguarantee. Finally, we validate the effectiveness of the proposed algorithm\nthrough experiments on a benchmark dataset.\n","authors":["Wei Huo","Changxin Liu","Kemi Ding","Karl Henrik Johansson","Ling Shi"],"pdf_url":"https://arxiv.org/pdf/2408.04315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04313v1","updated":"2024-08-08T08:47:20Z","published":"2024-08-08T08:47:20Z","title":"Better Locally Private Sparse Estimation Given Multiple Samples Per User","summary":"  Previous studies yielded discouraging results for item-level locally\ndifferentially private linear regression with $s^*$-sparsity assumption, where\nthe minimax rate for $nm$ samples is $\\mathcal{O}(s^{*}d / nm\\varepsilon^2)$.\nThis can be challenging for high-dimensional data, where the dimension $d$ is\nextremely large. In this work, we investigate user-level locally differentially\nprivate sparse linear regression. We show that with $n$ users each contributing\n$m$ samples, the linear dependency of dimension $d$ can be eliminated, yielding\nan error upper bound of $\\mathcal{O}(s^{*2} / nm\\varepsilon^2)$. We propose a\nframework that first selects candidate variables and then conducts estimation\nin the narrowed low-dimensional space, which is extendable to general sparse\nestimation problems with tight error bounds. Experiments on both synthetic and\nreal datasets demonstrate the superiority of the proposed methods. Both the\ntheoretical and empirical results suggest that, with the same number of\nsamples, locally private sparse estimation is better conducted when multiple\nsamples per user are available.\n","authors":["Yuheng Ma","Ke Jia","Hanfang Yang"],"pdf_url":"https://arxiv.org/pdf/2408.04313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11337v3","updated":"2024-08-08T08:44:52Z","published":"2023-12-18T16:41:30Z","title":"Challenges for Reinforcement Learning in Quantum Circuit Design","summary":"  Quantum computing (QC) in the current NISQ era is still limited in size and\nprecision. Hybrid applications mitigating those shortcomings are prevalent to\ngain early insight and advantages. Hybrid quantum machine learning (QML)\ncomprises both the application of QC to improve machine learning (ML) and ML to\nimprove QC architectures. This work considers the latter, leveraging\nreinforcement learning (RL) to improve quantum circuit design (QCD), which we\nformalize by a set of generic objectives. Furthermore, we propose qcd-gym, a\nconcrete framework formalized as a Markov decision process, to enable learning\npolicies capable of controlling a universal set of continuously parameterized\nquantum gates. Finally, we provide benchmark comparisons to assess the\nshortcomings and strengths of current state-of-the-art RL algorithms.\n","authors":["Philipp Altmann","Jonas Stein","Michael Kölle","Adelina Bärligea","Thomas Gabor","Thomy Phan","Sebastian Feld","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2312.11337v3.pdf","comment":"11 pages, 4 figures, accepted for publication at the 2024 IEEE\n  International Conference on Quantum Computing and Engineering (QCE)"},{"id":"http://arxiv.org/abs/2407.11652v6","updated":"2024-08-08T08:44:29Z","published":"2024-07-16T12:18:20Z","title":"CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical\n  Imaging","summary":"  Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.\n","authors":["Sunny Gupta","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2407.11652v6.pdf","comment":"I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version"},{"id":"http://arxiv.org/abs/2408.04310v1","updated":"2024-08-08T08:42:47Z","published":"2024-08-08T08:42:47Z","title":"Constructing Adversarial Examples for Vertical Federated Learning:\n  Optimal Client Corruption through Multi-Armed Bandit","summary":"  Vertical federated learning (VFL), where each participating client holds a\nsubset of data features, has found numerous applications in finance,\nhealthcare, and IoT systems. However, adversarial attacks, particularly through\nthe injection of adversarial examples (AEs), pose serious challenges to the\nsecurity of VFL models. In this paper, we investigate such vulnerabilities\nthrough developing a novel attack to disrupt the VFL inference process, under a\npractical scenario where the adversary is able to adaptively corrupt a subset\nof clients. We formulate the problem of finding optimal attack strategies as an\nonline optimization problem, which is decomposed into an inner problem of\nadversarial example generation (AEG) and an outer problem of corruption pattern\nselection (CPS). Specifically, we establish the equivalence between the\nformulated CPS problem and a multi-armed bandit (MAB) problem, and propose the\nThompson sampling with Empirical maximum reward (E-TS) algorithm for the\nadversary to efficiently identify the optimal subset of clients for corruption.\nThe key idea of E-TS is to introduce an estimation of the expected maximum\nreward for each arm, which helps to specify a small set of competitive arms, on\nwhich the exploration for the optimal arm is performed. This significantly\nreduces the exploration space, which otherwise can quickly become prohibitively\nlarge as the number of clients increases. We analytically characterize the\nregret bound of E-TS, and empirically demonstrate its capability of efficiently\nrevealing the optimal corruption pattern with the highest attack success rate,\nunder various datasets of popular VFL tasks.\n","authors":["Duanyi Yao","Songze Li","Ye Xue","Jin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.04310v1.pdf","comment":"Published on ICLR2024"},{"id":"http://arxiv.org/abs/2408.04309v1","updated":"2024-08-08T08:42:30Z","published":"2024-08-08T08:42:30Z","title":"TheGlueNote: Learned Representations for Robust and Flexible Note\n  Alignment","summary":"  Note alignment refers to the task of matching individual notes of two\nversions of the same symbolically encoded piece. Methods addressing this task\ncommonly rely on sequence alignment algorithms such as Hidden Markov Models or\nDynamic Time Warping (DTW) applied directly to note or onset sequences. While\nsuccessful in many cases, such methods struggle with large mismatches between\nthe versions. In this work, we learn note-wise representations from data\naugmented with various complex mismatch cases, e.g. repeats, skips, block\ninsertions, and long trills. At the heart of our approach lies a transformer\nencoder network - TheGlueNote - which predicts pairwise note similarities for\ntwo 512 note subsequences. We postprocess the predicted similarities using\nflavors of weightedDTW and pitch-separated onsetDTW to retrieve note matches\nfor two sequences of arbitrary length. Our approach performs on par with the\nstate of the art in terms of note alignment accuracy, is considerably more\nrobust to version mismatches, and works directly on any pair of MIDI files.\n","authors":["Silvan David Peter","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2408.04309v1.pdf","comment":"to be published in Proceedings of the 25th International Society for\n  Music Information Retrieval Conference (ISMIR), 2024"},{"id":"http://arxiv.org/abs/2408.04307v1","updated":"2024-08-08T08:40:15Z","published":"2024-08-08T08:40:15Z","title":"Partial Experts Checkpoint: Efficient Fault Tolerance for Sparse\n  Mixture-of-Experts Model Training","summary":"  As large language models continue to scale up, the imperative for fault\ntolerance in distributed deep learning systems intensifies, becoming a focal\narea of AI infrastructure research. Checkpoint has emerged as the predominant\nfault tolerance strategy, with extensive studies dedicated to optimizing its\nefficiency. However, the advent of the sparse Mixture-of-Experts (MoE) model\npresents new challenges for traditional checkpoint techniques due to the\nsubstantial increase in model size, despite comparable computational demands to\ndense models. Breaking new ground in the realm of efficient fault tolerance for\nMoE model training, we introduce a novel Partial Experts Checkpoint (PEC)\nmechanism alongside a corresponding PEC fault-tolerant system. Our approach\nstrategically checkpoints a selected subset of experts, thereby significantly\nreducing the checkpoint size for MoE models to a level comparable with that of\ndense models. The empirical analysis on our 8-expert GPT-MoE model demonstrates\nthat the proposed PEC approach facilitates a substantial 54.2% decrease in the\nsize of non-redundant checkpoint (no data-parallel duplication), without\ncompromising the final model quality. Moreover, our PEC fault-tolerant system\nachieves a 76.9% reduction in checkpoint workload per data-parallel distributed\nrank, thereby correspondingly diminishing the checkpointing time and\nfacilitating complete overlap with the training process.\n","authors":["Weilin Cai","Le Qin","Jiayi Huang"],"pdf_url":"https://arxiv.org/pdf/2408.04307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04303v1","updated":"2024-08-08T08:37:28Z","published":"2024-08-08T08:37:28Z","title":"Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language\n  Adaptation of LLMs for Low-Resource NLP","summary":"  The development of monolingual language models for low and mid-resource\nlanguages continues to be hindered by the difficulty in sourcing high-quality\ntraining data. In this study, we present a novel cross-lingual vocabulary\ntransfer strategy, trans-tokenization, designed to tackle this challenge and\nenable more efficient language adaptation. Our approach focuses on adapting a\nhigh-resource monolingual LLM to an unseen target language by initializing the\ntoken embeddings of the target language using a weighted average of\nsemantically similar token embeddings from the source language. For this, we\nleverage a translation resource covering both the source and target languages.\nWe validate our method with the Tweeties, a series of trans-tokenized LLMs, and\ndemonstrate their competitive performance on various downstream tasks across a\nsmall but diverse set of languages. Additionally, we introduce Hydra LLMs,\nmodels with multiple swappable language modeling heads and embedding tables,\nwhich further extend the capabilities of our trans-tokenization strategy. By\ndesigning a Hydra LLM based on the multilingual model TowerInstruct, we\ndeveloped a state-of-the-art machine translation model for Tatar, in a\nzero-shot manner, completely bypassing the need for high-quality parallel data.\nThis breakthrough is particularly significant for low-resource languages like\nTatar, where high-quality parallel data is hard to come by. By lowering the\ndata and time requirements for training high-quality models, our\ntrans-tokenization strategy allows for the development of LLMs for a wider\nrange of languages, especially those with limited resources. We hope that our\nwork will inspire further research and collaboration in the field of\ncross-lingual vocabulary transfer and contribute to the empowerment of\nlanguages on a global scale.\n","authors":["François Remy","Pieter Delobelle","Hayastan Avetisyan","Alfiya Khabibullina","Miryam de Lhoneux","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2408.04303v1.pdf","comment":"Accepted at COLM 2024"},{"id":"http://arxiv.org/abs/2402.12062v3","updated":"2024-08-08T08:36:03Z","published":"2024-02-19T11:30:00Z","title":"Causal Equal Protection as Algorithmic Fairness","summary":"  By combining the philosophical literature on statistical evidence and the\ninterdisciplinary literature on algorithmic fairness, we revisit recent\nobjections against classification parity in light of causal analyses of\nalgorithmic fairness and the distinction between predictive and diagnostic\nevidence. We focus on trial proceedings as a black-box classification algorithm\nin which defendants are sorted into two groups by convicting or acquitting\nthem. We defend a novel principle, causal equal protection, that combines\nclassification parity with the causal approach. In the do-calculus, causal\nequal protection requires that individuals should not be subject to uneven\nrisks of classification error because of their protected or socially salient\ncharacteristics. The explicit use of protected characteristics, however, may be\nrequired if it equalizes these risks.\n","authors":["Marcello Di Bello","Nicolò Cangiotti","Michele Loi"],"pdf_url":"https://arxiv.org/pdf/2402.12062v3.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.04301v1","updated":"2024-08-08T08:35:32Z","published":"2024-08-08T08:35:32Z","title":"Tackling Noisy Clients in Federated Learning with End-to-end Label\n  Correction","summary":"  Recently, federated learning (FL) has achieved wide successes for diverse\nprivacy-sensitive applications without sacrificing the sensitive private\ninformation of clients. However, the data quality of client datasets can not be\nguaranteed since corresponding annotations of different clients often contain\ncomplex label noise of varying degrees, which inevitably causes the performance\ndegradation. Intuitively, the performance degradation is dominated by clients\nwith higher noise rates since their trained models contain more misinformation\nfrom data, thus it is necessary to devise an effective optimization scheme to\nmitigate the negative impacts of these noisy clients. In this work, we propose\na two-stage framework FedELC to tackle this complicated label noise issue. The\nfirst stage aims to guide the detection of noisy clients with higher label\nnoise, while the second stage aims to correct the labels of noisy clients' data\nvia an end-to-end label correction framework which is achieved by learning\npossible ground-truth labels of noisy clients' datasets via back propagation.\nWe implement sixteen related methods and evaluate five datasets with three\ntypes of complicated label noise scenarios for a comprehensive comparison.\nExtensive experimental results demonstrate our proposed framework achieves\nsuperior performance than its counterparts for different scenarios.\nAdditionally, we effectively improve the data quality of detected noisy\nclients' local datasets with our label correction framework. The code is\navailable at https://github.com/Sprinter1999/FedELC.\n","authors":["Xuefeng Jiang","Sheng Sun","Jia Li","Jingjing Xue","Runhan Li","Zhiyuan Wu","Gang Xu","Yuwei Wang","Min Liu"],"pdf_url":"https://arxiv.org/pdf/2408.04301v1.pdf","comment":"To appear in ACM CIKM'24 full research paper track"},{"id":"http://arxiv.org/abs/2408.04295v1","updated":"2024-08-08T08:18:05Z","published":"2024-08-08T08:18:05Z","title":"Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal\n  Policy Optimization","summary":"  Multi-agent proximal policy optimization (MAPPO) has recently demonstrated\nstate-of-the-art performance on challenging multi-agent reinforcement learning\ntasks. However, MAPPO still struggles with the credit assignment problem,\nwherein the sheer difficulty in ascribing credit to individual agents' actions\nscales poorly with team size. In this paper, we propose a multi-agent\nreinforcement learning algorithm that adapts recent developments in credit\nassignment to improve upon MAPPO. Our approach leverages partial reward\ndecoupling (PRD), which uses a learned attention mechanism to estimate which of\na particular agent's teammates are relevant to its learning updates. We use\nthis estimate to dynamically decompose large groups of agents into smaller,\nmore manageable subgroups. We empirically demonstrate that our approach,\nPRD-MAPPO, decouples agents from teammates that do not influence their expected\nfuture reward, thereby streamlining credit assignment. We additionally show\nthat PRD-MAPPO yields significantly higher data efficiency and asymptotic\nperformance compared to both MAPPO and other state-of-the-art methods across\nseveral multi-agent tasks, including StarCraft II. Finally, we propose a\nversion of PRD-MAPPO that is applicable to \\textit{shared} reward settings,\nwhere PRD was previously not applicable, and empirically show that this also\nleads to performance improvements over MAPPO.\n","authors":["Aditya Kapoor","Benjamin Freed","Howie Choset","Jeff Schneider"],"pdf_url":"https://arxiv.org/pdf/2408.04295v1.pdf","comment":"20 pages, 5 figures, 12 tables, Reinforcement Learning Journal and\n  Reinforcement Learning Conference 2024"},{"id":"http://arxiv.org/abs/2408.04294v1","updated":"2024-08-08T08:17:50Z","published":"2024-08-08T08:17:50Z","title":"Dual-branch PolSAR Image Classification Based on GraphMAE and Local\n  Feature Extraction","summary":"  The annotation of polarimetric synthetic aperture radar (PolSAR) images is a\nlabor-intensive and time-consuming process. Therefore, classifying PolSAR\nimages with limited labels is a challenging task in remote sensing domain. In\nrecent years, self-supervised learning approaches have proven effective in\nPolSAR image classification with sparse labels. However, we observe a lack of\nresearch on generative selfsupervised learning in the studied task. Motivated\nby this, we propose a dual-branch classification model based on generative\nself-supervised learning in this paper. The first branch is a\nsuperpixel-branch, which learns superpixel-level polarimetric representations\nusing a generative self-supervised graph masked autoencoder. To acquire finer\nclassification results, a convolutional neural networks-based pixel-branch is\nfurther incorporated to learn pixel-level features. Classification with fused\ndual-branch features is finally performed to obtain the predictions.\nExperimental results on the benchmark Flevoland dataset demonstrate that our\napproach yields promising classification results.\n","authors":["Yuchen Wang","Ziyi Guo","Haixia Bi","Danfeng Hong","Chen Xu"],"pdf_url":"https://arxiv.org/pdf/2408.04294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04290v1","updated":"2024-08-08T08:06:42Z","published":"2024-08-08T08:06:42Z","title":"Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale\n  Transformer Approach","summary":"  Pneumonia, a severe respiratory disease, poses significant diagnostic\nchallenges, especially in underdeveloped regions. Traditional diagnostic\nmethods, such as chest X-rays, suffer from variability in interpretation among\nradiologists, necessitating reliable automated tools. In this study, we propose\na novel approach combining deep learning and transformer-based attention\nmechanisms to enhance pneumonia detection from chest X-rays. Our method begins\nwith lung segmentation using a TransUNet model that integrates our specialized\ntransformer module, which has fewer parameters compared to common transformers\nwhile maintaining performance. This model is trained on the \"Chest Xray Masks\nand Labels\" dataset and then applied to the Kermany and Cohen datasets to\nisolate lung regions, enhancing subsequent classification tasks. For\nclassification, we employ pre-trained ResNet models (ResNet-50 and ResNet-101)\nto extract multi-scale feature maps, processed through our modified transformer\nmodule. By employing our specialized transformer, we attain superior results\nwith significantly fewer parameters compared to common transformer models. Our\napproach achieves high accuracy rates of 92.79% on the Kermany dataset and\n95.11% on the Cohen dataset, ensuring robust and efficient performance suitable\nfor resource-constrained environments.\n\"https://github.com/amirrezafateh/Multi-Scale-Transformer-Pneumonia\"\n","authors":["Alireza Saber","Pouria Parhami","Alimihammad Siahkarzadeh","Amirreza Fateh"],"pdf_url":"https://arxiv.org/pdf/2408.04290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21670v2","updated":"2024-08-08T07:59:50Z","published":"2024-07-31T15:13:39Z","title":"Universal Approximation Theory: Foundations for Parallelism in Neural\n  Networks","summary":"  Neural networks are increasingly evolving towards training large models with\nbig data, a method that has demonstrated superior performance across many\ntasks. However, this approach introduces an urgent problem: current deep\nlearning models are predominantly serial, meaning that as the number of network\nlayers increases, so do the training and inference times. This is unacceptable\nif deep learning is to continue advancing. Therefore, this paper proposes a\ndeep learning parallelization strategy based on the Universal Approximation\nTheorem (UAT). From this foundation, we designed a parallel network called\nPara-Former to test our theory. Unlike traditional serial models, the inference\ntime of Para-Former does not increase with the number of layers, significantly\naccelerating the inference speed of multi-layer networks. Experimental results\nvalidate the effectiveness of this network.\n","authors":["Wei Wang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2407.21670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19429v3","updated":"2024-08-08T07:56:48Z","published":"2024-07-28T08:39:28Z","title":"FTF-ER: Feature-Topology Fusion-Based Experience Replay Method for\n  Continual Graph Learning","summary":"  Continual graph learning (CGL) is an important and challenging task that aims\nto extend static GNNs to dynamic task flow scenarios. As one of the mainstream\nCGL methods, the experience replay (ER) method receives widespread attention\ndue to its superior performance. However, existing ER methods focus on\nidentifying samples by feature significance or topological relevance, which\nlimits their utilization of comprehensive graph data. In addition, the\ntopology-based ER methods only consider local topological information and add\nneighboring nodes to the buffer, which ignores the global topological\ninformation and increases memory overhead. To bridge these gaps, we propose a\nnovel method called Feature-Topology Fusion-based Experience Replay (FTF-ER) to\neffectively mitigate the catastrophic forgetting issue with enhanced\nefficiency. Specifically, from an overall perspective to maximize the\nutilization of the entire graph data, we propose a highly complementary\napproach including both feature and global topological information, which can\nsignificantly improve the effectiveness of the sampled nodes. Moreover, to\nfurther utilize global topological information, we propose Hodge Potential\nScore (HPS) as a novel module to calculate the topological importance of nodes.\nHPS derives a global node ranking via Hodge decomposition on graphs, providing\nmore accurate global topological information compared to neighbor sampling. By\nexcluding neighbor sampling, HPS significantly reduces buffer storage costs for\nacquiring topological information and simultaneously decreases training time.\nCompared with state-of-the-art methods, FTF-ER achieves a significant\nimprovement of 3.6% in AA and 7.1% in AF on the OGB-Arxiv dataset,\ndemonstrating its superior performance in the class-incremental learning\nsetting.\n","authors":["Jinhui Pang","Changqing Lin","Xiaoshuai Hao","Rong Yin","Zixuan Wang","Zhihui Zhang","Jinglin He","Huang Tai Sheng"],"pdf_url":"https://arxiv.org/pdf/2407.19429v3.pdf","comment":"Accepted by ACM Multimedia 2024"},{"id":"http://arxiv.org/abs/2408.04283v1","updated":"2024-08-08T07:41:16Z","published":"2024-08-08T07:41:16Z","title":"Prompt-Assisted Semantic Interference Cancellation on Moderate\n  Interference Channels","summary":"  The performance of conventional interference management strategies degrades\nwhen interference power is comparable to signal power. We consider a new\nperspective on interference management using semantic communication.\nSpecifically, a multi-user semantic communication system is considered on\nmoderate interference channels (ICs), for which a novel framework of deep\nlearning-based prompt-assisted semantic interference cancellation (DeepPASIC)\nis proposed. Each transmitted signal is partitioned into common and private\nparts. The common parts of different users are transmitted simultaneously in a\nshared medium, resulting in superposition. The private part, on the other hand,\nserves as a prompt to assist in canceling the interference suffered by the\ncommon part at the semantic level. Simulation results demonstrate that the\nproposed DeepPASIC outperforms conventional interference management strategies\nunder moderate interference conditions.\n","authors":["Zian Meng","Qiang Li","Ashish Pandharipande","Xiaohu Ge"],"pdf_url":"https://arxiv.org/pdf/2408.04283v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.04277v1","updated":"2024-08-08T07:31:22Z","published":"2024-08-08T07:31:22Z","title":"Stability Analysis of Equivariant Convolutional Representations Through\n  The Lens of Equivariant Multi-layered CKNs","summary":"  In this paper we construct and theoretically analyse group equivariant\nconvolutional kernel networks (CKNs) which are useful in understanding the\ngeometry of (equivariant) CNNs through the lens of reproducing kernel Hilbert\nspaces (RKHSs). We then proceed to study the stability analysis of such\nequiv-CKNs under the action of diffeomorphism and draw a connection with\nequiv-CNNs, where the goal is to analyse the geometry of inductive biases of\nequiv-CNNs through the lens of reproducing kernel Hilbert spaces (RKHSs).\nTraditional deep learning architectures, including CNNs, trained with\nsophisticated optimization algorithms is vulnerable to perturbations, including\n`adversarial examples'. Understanding the RKHS norm of such models through CKNs\nis useful in designing the appropriate architecture and can be useful in\ndesigning robust equivariant representation learning models.\n","authors":["Soutrik Roy Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2408.04277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04276v1","updated":"2024-08-08T07:24:28Z","published":"2024-08-08T07:24:28Z","title":"Early Risk Assessment Model for ICA Timing Strategy in Unstable Angina\n  Patients Using Multi-Modal Machine Learning","summary":"  Background: Invasive coronary arteriography (ICA) is recognized as the gold\nstandard for diagnosing cardiovascular diseases, including unstable angina\n(UA). The challenge lies in determining the optimal timing for ICA in UA\npatients, balancing the need for revascularization in high-risk patients\nagainst the potential complications in low-risk ones. Unlike myocardial\ninfarction, UA does not have specific indicators like ST-segment deviation or\ncardiac enzymes, making risk assessment complex. Objectives: Our study aims to\nenhance the early risk assessment for UA patients by utilizing machine learning\nalgorithms. These algorithms can potentially identify patients who would\nbenefit most from ICA by analyzing less specific yet related indicators that\nare challenging for human physicians to interpret. Methods: We collected data\nfrom 640 UA patients at Shanghai General Hospital, including medical history\nand electrocardiograms (ECG). Machine learning algorithms were trained using\nmulti-modal demographic characteristics including clinical risk factors,\nsymptoms, biomarker levels, and ECG features extracted by pre-trained neural\nnetworks. The goal was to stratify patients based on their revascularization\nrisk. Additionally, we translated our models into applicable and explainable\nlook-up tables through discretization for practical clinical use. Results: The\nstudy achieved an Area Under the Curve (AUC) of $0.719 \\pm 0.065$ in risk\nstratification, significantly surpassing the widely adopted GRACE score's AUC\nof $0.579 \\pm 0.044$. Conclusions: The results suggest that machine learning\ncan provide superior risk stratification for UA patients. This improved\nstratification could help in balancing the risks, costs, and complications\nassociated with ICA, indicating a potential shift in clinical assessment\npractices for unstable angina.\n","authors":["Candi Zheng","Kun Liu","Yang Wang","Shiyi Chen","Hongli Li"],"pdf_url":"https://arxiv.org/pdf/2408.04276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11427v2","updated":"2024-08-08T07:23:01Z","published":"2024-07-16T06:45:27Z","title":"Semi-Supervised Generative Models for Disease Trajectories: A Case Study\n  on Systemic Sclerosis","summary":"  We propose a deep generative approach using latent temporal processes for\nmodeling and holistically analyzing complex disease trajectories, with a\nparticular focus on Systemic Sclerosis (SSc). We aim to learn temporal latent\nrepresentations of the underlying generative process that explain the observed\npatient disease trajectories in an interpretable and comprehensive way. To\nenhance the interpretability of these latent temporal processes, we develop a\nsemi-supervised approach for disentangling the latent space using established\nmedical knowledge. By combining the generative approach with medical\ndefinitions of different characteristics of SSc, we facilitate the discovery of\nnew aspects of the disease. We show that the learned temporal latent processes\ncan be utilized for further data analysis and clinical hypothesis testing,\nincluding finding similar patients and clustering SSc patient trajectories into\nnovel sub-types. Moreover, our method enables personalized online monitoring\nand prediction of multivariate time series with uncertainty quantification.\n","authors":["Cécile Trottet","Manuel Schürch","Ahmed Allam","Imon Barua","Liubov Petelytska","David Launay","Paolo Airò","Radim Bečvář","Christopher Denton","Mislav Radic","Oliver Distler","Anna-Maria Hoffmann-Vold","Michael Krauthammer","the EUSTAR collaborators"],"pdf_url":"https://arxiv.org/pdf/2407.11427v2.pdf","comment":"Accepted at Machine Learning for Healthcare 2024. arXiv admin note:\n  substantial text overlap with arXiv:2311.08149"},{"id":"http://arxiv.org/abs/2407.06204v2","updated":"2024-08-08T07:13:37Z","published":"2024-06-26T16:34:33Z","title":"A Survey on Mixture of Experts","summary":"  Large language models (LLMs) have garnered unprecedented advancements across\ndiverse fields, ranging from natural language processing to computer vision and\nbeyond. The prowess of LLMs is underpinned by their substantial model size,\nextensive and diverse datasets, and the vast computational power harnessed\nduring training, all of which contribute to the emergent abilities of LLMs\n(e.g., in-context learning) that are not present in small models. Within this\ncontext, the mixture of experts (MoE) has emerged as an effective method for\nsubstantially scaling up model capacity with minimal computation overhead,\ngaining significant attention from academia and industry. Despite its growing\nprevalence, there lacks a systematic and comprehensive review of the literature\non MoE. This survey seeks to bridge that gap, serving as an essential resource\nfor researchers delving into the intricacies of MoE. We first briefly introduce\nthe structure of the MoE layer, followed by proposing a new taxonomy of MoE.\nNext, we overview the core designs for various MoE models including both\nalgorithmic and systemic aspects, alongside collections of available\nopen-source implementations, hyperparameter configurations and empirical\nevaluations. Furthermore, we delineate the multifaceted applications of MoE in\npractice, and outline some potential directions for future research. To\nfacilitate ongoing updates and the sharing of cutting-edge developments in MoE\nresearch, we have established a resource repository accessible at\nhttps://github.com/withinmiaov/A-Survey-on-Mixture-of-Experts.\n","authors":["Weilin Cai","Juyong Jiang","Fan Wang","Jing Tang","Sunghun Kim","Jiayi Huang"],"pdf_url":"https://arxiv.org/pdf/2407.06204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10373v2","updated":"2024-08-08T07:06:40Z","published":"2024-01-18T20:43:43Z","title":"Harmonized Spatial and Spectral Learning for Robust and Generalized\n  Medical Image Segmentation","summary":"  Deep learning has demonstrated remarkable achievements in medical image\nsegmentation. However, prevailing deep learning models struggle with poor\ngeneralization due to (i) intra-class variations, where the same class appears\ndifferently in different samples, and (ii) inter-class independence, resulting\nin difficulties capturing intricate relationships between distinct objects,\nleading to higher false negative cases. This paper presents a novel approach\nthat synergies spatial and spectral representations to enhance\ndomain-generalized medical image segmentation. We introduce the innovative\nSpectral Correlation Coefficient objective to improve the model's capacity to\ncapture middle-order features and contextual long-range dependencies. This\nobjective complements traditional spatial objectives by incorporating valuable\nspectral information. Extensive experiments reveal that optimizing this\nobjective with existing architectures like UNet and TransUNet significantly\nenhances generalization, interpretability, and noise robustness, producing more\nconfident predictions. For instance, in cardiac segmentation, we observe a 0.81\npp and 1.63 pp (pp = percentage point) improvement in DSC over UNet and\nTransUNet, respectively. Our interpretability study demonstrates that, in most\ntasks, objectives optimized with UNet outperform even TransUNet by introducing\nglobal contextual information alongside local details. These findings\nunderscore the versatility and effectiveness of our proposed method across\ndiverse imaging modalities and medical domains.\n","authors":["Vandan Gorade","Sparsh Mittal","Debesh Jha","Rekha Singhal","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2401.10373v2.pdf","comment":"Early Accepted at ICPR-2024 for Oral Presentation"},{"id":"http://arxiv.org/abs/2408.04254v1","updated":"2024-08-08T06:47:21Z","published":"2024-08-08T06:47:21Z","title":"Generating Fine-Grained Causality in Climate Time Series Data for\n  Forecasting and Anomaly Detection","summary":"  Understanding the causal interaction of time series variables can contribute\nto time series data analysis for many real-world applications, such as climate\nforecasting and extreme weather alerts. However, causal relationships are\ndifficult to be fully observed in real-world complex settings, such as\nspatial-temporal data from deployed sensor networks. Therefore, to capture\nfine-grained causal relations among spatial-temporal variables for further a\nmore accurate and reliable time series analysis, we first design a conceptual\nfine-grained causal model named TBN Granger Causality, which adds\ntime-respecting Bayesian Networks to the previous time-lagged Neural Granger\nCausality to offset the instantaneous effects. Second, we propose an end-to-end\ndeep generative model called TacSas, which discovers TBN Granger Causality in a\ngenerative manner to help forecast time series data and detect possible\nanomalies during the forecast. For evaluations, besides the causality discovery\nbenchmark Lorenz-96, we also test TacSas on climate benchmark ERA5 for climate\nforecasting and the extreme weather benchmark of NOAA for extreme weather\nalerts.\n","authors":["Dongqi Fu","Yada Zhu","Hanghang Tong","Kommy Weldemariam","Onkar Bhardwaj","Jingrui He"],"pdf_url":"https://arxiv.org/pdf/2408.04254v1.pdf","comment":"ICML 2024 AI for Science Workshop"},{"id":"http://arxiv.org/abs/2312.10308v4","updated":"2024-08-08T06:40:12Z","published":"2023-12-16T03:50:24Z","title":"Event-Based Contrastive Learning for Medical Time Series","summary":"  In clinical practice, one often needs to identify whether a patient is at\nhigh risk of adverse outcomes after some key medical event. For example,\nquantifying the risk of adverse outcomes after an acute cardiovascular event\nhelps healthcare providers identify those patients at the highest risk of poor\noutcomes; i.e., patients who benefit from invasive therapies that can lower\ntheir risk. Assessing the risk of adverse outcomes, however, is challenging due\nto the complexity, variability, and heterogeneity of longitudinal medical data,\nespecially for individuals suffering from chronic diseases like heart failure.\nIn this paper, we introduce Event-Based Contrastive Learning (EBCL) - a method\nfor learning embeddings of heterogeneous patient data that preserves temporal\ninformation before and after key index events. We demonstrate that EBCL can be\nused to construct models that yield improved performance on important\ndownstream tasks relative to other pretraining methods. We develop and test the\nmethod using a cohort of heart failure patients obtained from a large hospital\nnetwork and the publicly available MIMIC-IV dataset consisting of patients in\nan intensive care unit at a large tertiary care center. On both cohorts, EBCL\npretraining yields models that are performant with respect to a number of\ndownstream tasks, including mortality, hospital readmission, and length of\nstay. In addition, unsupervised EBCL embeddings effectively cluster heart\nfailure patients into subgroups with distinct outcomes, thereby providing\ninformation that helps identify new heart failure phenotypes. The contrastive\nframework around the index event can be adapted to a wide array of time-series\ndatasets and provides information that can be used to guide personalized care.\n","authors":["Hyewon Jeong","Nassim Oufattole","Matthew Mcdermott","Aparna Balagopalan","Bryan Jangeesingh","Marzyeh Ghassemi","Collin Stultz"],"pdf_url":"https://arxiv.org/pdf/2312.10308v4.pdf","comment":"Accepted at Unifying Representations in Neural Models Workshop in\n  NeurIPS 2023, MLHC 2024"},{"id":"http://arxiv.org/abs/2403.19913v2","updated":"2024-08-08T06:38:31Z","published":"2024-03-29T01:53:24Z","title":"MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of\n  Large Language Models","summary":"  Large language models such as ChatGPT and GPT-4 have recently achieved\nastonishing performance on a variety of natural language processing tasks. In\nthis paper, we propose MANGO, a benchmark to evaluate their capabilities to\nperform text-based mapping and navigation. Our benchmark includes 53 mazes\ntaken from a suite of textgames: each maze is paired with a walkthrough that\nvisits every location but does not cover all possible paths. The task is\nquestion-answering: for each maze, a large language model reads the walkthrough\nand answers hundreds of mapping and navigation questions such as \"How should\nyou go to Attic from West of House?\" and \"Where are we if we go north and east\nfrom Cellar?\". Although these questions are easy to humans, it turns out that\neven GPT-4, the best-to-date language model, performs poorly at answering them.\nFurther, our experiments suggest that a strong mapping and navigation ability\nwould benefit large language models in performing relevant downstream tasks,\nsuch as playing textgames. Our MANGO benchmark will facilitate future research\non methods that improve the mapping and navigation capabilities of language\nmodels. We host our leaderboard, data, code, and evaluation program at\nhttps://mango.ttic.edu and https://github.com/oaklight/mango/.\n","authors":["Peng Ding","Jiading Fang","Peng Li","Kangrui Wang","Xiaochen Zhou","Mo Yu","Jing Li","Matthew R. Walter","Hongyuan Mei"],"pdf_url":"https://arxiv.org/pdf/2403.19913v2.pdf","comment":"COLM 2024 camera-ready"},{"id":"http://arxiv.org/abs/2408.04251v1","updated":"2024-08-08T06:36:56Z","published":"2024-08-08T06:36:56Z","title":"Cooperative Multi-Agent Deep Reinforcement Learning in Content Ranking\n  Optimization","summary":"  In a typical e-commerce setting, Content Ranking Optimization (CRO)\nmechanisms are employed to surface content on the search page to fulfill\ncustomers' shopping missions. CRO commonly utilizes models such as contextual\ndeep bandits model to independently rank content at different positions, e.g.,\none optimizer dedicated to organic search results and another to sponsored\nresults. However, this regional optimization approach does not necessarily\ntranslate to whole page optimization, e.g., maximizing revenue at the top of\nthe page may inadvertently diminish the revenue of lower positions. In this\npaper, we propose a reinforcement learning based method for whole page ranking\nto jointly optimize across all positions by: 1) shifting from position level\noptimization to whole page level optimization to achieve an overall optimized\nranking; 2) applying reinforcement learning to optimize for the cumulative\nrewards instead of the instant reward. We formulate page level CRO as a\ncooperative Multi-agent Markov Decision Process , and address it with the novel\nMulti-Agent Deep Deterministic Policy Gradient (MADDPG) model. MADDPG supports\na flexible and scalable joint optimization framework by adopting a \"centralized\ntraining and decentralized execution\" approach. Extensive experiments\ndemonstrate that MADDPG scales to a 2.5 billion action space in the public\nMujoco environment, and outperforms the deep bandits modeling by 25.7% on the\noffline CRO data set from a leading e-commerce company. We foresee that this\nnovel multi-agent optimization is applicable to similar joint optimization\nproblems in the field of information retrieval.\n","authors":["Zhou Qin","Kai Yuan","Pratik Lahiri","Wenyang Liu"],"pdf_url":"https://arxiv.org/pdf/2408.04251v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2408.04245v1","updated":"2024-08-08T06:17:13Z","published":"2024-08-08T06:17:13Z","title":"Scalable Transformer for High Dimensional Multivariate Time Series\n  Forecasting","summary":"  Deep models for Multivariate Time Series (MTS) forecasting have recently\ndemonstrated significant success. Channel-dependent models capture complex\ndependencies that channel-independent models cannot capture. However, the\nnumber of channels in real-world applications outpaces the capabilities of\nexisting channel-dependent models, and contrary to common expectations, some\nmodels underperform the channel-independent models in handling high-dimensional\ndata, which raises questions about the performance of channel-dependent models.\nTo address this, our study first investigates the reasons behind the suboptimal\nperformance of these channel-dependent models on high-dimensional MTS data. Our\nanalysis reveals that two primary issues lie in the introduced noise from\nunrelated series that increases the difficulty of capturing the crucial\ninter-channel dependencies, and challenges in training strategies due to\nhigh-dimensional data. To address these issues, we propose STHD, the Scalable\nTransformer for High-Dimensional Multivariate Time Series Forecasting. STHD has\nthree components: a) Relation Matrix Sparsity that limits the noise introduced\nand alleviates the memory issue; b) ReIndex applied as a training strategy to\nenable a more flexible batch size setting and increase the diversity of\ntraining data; and c) Transformer that handles 2-D inputs and captures channel\ndependencies. These components jointly enable STHD to manage the\nhigh-dimensional MTS while maintaining computational feasibility. Furthermore,\nexperimental results show STHD's considerable improvement on three\nhigh-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source\ncode and dataset are publicly available\nhttps://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.\n","authors":["Xin Zhou","Weiqing Wang","Wray Buntine","Shilin Qu","Abishek Sriramulu","Weicong Tan","Christoph Bergmeir"],"pdf_url":"https://arxiv.org/pdf/2408.04245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04242v1","updated":"2024-08-08T06:08:04Z","published":"2024-08-08T06:08:04Z","title":"The Ungrounded Alignment Problem","summary":"  Modern machine learning systems have demonstrated substantial abilities with\nmethods that either embrace or ignore human-provided knowledge, but combining\nbenefits of both styles remains a challenge. One particular challenge involves\ndesigning learning systems that exhibit built-in responses to specific abstract\nstimulus patterns, yet are still plastic enough to be agnostic about the\nmodality and exact form of their inputs. In this paper, we investigate what we\ncall The Ungrounded Alignment Problem, which asks How can we build in\npredefined knowledge in a system where we don't know how a given stimulus will\nbe grounded? This paper examines a simplified version of the general problem,\nwhere an unsupervised learner is presented with a sequence of images for the\ncharacters in a text corpus, and this learner is later evaluated on its ability\nto recognize specific (possibly rare) sequential patterns. Importantly, the\nlearner is given no labels during learning or evaluation, but must map images\nfrom an unknown font or permutation to its correct class label. That is, at no\npoint is our learner given labeled images, where an image vector is explicitly\nassociated with a class label. Despite ample work in unsupervised and\nself-supervised loss functions, all current methods require a labeled\nfine-tuning phase to map the learned representations to correct classes.\nFinding this mapping in the absence of labels may seem a fool's errand, but our\nmain result resolves this seeming paradox. We show that leveraging only letter\nbigram frequencies is sufficient for an unsupervised learner both to reliably\nassociate images to class labels and to reliably identify trigger words in the\nsequence of inputs. More generally, this method suggests an approach for\nencoding specific desired innate behaviour in modality-agnostic models.\n","authors":["Marc Pickett","Aakash Kumar Nain","Joseph Modayil","Llion Jones"],"pdf_url":"https://arxiv.org/pdf/2408.04242v1.pdf","comment":"7 pages, plus references and appendix"},{"id":"http://arxiv.org/abs/2408.04236v1","updated":"2024-08-08T05:43:20Z","published":"2024-08-08T05:43:20Z","title":"Cluster-Wide Task Slowdown Detection in Cloud System","summary":"  Slow task detection is a critical problem in cloud operation and maintenance\nsince it is highly related to user experience and can bring substantial\nliquidated damages. Most anomaly detection methods detect it from a single-task\naspect. However, considering millions of concurrent tasks in large-scale cloud\ncomputing clusters, it becomes impractical and inefficient. Moreover,\nsingle-task slowdowns are very common and do not necessarily indicate a\nmalfunction of a cluster due to its violent fluctuation nature in a virtual\nenvironment. Thus, we shift our attention to cluster-wide task slowdowns by\nutilizing the duration time distribution of tasks across a cluster, so that the\ncomputation complexity is not relevant to the number of tasks.\n  The task duration time distribution often exhibits compound periodicity and\nlocal exceptional fluctuations over time. Though transformer-based methods are\none of the most powerful methods to capture these time series normal variation\npatterns, we empirically find and theoretically explain the flaw of the\nstandard attention mechanism in reconstructing subperiods with low amplitude\nwhen dealing with compound periodicity.\n  To tackle these challenges, we propose SORN (i.e., Skimming Off subperiods in\ndescending amplitude order and Reconstructing Non-slowing fluctuation), which\nconsists of a Skimming Attention mechanism to reconstruct the compound\nperiodicity and a Neural Optimal Transport module to distinguish cluster-wide\nslowdowns from other exceptional fluctuations. Furthermore, since anomalies in\nthe training set are inevitable in a practical scenario, we propose a picky\nloss function, which adaptively assigns higher weights to reliable time slots\nin the training set. Extensive experiments demonstrate that SORN outperforms\nstate-of-the-art methods on multiple real-world industrial datasets.\n","authors":["Feiyi Chen","Yingying Zhang","Lunting Fan","Yuxuan Liang","Guansong Pang","Qingsong Wen","Shuiguang Deng"],"pdf_url":"https://arxiv.org/pdf/2408.04236v1.pdf","comment":"This paper has been accepted by KDD2024"},{"id":"http://arxiv.org/abs/2408.04232v1","updated":"2024-08-08T05:37:17Z","published":"2024-08-08T05:37:17Z","title":"Enhanced Traffic Flow Prediction with Multi-Segment Fusion Tensor Graph\n  Convolutional Networks","summary":"  Accurate traffic Flow Prediction can assist in traffic management, route\nplanning, and congestion mitigation, which holds significant importance in\nenhancing the efficiency and reliability of intelligent transportation systems\n(ITS). However, existing traffic flow prediction models suffer from limitations\nin capturing the complex spatial-temporal dependencies within traffic networks.\nIn order to address this issue, this study proposes a multi-segment fusion\ntensor graph convolutional network (MS-FTGCN) for traffic flow prediction with\nthe following three-fold ideas: a) building a unified spatial-temporal graph\nconvolutional framework based on Tensor M-product, which capture the\nspatial-temporal patterns simultaneously; b) incorporating hourly, daily, and\nweekly components to model multi temporal properties of traffic flows,\nrespectively; c) fusing the outputs of the three components by attention\nmechanism to obtain the final traffic flow prediction results. The results of\nexperiments conducted on two traffic flow datasets demonstrate that the\nproposed MS-FTGCN outperforms the state-of-the-art models.\n","authors":["Wei Zhang","Peng Tang"],"pdf_url":"https://arxiv.org/pdf/2408.04232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04229v1","updated":"2024-08-08T05:33:21Z","published":"2024-08-08T05:33:21Z","title":"Probabilistic Circuits for Cumulative Distribution Functions","summary":"  A probabilistic circuit (PC) succinctly expresses a function that represents\na multivariate probability distribution and, given sufficient structural\nproperties of the circuit, supports efficient probabilistic inference.\nTypically a PC computes the probability mass (or density) function (PMF or PDF)\nof the distribution. We consider PCs instead computing the cumulative\ndistribution function (CDF). We show that for distributions over binary random\nvariables these representations (PMF and CDF) are essentially equivalent, in\nthe sense that one can be transformed to the other in polynomial time. We then\nshow how a similar equivalence holds for distributions over finite discrete\nvariables using a modification of the standard encoding with binary variables\nthat aligns with the CDF semantics. Finally we show that for continuous\nvariables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently\ntransformed to each other by modifying only the leaves of the circuit.\n","authors":["Oliver Broadrick","William Cao","Benjie Wang","Martin Trapp","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2408.04229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04221v1","updated":"2024-08-08T05:09:02Z","published":"2024-08-08T05:09:02Z","title":"Connective Viewpoints of Signal-to-Noise Diffusion Models","summary":"  Diffusion models (DM) have become fundamental components of generative\nmodels, excelling across various domains such as image creation, audio\ngeneration, and complex data interpolation. Signal-to-Noise diffusion models\nconstitute a diverse family covering most state-of-the-art diffusion models.\nWhile there have been several attempts to study Signal-to-Noise (S2N) diffusion\nmodels from various perspectives, there remains a need for a comprehensive\nstudy connecting different viewpoints and exploring new perspectives. In this\nstudy, we offer a comprehensive perspective on noise schedulers, examining\ntheir role through the lens of the signal-to-noise ratio (SNR) and its\nconnections to information theory. Building upon this framework, we have\ndeveloped a generalized backward equation to enhance the performance of the\ninference process.\n","authors":["Khanh Doan","Long Tung Vuong","Tuan Nguyen","Anh Tuan Bui","Quyen Tran","Thanh-Toan Do","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2408.04221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04220v1","updated":"2024-08-08T05:06:22Z","published":"2024-08-08T05:06:22Z","title":"Diffusion Guided Language Modeling","summary":"  Current language models demonstrate remarkable proficiency in text\ngeneration. However, for many applications it is desirable to control\nattributes, such as sentiment, or toxicity, of the generated language --\nideally tailored towards each specific use case and target audience. For\nauto-regressive language models, existing guidance methods are prone to\ndecoding errors that cascade during generation and degrade performance. In\ncontrast, text diffusion models can easily be guided with, for example, a\nsimple linear sentiment classifier -- however they do suffer from significantly\nhigher perplexity than auto-regressive alternatives. In this paper we use a\nguided diffusion model to produce a latent proposal that steers an\nauto-regressive language model to generate text with desired properties. Our\nmodel inherits the unmatched fluency of the auto-regressive approach and the\nplug-and-play flexibility of diffusion. We show that it outperforms previous\nplug-and-play guidance methods across a wide range of benchmark data sets.\nFurther, controlling a new attribute in our framework is reduced to training a\nsingle logistic regression classifier.\n","authors":["Justin Lovelace","Varsha Kishore","Yiwei Chen","Kilian Q. Weinberger"],"pdf_url":"https://arxiv.org/pdf/2408.04220v1.pdf","comment":"ACL Findings 2024"},{"id":"http://arxiv.org/abs/2106.11528v3","updated":"2024-08-08T04:18:34Z","published":"2021-06-22T03:44:03Z","title":"Recent Deep Semi-supervised Learning Approaches and Related Works","summary":"  This work proposes an overview of the recent semi-supervised learning\napproaches and related works. Despite the remarkable success of neural networks\nin various applications, there exist a few formidable constraints, including\nthe need for a large amount of labeled data. Therefore, semi-supervised\nlearning, which is a learning scheme in which scarce labels and a larger amount\nof unlabeled data are utilized to train models (e.g., deep neural networks), is\ngetting more important. Based on the key assumptions of semi-supervised\nlearning, which are the manifold assumption, cluster assumption, and continuity\nassumption, the work reviews the recent semi-supervised learning approaches. In\nparticular, the methods in regard to using deep neural networks in a\nsemi-supervised learning setting are primarily discussed. In addition, the\nexisting works are first classified based on the underlying idea and explained,\nthen the holistic approaches that unify the aforementioned ideas are detailed.\n","authors":["Gyeongho Kim"],"pdf_url":"https://arxiv.org/pdf/2106.11528v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04353v5","updated":"2024-08-08T04:15:31Z","published":"2023-10-06T16:21:22Z","title":"An In-Context Learning Agent for Formal Theorem-Proving","summary":"  We present an in-context learning agent for formal theorem-proving in\nenvironments like Lean and Coq. Current state-of-the-art models for the problem\nare finetuned on environment-specific proof data. By contrast, our approach,\ncalled COPRA, repeatedly asks a high-capacity, general-purpose large language\nmodel (GPT-4) to propose tactic applications from within a stateful\nbacktracking search. Proposed tactics are executed in the underlying proof\nenvironment. Feedback from the execution is used to build the prompt for the\nnext model query, along with selected information from the search history and\nlemmas retrieved from an external database. We evaluate our implementation of\nCOPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the\nCompCert project. On these benchmarks, COPRA significantly outperforms few-shot\ninvocations of GPT-4. It also compares favorably against finetuning-based\napproaches, outperforming ReProver, a state-of-the-art finetuned approach for\nLean, in terms of the pass@1 metric. Our code and data are available at\nhttps://github.com/trishullab/copra.\n","authors":["Amitayush Thakur","George Tsoukalas","Yeming Wen","Jimmy Xin","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2310.04353v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04206v1","updated":"2024-08-08T04:05:50Z","published":"2024-08-08T04:05:50Z","title":"DC Algorithm for Estimation of Sparse Gaussian Graphical Models","summary":"  Sparse estimation for Gaussian graphical models is a crucial technique for\nmaking the relationships among numerous observed variables more interpretable\nand quantifiable. Various methods have been proposed, including graphical\nlasso, which utilizes the $\\ell_1$ norm as a regularization term, as well as\nmethods employing non-convex regularization terms. However, most of these\nmethods approximate the $\\ell_0$ norm with convex functions. To estimate more\naccurate solutions, it is desirable to treat the $\\ell_0$ norm directly as a\nregularization term. In this study, we formulate the sparse estimation problem\nfor Gaussian graphical models using the $\\ell_0$ norm and propose a method to\nsolve this problem using the Difference of Convex functions Algorithm (DCA).\nSpecifically, we convert the $\\ell_0$ norm constraint into an equivalent\nlargest-$K$ norm constraint, reformulate the constrained problem into a\npenalized form, and solve it using the DC algorithm (DCA). Furthermore, we\ndesigned an algorithm that efficiently computes using graphical lasso.\nExperimental results with synthetic data show that our method yields results\nthat are equivalent to or better than existing methods. Comparisons of model\nlearning through cross-validation confirm that our method is particularly\nadvantageous in selecting true edges.\n","authors":["Tomokaze Shiratori","Yuichi Takano"],"pdf_url":"https://arxiv.org/pdf/2408.04206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07887v5","updated":"2024-08-08T03:49:59Z","published":"2023-12-13T04:14:22Z","title":"Learn or Recall? Revisiting Incremental Learning with Pre-trained\n  Language Models","summary":"  Incremental Learning (IL) has been a long-standing problem in both vision and\nNatural Language Processing (NLP) communities. In recent years, as Pre-trained\nLanguage Models (PLMs) have achieved remarkable progress in various NLP\ndownstream tasks, utilizing PLMs as backbones has become a common practice in\nrecent research of IL in NLP. Most assume that catastrophic forgetting is the\nbiggest obstacle to achieving superior IL performance and propose various\ntechniques to overcome this issue. However, we find that this assumption is\nproblematic. Specifically, we revisit more than 20 methods on four\nclassification tasks (Text Classification, Intent Classification, Relation\nExtraction, and Named Entity Recognition) under the two most popular IL\nsettings (Class-Incremental and Task-Incremental) and reveal that most of them\nseverely underestimate the inherent anti-forgetting ability of PLMs. Based on\nthe observation, we propose a frustratingly easy method called SEQ* for IL with\nPLMs. The results show that SEQ* has competitive or superior performance\ncompared to state-of-the-art (SOTA) IL methods and requires considerably less\ntrainable parameters and training time. These findings urge us to revisit the\nIL with PLMs and encourage future studies to have a fundamental understanding\nof the catastrophic forgetting in PLMs. The data, code and scripts are publicly\navailable at\nhttps://github.com/zzz47zzz/codebase-for-incremental-learning-with-llm.\n","authors":["Junhao Zheng","Shengjie Qiu","Qianli Ma"],"pdf_url":"https://arxiv.org/pdf/2312.07887v5.pdf","comment":"ACL 2024 main conference (Oral)"},{"id":"http://arxiv.org/abs/2312.10385v4","updated":"2024-08-08T03:44:21Z","published":"2023-12-16T08:48:46Z","title":"Imitate the Good and Avoid the Bad: An Incremental Approach to Safe\n  Reinforcement Learning","summary":"  A popular framework for enforcing safe actions in Reinforcement Learning (RL)\nis Constrained RL, where trajectory based constraints on expected cost (or\nother cost measures) are employed to enforce safety and more importantly these\nconstraints are enforced while maximizing expected reward. Most recent\napproaches for solving Constrained RL convert the trajectory based cost\nconstraint into a surrogate problem that can be solved using minor\nmodifications to RL methods. A key drawback with such approaches is an over or\nunderestimation of the cost constraint at each state. Therefore, we provide an\napproach that does not modify the trajectory based cost constraint and instead\nimitates ``good'' trajectories and avoids ``bad'' trajectories generated from\nincrementally improving policies. We employ an oracle that utilizes a reward\nthreshold (which is varied with learning) and the overall cost constraint to\nlabel trajectories as ``good'' or ``bad''. A key advantage of our approach is\nthat we are able to work from any starting policy or set of trajectories and\nimprove on it. In an exhaustive set of experiments, we demonstrate that our\napproach is able to outperform top benchmark approaches for solving Constrained\nRL problems, with respect to expected cost, CVaR cost, or even unknown cost\nconstraints.\n","authors":["Huy Hoang","Tien Mai","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2312.10385v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04193v1","updated":"2024-08-08T03:25:41Z","published":"2024-08-08T03:25:41Z","title":"Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate\n  Graph Neural Networks","summary":"  Crime forecasting is a critical component of urban analysis and essential for\nstabilizing society today. Unlike other time series forecasting problems, crime\nincidents are sparse, particularly in small regions and within specific time\nperiods. Traditional spatial-temporal deep learning models often struggle with\nthis sparsity, as they typically cannot effectively handle the non-Gaussian\nnature of crime data, which is characterized by numerous zeros and\nover-dispersed patterns. To address these challenges, we introduce a novel\napproach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial\nGraph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and\nconvolution networks to analyze spatial, temporal, and multivariate\ncorrelations, enabling the parameterization of probabilistic distributions of\ncrime incidents. By incorporating a Zero-Inflated Negative Binomial model,\nSTMGNN-ZINB effectively manages the sparse nature of crime data, enhancing\nprediction accuracy and the precision of confidence intervals. Our evaluation\non real-world datasets confirms that STMGNN-ZINB outperforms existing models,\nproviding a more reliable tool for predicting and understanding crime dynamics.\n","authors":["Zepu Wang","Xiaobo Ma","Huajie Yang","Weimin Lvu","Peng Sun","Sharath Chandra Guntuku"],"pdf_url":"https://arxiv.org/pdf/2408.04193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12539v3","updated":"2024-08-08T03:20:17Z","published":"2023-08-24T03:53:55Z","title":"CALM : A Multi-task Benchmark for Comprehensive Assessment of Language\n  Model Bias","summary":"  As language models (LMs) become increasingly powerful and widely used, it is\nimportant to quantify them for sociodemographic bias with potential for harm.\nPrior measures of bias are sensitive to perturbations in the templates designed\nto compare performance across social groups, due to factors such as low\ndiversity or limited number of templates. Also, most previous work considers\nonly one NLP task. We introduce Comprehensive Assessment of Language Models\n(CALM) for robust measurement of two types of universally relevant\nsociodemographic bias, gender and race. CALM integrates sixteen datasets for\nquestion-answering, sentiment analysis and natural language inference. Examples\nfrom each dataset are filtered to produce 224 templates with high diversity\n(e.g., length, vocabulary). We assemble 50 highly frequent person names for\neach of seven distinct demographic groups to generate 78,400 prompts covering\nthe three NLP tasks. Our empirical evaluation shows that CALM bias scores are\nmore robust and far less sensitive than previous bias measurements to\nperturbations in the templates, such as synonym substitution, or to random\nsubset selection of templates. We apply CALM to 20 large language models, and\nfind that for 2 language model series, larger parameter models tend to be more\nbiased than smaller ones. The T0 series is the least biased model families, of\nthe 20 LLMs investigated here. The code is available at\nhttps://github.com/vipulgupta1011/CALM.\n","authors":["Vipul Gupta","Pranav Narayanan Venkit","Hugo Laurençon","Shomir Wilson","Rebecca J. Passonneau"],"pdf_url":"https://arxiv.org/pdf/2308.12539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04190v1","updated":"2024-08-08T03:18:42Z","published":"2024-08-08T03:18:42Z","title":"Listwise Reward Estimation for Offline Preference-based Reinforcement\n  Learning","summary":"  In Reinforcement Learning (RL), designing precise reward functions remains to\nbe a challenge, particularly when aligning with human intent. Preference-based\nRL (PbRL) was introduced to address this problem by learning reward models from\nhuman feedback. However, existing PbRL methods have limitations as they often\noverlook the second-order preference that indicates the relative strength of\npreference. In this paper, we propose Listwise Reward Estimation (LiRE), a\nnovel approach for offline PbRL that leverages second-order preference\ninformation by constructing a Ranked List of Trajectories (RLT), which can be\nefficiently built by using the same ternary feedback type as traditional\nmethods. To validate the effectiveness of LiRE, we propose a new offline PbRL\ndataset that objectively reflects the effect of the estimated rewards. Our\nextensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,\noutperforming state-of-the-art baselines even with modest feedback budgets and\nenjoying robustness with respect to the number of feedbacks and feedback noise.\nOur code is available at https://github.com/chwoong/LiRE\n","authors":["Heewoong Choi","Sangwon Jung","Hongjoon Ahn","Taesup Moon"],"pdf_url":"https://arxiv.org/pdf/2408.04190v1.pdf","comment":"21 pages, ICML 2024"},{"id":"http://arxiv.org/abs/2308.09296v4","updated":"2024-08-08T03:06:37Z","published":"2023-08-18T04:45:56Z","title":"CARLA: Self-supervised Contrastive Representation Learning for Time\n  Series Anomaly Detection","summary":"  One main challenge in time series anomaly detection (TSAD) is the lack of\nlabelled data in many real-life scenarios. Most of the existing anomaly\ndetection methods focus on learning the normal behaviour of unlabelled time\nseries in an unsupervised manner. The normal boundary is often defined tightly,\nresulting in slight deviations being classified as anomalies, consequently\nleading to a high false positive rate and a limited ability to generalise\nnormal patterns. To address this, we introduce a novel end-to-end\nself-supervised ContrAstive Representation Learning approach for time series\nAnomaly detection (CARLA). While existing contrastive learning methods assume\nthat augmented time series windows are positive samples and temporally distant\nwindows are negative samples, we argue that these assumptions are limited as\naugmentation of time series can transform them to negative samples, and a\ntemporally distant window can represent a positive sample. Our contrastive\napproach leverages existing generic knowledge about time series anomalies and\ninjects various types of anomalies as negative samples. Therefore, CARLA not\nonly learns normal behaviour but also learns deviations indicating anomalies.\nIt creates similar representations for temporally closed windows and distinct\nones for anomalies. Additionally, it leverages the information about\nrepresentations' neighbours through a self-supervised approach to classify\nwindows based on their nearest/furthest neighbours to further enhance the\nperformance of anomaly detection. In extensive tests on seven major real-world\ntime series anomaly detection datasets, CARLA shows superior performance over\nstate-of-the-art self-supervised and unsupervised TSAD methods. Our research\nshows the potential of contrastive representation learning to advance time\nseries anomaly detection.\n","authors":["Zahra Zamanzadeh Darban","Geoffrey I. Webb","Shirui Pan","Charu C. Aggarwal","Mahsa Salehi"],"pdf_url":"https://arxiv.org/pdf/2308.09296v4.pdf","comment":"36 pages, 9 figures, 9 tables"},{"id":"http://arxiv.org/abs/2408.04179v1","updated":"2024-08-08T02:53:09Z","published":"2024-08-08T02:53:09Z","title":"An Upper Confidence Bound Approach to Estimating the Maximum Mean","summary":"  Estimating the maximum mean finds a variety of applications in practice. In\nthis paper, we study estimation of the maximum mean using an upper confidence\nbound (UCB) approach where the sampling budget is adaptively allocated to one\nof the systems. We study in depth the existing grand average (GA) estimator,\nand propose a new largest-size average (LSA) estimator. Specifically, we\nestablish statistical guarantees, including strong consistency, asymptotic mean\nsquared errors, and central limit theorems (CLTs) for both estimators, which\nare new to the literature. We show that LSA is preferable over GA, as the bias\nof the former decays at a rate much faster than that of the latter when sample\nsize increases. By using the CLTs, we further construct asymptotically valid\nconfidence intervals for the maximum mean, and propose a single hypothesis test\nfor a multiple comparison problem with application to clinical trials.\nStatistical efficiency of the resulting point and interval estimates and the\nproposed single hypothesis test is demonstrated via numerical examples.\n","authors":["Zhang Kun","Liu Guangwu","Shi Wen"],"pdf_url":"https://arxiv.org/pdf/2408.04179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12808v2","updated":"2024-08-08T02:44:47Z","published":"2024-02-20T08:27:50Z","title":"Learning Generalization and Regularization of Nonhomogeneous Temporal\n  Poisson Processes","summary":"  The Poisson process, especially the nonhomogeneous Poisson process (NHPP), is\nan essentially important counting process with numerous real-world\napplications. Up to date, almost all works in the literature have been on the\nestimation of NHPPs with infinite data using non-data driven binning methods.\nIn this paper, we formulate the problem of estimation of NHPPs from finite and\nlimited data as a learning generalization problem. We mathematically show that\nwhile binning methods are essential for the estimation of NHPPs, they pose a\nthreat of overfitting when the amount of data is limited. We propose a\nframework for regularized learning of NHPPs with two new adaptive and\ndata-driven binning methods that help to remove the ad-hoc tuning of binning\nparameters. Our methods are experimentally tested on synthetic and real-world\ndatasets and the results show their effectiveness.\n","authors":["Son Nguyen Van","Hoai Nguyen Xuan"],"pdf_url":"https://arxiv.org/pdf/2402.12808v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2408.04175v1","updated":"2024-08-08T02:38:19Z","published":"2024-08-08T02:38:19Z","title":"pyBregMan: A Python library for Bregman Manifolds","summary":"  A Bregman manifold is a synonym for a dually flat space in information\ngeometry which admits as a canonical divergence a Bregman divergence. Bregman\nmanifolds are induced by smooth strictly convex functions like the cumulant or\npartition functions of regular exponential families, the negative entropy of\nmixture families, or the characteristic functions of regular cones just to list\na few such convex Bregman generators. We describe the design of pyBregMan, a\nlibrary which implements generic operations on Bregman manifolds and\ninstantiate several common Bregman manifolds used in information sciences. At\nthe core of the library is the notion of Legendre-Fenchel duality inducing a\ncanonical pair of dual potential functions and dual Bregman divergences. The\nlibrary also implements the Fisher-Rao manifolds of categorical/multinomial\ndistributions and multivariate normal distributions. To demonstrate the use of\nthe pyBregMan kernel manipulating those Bregman and Fisher-Rao manifolds, the\nlibrary also provides several core algorithms for various applications in\nstatistics, machine learning, information fusion, and so on.\n","authors":["Frank Nielsen","Alexander Soen"],"pdf_url":"https://arxiv.org/pdf/2408.04175v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2408.04174v1","updated":"2024-08-08T02:36:04Z","published":"2024-08-08T02:36:04Z","title":"wav2graph: A Framework for Supervised Learning Knowledge Graph from\n  Speech","summary":"  Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.\n","authors":["Khai Le-Duc","Quy-Anh Dang","Tan-Hanh Pham","Truong-Son Hy"],"pdf_url":"https://arxiv.org/pdf/2408.04174v1.pdf","comment":"Preprint, 32 pages"},{"id":"http://arxiv.org/abs/2207.05377v2","updated":"2024-08-08T02:10:45Z","published":"2022-07-12T08:20:41Z","title":"On the Generalization for Transfer Learning: An Information-Theoretic\n  Analysis","summary":"  Transfer learning, or domain adaptation, is concerned with machine learning\nproblems in which training and testing data come from possibly different\nprobability distributions. In this work, we give an information-theoretic\nanalysis of the generalization error and excess risk of transfer learning\nalgorithms. Our results suggest, perhaps as expected, that the Kullback-Leibler\n(KL) divergence $D(\\mu\\|\\mu')$ plays an important role in the characterizations\nwhere $\\mu$ and $\\mu'$ denote the distribution of the training data and the\ntesting data, respectively. Specifically, we provide generalization error and\nexcess risk upper bounds for learning algorithms where data from both\ndistributions are available in the training phase. Recognizing that the bounds\ncould be sub-optimal in general, we provide improved excess risk upper bounds\nfor a certain class of algorithms, including the empirical risk minimization\n(ERM) algorithm, by making stronger assumptions through the \\textit{central\ncondition}. To demonstrate the usefulness of the bounds, we further extend the\nanalysis to the Gibbs algorithm and the noisy stochastic gradient descent\nmethod. We then generalize the mutual information bound with other divergences\nsuch as $\\phi$-divergence and Wasserstein distance, which may lead to tighter\nbounds and can handle the case when $\\mu$ is not absolutely continuous with\nrespect to $\\mu'$. Several numerical results are provided to demonstrate our\ntheoretical findings. Lastly, to address the problem that the bounds are often\nnot directly applicable in practice due to the absence of the distributional\nknowledge of the data, we develop an algorithm (called InfoBoost) that\ndynamically adjusts the importance weights for both source and target data\nbased on certain information measures. The empirical results show the\neffectiveness of the proposed algorithm.\n","authors":["Xuetong Wu","Jonathan H. Manton","Uwe Aickelin","Jingge Zhu"],"pdf_url":"https://arxiv.org/pdf/2207.05377v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.05879v2","updated":"2024-08-08T01:54:30Z","published":"2024-04-08T21:26:04Z","title":"Rapid and Precise Topological Comparison with Merge Tree Neural Networks","summary":"  Merge trees are a valuable tool in the scientific visualization of scalar\nfields; however, current methods for merge tree comparisons are computationally\nexpensive, primarily due to the exhaustive matching between tree nodes. To\naddress this challenge, we introduce the Merge Tree Neural Network (MTNN), a\nlearned neural network model designed for merge tree comparison. The MTNN\nenables rapid and high-quality similarity computation. We first demonstrate how\nto train graph neural networks, which emerged as effective encoders for graphs,\nin order to produce embeddings of merge trees in vector spaces for efficient\nsimilarity comparison. Next, we formulate the novel MTNN model that further\nimproves the similarity comparisons by integrating the tree and node embeddings\nwith a new topological attention mechanism. We demonstrate the effectiveness of\nour model on real-world data in different domains and examine our model's\ngeneralizability across various datasets. Our experimental analysis\ndemonstrates our approach's superiority in accuracy and efficiency. In\nparticular, we speed up the prior state-of-the-art by more than $100\\times$ on\nthe benchmark datasets while maintaining an error rate below $0.1\\%$.\n","authors":["Yu Qin","Brittany Terese Fasy","Carola Wenk","Brian Summa"],"pdf_url":"https://arxiv.org/pdf/2404.05879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00736v4","updated":"2024-08-08T01:49:10Z","published":"2023-09-01T21:16:02Z","title":"Prediction Error Estimation in Random Forests","summary":"  In this paper, error estimates of classification Random Forests are\nquantitatively assessed. Based on the initial theoretical framework built by\nBates et al. (2023), the true error rate and expected error rate are\ntheoretically and empirically investigated in the context of a variety of error\nestimation methods common to Random Forests. We show that in the classification\ncase, Random Forests' estimates of prediction error is closer on average to the\ntrue error rate instead of the average prediction error. This is opposite the\nfindings of Bates et al. (2023) which are given for logistic regression. We\nfurther show that our result holds across different error estimation strategies\nsuch as cross-validation, bagging, and data splitting.\n","authors":["Ian Krupkin","Johanna Hardin"],"pdf_url":"https://arxiv.org/pdf/2309.00736v4.pdf","comment":"As we were working on revisions, we found a fatal flaw in the\n  procedure. All of the results are problematic / wrong"},{"id":"http://arxiv.org/abs/2311.08817v2","updated":"2024-08-08T01:46:19Z","published":"2023-11-15T09:38:53Z","title":"MAP's not dead yet: Uncovering true language model modes by conditioning\n  away degeneracy","summary":"  It has been widely observed that exact or approximate MAP (mode-seeking)\ndecoding from natural language generation (NLG) models consistently leads to\ndegenerate outputs (Holtzman et al., 2019; Stahlberg and Byrne, 2019). Prior\nwork has attributed this behavior to either a fundamental and unavoidable\ninadequacy of modes in probabilistic models or weaknesses in language modeling.\nContrastingly, we argue that degenerate modes can even occur in the absence of\nany modeling error, due to contamination of the training data. Specifically, we\nargue that mixing even a tiny amount of low-entropy noise with a population\ntext distribution can cause the data distribution's mode to become degenerate.\nWe therefore propose to apply MAP decoding to the model's true conditional\ndistribution where the conditioning variable explicitly avoids specific\ndegenerate behavior. Using exact search, we empirically verify that the\nlength-conditional modes of machine translation models and language models are\nindeed more fluent and topical than their unconditional modes. For the first\ntime, we also share many examples of exact modal sequences from these models,\nand from several variants of the LLaMA-7B model. Notably, we observe that\nvarious kinds of degenerate modes persist, even at the scale of LLaMA-7B.\nAlthough we cannot tractably address these degeneracies with exact search, we\nperform a classifier-based approximate search on LLaMA-7B, a model which was\nnot trained for instruction following, and find that we are able to elicit\nreasonable outputs without any finetuning.\n","authors":["Davis Yoshida","Kartik Goyal","Kevin Gimpel"],"pdf_url":"https://arxiv.org/pdf/2311.08817v2.pdf","comment":"52 pages, 5 figures, ACL version"},{"id":"http://arxiv.org/abs/2408.04154v1","updated":"2024-08-08T01:42:31Z","published":"2024-08-08T01:42:31Z","title":"The Data Addition Dilemma","summary":"  In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.\n","authors":["Judy Hanwen Shen","Inioluwa Deborah Raji","Irene Y. Chen"],"pdf_url":"https://arxiv.org/pdf/2408.04154v1.pdf","comment":"Machine Learning For Health Care 2024 (MLHC)"},{"id":"http://arxiv.org/abs/2408.00992v3","updated":"2024-08-08T01:23:11Z","published":"2024-08-02T03:44:14Z","title":"Fairness in Large Language Models in Three Hours","summary":"  Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.\n","authors":["Thang Doan Viet","Zichong Wang","Minh Nhat Nguyen","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.00992v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.09340v4","updated":"2024-08-08T00:30:35Z","published":"2023-03-16T14:21:45Z","title":"Improving Automated Hemorrhage Detection in Sparse-view Computed\n  Tomography via Deep Convolutional Neural Network based Artifact Reduction","summary":"  This is a preprint. The latest version has been published here:\nhttps://pubs.rsna.org/doi/10.1148/ryai.230275\n  Purpose: Sparse-view computed tomography (CT) is an effective way to reduce\ndose by lowering the total number of views acquired, albeit at the expense of\nimage quality, which, in turn, can impact the ability to detect diseases. We\nexplore deep learning-based artifact reduction in sparse-view cranial CT scans\nand its impact on automated hemorrhage detection. Methods: We trained a U-Net\nfor artefact reduction on simulated sparse-view cranial CT scans from 3000\npatients obtained from a public dataset and reconstructed with varying levels\nof sub-sampling. Additionally, we trained a convolutional neural network on\nfully sampled CT data from 17,545 patients for automated hemorrhage detection.\nWe evaluated the classification performance using the area under the receiver\noperator characteristic curves (AUC-ROCs) with corresponding 95% confidence\nintervals (CIs) and the DeLong test, along with confusion matrices. The\nperformance of the U-Net was compared to an analytical approach based on total\nvariation (TV). Results: The U-Net performed superior compared to unprocessed\nand TV-processed images with respect to image quality and automated hemorrhage\ndiagnosis. With U-Net post-processing, the number of views can be reduced from\n4096 (AUC-ROC: 0.974; 95% CI: 0.972-0.976) views to 512 views (0.973;\n0.971-0.975) with minimal decrease in hemorrhage detection (P<.001) and to 256\nviews (0.967; 0.964-0.969) with a slight performance decrease (P<.001).\nConclusion: The results suggest that U-Net based artifact reduction\nsubstantially enhances automated hemorrhage detection in sparse-view cranial\nCTs. Our findings highlight that appropriate post-processing is crucial for\noptimal image quality and diagnostic accuracy while minimizing radiation dose.\n","authors":["Johannes Thalhammer","Manuel Schultheiss","Tina Dorosti","Tobias Lasser","Franz Pfeiffer","Daniela Pfeiffer","Florian Schaff"],"pdf_url":"https://arxiv.org/pdf/2303.09340v4.pdf","comment":"11 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2406.15786v4","updated":"2024-08-08T00:30:20Z","published":"2024-06-22T08:41:48Z","title":"What Matters in Transformers? Not All Attention is Needed","summary":"  Scaling Transformer-based large language models (LLMs) has demonstrated\npromising performance across various tasks. However, it also introduces\nredundant structures, posing challenges for real-world deployment. Despite some\nrecognition of redundancy in LLMs, the variability of redundancy across\ndifferent modules, such as MLP and Attention layers, is under-explored. In this\nwork, we investigate the varying redundancy across different modules within\nTransformers, including Blocks, MLP, and Attention layers, using a\nsimilarity-based metric. This metric operates on the premise that redundant\nstructures produce outputs highly similar to their inputs. Surprisingly, while\nattention layers are essential for transformers and distinguish them from other\nmainstream architectures, we found that a large proportion of attention layers\nexhibit excessively high similarity and can be safely pruned without degrading\nperformance, leading to reduced memory and computation costs. Additionally, we\nfurther propose a method that jointly drops Attention and MLP layers, achieving\nimproved performance and dropping ratios. Extensive experiments demonstrate the\neffectiveness of our methods, e.g., Llama-3-70B maintains comparable\nperformance even after pruning half of the attention layers. Our findings\nprovide valuable insights for future network architecture design. The code is\nreleased at: \\url{https://github.com/Shwai-He/LLM-Drop}.\n","authors":["Shwai He","Guoheng Sun","Zheyu Shen","Ang Li"],"pdf_url":"https://arxiv.org/pdf/2406.15786v4.pdf","comment":"15 pages, 13 figures, 6 tables"}],"Machine Learning Theory":[{"id":"http://arxiv.org/abs/2408.04607v1","updated":"2024-08-08T17:27:29Z","published":"2024-08-08T17:27:29Z","title":"Risk and cross validation in ridge regression with correlated samples","summary":"  Recent years have seen substantial advances in our understanding of\nhigh-dimensional ridge regression, but existing theories assume that training\nexamples are independent. By leveraging recent techniques from random matrix\ntheory and free probability, we provide sharp asymptotics for the in- and\nout-of-sample risks of ridge regression when the data points have arbitrary\ncorrelations. We demonstrate that in this setting, the generalized cross\nvalidation estimator (GCV) fails to correctly predict the out-of-sample risk.\nHowever, in the case where the noise residuals have the same correlations as\nthe data points, one can modify the GCV to yield an efficiently-computable\nunbiased estimator that concentrates in the high-dimensional limit, which we\ndub CorrGCV. We further extend our asymptotic analysis to the case where the\ntest point has nontrivial correlations with the training set, a setting often\nencountered in time series forecasting. Assuming knowledge of the correlation\nstructure of the time series, this again yields an extension of the GCV\nestimator, and sharply characterizes the degree to which such test points yield\nan overly optimistic prediction of long-time risk. We validate the predictions\nof our theory across a variety of high dimensional data.\n","authors":["Alexander Atanasov","Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2408.04607v1.pdf","comment":"44 pages, 18 figures"},{"id":"http://arxiv.org/abs/2408.04595v1","updated":"2024-08-08T17:11:36Z","published":"2024-08-08T17:11:36Z","title":"Inference with the Upper Confidence Bound Algorithm","summary":"  In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.\n","authors":["Koulik Khamaru","Cun-Hui Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.04595v1.pdf","comment":"17 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.04569v1","updated":"2024-08-08T16:28:56Z","published":"2024-08-08T16:28:56Z","title":"Activation thresholds and expressiveness of polynomial neural networks","summary":"  Polynomial neural networks have been implemented in a range of applications\nand present an advantageous framework for theoretical machine learning. A\npolynomial neural network of fixed architecture and activation degree gives an\nalgebraic map from the network's weights to a set of polynomials. The image of\nthis map is the space of functions representable by the network. Its Zariski\nclosure is an affine variety known as a neurovariety. The dimension of a\npolynomial neural network's neurovariety provides a measure of its\nexpressivity. In this work, we introduce the notion of the activation threshold\nof a network architecture which expresses when the dimension of a neurovariety\nachieves its theoretical maximum. In addition, we prove expressiveness results\nfor polynomial neural networks with equi-width~architectures.\n","authors":["Bella Finkel","Jose Israel Rodriguez","Chenxi Wu","Thomas Yahl"],"pdf_url":"https://arxiv.org/pdf/2408.04569v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2406.01561v3","updated":"2024-08-08T16:00:01Z","published":"2024-06-03T17:44:11Z","title":"Long and Short Guidance in Score identity Distillation for One-Step\n  Text-to-Image Generation","summary":"  Diffusion-based text-to-image generation models trained on extensive\ntext-image pairs have shown the capacity to generate photorealistic images\nconsistent with textual descriptions. However, a significant limitation of\nthese models is their slow sample generation, which requires iterative\nrefinement through the same network. In this paper, we enhance Score identity\nDistillation (SiD) by developing long and short classifier-free guidance (LSG)\nto efficiently distill pretrained Stable Diffusion models without using real\ntraining data. SiD aims to optimize a model-based explicit score matching loss,\nutilizing a score-identity-based approximation alongside the proposed LSG for\npractical computation. By training exclusively with fake images synthesized\nwith its one-step generator, SiD equipped with LSG rapidly improves FID and\nCLIP scores, achieving state-of-the-art FID performance while maintaining a\ncompetitive CLIP score. Specifically, its data-free distillation of Stable\nDiffusion 1.5 achieves a record low FID of 8.15 on the COCO-2014 validation\nset, with a CLIP score of 0.304 at an LSG scale of 1.5, and an FID of 9.56 with\na CLIP score of 0.313 at an LSG scale of 2. Our code and distilled one-step\ntext-to-image generators are available at\nhttps://github.com/mingyuanzhou/SiD-LSG.\n","authors":["Mingyuan Zhou","Zhendong Wang","Huangjie Zheng","Hai Huang"],"pdf_url":"https://arxiv.org/pdf/2406.01561v3.pdf","comment":"Code and model checkpoints available at\n  https://github.com/mingyuanzhou/SiD-LSG"},{"id":"http://arxiv.org/abs/2408.04526v1","updated":"2024-08-08T15:26:18Z","published":"2024-08-08T15:26:18Z","title":"Hybrid Reinforcement Learning Breaks Sample Size Barriers in Linear MDPs","summary":"  Hybrid Reinforcement Learning (RL), where an agent learns from both an\noffline dataset and online explorations in an unknown environment, has garnered\nsignificant recent interest. A crucial question posed by Xie et al. (2022) is\nwhether hybrid RL can improve upon the existing lower bounds established in\npurely offline and purely online RL without relying on the single-policy\nconcentrability assumption. While Li et al. (2023) provided an affirmative\nanswer to this question in the tabular PAC RL case, the question remains\nunsettled for both the regret-minimizing RL case and the non-tabular case.\n  In this work, building upon recent advancements in offline RL and\nreward-agnostic exploration, we develop computationally efficient algorithms\nfor both PAC and regret-minimizing RL with linear function approximation,\nwithout single-policy concentrability. We demonstrate that these algorithms\nachieve sharper error or regret bounds that are no worse than, and can improve\non, the optimal sample complexity in offline RL (the first algorithm, for PAC\nRL) and online RL (the second algorithm, for regret-minimizing RL) in linear\nMarkov decision processes (MDPs), regardless of the quality of the behavior\npolicy. To our knowledge, this work establishes the tightest theoretical\nguarantees currently available for hybrid RL in linear MDPs.\n","authors":["Kevin Tan","Wei Fan","Yuting Wei"],"pdf_url":"https://arxiv.org/pdf/2408.04526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08648v3","updated":"2024-08-08T13:09:51Z","published":"2022-12-16T18:48:54Z","title":"Connecting Permutation Equivariant Neural Networks and Partition\n  Diagrams","summary":"  Permutation equivariant neural networks are often constructed using tensor\npowers of $\\mathbb{R}^{n}$ as their layer spaces. We show that all of the\nweight matrices that appear in these neural networks can be obtained from\nSchur-Weyl duality between the symmetric group and the partition algebra. In\nparticular, we adapt Schur-Weyl duality to derive a simple, diagrammatic method\nfor calculating the weight matrices themselves.\n","authors":["Edward Pearce-Crump"],"pdf_url":"https://arxiv.org/pdf/2212.08648v3.pdf","comment":"ECAI 2024; 16 pages"},{"id":"http://arxiv.org/abs/2310.20609v2","updated":"2024-08-08T12:51:23Z","published":"2023-10-31T16:44:26Z","title":"Graph Matching via convex relaxation to the simplex","summary":"  This paper addresses the Graph Matching problem, which consists of finding\nthe best possible alignment between two input graphs, and has many applications\nin computer vision, network deanonymization and protein alignment. A common\napproach to tackle this problem is through convex relaxations of the NP-hard\n\\emph{Quadratic Assignment Problem} (QAP).\n  Here, we introduce a new convex relaxation onto the unit simplex and develop\nan efficient mirror descent scheme with closed-form iterations for solving this\nproblem. Under the correlated Gaussian Wigner model, we show that the simplex\nrelaxation admits a unique solution with high probability. In the noiseless\ncase, this is shown to imply exact recovery of the ground truth permutation.\nAdditionally, we establish a novel sufficiency condition for the input matrix\nin standard greedy rounding methods, which is less restrictive than the\ncommonly used `diagonal dominance' condition. We use this condition to show\nexact one-step recovery of the ground truth (holding almost surely) via the\nmirror descent scheme, in the noiseless setting. We also use this condition to\nobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.\n2019] in the noiseless setting.\n","authors":["Ernesto Araya Valdivia","Hemant Tyagi"],"pdf_url":"https://arxiv.org/pdf/2310.20609v2.pdf","comment":"We fixed some typos and added Lemma 4. Reference to the published\n  version below"},{"id":"http://arxiv.org/abs/2406.01661v2","updated":"2024-08-08T12:17:56Z","published":"2024-06-03T17:55:02Z","title":"A Diffusion Model Framework for Unsupervised Neural Combinatorial\n  Optimization","summary":"  Learning to sample from intractable distributions over discrete sets without\nrelying on corresponding training data is a central problem in a wide range of\nfields, including Combinatorial Optimization. Currently, popular deep\nlearning-based approaches rely primarily on generative models that yield exact\nsample likelihoods. This work introduces a method that lifts this restriction\nand opens the possibility to employ highly expressive latent variable models\nlike diffusion models. Our approach is conceptually based on a loss that upper\nbounds the reverse Kullback-Leibler divergence and evades the requirement of\nexact sample likelihoods. We experimentally validate our approach in data-free\nCombinatorial Optimization and demonstrate that our method achieves a new\nstate-of-the-art on a wide range of benchmark problems.\n","authors":["Sebastian Sanokowski","Sepp Hochreiter","Sebastian Lehner"],"pdf_url":"https://arxiv.org/pdf/2406.01661v2.pdf","comment":"Accepted at ICML 2024"},{"id":"http://arxiv.org/abs/2408.04391v1","updated":"2024-08-08T11:51:34Z","published":"2024-08-08T11:51:34Z","title":"Robustness investigation of quality measures for the assessment of\n  machine learning models","summary":"  In this paper the accuracy and robustness of quality measures for the\nassessment of machine learning models are investigated. The prediction quality\nof a machine learning model is evaluated model-independent based on a\ncross-validation approach, where the approximation error is estimated for\nunknown data. The presented measures quantify the amount of explained variation\nin the model prediction. The reliability of these measures is assessed by means\nof several numerical examples, where an additional data set for the\nverification of the estimated prediction error is available. Furthermore, the\nconfidence bounds of the presented quality measures are estimated and local\nquality measures are derived from the prediction residuals obtained by the\ncross-validation approach.\n","authors":["Thomas Most","Lars Gräning","Sebastian Wolff"],"pdf_url":"https://arxiv.org/pdf/2408.04391v1.pdf","comment":"under review, submitted to the journal Engineering Modelling,\n  Analysis & Simulation (EMAS)"},{"id":"http://arxiv.org/abs/2203.10571v4","updated":"2024-08-08T08:54:59Z","published":"2022-03-20T14:48:37Z","title":"Distributionally robust risk evaluation with a causality constraint and\n  structural information","summary":"  This work studies the distributionally robust evaluation of expected values\nover temporal data. A set of alternative measures is characterized by the\ncausal optimal transport. We prove the strong duality and recast the causality\nconstraint as minimization over an infinite-dimensional test function space. We\napproximate test functions by neural networks and prove the sample complexity\nwith Rademacher complexity. An example is given to validate the feasibility of\ntechnical assumptions. Moreover, when structural information is available to\nfurther restrict the ambiguity set, we prove the dual formulation and provide\nefficient optimization methods. Our framework outperforms the classic\ncounterparts in the distributionally robust portfolio selection problem. The\nconnection with the naive strategy is also investigated numerically.\n","authors":["Bingyan Han"],"pdf_url":"https://arxiv.org/pdf/2203.10571v4.pdf","comment":"Major revision. Add a new Section on regularized NNs"},{"id":"http://arxiv.org/abs/2408.04313v1","updated":"2024-08-08T08:47:20Z","published":"2024-08-08T08:47:20Z","title":"Better Locally Private Sparse Estimation Given Multiple Samples Per User","summary":"  Previous studies yielded discouraging results for item-level locally\ndifferentially private linear regression with $s^*$-sparsity assumption, where\nthe minimax rate for $nm$ samples is $\\mathcal{O}(s^{*}d / nm\\varepsilon^2)$.\nThis can be challenging for high-dimensional data, where the dimension $d$ is\nextremely large. In this work, we investigate user-level locally differentially\nprivate sparse linear regression. We show that with $n$ users each contributing\n$m$ samples, the linear dependency of dimension $d$ can be eliminated, yielding\nan error upper bound of $\\mathcal{O}(s^{*2} / nm\\varepsilon^2)$. We propose a\nframework that first selects candidate variables and then conducts estimation\nin the narrowed low-dimensional space, which is extendable to general sparse\nestimation problems with tight error bounds. Experiments on both synthetic and\nreal datasets demonstrate the superiority of the proposed methods. Both the\ntheoretical and empirical results suggest that, with the same number of\nsamples, locally private sparse estimation is better conducted when multiple\nsamples per user are available.\n","authors":["Yuheng Ma","Ke Jia","Hanfang Yang"],"pdf_url":"https://arxiv.org/pdf/2408.04313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11427v2","updated":"2024-08-08T07:23:01Z","published":"2024-07-16T06:45:27Z","title":"Semi-Supervised Generative Models for Disease Trajectories: A Case Study\n  on Systemic Sclerosis","summary":"  We propose a deep generative approach using latent temporal processes for\nmodeling and holistically analyzing complex disease trajectories, with a\nparticular focus on Systemic Sclerosis (SSc). We aim to learn temporal latent\nrepresentations of the underlying generative process that explain the observed\npatient disease trajectories in an interpretable and comprehensive way. To\nenhance the interpretability of these latent temporal processes, we develop a\nsemi-supervised approach for disentangling the latent space using established\nmedical knowledge. By combining the generative approach with medical\ndefinitions of different characteristics of SSc, we facilitate the discovery of\nnew aspects of the disease. We show that the learned temporal latent processes\ncan be utilized for further data analysis and clinical hypothesis testing,\nincluding finding similar patients and clustering SSc patient trajectories into\nnovel sub-types. Moreover, our method enables personalized online monitoring\nand prediction of multivariate time series with uncertainty quantification.\n","authors":["Cécile Trottet","Manuel Schürch","Ahmed Allam","Imon Barua","Liubov Petelytska","David Launay","Paolo Airò","Radim Bečvář","Christopher Denton","Mislav Radic","Oliver Distler","Anna-Maria Hoffmann-Vold","Michael Krauthammer","the EUSTAR collaborators"],"pdf_url":"https://arxiv.org/pdf/2407.11427v2.pdf","comment":"Accepted at Machine Learning for Healthcare 2024. arXiv admin note:\n  substantial text overlap with arXiv:2311.08149"},{"id":"http://arxiv.org/abs/2408.04179v1","updated":"2024-08-08T02:53:09Z","published":"2024-08-08T02:53:09Z","title":"An Upper Confidence Bound Approach to Estimating the Maximum Mean","summary":"  Estimating the maximum mean finds a variety of applications in practice. In\nthis paper, we study estimation of the maximum mean using an upper confidence\nbound (UCB) approach where the sampling budget is adaptively allocated to one\nof the systems. We study in depth the existing grand average (GA) estimator,\nand propose a new largest-size average (LSA) estimator. Specifically, we\nestablish statistical guarantees, including strong consistency, asymptotic mean\nsquared errors, and central limit theorems (CLTs) for both estimators, which\nare new to the literature. We show that LSA is preferable over GA, as the bias\nof the former decays at a rate much faster than that of the latter when sample\nsize increases. By using the CLTs, we further construct asymptotically valid\nconfidence intervals for the maximum mean, and propose a single hypothesis test\nfor a multiple comparison problem with application to clinical trials.\nStatistical efficiency of the resulting point and interval estimates and the\nproposed single hypothesis test is demonstrated via numerical examples.\n","authors":["Zhang Kun","Liu Guangwu","Shi Wen"],"pdf_url":"https://arxiv.org/pdf/2408.04179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12808v2","updated":"2024-08-08T02:44:47Z","published":"2024-02-20T08:27:50Z","title":"Learning Generalization and Regularization of Nonhomogeneous Temporal\n  Poisson Processes","summary":"  The Poisson process, especially the nonhomogeneous Poisson process (NHPP), is\nan essentially important counting process with numerous real-world\napplications. Up to date, almost all works in the literature have been on the\nestimation of NHPPs with infinite data using non-data driven binning methods.\nIn this paper, we formulate the problem of estimation of NHPPs from finite and\nlimited data as a learning generalization problem. We mathematically show that\nwhile binning methods are essential for the estimation of NHPPs, they pose a\nthreat of overfitting when the amount of data is limited. We propose a\nframework for regularized learning of NHPPs with two new adaptive and\ndata-driven binning methods that help to remove the ad-hoc tuning of binning\nparameters. Our methods are experimentally tested on synthetic and real-world\ndatasets and the results show their effectiveness.\n","authors":["Son Nguyen Van","Hoai Nguyen Xuan"],"pdf_url":"https://arxiv.org/pdf/2402.12808v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2309.00736v4","updated":"2024-08-08T01:49:10Z","published":"2023-09-01T21:16:02Z","title":"Prediction Error Estimation in Random Forests","summary":"  In this paper, error estimates of classification Random Forests are\nquantitatively assessed. Based on the initial theoretical framework built by\nBates et al. (2023), the true error rate and expected error rate are\ntheoretically and empirically investigated in the context of a variety of error\nestimation methods common to Random Forests. We show that in the classification\ncase, Random Forests' estimates of prediction error is closer on average to the\ntrue error rate instead of the average prediction error. This is opposite the\nfindings of Bates et al. (2023) which are given for logistic regression. We\nfurther show that our result holds across different error estimation strategies\nsuch as cross-validation, bagging, and data splitting.\n","authors":["Ian Krupkin","Johanna Hardin"],"pdf_url":"https://arxiv.org/pdf/2309.00736v4.pdf","comment":"As we were working on revisions, we found a fatal flaw in the\n  procedure. All of the results are problematic / wrong"},{"id":"http://arxiv.org/abs/2408.04154v1","updated":"2024-08-08T01:42:31Z","published":"2024-08-08T01:42:31Z","title":"The Data Addition Dilemma","summary":"  In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.\n","authors":["Judy Hanwen Shen","Inioluwa Deborah Raji","Irene Y. Chen"],"pdf_url":"https://arxiv.org/pdf/2408.04154v1.pdf","comment":"Machine Learning For Health Care 2024 (MLHC)"},{"id":"http://arxiv.org/abs/2408.04149v1","updated":"2024-08-08T01:23:00Z","published":"2024-08-08T01:23:00Z","title":"A tutorial on the dynamic Laplacian","summary":"  Spectral techniques are popular and robust approaches to data analysis. A\nprominent example is the use of eigenvectors of a Laplacian, constructed from\ndata affinities, to identify natural data groupings or clusters, or to produce\na simplified representation of data lying on a manifold. This tutorial concerns\nthe dynamic Laplacian, which is a natural generalisation of the Laplacian to\nhandle data that has a time component and lies on a time-evolving manifold. In\nthis dynamic setting, clusters correspond to long-lived ``coherent''\ncollections. We begin with a gentle recap of spectral geometry before\ndescribing the dynamic generalisations. We also discuss computational methods\nand the automatic separation of many distinct features through the SEBA\nalgorithm. The purpose of this tutorial is to bring together many results from\nthe dynamic Laplacian literature into a single short document, written in an\naccessible style.\n","authors":["Gary Froyland"],"pdf_url":"https://arxiv.org/pdf/2408.04149v1.pdf","comment":null}]}}